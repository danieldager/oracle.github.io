/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@mongodb-js/saslprep/dist/code-points-data.js":
/*!********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/code-points-data.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst zlib_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'zlib'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nexports[\"default\"] = (0, zlib_1.gunzipSync)(Buffer.from('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', 'base64'));\n//# sourceMappingURL=code-points-data.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/@mongodb-js/saslprep/dist/code-points-data.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/index.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst memory_code_points_1 = __webpack_require__(/*! ./memory-code-points */ \"./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js\");\nconst mapping2space = memory_code_points_1.non_ASCII_space_characters;\nconst mapping2nothing = memory_code_points_1.commonly_mapped_to_nothing;\nconst getCodePoint = (character) => character.codePointAt(0);\nconst first = (x) => x[0];\nconst last = (x) => x[x.length - 1];\nfunction toCodePoints(input) {\n    const codepoints = [];\n    const size = input.length;\n    for (let i = 0; i < size; i += 1) {\n        const before = input.charCodeAt(i);\n        if (before >= 0xd800 && before <= 0xdbff && size > i + 1) {\n            const next = input.charCodeAt(i + 1);\n            if (next >= 0xdc00 && next <= 0xdfff) {\n                codepoints.push((before - 0xd800) * 0x400 + next - 0xdc00 + 0x10000);\n                i += 1;\n                continue;\n            }\n        }\n        codepoints.push(before);\n    }\n    return codepoints;\n}\nfunction saslprep(input, opts = {}) {\n    if (typeof input !== 'string') {\n        throw new TypeError('Expected string.');\n    }\n    if (input.length === 0) {\n        return '';\n    }\n    const mapped_input = toCodePoints(input)\n        .map((character) => (mapping2space.get(character) ? 0x20 : character))\n        .filter((character) => !mapping2nothing.get(character));\n    const normalized_input = String.fromCodePoint\n        .apply(null, mapped_input)\n        .normalize('NFKC');\n    const normalized_map = toCodePoints(normalized_input);\n    const hasProhibited = normalized_map.some((character) => memory_code_points_1.prohibited_characters.get(character));\n    if (hasProhibited) {\n        throw new Error('Prohibited character, see https://tools.ietf.org/html/rfc4013#section-2.3');\n    }\n    if (opts.allowUnassigned !== true) {\n        const hasUnassigned = normalized_map.some((character) => memory_code_points_1.unassigned_code_points.get(character));\n        if (hasUnassigned) {\n            throw new Error('Unassigned code point, see https://tools.ietf.org/html/rfc4013#section-2.5');\n        }\n    }\n    const hasBidiRAL = normalized_map.some((character) => memory_code_points_1.bidirectional_r_al.get(character));\n    const hasBidiL = normalized_map.some((character) => memory_code_points_1.bidirectional_l.get(character));\n    if (hasBidiRAL && hasBidiL) {\n        throw new Error('String must not contain RandALCat and LCat at the same time,' +\n            ' see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    const isFirstBidiRAL = memory_code_points_1.bidirectional_r_al.get(getCodePoint(first(normalized_input)));\n    const isLastBidiRAL = memory_code_points_1.bidirectional_r_al.get(getCodePoint(last(normalized_input)));\n    if (hasBidiRAL && !(isFirstBidiRAL && isLastBidiRAL)) {\n        throw new Error('Bidirectional RandALCat character must be the first and the last' +\n            ' character of the string, see https://tools.ietf.org/html/rfc3454#section-6');\n    }\n    return normalized_input;\n}\nsaslprep.saslprep = saslprep;\nsaslprep.default = saslprep;\nmodule.exports = saslprep;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/@mongodb-js/saslprep/dist/index.js?");

/***/ }),

/***/ "./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.bidirectional_l = exports.bidirectional_r_al = exports.prohibited_characters = exports.non_ASCII_space_characters = exports.commonly_mapped_to_nothing = exports.unassigned_code_points = void 0;\nconst sparse_bitfield_1 = __importDefault(__webpack_require__(/*! sparse-bitfield */ \"./node_modules/sparse-bitfield/index.js\"));\nconst code_points_data_1 = __importDefault(__webpack_require__(/*! ./code-points-data */ \"./node_modules/@mongodb-js/saslprep/dist/code-points-data.js\"));\nlet offset = 0;\nfunction read() {\n    const size = code_points_data_1.default.readUInt32BE(offset);\n    offset += 4;\n    const codepoints = code_points_data_1.default.slice(offset, offset + size);\n    offset += size;\n    return (0, sparse_bitfield_1.default)({ buffer: codepoints });\n}\nexports.unassigned_code_points = read();\nexports.commonly_mapped_to_nothing = read();\nexports.non_ASCII_space_characters = read();\nexports.prohibited_characters = read();\nexports.bidirectional_r_al = read();\nexports.bidirectional_l = read();\n//# sourceMappingURL=memory-code-points.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/@mongodb-js/saslprep/dist/memory-code-points.js?");

/***/ }),

/***/ "./node_modules/dotenv/lib/main.js":
/*!*****************************************!*\
  !*** ./node_modules/dotenv/lib/main.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const fs = __webpack_require__(/*! fs */ \"?a0c3\")\nconst path = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'path'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst packageJson = __webpack_require__(/*! ../package.json */ \"./node_modules/dotenv/package.json\")\n\nconst version = packageJson.version\n\nconst LINE = /(?:^|^)\\s*(?:export\\s+)?([\\w.-]+)(?:\\s*=\\s*?|:\\s+?)(\\s*'(?:\\\\'|[^'])*'|\\s*\"(?:\\\\\"|[^\"])*\"|\\s*`(?:\\\\`|[^`])*`|[^#\\r\\n]+)?\\s*(?:#.*)?(?:$|$)/mg\n\n// Parse src into an Object\nfunction parse (src) {\n  const obj = {}\n\n  // Convert buffer to string\n  let lines = src.toString()\n\n  // Convert line breaks to same format\n  lines = lines.replace(/\\r\\n?/mg, '\\n')\n\n  let match\n  while ((match = LINE.exec(lines)) != null) {\n    const key = match[1]\n\n    // Default undefined or null to empty string\n    let value = (match[2] || '')\n\n    // Remove whitespace\n    value = value.trim()\n\n    // Check if double quoted\n    const maybeQuote = value[0]\n\n    // Remove surrounding quotes\n    value = value.replace(/^(['\"`])([\\s\\S]*)\\1$/mg, '$2')\n\n    // Expand newlines if double quoted\n    if (maybeQuote === '\"') {\n      value = value.replace(/\\\\n/g, '\\n')\n      value = value.replace(/\\\\r/g, '\\r')\n    }\n\n    // Add to object\n    obj[key] = value\n  }\n\n  return obj\n}\n\nfunction _parseVault (options) {\n  const vaultPath = _vaultPath(options)\n\n  // Parse .env.vault\n  const result = DotenvModule.configDotenv({ path: vaultPath })\n  if (!result.parsed) {\n    throw new Error(`MISSING_DATA: Cannot parse ${vaultPath} for an unknown reason`)\n  }\n\n  // handle scenario for comma separated keys - for use with key rotation\n  // example: DOTENV_KEY=\"dotenv://:key_1234@dotenv.org/vault/.env.vault?environment=prod,dotenv://:key_7890@dotenv.org/vault/.env.vault?environment=prod\"\n  const keys = _dotenvKey(options).split(',')\n  const length = keys.length\n\n  let decrypted\n  for (let i = 0; i < length; i++) {\n    try {\n      // Get full key\n      const key = keys[i].trim()\n\n      // Get instructions for decrypt\n      const attrs = _instructions(result, key)\n\n      // Decrypt\n      decrypted = DotenvModule.decrypt(attrs.ciphertext, attrs.key)\n\n      break\n    } catch (error) {\n      // last key\n      if (i + 1 >= length) {\n        throw error\n      }\n      // try next key\n    }\n  }\n\n  // Parse decrypted .env string\n  return DotenvModule.parse(decrypted)\n}\n\nfunction _log (message) {\n  console.log(`[dotenv@${version}][INFO] ${message}`)\n}\n\nfunction _warn (message) {\n  console.log(`[dotenv@${version}][WARN] ${message}`)\n}\n\nfunction _debug (message) {\n  console.log(`[dotenv@${version}][DEBUG] ${message}`)\n}\n\nfunction _dotenvKey (options) {\n  // prioritize developer directly setting options.DOTENV_KEY\n  if (options && options.DOTENV_KEY && options.DOTENV_KEY.length > 0) {\n    return options.DOTENV_KEY\n  }\n\n  // secondary infra already contains a DOTENV_KEY environment variable\n  if (process.env.DOTENV_KEY && process.env.DOTENV_KEY.length > 0) {\n    return process.env.DOTENV_KEY\n  }\n\n  // fallback to empty string\n  return ''\n}\n\nfunction _instructions (result, dotenvKey) {\n  // Parse DOTENV_KEY. Format is a URI\n  let uri\n  try {\n    uri = new URL(dotenvKey)\n  } catch (error) {\n    if (error.code === 'ERR_INVALID_URL') {\n      throw new Error('INVALID_DOTENV_KEY: Wrong format. Must be in valid uri format like dotenv://:key_1234@dotenv.org/vault/.env.vault?environment=development')\n    }\n\n    throw error\n  }\n\n  // Get decrypt key\n  const key = uri.password\n  if (!key) {\n    throw new Error('INVALID_DOTENV_KEY: Missing key part')\n  }\n\n  // Get environment\n  const environment = uri.searchParams.get('environment')\n  if (!environment) {\n    throw new Error('INVALID_DOTENV_KEY: Missing environment part')\n  }\n\n  // Get ciphertext payload\n  const environmentKey = `DOTENV_VAULT_${environment.toUpperCase()}`\n  const ciphertext = result.parsed[environmentKey] // DOTENV_VAULT_PRODUCTION\n  if (!ciphertext) {\n    throw new Error(`NOT_FOUND_DOTENV_ENVIRONMENT: Cannot locate environment ${environmentKey} in your .env.vault file.`)\n  }\n\n  return { ciphertext, key }\n}\n\nfunction _vaultPath (options) {\n  let dotenvPath = path.resolve(process.cwd(), '.env')\n\n  if (options && options.path && options.path.length > 0) {\n    dotenvPath = options.path\n  }\n\n  // Locate .env.vault\n  return dotenvPath.endsWith('.vault') ? dotenvPath : `${dotenvPath}.vault`\n}\n\nfunction _resolveHome (envPath) {\n  return envPath[0] === '~' ? path.join(os.homedir(), envPath.slice(1)) : envPath\n}\n\nfunction _configVault (options) {\n  _log('Loading env from encrypted .env.vault')\n\n  const parsed = DotenvModule._parseVault(options)\n\n  let processEnv = process.env\n  if (options && options.processEnv != null) {\n    processEnv = options.processEnv\n  }\n\n  DotenvModule.populate(processEnv, parsed, options)\n\n  return { parsed }\n}\n\nfunction configDotenv (options) {\n  let dotenvPath = path.resolve(process.cwd(), '.env')\n  let encoding = 'utf8'\n  const debug = Boolean(options && options.debug)\n\n  if (options) {\n    if (options.path != null) {\n      dotenvPath = _resolveHome(options.path)\n    }\n    if (options.encoding != null) {\n      encoding = options.encoding\n    }\n  }\n\n  try {\n    // Specifying an encoding returns a string instead of a buffer\n    const parsed = DotenvModule.parse(fs.readFileSync(dotenvPath, { encoding }))\n\n    let processEnv = process.env\n    if (options && options.processEnv != null) {\n      processEnv = options.processEnv\n    }\n\n    DotenvModule.populate(processEnv, parsed, options)\n\n    return { parsed }\n  } catch (e) {\n    if (debug) {\n      _debug(`Failed to load ${dotenvPath} ${e.message}`)\n    }\n\n    return { error: e }\n  }\n}\n\n// Populates process.env from .env file\nfunction config (options) {\n  const vaultPath = _vaultPath(options)\n\n  // fallback to original dotenv if DOTENV_KEY is not set\n  if (_dotenvKey(options).length === 0) {\n    return DotenvModule.configDotenv(options)\n  }\n\n  // dotenvKey exists but .env.vault file does not exist\n  if (!fs.existsSync(vaultPath)) {\n    _warn(`You set DOTENV_KEY but you are missing a .env.vault file at ${vaultPath}. Did you forget to build it?`)\n\n    return DotenvModule.configDotenv(options)\n  }\n\n  return DotenvModule._configVault(options)\n}\n\nfunction decrypt (encrypted, keyStr) {\n  const key = Buffer.from(keyStr.slice(-64), 'hex')\n  let ciphertext = Buffer.from(encrypted, 'base64')\n\n  const nonce = ciphertext.slice(0, 12)\n  const authTag = ciphertext.slice(-16)\n  ciphertext = ciphertext.slice(12, -16)\n\n  try {\n    const aesgcm = crypto.createDecipheriv('aes-256-gcm', key, nonce)\n    aesgcm.setAuthTag(authTag)\n    return `${aesgcm.update(ciphertext)}${aesgcm.final()}`\n  } catch (error) {\n    const isRange = error instanceof RangeError\n    const invalidKeyLength = error.message === 'Invalid key length'\n    const decryptionFailed = error.message === 'Unsupported state or unable to authenticate data'\n\n    if (isRange || invalidKeyLength) {\n      const msg = 'INVALID_DOTENV_KEY: It must be 64 characters long (or more)'\n      throw new Error(msg)\n    } else if (decryptionFailed) {\n      const msg = 'DECRYPTION_FAILED: Please check your DOTENV_KEY'\n      throw new Error(msg)\n    } else {\n      console.error('Error: ', error.code)\n      console.error('Error: ', error.message)\n      throw error\n    }\n  }\n}\n\n// Populate process.env with parsed values\nfunction populate (processEnv, parsed, options = {}) {\n  const debug = Boolean(options && options.debug)\n  const override = Boolean(options && options.override)\n\n  if (typeof parsed !== 'object') {\n    throw new Error('OBJECT_REQUIRED: Please check the processEnv argument being passed to populate')\n  }\n\n  // Set process.env\n  for (const key of Object.keys(parsed)) {\n    if (Object.prototype.hasOwnProperty.call(processEnv, key)) {\n      if (override === true) {\n        processEnv[key] = parsed[key]\n      }\n\n      if (debug) {\n        if (override === true) {\n          _debug(`\"${key}\" is already defined and WAS overwritten`)\n        } else {\n          _debug(`\"${key}\" is already defined and was NOT overwritten`)\n        }\n      }\n    } else {\n      processEnv[key] = parsed[key]\n    }\n  }\n}\n\nconst DotenvModule = {\n  configDotenv,\n  _configVault,\n  _parseVault,\n  config,\n  decrypt,\n  parse,\n  populate\n}\n\nmodule.exports.configDotenv = DotenvModule.configDotenv\nmodule.exports._configVault = DotenvModule._configVault\nmodule.exports._parseVault = DotenvModule._parseVault\nmodule.exports.config = DotenvModule.config\nmodule.exports.decrypt = DotenvModule.decrypt\nmodule.exports.parse = DotenvModule.parse\nmodule.exports.populate = DotenvModule.populate\n\nmodule.exports = DotenvModule\n\n\n//# sourceURL=webpack://oracle2/./node_modules/dotenv/lib/main.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://oracle2/./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/memory-pager/index.js":
/*!********************************************!*\
  !*** ./node_modules/memory-pager/index.js ***!
  \********************************************/
/***/ ((module) => {

eval("module.exports = Pager\n\nfunction Pager (pageSize, opts) {\n  if (!(this instanceof Pager)) return new Pager(pageSize, opts)\n\n  this.length = 0\n  this.updates = []\n  this.path = new Uint16Array(4)\n  this.pages = new Array(32768)\n  this.maxPages = this.pages.length\n  this.level = 0\n  this.pageSize = pageSize || 1024\n  this.deduplicate = opts ? opts.deduplicate : null\n  this.zeros = this.deduplicate ? alloc(this.deduplicate.length) : null\n}\n\nPager.prototype.updated = function (page) {\n  while (this.deduplicate && page.buffer[page.deduplicate] === this.deduplicate[page.deduplicate]) {\n    page.deduplicate++\n    if (page.deduplicate === this.deduplicate.length) {\n      page.deduplicate = 0\n      if (page.buffer.equals && page.buffer.equals(this.deduplicate)) page.buffer = this.deduplicate\n      break\n    }\n  }\n  if (page.updated || !this.updates) return\n  page.updated = true\n  this.updates.push(page)\n}\n\nPager.prototype.lastUpdate = function () {\n  if (!this.updates || !this.updates.length) return null\n  var page = this.updates.pop()\n  page.updated = false\n  return page\n}\n\nPager.prototype._array = function (i, noAllocate) {\n  if (i >= this.maxPages) {\n    if (noAllocate) return\n    grow(this, i)\n  }\n\n  factor(i, this.path)\n\n  var arr = this.pages\n\n  for (var j = this.level; j > 0; j--) {\n    var p = this.path[j]\n    var next = arr[p]\n\n    if (!next) {\n      if (noAllocate) return\n      next = arr[p] = new Array(32768)\n    }\n\n    arr = next\n  }\n\n  return arr\n}\n\nPager.prototype.get = function (i, noAllocate) {\n  var arr = this._array(i, noAllocate)\n  var first = this.path[0]\n  var page = arr && arr[first]\n\n  if (!page && !noAllocate) {\n    page = arr[first] = new Page(i, alloc(this.pageSize))\n    if (i >= this.length) this.length = i + 1\n  }\n\n  if (page && page.buffer === this.deduplicate && this.deduplicate && !noAllocate) {\n    page.buffer = copy(page.buffer)\n    page.deduplicate = 0\n  }\n\n  return page\n}\n\nPager.prototype.set = function (i, buf) {\n  var arr = this._array(i, false)\n  var first = this.path[0]\n\n  if (i >= this.length) this.length = i + 1\n\n  if (!buf || (this.zeros && buf.equals && buf.equals(this.zeros))) {\n    arr[first] = undefined\n    return\n  }\n\n  if (this.deduplicate && buf.equals && buf.equals(this.deduplicate)) {\n    buf = this.deduplicate\n  }\n\n  var page = arr[first]\n  var b = truncate(buf, this.pageSize)\n\n  if (page) page.buffer = b\n  else arr[first] = new Page(i, b)\n}\n\nPager.prototype.toBuffer = function () {\n  var list = new Array(this.length)\n  var empty = alloc(this.pageSize)\n  var ptr = 0\n\n  while (ptr < list.length) {\n    var arr = this._array(ptr, true)\n    for (var i = 0; i < 32768 && ptr < list.length; i++) {\n      list[ptr++] = (arr && arr[i]) ? arr[i].buffer : empty\n    }\n  }\n\n  return Buffer.concat(list)\n}\n\nfunction grow (pager, index) {\n  while (pager.maxPages < index) {\n    var old = pager.pages\n    pager.pages = new Array(32768)\n    pager.pages[0] = old\n    pager.level++\n    pager.maxPages *= 32768\n  }\n}\n\nfunction truncate (buf, len) {\n  if (buf.length === len) return buf\n  if (buf.length > len) return buf.slice(0, len)\n  var cpy = alloc(len)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction alloc (size) {\n  if (Buffer.alloc) return Buffer.alloc(size)\n  var buf = new Buffer(size)\n  buf.fill(0)\n  return buf\n}\n\nfunction copy (buf) {\n  var cpy = Buffer.allocUnsafe ? Buffer.allocUnsafe(buf.length) : new Buffer(buf.length)\n  buf.copy(cpy)\n  return cpy\n}\n\nfunction Page (i, buf) {\n  this.offset = i * buf.length\n  this.buffer = buf\n  this.updated = false\n  this.deduplicate = 0\n}\n\nfunction factor (n, out) {\n  n = (n - (out[0] = (n & 32767))) / 32768\n  n = (n - (out[1] = (n & 32767))) / 32768\n  out[3] = ((n - (out[2] = (n & 32767))) / 32768) & 32767\n}\n\n\n//# sourceURL=webpack://oracle2/./node_modules/memory-pager/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommaAndColonSeparatedRecord = exports.ConnectionString = exports.redactConnectionString = void 0;\nconst whatwg_url_1 = __webpack_require__(/*! whatwg-url */ \"./node_modules/whatwg-url/index.js\");\nconst redact_1 = __webpack_require__(/*! ./redact */ \"./node_modules/mongodb-connection-string-url/lib/redact.js\");\nObject.defineProperty(exports, \"redactConnectionString\", ({ enumerable: true, get: function () { return redact_1.redactConnectionString; } }));\nconst DUMMY_HOSTNAME = '__this_is_a_placeholder__';\nfunction connectionStringHasValidScheme(connectionString) {\n    return (connectionString.startsWith('mongodb://') ||\n        connectionString.startsWith('mongodb+srv://'));\n}\nconst HOSTS_REGEX = /^(?<protocol>[^/]+):\\/\\/(?:(?<username>[^:@]*)(?::(?<password>[^@]*))?@)?(?<hosts>(?!:)[^/?@]*)(?<rest>.*)/;\nclass CaseInsensitiveMap extends Map {\n    delete(name) {\n        return super.delete(this._normalizeKey(name));\n    }\n    get(name) {\n        return super.get(this._normalizeKey(name));\n    }\n    has(name) {\n        return super.has(this._normalizeKey(name));\n    }\n    set(name, value) {\n        return super.set(this._normalizeKey(name), value);\n    }\n    _normalizeKey(name) {\n        name = `${name}`;\n        for (const key of this.keys()) {\n            if (key.toLowerCase() === name.toLowerCase()) {\n                name = key;\n                break;\n            }\n        }\n        return name;\n    }\n}\nfunction caseInsenstiveURLSearchParams(Ctor) {\n    return class CaseInsenstiveURLSearchParams extends Ctor {\n        append(name, value) {\n            return super.append(this._normalizeKey(name), value);\n        }\n        delete(name) {\n            return super.delete(this._normalizeKey(name));\n        }\n        get(name) {\n            return super.get(this._normalizeKey(name));\n        }\n        getAll(name) {\n            return super.getAll(this._normalizeKey(name));\n        }\n        has(name) {\n            return super.has(this._normalizeKey(name));\n        }\n        set(name, value) {\n            return super.set(this._normalizeKey(name), value);\n        }\n        keys() {\n            return super.keys();\n        }\n        values() {\n            return super.values();\n        }\n        entries() {\n            return super.entries();\n        }\n        [Symbol.iterator]() {\n            return super[Symbol.iterator]();\n        }\n        _normalizeKey(name) {\n            return CaseInsensitiveMap.prototype._normalizeKey.call(this, name);\n        }\n    };\n}\nclass URLWithoutHost extends whatwg_url_1.URL {\n}\nclass MongoParseError extends Error {\n    get name() {\n        return 'MongoParseError';\n    }\n}\nclass ConnectionString extends URLWithoutHost {\n    constructor(uri, options = {}) {\n        var _a;\n        const { looseValidation } = options;\n        if (!looseValidation && !connectionStringHasValidScheme(uri)) {\n            throw new MongoParseError('Invalid scheme, expected connection string to start with \"mongodb://\" or \"mongodb+srv://\"');\n        }\n        const match = uri.match(HOSTS_REGEX);\n        if (!match) {\n            throw new MongoParseError(`Invalid connection string \"${uri}\"`);\n        }\n        const { protocol, username, password, hosts, rest } = (_a = match.groups) !== null && _a !== void 0 ? _a : {};\n        if (!looseValidation) {\n            if (!protocol || !hosts) {\n                throw new MongoParseError(`Protocol and host list are required in \"${uri}\"`);\n            }\n            try {\n                decodeURIComponent(username !== null && username !== void 0 ? username : '');\n                decodeURIComponent(password !== null && password !== void 0 ? password : '');\n            }\n            catch (err) {\n                throw new MongoParseError(err.message);\n            }\n            const illegalCharacters = /[:/?#[\\]@]/gi;\n            if (username === null || username === void 0 ? void 0 : username.match(illegalCharacters)) {\n                throw new MongoParseError(`Username contains unescaped characters ${username}`);\n            }\n            if (!username || !password) {\n                const uriWithoutProtocol = uri.replace(`${protocol}://`, '');\n                if (uriWithoutProtocol.startsWith('@') || uriWithoutProtocol.startsWith(':')) {\n                    throw new MongoParseError('URI contained empty userinfo section');\n                }\n            }\n            if (password === null || password === void 0 ? void 0 : password.match(illegalCharacters)) {\n                throw new MongoParseError('Password contains unescaped characters');\n            }\n        }\n        let authString = '';\n        if (typeof username === 'string')\n            authString += username;\n        if (typeof password === 'string')\n            authString += `:${password}`;\n        if (authString)\n            authString += '@';\n        try {\n            super(`${protocol.toLowerCase()}://${authString}${DUMMY_HOSTNAME}${rest}`);\n        }\n        catch (err) {\n            if (looseValidation) {\n                new ConnectionString(uri, {\n                    ...options,\n                    looseValidation: false\n                });\n            }\n            if (typeof err.message === 'string') {\n                err.message = err.message.replace(DUMMY_HOSTNAME, hosts);\n            }\n            throw err;\n        }\n        this._hosts = hosts.split(',');\n        if (!looseValidation) {\n            if (this.isSRV && this.hosts.length !== 1) {\n                throw new MongoParseError('mongodb+srv URI cannot have multiple service names');\n            }\n            if (this.isSRV && this.hosts.some(host => host.includes(':'))) {\n                throw new MongoParseError('mongodb+srv URI cannot have port number');\n            }\n        }\n        if (!this.pathname) {\n            this.pathname = '/';\n        }\n        Object.setPrototypeOf(this.searchParams, caseInsenstiveURLSearchParams(this.searchParams.constructor).prototype);\n    }\n    get host() { return DUMMY_HOSTNAME; }\n    set host(_ignored) { throw new Error('No single host for connection string'); }\n    get hostname() { return DUMMY_HOSTNAME; }\n    set hostname(_ignored) { throw new Error('No single host for connection string'); }\n    get port() { return ''; }\n    set port(_ignored) { throw new Error('No single host for connection string'); }\n    get href() { return this.toString(); }\n    set href(_ignored) { throw new Error('Cannot set href for connection strings'); }\n    get isSRV() {\n        return this.protocol.includes('srv');\n    }\n    get hosts() {\n        return this._hosts;\n    }\n    set hosts(list) {\n        this._hosts = list;\n    }\n    toString() {\n        return super.toString().replace(DUMMY_HOSTNAME, this.hosts.join(','));\n    }\n    clone() {\n        return new ConnectionString(this.toString(), {\n            looseValidation: true\n        });\n    }\n    redact(options) {\n        return (0, redact_1.redactValidConnectionString)(this, options);\n    }\n    typedSearchParams() {\n        const sametype =  false && 0;\n        return this.searchParams;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        const { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash } = this;\n        return { href, origin, protocol, username, password, hosts, pathname, search, searchParams, hash };\n    }\n}\nexports.ConnectionString = ConnectionString;\nclass CommaAndColonSeparatedRecord extends CaseInsensitiveMap {\n    constructor(from) {\n        super();\n        for (const entry of (from !== null && from !== void 0 ? from : '').split(',')) {\n            if (!entry)\n                continue;\n            const colonIndex = entry.indexOf(':');\n            if (colonIndex === -1) {\n                this.set(entry, '');\n            }\n            else {\n                this.set(entry.slice(0, colonIndex), entry.slice(colonIndex + 1));\n            }\n        }\n    }\n    toString() {\n        return [...this].map(entry => entry.join(':')).join(',');\n    }\n}\nexports.CommaAndColonSeparatedRecord = CommaAndColonSeparatedRecord;\nexports[\"default\"] = ConnectionString;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb-connection-string-url/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb-connection-string-url/lib/redact.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb-connection-string-url/lib/redact.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.redactConnectionString = exports.redactValidConnectionString = void 0;\nconst index_1 = __importStar(__webpack_require__(/*! ./index */ \"./node_modules/mongodb-connection-string-url/lib/index.js\"));\nfunction redactValidConnectionString(inputUrl, options) {\n    var _a, _b;\n    const url = inputUrl.clone();\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '_credentials_';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    if ((url.username || url.password) && redactUsernames) {\n        url.username = replacementString;\n        url.password = '';\n    }\n    else if (url.password) {\n        url.password = replacementString;\n    }\n    if (url.searchParams.has('authMechanismProperties')) {\n        const props = new index_1.CommaAndColonSeparatedRecord(url.searchParams.get('authMechanismProperties'));\n        if (props.get('AWS_SESSION_TOKEN')) {\n            props.set('AWS_SESSION_TOKEN', replacementString);\n            url.searchParams.set('authMechanismProperties', props.toString());\n        }\n    }\n    if (url.searchParams.has('tlsCertificateKeyFilePassword')) {\n        url.searchParams.set('tlsCertificateKeyFilePassword', replacementString);\n    }\n    if (url.searchParams.has('proxyUsername') && redactUsernames) {\n        url.searchParams.set('proxyUsername', replacementString);\n    }\n    if (url.searchParams.has('proxyPassword')) {\n        url.searchParams.set('proxyPassword', replacementString);\n    }\n    return url;\n}\nexports.redactValidConnectionString = redactValidConnectionString;\nfunction redactConnectionString(uri, options) {\n    var _a, _b;\n    const replacementString = (_a = options === null || options === void 0 ? void 0 : options.replacementString) !== null && _a !== void 0 ? _a : '<credentials>';\n    const redactUsernames = (_b = options === null || options === void 0 ? void 0 : options.redactUsernames) !== null && _b !== void 0 ? _b : true;\n    let parsed;\n    try {\n        parsed = new index_1.default(uri);\n    }\n    catch (_c) { }\n    if (parsed) {\n        options = { ...options, replacementString: '___credentials___' };\n        return parsed.redact(options).toString().replace(/___credentials___/g, replacementString);\n    }\n    const R = replacementString;\n    const replacements = [\n        uri => uri.replace(redactUsernames ? /(\\/\\/)(.*)(@)/g : /(\\/\\/[^@]*:)(.*)(@)/g, `$1${R}$3`),\n        uri => uri.replace(/(AWS_SESSION_TOKEN(:|%3A))([^,&]+)/gi, `$1${R}`),\n        uri => uri.replace(/(tlsCertificateKeyFilePassword=)([^&]+)/gi, `$1${R}`),\n        uri => redactUsernames ? uri.replace(/(proxyUsername=)([^&]+)/gi, `$1${R}`) : uri,\n        uri => uri.replace(/(proxyPassword=)([^&]+)/gi, `$1${R}`)\n    ];\n    for (const replacer of replacements) {\n        uri = replacer(uri);\n    }\n    return uri;\n}\nexports.redactConnectionString = redactConnectionString;\n//# sourceMappingURL=redact.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb-connection-string-url/lib/redact.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/admin.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/admin.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Admin = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_databases_1 = __webpack_require__(/*! ./operations/list_databases */ \"./node_modules/mongodb/lib/operations/list_databases.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst validate_collection_1 = __webpack_require__(/*! ./operations/validate_collection */ \"./node_modules/mongodb/lib/operations/validate_collection.js\");\n/**\n * The **Admin** class is an internal class that allows convenient access to\n * the admin functionality and commands for MongoDB.\n *\n * **ADMIN Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const admin = client.db().admin();\n * const dbInfo = await admin.listDatabases();\n * for (const db of dbInfo.databases) {\n *   console.log(db.name);\n * }\n * ```\n */\nclass Admin {\n    /**\n     * Create a new Admin instance\n     * @internal\n     */\n    constructor(db) {\n        this.s = { db };\n    }\n    /**\n     * Execute a command\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to execute\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new run_command_1.RunAdminCommandOperation(command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async buildInfo(options) {\n        return this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve the server build information\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverInfo(options) {\n        return this.command({ buildinfo: 1 }, options);\n    }\n    /**\n     * Retrieve this db's server status.\n     *\n     * @param options - Optional settings for the command\n     */\n    async serverStatus(options) {\n        return this.command({ serverStatus: 1 }, options);\n    }\n    /**\n     * Ping the MongoDB server and retrieve results\n     *\n     * @param options - Optional settings for the command\n     */\n    async ping(options) {\n        return this.command({ ping: 1 }, options);\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new remove_user_1.RemoveUserOperation(this.s.db, username, { dbName: 'admin', ...options }));\n    }\n    /**\n     * Validate an existing collection\n     *\n     * @param collectionName - The name of the collection to validate.\n     * @param options - Optional settings for the command\n     */\n    async validateCollection(collectionName, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new validate_collection_1.ValidateCollectionOperation(this, collectionName, options));\n    }\n    /**\n     * List the available databases\n     *\n     * @param options - Optional settings for the command\n     */\n    async listDatabases(options) {\n        return (0, execute_operation_1.executeOperation)(this.s.db.client, new list_databases_1.ListDatabasesOperation(this.s.db, options));\n    }\n    /**\n     * Get ReplicaSet status\n     *\n     * @param options - Optional settings for the command\n     */\n    async replSetGetStatus(options) {\n        return this.command({ replSetGetStatus: 1 }, options);\n    }\n}\nexports.Admin = Admin;\n//# sourceMappingURL=admin.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/admin.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bson.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/bson.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveBSONOptions = exports.pluckBSONSerializeOptions = exports.UUID = exports.Timestamp = exports.serialize = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.Double = exports.deserialize = exports.Decimal128 = exports.DBRef = exports.Code = exports.calculateObjectSize = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.BSON = exports.Binary = void 0;\nvar bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_1.Binary; } }));\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_1.BSON; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_1.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_1.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_1.BSONType; } }));\nObject.defineProperty(exports, \"calculateObjectSize\", ({ enumerable: true, get: function () { return bson_1.calculateObjectSize; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_1.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_1.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_1.Decimal128; } }));\nObject.defineProperty(exports, \"deserialize\", ({ enumerable: true, get: function () { return bson_1.deserialize; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_1.Double; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_1.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_1.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_1.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_1.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_1.ObjectId; } }));\nObject.defineProperty(exports, \"serialize\", ({ enumerable: true, get: function () { return bson_1.serialize; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_1.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_1.UUID; } }));\nfunction pluckBSONSerializeOptions(options) {\n    const { fieldsAsRaw, useBigInt64, promoteValues, promoteBuffers, promoteLongs, serializeFunctions, ignoreUndefined, bsonRegExp, raw, enableUtf8Validation } = options;\n    return {\n        fieldsAsRaw,\n        useBigInt64,\n        promoteValues,\n        promoteBuffers,\n        promoteLongs,\n        serializeFunctions,\n        ignoreUndefined,\n        bsonRegExp,\n        raw,\n        enableUtf8Validation\n    };\n}\nexports.pluckBSONSerializeOptions = pluckBSONSerializeOptions;\n/**\n * Merge the given BSONSerializeOptions, preferring options over the parent's options, and\n * substituting defaults for values not set.\n *\n * @internal\n */\nfunction resolveBSONOptions(options, parent) {\n    const parentOptions = parent?.bsonOptions;\n    return {\n        raw: options?.raw ?? parentOptions?.raw ?? false,\n        useBigInt64: options?.useBigInt64 ?? parentOptions?.useBigInt64 ?? false,\n        promoteLongs: options?.promoteLongs ?? parentOptions?.promoteLongs ?? true,\n        promoteValues: options?.promoteValues ?? parentOptions?.promoteValues ?? true,\n        promoteBuffers: options?.promoteBuffers ?? parentOptions?.promoteBuffers ?? false,\n        ignoreUndefined: options?.ignoreUndefined ?? parentOptions?.ignoreUndefined ?? false,\n        bsonRegExp: options?.bsonRegExp ?? parentOptions?.bsonRegExp ?? false,\n        serializeFunctions: options?.serializeFunctions ?? parentOptions?.serializeFunctions ?? false,\n        fieldsAsRaw: options?.fieldsAsRaw ?? parentOptions?.fieldsAsRaw ?? {},\n        enableUtf8Validation: options?.enableUtf8Validation ?? parentOptions?.enableUtf8Validation ?? true\n    };\n}\nexports.resolveBSONOptions = resolveBSONOptions;\n//# sourceMappingURL=bson.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/bson.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkOperationBase = exports.FindOperators = exports.MongoBulkWriteError = exports.mergeBatchResults = exports.WriteError = exports.WriteConcernError = exports.BulkWriteResult = exports.Batch = exports.BatchType = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst delete_1 = __webpack_require__(/*! ../operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst insert_1 = __webpack_require__(/*! ../operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst operation_1 = __webpack_require__(/*! ../operations/operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst update_1 = __webpack_require__(/*! ../operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nconst kServerError = Symbol('serverError');\n/** @public */\nexports.BatchType = Object.freeze({\n    INSERT: 1,\n    UPDATE: 2,\n    DELETE: 3\n});\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nclass Batch {\n    constructor(batchType, originalZeroIndex) {\n        this.originalZeroIndex = originalZeroIndex;\n        this.currentIndex = 0;\n        this.originalIndexes = [];\n        this.batchType = batchType;\n        this.operations = [];\n        this.size = 0;\n        this.sizeBytes = 0;\n    }\n}\nexports.Batch = Batch;\n/**\n * @public\n * The result of a bulk write.\n */\nclass BulkWriteResult {\n    static generateIdMap(ids) {\n        const idMap = {};\n        for (const doc of ids) {\n            idMap[doc.index] = doc._id;\n        }\n        return idMap;\n    }\n    /**\n     * Create a new BulkWriteResult instance\n     * @internal\n     */\n    constructor(bulkResult, isOrdered) {\n        this.result = bulkResult;\n        this.insertedCount = this.result.nInserted ?? 0;\n        this.matchedCount = this.result.nMatched ?? 0;\n        this.modifiedCount = this.result.nModified ?? 0;\n        this.deletedCount = this.result.nRemoved ?? 0;\n        this.upsertedCount = this.result.upserted.length ?? 0;\n        this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);\n        this.insertedIds = BulkWriteResult.generateIdMap(this.getSuccessfullyInsertedIds(bulkResult, isOrdered));\n        Object.defineProperty(this, 'result', { value: this.result, enumerable: false });\n    }\n    /** Evaluates to true if the bulk operation correctly executes */\n    get ok() {\n        return this.result.ok;\n    }\n    /**\n     * Returns document_ids that were actually inserted\n     * @internal\n     */\n    getSuccessfullyInsertedIds(bulkResult, isOrdered) {\n        if (bulkResult.writeErrors.length === 0)\n            return bulkResult.insertedIds;\n        if (isOrdered) {\n            return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);\n        }\n        return bulkResult.insertedIds.filter(({ index }) => !bulkResult.writeErrors.some(writeError => index === writeError.index));\n    }\n    /** Returns the upserted id at the given index */\n    getUpsertedIdAt(index) {\n        return this.result.upserted[index];\n    }\n    /** Returns raw internal result */\n    getRawResponse() {\n        return this.result;\n    }\n    /** Returns true if the bulk operation contains a write error */\n    hasWriteErrors() {\n        return this.result.writeErrors.length > 0;\n    }\n    /** Returns the number of write errors off the bulk operation */\n    getWriteErrorCount() {\n        return this.result.writeErrors.length;\n    }\n    /** Returns a specific write error object */\n    getWriteErrorAt(index) {\n        return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n    }\n    /** Retrieve all write errors */\n    getWriteErrors() {\n        return this.result.writeErrors;\n    }\n    /** Retrieve the write concern error if one exists */\n    getWriteConcernError() {\n        if (this.result.writeConcernErrors.length === 0) {\n            return;\n        }\n        else if (this.result.writeConcernErrors.length === 1) {\n            // Return the error\n            return this.result.writeConcernErrors[0];\n        }\n        else {\n            // Combine the errors\n            let errmsg = '';\n            for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n                const err = this.result.writeConcernErrors[i];\n                errmsg = errmsg + err.errmsg;\n                // TODO: Something better\n                if (i === 0)\n                    errmsg = errmsg + ' and ';\n            }\n            return new WriteConcernError({ errmsg, code: error_1.MONGODB_ERROR_CODES.WriteConcernFailed });\n        }\n    }\n    toString() {\n        return `BulkWriteResult(${this.result})`;\n    }\n    isOk() {\n        return this.result.ok === 1;\n    }\n}\nexports.BulkWriteResult = BulkWriteResult;\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nclass WriteConcernError {\n    constructor(error) {\n        this[kServerError] = error;\n    }\n    /** Write concern error code. */\n    get code() {\n        return this[kServerError].code;\n    }\n    /** Write concern error message. */\n    get errmsg() {\n        return this[kServerError].errmsg;\n    }\n    /** Write concern error info. */\n    get errInfo() {\n        return this[kServerError].errInfo;\n    }\n    toJSON() {\n        return this[kServerError];\n    }\n    toString() {\n        return `WriteConcernError(${this.errmsg})`;\n    }\n}\nexports.WriteConcernError = WriteConcernError;\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nclass WriteError {\n    constructor(err) {\n        this.err = err;\n    }\n    /** WriteError code. */\n    get code() {\n        return this.err.code;\n    }\n    /** WriteError original bulk operation index. */\n    get index() {\n        return this.err.index;\n    }\n    /** WriteError message. */\n    get errmsg() {\n        return this.err.errmsg;\n    }\n    /** WriteError details. */\n    get errInfo() {\n        return this.err.errInfo;\n    }\n    /** Returns the underlying operation that caused the error */\n    getOperation() {\n        return this.err.op;\n    }\n    toJSON() {\n        return { code: this.err.code, index: this.err.index, errmsg: this.err.errmsg, op: this.err.op };\n    }\n    toString() {\n        return `WriteError(${JSON.stringify(this.toJSON())})`;\n    }\n}\nexports.WriteError = WriteError;\n/** Merges results into shared data structure */\nfunction mergeBatchResults(batch, bulkResult, err, result) {\n    // If we have an error set the result to be the err object\n    if (err) {\n        result = err;\n    }\n    else if (result && result.result) {\n        result = result.result;\n    }\n    if (result == null) {\n        return;\n    }\n    // Do we have a top level error stop processing and return\n    if (result.ok === 0 && bulkResult.ok === 1) {\n        bulkResult.ok = 0;\n        const writeError = {\n            index: 0,\n            code: result.code || 0,\n            errmsg: result.message,\n            errInfo: result.errInfo,\n            op: batch.operations[0]\n        };\n        bulkResult.writeErrors.push(new WriteError(writeError));\n        return;\n    }\n    else if (result.ok === 0 && bulkResult.ok === 0) {\n        return;\n    }\n    // If we have an insert Batch type\n    if (isInsertBatch(batch) && result.n) {\n        bulkResult.nInserted = bulkResult.nInserted + result.n;\n    }\n    // If we have an insert Batch type\n    if (isDeleteBatch(batch) && result.n) {\n        bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n    }\n    let nUpserted = 0;\n    // We have an array of upserted values, we need to rewrite the indexes\n    if (Array.isArray(result.upserted)) {\n        nUpserted = result.upserted.length;\n        for (let i = 0; i < result.upserted.length; i++) {\n            bulkResult.upserted.push({\n                index: result.upserted[i].index + batch.originalZeroIndex,\n                _id: result.upserted[i]._id\n            });\n        }\n    }\n    else if (result.upserted) {\n        nUpserted = 1;\n        bulkResult.upserted.push({\n            index: batch.originalZeroIndex,\n            _id: result.upserted\n        });\n    }\n    // If we have an update Batch type\n    if (isUpdateBatch(batch) && result.n) {\n        const nModified = result.nModified;\n        bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n        bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n        if (typeof nModified === 'number') {\n            bulkResult.nModified = bulkResult.nModified + nModified;\n        }\n        else {\n            bulkResult.nModified = 0;\n        }\n    }\n    if (Array.isArray(result.writeErrors)) {\n        for (let i = 0; i < result.writeErrors.length; i++) {\n            const writeError = {\n                index: batch.originalIndexes[result.writeErrors[i].index],\n                code: result.writeErrors[i].code,\n                errmsg: result.writeErrors[i].errmsg,\n                errInfo: result.writeErrors[i].errInfo,\n                op: batch.operations[result.writeErrors[i].index]\n            };\n            bulkResult.writeErrors.push(new WriteError(writeError));\n        }\n    }\n    if (result.writeConcernError) {\n        bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n    }\n}\nexports.mergeBatchResults = mergeBatchResults;\nfunction executeCommands(bulkOperation, options, callback) {\n    if (bulkOperation.s.batches.length === 0) {\n        return callback(undefined, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered));\n    }\n    const batch = bulkOperation.s.batches.shift();\n    function resultHandler(err, result) {\n        // Error is a driver related error not a bulk op error, return early\n        if (err && 'message' in err && !(err instanceof error_1.MongoWriteConcernError)) {\n            return callback(new MongoBulkWriteError(err, new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered)));\n        }\n        if (err instanceof error_1.MongoWriteConcernError) {\n            return handleMongoWriteConcernError(batch, bulkOperation.s.bulkResult, bulkOperation.isOrdered, err, callback);\n        }\n        // Merge the results together\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, result);\n        const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n        if (bulkOperation.handleWriteError(callback, writeResult))\n            return;\n        // Execute the next command in line\n        executeCommands(bulkOperation, options, callback);\n    }\n    const finalOptions = (0, utils_1.resolveOptions)(bulkOperation, {\n        ...options,\n        ordered: bulkOperation.isOrdered\n    });\n    if (finalOptions.bypassDocumentValidation !== true) {\n        delete finalOptions.bypassDocumentValidation;\n    }\n    // Set an operationIf if provided\n    if (bulkOperation.operationId) {\n        resultHandler.operationId = bulkOperation.operationId;\n    }\n    // Is the bypassDocumentValidation options specific\n    if (bulkOperation.s.bypassDocumentValidation === true) {\n        finalOptions.bypassDocumentValidation = true;\n    }\n    // Is the checkKeys option disabled\n    if (bulkOperation.s.checkKeys === false) {\n        finalOptions.checkKeys = false;\n    }\n    if (finalOptions.retryWrites) {\n        if (isUpdateBatch(batch)) {\n            finalOptions.retryWrites = finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n        }\n        if (isDeleteBatch(batch)) {\n            finalOptions.retryWrites =\n                finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n        }\n    }\n    try {\n        if (isInsertBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new insert_1.InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n        else if (isUpdateBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new update_1.UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n        else if (isDeleteBatch(batch)) {\n            (0, execute_operation_1.executeOperation)(bulkOperation.s.collection.client, new delete_1.DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions), resultHandler);\n        }\n    }\n    catch (err) {\n        // Force top level error\n        err.ok = 0;\n        // Merge top level error and return\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, err, undefined);\n        callback();\n    }\n}\nfunction handleMongoWriteConcernError(batch, bulkResult, isOrdered, err, callback) {\n    mergeBatchResults(batch, bulkResult, undefined, err.result);\n    callback(new MongoBulkWriteError({\n        message: err.result?.writeConcernError.errmsg,\n        code: err.result?.writeConcernError.result\n    }, new BulkWriteResult(bulkResult, isOrdered)));\n}\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nclass MongoBulkWriteError extends error_1.MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(error, result) {\n        super(error);\n        this.writeErrors = [];\n        if (error instanceof WriteConcernError)\n            this.err = error;\n        else if (!(error instanceof Error)) {\n            this.message = error.message;\n            this.code = error.code;\n            this.writeErrors = error.writeErrors ?? [];\n        }\n        this.result = result;\n        Object.assign(this, error);\n    }\n    get name() {\n        return 'MongoBulkWriteError';\n    }\n    /** Number of documents inserted. */\n    get insertedCount() {\n        return this.result.insertedCount;\n    }\n    /** Number of documents matched for update. */\n    get matchedCount() {\n        return this.result.matchedCount;\n    }\n    /** Number of documents modified. */\n    get modifiedCount() {\n        return this.result.modifiedCount;\n    }\n    /** Number of documents deleted. */\n    get deletedCount() {\n        return this.result.deletedCount;\n    }\n    /** Number of documents upserted. */\n    get upsertedCount() {\n        return this.result.upsertedCount;\n    }\n    /** Inserted document generated Id's, hash key is the index of the originating operation */\n    get insertedIds() {\n        return this.result.insertedIds;\n    }\n    /** Upserted document generated Id's, hash key is the index of the originating operation */\n    get upsertedIds() {\n        return this.result.upsertedIds;\n    }\n}\nexports.MongoBulkWriteError = MongoBulkWriteError;\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nclass FindOperators {\n    /**\n     * Creates a new FindOperators object.\n     * @internal\n     */\n    constructor(bulkOperation) {\n        this.bulkOperation = bulkOperation;\n    }\n    /** Add a multiple update operation to the bulk operation */\n    update(updateDocument) {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, {\n            ...currentOp,\n            multi: true\n        }));\n    }\n    /** Add a single update operation to the bulk operation */\n    updateOne(updateDocument) {\n        if (!(0, utils_1.hasAtomicOperators)(updateDocument)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, updateDocument, { ...currentOp, multi: false }));\n    }\n    /** Add a replace one operation to the bulk operation */\n    replaceOne(replacement) {\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.UPDATE, (0, update_1.makeUpdateStatement)(currentOp.selector, replacement, { ...currentOp, multi: false }));\n    }\n    /** Add a delete one operation to the bulk operation */\n    deleteOne() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 1 }));\n    }\n    /** Add a delete many operation to the bulk operation */\n    delete() {\n        const currentOp = buildCurrentOp(this.bulkOperation);\n        return this.bulkOperation.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(currentOp.selector, { ...currentOp, limit: 0 }));\n    }\n    /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n    upsert() {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.upsert = true;\n        return this;\n    }\n    /** Specifies the collation for the query condition. */\n    collation(collation) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.collation = collation;\n        return this;\n    }\n    /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n    arrayFilters(arrayFilters) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n        return this;\n    }\n    /** Specifies hint for the bulk operation. */\n    hint(hint) {\n        if (!this.bulkOperation.s.currentOp) {\n            this.bulkOperation.s.currentOp = {};\n        }\n        this.bulkOperation.s.currentOp.hint = hint;\n        return this;\n    }\n}\nexports.FindOperators = FindOperators;\nconst executeCommandsAsync = (0, util_1.promisify)(executeCommands);\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nclass BulkWriteShimOperation extends operation_1.AbstractOperation {\n    constructor(bulkOperation, options) {\n        super(options);\n        this.bulkOperation = bulkOperation;\n    }\n    execute(_server, session) {\n        if (this.options.session == null) {\n            // An implicit session could have been created by 'executeOperation'\n            // So if we stick it on finalOptions here, each bulk operation\n            // will use this same session, it'll be passed in the same way\n            // an explicit session would be\n            this.options.session = session;\n        }\n        return executeCommandsAsync(this.bulkOperation, this.options);\n    }\n}\n/** @public */\nclass BulkOperationBase {\n    /**\n     * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n     * @internal\n     */\n    constructor(collection, options, isOrdered) {\n        // determine whether bulkOperation is ordered or unordered\n        this.isOrdered = isOrdered;\n        const topology = (0, utils_1.getTopology)(collection);\n        options = options == null ? {} : options;\n        // TODO Bring from driver information in hello\n        // Get the namespace for the write operations\n        const namespace = collection.s.namespace;\n        // Used to mark operation as executed\n        const executed = false;\n        // Current item\n        const currentOp = undefined;\n        // Set max byte size\n        const hello = topology.lastHello();\n        // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n        // over 2mb are still allowed\n        const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n        const maxBsonObjectSize = hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n        const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n        const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n        // Calculates the largest possible size of an Array key, represented as a BSON string\n        // element. This calculation:\n        //     1 byte for BSON type\n        //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n        //   + 1 bytes for null terminator\n        const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n        // Final options for retryable writes\n        let finalOptions = Object.assign({}, options);\n        finalOptions = (0, utils_1.applyRetryableWrites)(finalOptions, collection.s.db);\n        // Final results\n        const bulkResult = {\n            ok: 1,\n            writeErrors: [],\n            writeConcernErrors: [],\n            insertedIds: [],\n            nInserted: 0,\n            nUpserted: 0,\n            nMatched: 0,\n            nModified: 0,\n            nRemoved: 0,\n            upserted: []\n        };\n        // Internal state\n        this.s = {\n            // Final result\n            bulkResult,\n            // Current batch state\n            currentBatch: undefined,\n            currentIndex: 0,\n            // ordered specific\n            currentBatchSize: 0,\n            currentBatchSizeBytes: 0,\n            // unordered specific\n            currentInsertBatch: undefined,\n            currentUpdateBatch: undefined,\n            currentRemoveBatch: undefined,\n            batches: [],\n            // Write concern\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Max batch size options\n            maxBsonObjectSize,\n            maxBatchSizeBytes,\n            maxWriteBatchSize,\n            maxKeySize,\n            // Namespace\n            namespace,\n            // Topology\n            topology,\n            // Options\n            options: finalOptions,\n            // BSON options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options),\n            // Current operation\n            currentOp,\n            // Executed\n            executed,\n            // Collection\n            collection,\n            // Fundamental error\n            err: undefined,\n            // check keys\n            checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n        };\n        // bypass Validation\n        if (options.bypassDocumentValidation === true) {\n            this.s.bypassDocumentValidation = true;\n        }\n    }\n    /**\n     * Add a single insert document to the bulk operation\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Adds three inserts to the bulkOp.\n     * bulkOp\n     *   .insert({ a: 1 })\n     *   .insert({ b: 2 })\n     *   .insert({ c: 3 });\n     * await bulkOp.execute();\n     * ```\n     */\n    insert(document) {\n        if (document._id == null && !shouldForceServerObjectId(this)) {\n            document._id = new bson_1.ObjectId();\n        }\n        return this.addToOperationsList(exports.BatchType.INSERT, document);\n    }\n    /**\n     * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n     * Returns a builder object used to complete the definition of the operation.\n     *\n     * @example\n     * ```ts\n     * const bulkOp = collection.initializeOrderedBulkOp();\n     *\n     * // Add an updateOne to the bulkOp\n     * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n     *\n     * // Add an updateMany to the bulkOp\n     * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n     *\n     * // Add an upsert\n     * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n     *\n     * // Add a deletion\n     * bulkOp.find({ g: 7 }).deleteOne();\n     *\n     * // Add a multi deletion\n     * bulkOp.find({ h: 8 }).delete();\n     *\n     * // Add a replaceOne\n     * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n     *\n     * // Update using a pipeline (requires Mongodb 4.2 or higher)\n     * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n     *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n     * ]);\n     *\n     * // All of the ops will now be executed\n     * await bulkOp.execute();\n     * ```\n     */\n    find(selector) {\n        if (!selector) {\n            throw new error_1.MongoInvalidArgumentError('Bulk find operation must specify a selector');\n        }\n        // Save a current selector\n        this.s.currentOp = {\n            selector: selector\n        };\n        return new FindOperators(this);\n    }\n    /** Specifies a raw operation to perform in the bulk write. */\n    raw(op) {\n        if (op == null || typeof op !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Operation must be an object with an operation key');\n        }\n        if ('insertOne' in op) {\n            const forceServerObjectId = shouldForceServerObjectId(this);\n            if (op.insertOne && op.insertOne.document == null) {\n                // NOTE: provided for legacy support, but this is a malformed operation\n                if (forceServerObjectId !== true && op.insertOne._id == null) {\n                    op.insertOne._id = new bson_1.ObjectId();\n                }\n                return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne);\n            }\n            if (forceServerObjectId !== true && op.insertOne.document._id == null) {\n                op.insertOne.document._id = new bson_1.ObjectId();\n            }\n            return this.addToOperationsList(exports.BatchType.INSERT, op.insertOne.document);\n        }\n        if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n            if ('replaceOne' in op) {\n                if ('q' in op.replaceOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.replaceOne.filter, op.replaceOne.replacement, { ...op.replaceOne, multi: false });\n                if ((0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Replacement document must not use atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateOne' in op) {\n                if ('q' in op.updateOne) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateOne.filter, op.updateOne.update, {\n                    ...op.updateOne,\n                    multi: false\n                });\n                if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n            if ('updateMany' in op) {\n                if ('q' in op.updateMany) {\n                    throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n                }\n                const updateStatement = (0, update_1.makeUpdateStatement)(op.updateMany.filter, op.updateMany.update, {\n                    ...op.updateMany,\n                    multi: true\n                });\n                if (!(0, utils_1.hasAtomicOperators)(updateStatement.u)) {\n                    throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n                }\n                return this.addToOperationsList(exports.BatchType.UPDATE, updateStatement);\n            }\n        }\n        if ('deleteOne' in op) {\n            if ('q' in op.deleteOne) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteOne.filter, { ...op.deleteOne, limit: 1 }));\n        }\n        if ('deleteMany' in op) {\n            if ('q' in op.deleteMany) {\n                throw new error_1.MongoInvalidArgumentError('Raw operations are not allowed');\n            }\n            return this.addToOperationsList(exports.BatchType.DELETE, (0, delete_1.makeDeleteStatement)(op.deleteMany.filter, { ...op.deleteMany, limit: 0 }));\n        }\n        // otherwise an unknown operation was provided\n        throw new error_1.MongoInvalidArgumentError('bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany');\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get batches() {\n        const batches = [...this.s.batches];\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                batches.push(this.s.currentRemoveBatch);\n        }\n        return batches;\n    }\n    async execute(options = {}) {\n        if (this.s.executed) {\n            throw new error_1.MongoBatchReExecutionError();\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            this.s.writeConcern = writeConcern;\n        }\n        // If we have current batch\n        if (this.isOrdered) {\n            if (this.s.currentBatch)\n                this.s.batches.push(this.s.currentBatch);\n        }\n        else {\n            if (this.s.currentInsertBatch)\n                this.s.batches.push(this.s.currentInsertBatch);\n            if (this.s.currentUpdateBatch)\n                this.s.batches.push(this.s.currentUpdateBatch);\n            if (this.s.currentRemoveBatch)\n                this.s.batches.push(this.s.currentRemoveBatch);\n        }\n        // If we have no operations in the bulk raise an error\n        if (this.s.batches.length === 0) {\n            throw new error_1.MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n        }\n        this.s.executed = true;\n        const finalOptions = { ...this.s.options, ...options };\n        const operation = new BulkWriteShimOperation(this, finalOptions);\n        return (0, execute_operation_1.executeOperation)(this.s.collection.client, operation);\n    }\n    /**\n     * Handles the write error before executing commands\n     * @internal\n     */\n    handleWriteError(callback, writeResult) {\n        if (this.s.bulkResult.writeErrors.length > 0) {\n            const msg = this.s.bulkResult.writeErrors[0].errmsg\n                ? this.s.bulkResult.writeErrors[0].errmsg\n                : 'write operation failed';\n            callback(new MongoBulkWriteError({\n                message: msg,\n                code: this.s.bulkResult.writeErrors[0].code,\n                writeErrors: this.s.bulkResult.writeErrors\n            }, writeResult));\n            return true;\n        }\n        const writeConcernError = writeResult.getWriteConcernError();\n        if (writeConcernError) {\n            callback(new MongoBulkWriteError(writeConcernError, writeResult));\n            return true;\n        }\n        return false;\n    }\n}\nexports.BulkOperationBase = BulkOperationBase;\nObject.defineProperty(BulkOperationBase.prototype, 'length', {\n    enumerable: true,\n    get() {\n        return this.s.currentIndex;\n    }\n});\nfunction shouldForceServerObjectId(bulkOperation) {\n    if (typeof bulkOperation.s.options.forceServerObjectId === 'boolean') {\n        return bulkOperation.s.options.forceServerObjectId;\n    }\n    if (typeof bulkOperation.s.collection.s.db.options?.forceServerObjectId === 'boolean') {\n        return bulkOperation.s.collection.s.db.options?.forceServerObjectId;\n    }\n    return false;\n}\nfunction isInsertBatch(batch) {\n    return batch.batchType === exports.BatchType.INSERT;\n}\nfunction isUpdateBatch(batch) {\n    return batch.batchType === exports.BatchType.UPDATE;\n}\nfunction isDeleteBatch(batch) {\n    return batch.batchType === exports.BatchType.DELETE;\n}\nfunction buildCurrentOp(bulkOp) {\n    let { currentOp } = bulkOp.s;\n    bulkOp.s.currentOp = undefined;\n    if (!currentOp)\n        currentOp = {};\n    return currentOp;\n}\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/bulk/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/ordered.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/ordered.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OrderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, true);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize)\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatchSize > 0 &&\n                this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n            // Reset the current size trackers\n            this.s.currentBatchSize = 0;\n            this.s.currentBatchSizeBytes = 0;\n        }\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.currentIndex,\n                _id: document._id\n            });\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatchSize += 1;\n        this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n        this.s.currentIndex += 1;\n        return this;\n    }\n}\nexports.OrderedBulkOperation = OrderedBulkOperation;\n//# sourceMappingURL=ordered.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/bulk/ordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/bulk/unordered.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/bulk/unordered.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UnorderedBulkOperation = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/bulk/common.js\");\n/** @public */\nclass UnorderedBulkOperation extends common_1.BulkOperationBase {\n    /** @internal */\n    constructor(collection, options) {\n        super(collection, options, false);\n    }\n    handleWriteError(callback, writeResult) {\n        if (this.s.batches.length) {\n            return false;\n        }\n        return super.handleWriteError(callback, writeResult);\n    }\n    addToOperationsList(batchType, document) {\n        // Get the bsonSize\n        const bsonSize = BSON.calculateObjectSize(document, {\n            checkKeys: false,\n            // Since we don't know what the user selected for BSON options here,\n            // err on the safe side, and check the size with ignoreUndefined: false.\n            ignoreUndefined: false\n        });\n        // Throw error if the doc is bigger than the max BSON size\n        if (bsonSize >= this.s.maxBsonObjectSize) {\n            // TODO(NODE-3483): Change this to MongoBSONError\n            throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n        }\n        // Holds the current batch\n        this.s.currentBatch = undefined;\n        // Get the right type of batch\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentBatch = this.s.currentInsertBatch;\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentBatch = this.s.currentUpdateBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentBatch = this.s.currentRemoveBatch;\n        }\n        const maxKeySize = this.s.maxKeySize;\n        // Create a new batch object if we don't have a current one\n        if (this.s.currentBatch == null) {\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // Check if we need to create a new batch\n        if (\n        // New batch if we exceed the max batch op size\n        this.s.currentBatch.size + 1 >= this.s.maxWriteBatchSize ||\n            // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n            // since we can't sent an empty batch\n            (this.s.currentBatch.size > 0 &&\n                this.s.currentBatch.sizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n            // New batch if the new op does not have the same op type as the current batch\n            this.s.currentBatch.batchType !== batchType) {\n            // Save the batch to the execution stack\n            this.s.batches.push(this.s.currentBatch);\n            // Create a new batch\n            this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n        }\n        // We have an array of documents\n        if (Array.isArray(document)) {\n            throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n        }\n        this.s.currentBatch.operations.push(document);\n        this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n        this.s.currentIndex = this.s.currentIndex + 1;\n        // Save back the current Batch to the right type\n        if (batchType === common_1.BatchType.INSERT) {\n            this.s.currentInsertBatch = this.s.currentBatch;\n            this.s.bulkResult.insertedIds.push({\n                index: this.s.bulkResult.insertedIds.length,\n                _id: document._id\n            });\n        }\n        else if (batchType === common_1.BatchType.UPDATE) {\n            this.s.currentUpdateBatch = this.s.currentBatch;\n        }\n        else if (batchType === common_1.BatchType.DELETE) {\n            this.s.currentRemoveBatch = this.s.currentBatch;\n        }\n        // Update current batch size\n        this.s.currentBatch.size += 1;\n        this.s.currentBatch.sizeBytes += maxKeySize + bsonSize;\n        return this;\n    }\n}\nexports.UnorderedBulkOperation = UnorderedBulkOperation;\n//# sourceMappingURL=unordered.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/bulk/unordered.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/change_stream.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/change_stream.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStream = void 0;\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kCursorStream = Symbol('cursorStream');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kMode = Symbol('mode');\nconst CHANGE_STREAM_OPTIONS = [\n    'resumeAfter',\n    'startAfter',\n    'startAtOperationTime',\n    'fullDocument',\n    'fullDocumentBeforeChange',\n    'showExpandedEvents'\n];\nconst CHANGE_DOMAIN_TYPES = {\n    COLLECTION: Symbol('Collection'),\n    DATABASE: Symbol('Database'),\n    CLUSTER: Symbol('Cluster')\n};\nconst CHANGE_STREAM_EVENTS = [constants_1.RESUME_TOKEN_CHANGED, constants_1.END, constants_1.CLOSE];\nconst NO_RESUME_TOKEN_ERROR = 'A change stream document has been received that lacks a resume token (_id).';\nconst CHANGESTREAM_CLOSED_ERROR = 'ChangeStream is closed';\n/**\n * Creates a new Change Stream instance. Normally created using {@link Collection#watch|Collection.watch()}.\n * @public\n */\nclass ChangeStream extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @internal\n     *\n     * @param parent - The parent object that created this change stream\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents\n     */\n    constructor(parent, pipeline = [], options = {}) {\n        super();\n        this.pipeline = pipeline;\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        if (parent instanceof collection_1.Collection) {\n            this.type = CHANGE_DOMAIN_TYPES.COLLECTION;\n        }\n        else if (parent instanceof db_1.Db) {\n            this.type = CHANGE_DOMAIN_TYPES.DATABASE;\n        }\n        else if (parent instanceof mongo_client_1.MongoClient) {\n            this.type = CHANGE_DOMAIN_TYPES.CLUSTER;\n        }\n        else {\n            throw new error_1.MongoChangeStreamError('Parent provided to ChangeStream constructor must be an instance of Collection, Db, or MongoClient');\n        }\n        this.parent = parent;\n        this.namespace = parent.s.namespace;\n        if (!this.options.readPreference && parent.readPreference) {\n            this.options.readPreference = parent.readPreference;\n        }\n        // Create contained Change Stream cursor\n        this.cursor = this._createChangeStreamCursor(options);\n        this[kClosed] = false;\n        this[kMode] = false;\n        // Listen for any `change` listeners being added to ChangeStream\n        this.on('newListener', eventName => {\n            if (eventName === 'change' && this.cursor && this.listenerCount('change') === 0) {\n                this._streamEvents(this.cursor);\n            }\n        });\n        this.on('removeListener', eventName => {\n            if (eventName === 'change' && this.listenerCount('change') === 0 && this.cursor) {\n                this[kCursorStream]?.removeAllListeners('data');\n            }\n        });\n    }\n    /** @internal */\n    get cursorStream() {\n        return this[kCursorStream];\n    }\n    /** The cached resume token that is used to resume after the most recently returned change. */\n    get resumeToken() {\n        return this.cursor?.resumeToken;\n    }\n    /** Check if there is any document still available in the Change Stream */\n    async hasNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const hasNext = await this.cursor.hasNext();\n                return hasNext;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /** Get the next available document from the Change Stream. */\n    async next() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.next();\n                const processedChange = this._processChange(change ?? null);\n                return processedChange;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    /**\n     * Try to get the next available document from the Change Stream's cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        this._setIsIterator();\n        // Change streams must resume indefinitely while each resume event succeeds.\n        // This loop continues until either a change event is received or until a resume attempt\n        // fails.\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            try {\n                const change = await this.cursor.tryNext();\n                return change ?? null;\n            }\n            catch (error) {\n                try {\n                    await this._processErrorIteratorMode(error);\n                }\n                catch (error) {\n                    try {\n                        await this.close();\n                    }\n                    catch {\n                        // We are not concerned with errors from close()\n                    }\n                    throw error;\n                }\n            }\n        }\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            // Change streams run indefinitely as long as errors are resumable\n            // So the only loop breaking condition is if `next()` throws\n            while (true) {\n                yield await this.next();\n            }\n        }\n        finally {\n            try {\n                await this.close();\n            }\n            catch {\n                // we're not concerned with errors from close()\n            }\n        }\n    }\n    /** Is the cursor closed */\n    get closed() {\n        return this[kClosed] || this.cursor.closed;\n    }\n    /** Close the Change Stream */\n    async close() {\n        this[kClosed] = true;\n        const cursor = this.cursor;\n        try {\n            await cursor.close();\n        }\n        finally {\n            this._endStream();\n        }\n    }\n    /**\n     * Return a modified Readable stream including a possible transform method.\n     *\n     * NOTE: When using a Stream to process change stream events, the stream will\n     * NOT automatically resume in the case a resumable error is encountered.\n     *\n     * @throws MongoChangeStreamError if the underlying cursor or the change stream is closed\n     */\n    stream(options) {\n        if (this.closed) {\n            throw new error_1.MongoChangeStreamError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        this.streamOptions = options;\n        return this.cursor.stream(options);\n    }\n    /** @internal */\n    _setIsEmitter() {\n        if (this[kMode] === 'iterator') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an EventEmitter after being used as an iterator');\n        }\n        this[kMode] = 'emitter';\n    }\n    /** @internal */\n    _setIsIterator() {\n        if (this[kMode] === 'emitter') {\n            // TODO(NODE-3485): Replace with MongoChangeStreamModeError\n            throw new error_1.MongoAPIError('ChangeStream cannot be used as an iterator after being used as an EventEmitter');\n        }\n        this[kMode] = 'iterator';\n    }\n    /**\n     * Create a new change stream cursor based on self's configuration\n     * @internal\n     */\n    _createChangeStreamCursor(options) {\n        const changeStreamStageOptions = (0, utils_1.filterOptions)(options, CHANGE_STREAM_OPTIONS);\n        if (this.type === CHANGE_DOMAIN_TYPES.CLUSTER) {\n            changeStreamStageOptions.allChangesForCluster = true;\n        }\n        const pipeline = [{ $changeStream: changeStreamStageOptions }, ...this.pipeline];\n        const client = this.type === CHANGE_DOMAIN_TYPES.CLUSTER\n            ? this.parent\n            : this.type === CHANGE_DOMAIN_TYPES.DATABASE\n                ? this.parent.client\n                : this.type === CHANGE_DOMAIN_TYPES.COLLECTION\n                    ? this.parent.client\n                    : null;\n        if (client == null) {\n            // This should never happen because of the assertion in the constructor\n            throw new error_1.MongoRuntimeError(`Changestream type should only be one of cluster, database, collection. Found ${this.type.toString()}`);\n        }\n        const changeStreamCursor = new change_stream_cursor_1.ChangeStreamCursor(client, this.namespace, pipeline, options);\n        for (const event of CHANGE_STREAM_EVENTS) {\n            changeStreamCursor.on(event, e => this.emit(event, e));\n        }\n        if (this.listenerCount(ChangeStream.CHANGE) > 0) {\n            this._streamEvents(changeStreamCursor);\n        }\n        return changeStreamCursor;\n    }\n    /** @internal */\n    _closeEmitterModeWithError(error) {\n        this.emit(ChangeStream.ERROR, error);\n        this.close().catch(() => null);\n    }\n    /** @internal */\n    _streamEvents(cursor) {\n        this._setIsEmitter();\n        const stream = this[kCursorStream] ?? cursor.stream();\n        this[kCursorStream] = stream;\n        stream.on('data', change => {\n            try {\n                const processedChange = this._processChange(change);\n                this.emit(ChangeStream.CHANGE, processedChange);\n            }\n            catch (error) {\n                this.emit(ChangeStream.ERROR, error);\n            }\n        });\n        stream.on('error', error => this._processErrorStreamMode(error));\n    }\n    /** @internal */\n    _endStream() {\n        const cursorStream = this[kCursorStream];\n        if (cursorStream) {\n            ['data', 'close', 'end', 'error'].forEach(event => cursorStream.removeAllListeners(event));\n            cursorStream.destroy();\n        }\n        this[kCursorStream] = undefined;\n    }\n    /** @internal */\n    _processChange(change) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        // a null change means the cursor has been notified, implicitly closing the change stream\n        if (change == null) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoRuntimeError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (change && !change._id) {\n            throw new error_1.MongoChangeStreamError(NO_RESUME_TOKEN_ERROR);\n        }\n        // cache the resume token\n        this.cursor.cacheResumeToken(change._id);\n        // wipe the startAtOperationTime if there was one so that there won't be a conflict\n        // between resumeToken and startAtOperationTime if we need to reconnect the cursor\n        this.options.startAtOperationTime = undefined;\n        return change;\n    }\n    /** @internal */\n    _processErrorStreamMode(changeStreamError) {\n        // If the change stream has been closed explicitly, do not process error.\n        if (this[kClosed])\n            return;\n        if ((0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            this._endStream();\n            this.cursor.close().catch(() => null);\n            const topology = (0, utils_1.getTopology)(this.parent);\n            topology.selectServer(this.cursor.readPreference, {}, serverSelectionError => {\n                if (serverSelectionError)\n                    return this._closeEmitterModeWithError(changeStreamError);\n                this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n            });\n        }\n        else {\n            this._closeEmitterModeWithError(changeStreamError);\n        }\n    }\n    /** @internal */\n    async _processErrorIteratorMode(changeStreamError) {\n        if (this[kClosed]) {\n            // TODO(NODE-3485): Replace with MongoChangeStreamClosedError\n            throw new error_1.MongoAPIError(CHANGESTREAM_CLOSED_ERROR);\n        }\n        if (!(0, error_1.isResumableError)(changeStreamError, this.cursor.maxWireVersion)) {\n            try {\n                await this.close();\n            }\n            catch {\n                // ignore errors from close\n            }\n            throw changeStreamError;\n        }\n        await this.cursor.close().catch(() => null);\n        const topology = (0, utils_1.getTopology)(this.parent);\n        try {\n            await topology.selectServerAsync(this.cursor.readPreference, {});\n            this.cursor = this._createChangeStreamCursor(this.cursor.resumeOptions);\n        }\n        catch {\n            // if the topology can't reconnect, close the stream\n            await this.close();\n            throw changeStreamError;\n        }\n    }\n}\n/** @event */\nChangeStream.RESPONSE = constants_1.RESPONSE;\n/** @event */\nChangeStream.MORE = constants_1.MORE;\n/** @event */\nChangeStream.INIT = constants_1.INIT;\n/** @event */\nChangeStream.CLOSE = constants_1.CLOSE;\n/**\n * Fired for each new matching change in the specified namespace. Attaching a `change`\n * event listener to a Change Stream will switch the stream into flowing mode. Data will\n * then be passed as soon as it is available.\n * @event\n */\nChangeStream.CHANGE = constants_1.CHANGE;\n/** @event */\nChangeStream.END = constants_1.END;\n/** @event */\nChangeStream.ERROR = constants_1.ERROR;\n/**\n * Emitted each time the change stream stores a new resume token.\n * @event\n */\nChangeStream.RESUME_TOKEN_CHANGED = constants_1.RESUME_TOKEN_CHANGED;\nexports.ChangeStream = ChangeStream;\n//# sourceMappingURL=change_stream.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/change_stream.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js":
/*!***************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AutoEncrypter = exports.AutoEncryptionLoggerLevel = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ../mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst mongocryptd_manager_1 = __webpack_require__(/*! ./mongocryptd_manager */ \"./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/** @public */\nexports.AutoEncryptionLoggerLevel = Object.freeze({\n    FatalError: 0,\n    Error: 1,\n    Warning: 2,\n    Info: 3,\n    Trace: 4\n});\n// Typescript errors if we index objects with `Symbol.for(...)`, so\n// to avoid TS errors we pull them out into variables.  Then we can type\n// the objects (and class) that we expect to see them on and prevent TS\n// errors.\n/** @internal */\nconst kDecorateResult = Symbol.for('@@mdb.decorateDecryptionResult');\n/** @internal */\nconst kDecoratedKeys = Symbol.for('@@mdb.decryptedKeys');\n/**\n * @internal An internal class to be used by the driver for auto encryption\n * **NOTE**: Not meant to be instantiated directly, this is for internal use only.\n */\nclass AutoEncrypter {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create an AutoEncrypter\n     *\n     * **Note**: Do not instantiate this class directly. Rather, supply the relevant options to a MongoClient\n     *\n     * **Note**: Supplying `options.schemaMap` provides more security than relying on JSON Schemas obtained from the server.\n     * It protects against a malicious server advertising a false JSON Schema, which could trick the client into sending unencrypted data that should be encrypted.\n     * Schemas supplied in the schemaMap only apply to configuring automatic encryption for Client-Side Field Level Encryption.\n     * Other validation rules in the JSON schema will not be enforced by the driver and will result in an error.\n     *\n     * @example <caption>Create an AutoEncrypter that makes use of mongocryptd</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using mongocryptd\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {\n     *         accessKeyId: AWS_ACCESS_KEY,\n     *         secretAccessKey: AWS_SECRET_KEY\n     *       }\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     * @example <caption>Create an AutoEncrypter that makes use of libmongocrypt's CSFLE shared library</caption>\n     * ```ts\n     * // Enabling autoEncryption via a MongoClient using CSFLE shared library\n     * const { MongoClient } = require('mongodb');\n     * const client = new MongoClient(URL, {\n     *   autoEncryption: {\n     *     kmsProviders: {\n     *       aws: {}\n     *     },\n     *     extraOptions: {\n     *       cryptSharedLibPath: '/path/to/local/crypt/shared/lib',\n     *       cryptSharedLibRequired: true\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * await client.connect();\n     * // From here on, the client will be encrypting / decrypting automatically\n     */\n    constructor(client, options) {\n        /**\n         * Used by devtools to enable decorating decryption results.\n         *\n         * When set and enabled, `decrypt` will automatically recursively\n         * traverse a decrypted document and if a field has been decrypted,\n         * it will mark it as decrypted.  Compass uses this to determine which\n         * fields were decrypted.\n         */\n        this[_a] = false;\n        this._client = client;\n        this._bypassEncryption = options.bypassAutoEncryption === true;\n        this._keyVaultNamespace = options.keyVaultNamespace || 'admin.datakeys';\n        this._keyVaultClient = options.keyVaultClient || client;\n        this._metaDataClient = options.metadataClient || client;\n        this._proxyOptions = options.proxyOptions || {};\n        this._tlsOptions = options.tlsOptions || {};\n        this._kmsProviders = options.kmsProviders || {};\n        const mongoCryptOptions = {\n            cryptoCallbacks\n        };\n        if (options.schemaMap) {\n            mongoCryptOptions.schemaMap = Buffer.isBuffer(options.schemaMap)\n                ? options.schemaMap\n                : (0, bson_1.serialize)(options.schemaMap);\n        }\n        if (options.encryptedFieldsMap) {\n            mongoCryptOptions.encryptedFieldsMap = Buffer.isBuffer(options.encryptedFieldsMap)\n                ? options.encryptedFieldsMap\n                : (0, bson_1.serialize)(options.encryptedFieldsMap);\n        }\n        mongoCryptOptions.kmsProviders = !Buffer.isBuffer(this._kmsProviders)\n            ? (0, bson_1.serialize)(this._kmsProviders)\n            : this._kmsProviders;\n        if (options.options?.logger) {\n            mongoCryptOptions.logger = options.options.logger;\n        }\n        if (options.extraOptions && options.extraOptions.cryptSharedLibPath) {\n            mongoCryptOptions.cryptSharedLibPath = options.extraOptions.cryptSharedLibPath;\n        }\n        if (options.bypassQueryAnalysis) {\n            mongoCryptOptions.bypassQueryAnalysis = options.bypassQueryAnalysis;\n        }\n        this._bypassMongocryptdAndCryptShared = this._bypassEncryption || !!options.bypassQueryAnalysis;\n        if (options.extraOptions && options.extraOptions.cryptSharedLibSearchPaths) {\n            // Only for driver testing\n            mongoCryptOptions.cryptSharedLibSearchPaths = options.extraOptions.cryptSharedLibSearchPaths;\n        }\n        else if (!this._bypassMongocryptdAndCryptShared) {\n            mongoCryptOptions.cryptSharedLibSearchPaths = ['$SYSTEM'];\n        }\n        const MongoCrypt = AutoEncrypter.getMongoCrypt();\n        this._mongocrypt = new MongoCrypt(mongoCryptOptions);\n        this._contextCounter = 0;\n        if (options.extraOptions &&\n            options.extraOptions.cryptSharedLibRequired &&\n            !this.cryptSharedLibVersionInfo) {\n            throw new errors_1.MongoCryptInvalidArgumentError('`cryptSharedLibRequired` set but no crypt_shared library loaded');\n        }\n        // Only instantiate mongocryptd manager/client once we know for sure\n        // that we are not using the CSFLE shared library.\n        if (!this._bypassMongocryptdAndCryptShared && !this.cryptSharedLibVersionInfo) {\n            this._mongocryptdManager = new mongocryptd_manager_1.MongocryptdManager(options.extraOptions);\n            const clientOptions = {\n                serverSelectionTimeoutMS: 10000\n            };\n            if (options.extraOptions == null || typeof options.extraOptions.mongocryptdURI !== 'string') {\n                clientOptions.family = 4;\n            }\n            this._mongocryptdClient = new mongo_client_1.MongoClient(this._mongocryptdManager.uri, clientOptions);\n        }\n    }\n    /**\n     * Initializes the auto encrypter by spawning a mongocryptd and connecting to it.\n     *\n     * This function is a no-op when bypassSpawn is set or the crypt shared library is used.\n     */\n    async init() {\n        if (this._bypassMongocryptdAndCryptShared || this.cryptSharedLibVersionInfo) {\n            return;\n        }\n        if (!this._mongocryptdManager) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdManager is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdClient) {\n            throw new error_1.MongoRuntimeError('Reached impossible state: mongocryptdClient is undefined when neither bypassSpawn nor the shared lib are specified.');\n        }\n        if (!this._mongocryptdManager.bypassSpawn) {\n            await this._mongocryptdManager.spawn();\n        }\n        try {\n            const client = await this._mongocryptdClient.connect();\n            return client;\n        }\n        catch (error) {\n            const { message } = error;\n            if (message && (message.match(/timed out after/) || message.match(/ENOTFOUND/))) {\n                throw new error_1.MongoRuntimeError('Unable to connect to `mongocryptd`, please make sure it is running or in your PATH for auto-spawn', { cause: error });\n            }\n            throw error;\n        }\n    }\n    /**\n     * Cleans up the `_mongocryptdClient`, if present.\n     */\n    async teardown(force) {\n        await this._mongocryptdClient?.close(force);\n    }\n    /**\n     * Encrypt a command for a given namespace.\n     */\n    async encrypt(ns, cmd, options = {}) {\n        if (this._bypassEncryption) {\n            // If `bypassAutoEncryption` has been specified, don't encrypt\n            return cmd;\n        }\n        const commandBuffer = Buffer.isBuffer(cmd) ? cmd : (0, bson_1.serialize)(cmd, options);\n        const context = this._mongocrypt.makeEncryptionContext(utils_1.MongoDBCollectionNamespace.fromString(ns).db, commandBuffer);\n        context.id = this._contextCounter++;\n        context.ns = ns;\n        context.document = cmd;\n        const stateMachine = new state_machine_1.StateMachine({\n            promoteValues: false,\n            promoteLongs: false,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        return stateMachine.execute(this, context);\n    }\n    /**\n     * Decrypt a command response\n     */\n    async decrypt(response, options = {}) {\n        const buffer = Buffer.isBuffer(response) ? response : (0, bson_1.serialize)(response, options);\n        const context = this._mongocrypt.makeDecryptionContext(buffer);\n        context.id = this._contextCounter++;\n        const stateMachine = new state_machine_1.StateMachine({\n            ...options,\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const decorateResult = this[kDecorateResult];\n        const result = await stateMachine.execute(this, context);\n        if (decorateResult) {\n            decorateDecryptionResult(result, response);\n        }\n        return result;\n    }\n    /**\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return (0, providers_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    /**\n     * Return the current libmongocrypt's CSFLE shared library version\n     * as `{ version: bigint, versionStr: string }`, or `null` if no CSFLE\n     * shared library was loaded.\n     */\n    get cryptSharedLibVersionInfo() {\n        return this._mongocrypt.cryptSharedLibVersionInfo;\n    }\n    static get libmongocryptVersion() {\n        return AutoEncrypter.getMongoCrypt().libmongocryptVersion;\n    }\n}\nexports.AutoEncrypter = AutoEncrypter;\n_a = kDecorateResult;\n/**\n * Recurse through the (identically-shaped) `decrypted` and `original`\n * objects and attach a `decryptedKeys` property on each sub-object that\n * contained encrypted fields. Because we only call this on BSON responses,\n * we do not need to worry about circular references.\n *\n * @internal\n */\nfunction decorateDecryptionResult(decrypted, original, isTopLevelDecorateCall = true) {\n    if (isTopLevelDecorateCall) {\n        // The original value could have been either a JS object or a BSON buffer\n        if (Buffer.isBuffer(original)) {\n            original = (0, bson_1.deserialize)(original);\n        }\n        if (Buffer.isBuffer(decrypted)) {\n            throw new error_1.MongoRuntimeError('Expected result of decryption to be deserialized BSON object');\n        }\n    }\n    if (!decrypted || typeof decrypted !== 'object')\n        return;\n    for (const k of Object.keys(decrypted)) {\n        const originalValue = original[k];\n        // An object was decrypted by libmongocrypt if and only if it was\n        // a BSON Binary object with subtype 6.\n        if (originalValue && originalValue._bsontype === 'Binary' && originalValue.sub_type === 6) {\n            if (!decrypted[kDecoratedKeys]) {\n                Object.defineProperty(decrypted, kDecoratedKeys, {\n                    value: [],\n                    configurable: true,\n                    enumerable: false,\n                    writable: false\n                });\n            }\n            // this is defined in the preceding if-statement\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            decrypted[kDecoratedKeys].push(k);\n            // Do not recurse into this decrypted value. It could be a sub-document/array,\n            // in which case there is no original value associated with its subfields.\n            continue;\n        }\n        decorateDecryptionResult(decrypted[k], originalValue, false);\n    }\n}\n//# sourceMappingURL=auto_encrypter.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/client_encryption.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/client_encryption.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ClientEncryption = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst cryptoCallbacks = __webpack_require__(/*! ./crypto_callbacks */ \"./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst index_1 = __webpack_require__(/*! ./providers/index */ \"./node_modules/mongodb/lib/client-side-encryption/providers/index.js\");\nconst state_machine_1 = __webpack_require__(/*! ./state_machine */ \"./node_modules/mongodb/lib/client-side-encryption/state_machine.js\");\n/**\n * @public\n * The public interface for explicit in-use encryption\n */\nclass ClientEncryption {\n    /** @internal */\n    static getMongoCrypt() {\n        const encryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in encryption) {\n            throw encryption.kModuleError;\n        }\n        return encryption.MongoCrypt;\n    }\n    /**\n     * Create a new encryption instance\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     local: {\n     *       key: masterKey // The master key used for encryption/decryption. A 96-byte long Buffer\n     *     }\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * new ClientEncryption(mongoClient, {\n     *   keyVaultNamespace: 'client.encryption',\n     *   kmsProviders: {\n     *     aws: {\n     *       accessKeyId: AWS_ACCESS_KEY,\n     *       secretAccessKey: AWS_SECRET_KEY\n     *     }\n     *   }\n     * });\n     * ```\n     */\n    constructor(client, options) {\n        this._client = client;\n        this._proxyOptions = options.proxyOptions ?? {};\n        this._tlsOptions = options.tlsOptions ?? {};\n        this._kmsProviders = options.kmsProviders || {};\n        if (options.keyVaultNamespace == null) {\n            throw new errors_1.MongoCryptInvalidArgumentError('Missing required option `keyVaultNamespace`');\n        }\n        const mongoCryptOptions = {\n            ...options,\n            cryptoCallbacks,\n            kmsProviders: !Buffer.isBuffer(this._kmsProviders)\n                ? (0, bson_1.serialize)(this._kmsProviders)\n                : this._kmsProviders\n        };\n        this._keyVaultNamespace = options.keyVaultNamespace;\n        this._keyVaultClient = options.keyVaultClient || client;\n        const MongoCrypt = ClientEncryption.getMongoCrypt();\n        this._mongoCrypt = new MongoCrypt(mongoCryptOptions);\n    }\n    /**\n     * Creates a data key used for explicit encryption and inserts it into the key vault namespace\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create a local key\n     * const dataKeyId = await clientEncryption.createDataKey('local');\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   }\n     * });\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Using async/await to create an aws key with a keyAltName\n     * const dataKeyId = await clientEncryption.createDataKey('aws', {\n     *   masterKey: {\n     *     region: 'us-east-1',\n     *     key: 'xxxxxxxxxxxxxx' // CMK ARN here\n     *   },\n     *   keyAltNames: [ 'mySpecialKey' ]\n     * });\n     * ```\n     */\n    async createDataKey(provider, options = {}) {\n        if (options.keyAltNames && !Array.isArray(options.keyAltNames)) {\n            throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but was of type ${typeof options.keyAltNames}.`);\n        }\n        let keyAltNames = undefined;\n        if (options.keyAltNames && options.keyAltNames.length > 0) {\n            keyAltNames = options.keyAltNames.map((keyAltName, i) => {\n                if (typeof keyAltName !== 'string') {\n                    throw new errors_1.MongoCryptInvalidArgumentError(`Option \"keyAltNames\" must be an array of strings, but item at index ${i} was of type ${typeof keyAltName}`);\n                }\n                return (0, bson_1.serialize)({ keyAltName });\n            });\n        }\n        let keyMaterial = undefined;\n        if (options.keyMaterial) {\n            keyMaterial = (0, bson_1.serialize)({ keyMaterial: options.keyMaterial });\n        }\n        const dataKeyBson = (0, bson_1.serialize)({\n            provider,\n            ...options.masterKey\n        });\n        const context = this._mongoCrypt.makeDataKeyContext(dataKeyBson, {\n            keyAltNames,\n            keyMaterial\n        });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const dataKey = await stateMachine.execute(this, context);\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const { insertedId } = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .insertOne(dataKey, { writeConcern: { w: 'majority' } });\n        return insertedId;\n    }\n    /**\n     * Searches the keyvault for any data keys matching the provided filter.  If there are matches, rewrapManyDataKey then attempts to re-wrap the data keys using the provided options.\n     *\n     * If no matches are found, then no bulk write is performed.\n     *\n     * @example\n     * ```ts\n     * // rewrapping all data data keys (using a filter that matches all documents)\n     * const filter = {};\n     *\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     * if (result.bulkWriteResult != null) {\n     *  // keys were re-wrapped, results will be available in the bulkWrite object.\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // attempting to rewrap all data keys with no matches\n     * const filter = { _id: new Binary() } // assume _id matches no documents in the database\n     * const result = await clientEncryption.rewrapManyDataKey(filter);\n     *\n     * if (result.bulkWriteResult == null) {\n     *  // no keys matched, `bulkWriteResult` does not exist on the result object\n     * }\n     * ```\n     */\n    async rewrapManyDataKey(filter, options) {\n        let keyEncryptionKeyBson = undefined;\n        if (options) {\n            const keyEncryptionKey = Object.assign({ provider: options.provider }, options.masterKey);\n            keyEncryptionKeyBson = (0, bson_1.serialize)(keyEncryptionKey);\n        }\n        const filterBson = (0, bson_1.serialize)(filter);\n        const context = this._mongoCrypt.makeRewrapManyDataKeyContext(filterBson, keyEncryptionKeyBson);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v: dataKeys } = await stateMachine.execute(this, context);\n        if (dataKeys.length === 0) {\n            return {};\n        }\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const replacements = dataKeys.map((key) => ({\n            updateOne: {\n                filter: { _id: key._id },\n                update: {\n                    $set: {\n                        masterKey: key.masterKey,\n                        keyMaterial: key.keyMaterial\n                    },\n                    $currentDate: {\n                        updateDate: true\n                    }\n                }\n            }\n        }));\n        const result = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .bulkWrite(replacements, {\n            writeConcern: { w: 'majority' }\n        });\n        return { bulkWriteResult: result };\n    }\n    /**\n     * Deletes the key with the provided id from the keyvault, if it exists.\n     *\n     * @example\n     * ```ts\n     * // delete a key by _id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const { deletedCount } = await clientEncryption.deleteKey(id);\n     *\n     * if (deletedCount != null && deletedCount > 0) {\n     *   // successful deletion\n     * }\n     * ```\n     *\n     */\n    async deleteKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .deleteOne({ _id }, { writeConcern: { w: 'majority' } });\n    }\n    /**\n     * Finds all the keys currently stored in the keyvault.\n     *\n     * This method will not throw.\n     *\n     * @returns a FindCursor over all keys in the keyvault.\n     * @example\n     * ```ts\n     * // fetching all keys\n     * const keys = await clientEncryption.getKeys().toArray();\n     * ```\n     */\n    getKeys() {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .find({}, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault with the specified _id.\n     *\n     * Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // getting a key by id\n     * const id = new Binary(); // id is a bson binary subtype 4 object\n     * const key = await clientEncryption.getKey(id);\n     * if (!key) {\n     *  // key is null if there was no matching key\n     * }\n     * ```\n     */\n    async getKey(_id) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ _id }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Finds a key in the keyvault which has the specified keyAltName.\n     *\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the keyAltName.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // get a key by alt name\n     * const keyAltName = 'keyAltName';\n     * const key = await clientEncryption.getKeyByAltName(keyAltName);\n     * if (!key) {\n     *  // key is null if there is no matching key\n     * }\n     * ```\n     */\n    async getKeyByAltName(keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        return this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOne({ keyAltNames: keyAltName }, { readConcern: { level: 'majority' } });\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to adding the new altKeyName).\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // adding an keyAltName to a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.addKeyAltName(id, keyAltName);\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async addKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, { $addToSet: { keyAltNames: keyAltName } }, { writeConcern: { w: 'majority' }, returnDocument: 'before' });\n        return value;\n    }\n    /**\n     * Adds a keyAltName to a key identified by the provided _id.\n     *\n     * This method resolves to/returns the *old* key value (prior to removing the new altKeyName).\n     *\n     * If the removed keyAltName is the last keyAltName for that key, the `altKeyNames` property is unset from the document.\n     *\n     * @param _id - The id of the document to update.\n     * @param keyAltName - a keyAltName to search for a key\n     * @returns Returns a promise that either resolves to a {@link DataKey} if a document matches the key or null if no documents\n     * match the id.  The promise rejects with an error if an error is thrown.\n     * @example\n     * ```ts\n     * // removing a key alt name from a data key\n     * const id = new Binary();  // id is a bson binary subtype 4 object\n     * const keyAltName = 'keyAltName';\n     * const oldKey = await clientEncryption.removeKeyAltName(id, keyAltName);\n     *\n     * if (!oldKey) {\n     *  // null is returned if there is no matching document with an id matching the supplied id\n     * }\n     * ```\n     */\n    async removeKeyAltName(_id, keyAltName) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(this._keyVaultNamespace);\n        const pipeline = [\n            {\n                $set: {\n                    keyAltNames: {\n                        $cond: [\n                            {\n                                $eq: ['$keyAltNames', [keyAltName]]\n                            },\n                            '$$REMOVE',\n                            {\n                                $filter: {\n                                    input: '$keyAltNames',\n                                    cond: {\n                                        $ne: ['$$this', keyAltName]\n                                    }\n                                }\n                            }\n                        ]\n                    }\n                }\n            }\n        ];\n        const value = await this._keyVaultClient\n            .db(dbName)\n            .collection(collectionName)\n            .findOneAndUpdate({ _id }, pipeline, {\n            writeConcern: { w: 'majority' },\n            returnDocument: 'before'\n        });\n        return value;\n    }\n    /**\n     * A convenience method for creating an encrypted collection.\n     * This method will create data keys for any encryptedFields that do not have a `keyId` defined\n     * and then create a new collection with the full set of encryptedFields.\n     *\n     * @param db - A Node.js driver Db object with which to create the collection\n     * @param name - The name of the collection to be created\n     * @param options - Options for createDataKey and for createCollection\n     * @returns created collection and generated encryptedFields\n     * @throws MongoCryptCreateDataKeyError - If part way through the process a createDataKey invocation fails, an error will be rejected that has the partial `encryptedFields` that were created.\n     * @throws MongoCryptCreateEncryptedCollectionError - If creating the collection fails, an error will be rejected that has the entire `encryptedFields` that were created.\n     */\n    async createEncryptedCollection(db, name, options) {\n        const { provider, masterKey, createCollectionOptions: { encryptedFields: { ...encryptedFields }, ...createCollectionOptions } } = options;\n        if (Array.isArray(encryptedFields.fields)) {\n            const createDataKeyPromises = encryptedFields.fields.map(async (field) => field == null || typeof field !== 'object' || field.keyId != null\n                ? field\n                : {\n                    ...field,\n                    keyId: await this.createDataKey(provider, { masterKey })\n                });\n            const createDataKeyResolutions = await Promise.allSettled(createDataKeyPromises);\n            encryptedFields.fields = createDataKeyResolutions.map((resolution, index) => resolution.status === 'fulfilled' ? resolution.value : encryptedFields.fields[index]);\n            const rejection = createDataKeyResolutions.find((result) => result.status === 'rejected');\n            if (rejection != null) {\n                throw new errors_1.MongoCryptCreateDataKeyError(encryptedFields, { cause: rejection.reason });\n            }\n        }\n        try {\n            const collection = await db.createCollection(name, {\n                ...createCollectionOptions,\n                encryptedFields\n            });\n            return { collection, encryptedFields };\n        }\n        catch (cause) {\n            throw new errors_1.MongoCryptCreateEncryptedCollectionError(encryptedFields, { cause });\n        }\n    }\n    /**\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to serialize. Must be of a type that can be serialized into BSON\n     * @param options -\n     * @returns a Promise that either resolves with the encrypted value, or rejects with an error.\n     *\n     * @example\n     * ```ts\n     * // Encryption with async/await api\n     * async function encryptMyData(value) {\n     *   const keyId = await clientEncryption.createDataKey('local');\n     *   return clientEncryption.encrypt(value, { keyId, algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     *\n     * @example\n     * ```ts\n     * // Encryption using a keyAltName\n     * async function encryptMyData(value) {\n     *   await clientEncryption.createDataKey('local', { keyAltNames: 'mySpecialKey' });\n     *   return clientEncryption.encrypt(value, { keyAltName: 'mySpecialKey', algorithm: 'AEAD_AES_256_CBC_HMAC_SHA_512-Deterministic' });\n     * }\n     * ```\n     */\n    async encrypt(value, options) {\n        return this._encrypt(value, false, options);\n    }\n    /**\n     * Encrypts a Match Expression or Aggregate Expression to query a range index.\n     *\n     * Only supported when queryType is \"rangePreview\" and algorithm is \"RangePreview\".\n     *\n     * @experimental The Range algorithm is experimental only. It is not intended for production use. It is subject to breaking changes.\n     *\n     * @param expression - a BSON document of one of the following forms:\n     *  1. A Match Expression of this form:\n     *      `{$and: [{<field>: {$gt: <value1>}}, {<field>: {$lt: <value2> }}]}`\n     *  2. An Aggregate Expression of this form:\n     *      `{$and: [{$gt: [<fieldpath>, <value1>]}, {$lt: [<fieldpath>, <value2>]}]}`\n     *\n     *    `$gt` may also be `$gte`. `$lt` may also be `$lte`.\n     *\n     * @param options -\n     * @returns Returns a Promise that either resolves with the encrypted value or rejects with an error.\n     */\n    async encryptExpression(expression, options) {\n        return this._encrypt(expression, true, options);\n    }\n    /**\n     * Explicitly decrypt a provided encrypted value\n     *\n     * @param value - An encrypted value\n     * @returns a Promise that either resolves with the decrypted value, or rejects with an error\n     *\n     * @example\n     * ```ts\n     * // Decrypting value with async/await API\n     * async function decryptMyValue(value) {\n     *   return clientEncryption.decrypt(value);\n     * }\n     * ```\n     */\n    async decrypt(value) {\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const context = this._mongoCrypt.makeExplicitDecryptionContext(valueBuffer);\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const { v } = await stateMachine.execute(this, context);\n        return v;\n    }\n    /**\n     * @internal\n     * Ask the user for KMS credentials.\n     *\n     * This returns anything that looks like the kmsProviders original input\n     * option. It can be empty, and any provider specified here will override\n     * the original ones.\n     */\n    async askForKMSCredentials() {\n        return (0, index_1.refreshKMSCredentials)(this._kmsProviders);\n    }\n    static get libmongocryptVersion() {\n        return ClientEncryption.getMongoCrypt().libmongocryptVersion;\n    }\n    /**\n     * @internal\n     * A helper that perform explicit encryption of values and expressions.\n     * Explicitly encrypt a provided value. Note that either `options.keyId` or `options.keyAltName` must\n     * be specified. Specifying both `options.keyId` and `options.keyAltName` is considered an error.\n     *\n     * @param value - The value that you wish to encrypt. Must be of a type that can be serialized into BSON\n     * @param expressionMode - a boolean that indicates whether or not to encrypt the value as an expression\n     * @param options - options to pass to encrypt\n     * @returns the raw result of the call to stateMachine.execute().  When expressionMode is set to true, the return\n     *          value will be a bson document.  When false, the value will be a BSON Binary.\n     *\n     */\n    async _encrypt(value, expressionMode, options) {\n        const { algorithm, keyId, keyAltName, contentionFactor, queryType, rangeOptions } = options;\n        const contextOptions = {\n            expressionMode,\n            algorithm\n        };\n        if (keyId) {\n            contextOptions.keyId = keyId.buffer;\n        }\n        if (keyAltName) {\n            if (keyId) {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options\" cannot contain both \"keyId\" and \"keyAltName\"`);\n            }\n            if (typeof keyAltName !== 'string') {\n                throw new errors_1.MongoCryptInvalidArgumentError(`\"options.keyAltName\" must be of type string, but was of type ${typeof keyAltName}`);\n            }\n            contextOptions.keyAltName = (0, bson_1.serialize)({ keyAltName });\n        }\n        if (typeof contentionFactor === 'number' || typeof contentionFactor === 'bigint') {\n            contextOptions.contentionFactor = contentionFactor;\n        }\n        if (typeof queryType === 'string') {\n            contextOptions.queryType = queryType;\n        }\n        if (typeof rangeOptions === 'object') {\n            contextOptions.rangeOptions = (0, bson_1.serialize)(rangeOptions);\n        }\n        const valueBuffer = (0, bson_1.serialize)({ v: value });\n        const stateMachine = new state_machine_1.StateMachine({\n            proxyOptions: this._proxyOptions,\n            tlsOptions: this._tlsOptions\n        });\n        const context = this._mongoCrypt.makeExplicitEncryptionContext(valueBuffer, contextOptions);\n        const result = await stateMachine.execute(this, context);\n        return result.v;\n    }\n}\nexports.ClientEncryption = ClientEncryption;\n//# sourceMappingURL=client_encryption.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/client_encryption.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.hmacSha256Hook = exports.hmacSha512Hook = exports.aes256CtrDecryptHook = exports.aes256CtrEncryptHook = exports.aes256CbcDecryptHook = exports.aes256CbcEncryptHook = exports.signRsaSha256Hook = exports.makeHmacHook = exports.sha256Hook = exports.randomHook = exports.makeAES256Hook = void 0;\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nfunction makeAES256Hook(method, mode) {\n    return function (key, iv, input, output) {\n        let result;\n        try {\n            const cipher = crypto[method](mode, key, iv);\n            cipher.setAutoPadding(false);\n            result = cipher.update(input);\n            const final = cipher.final();\n            if (final.length > 0) {\n                result = Buffer.concat([result, final]);\n            }\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeAES256Hook = makeAES256Hook;\nfunction randomHook(buffer, count) {\n    try {\n        crypto.randomFillSync(buffer, 0, count);\n    }\n    catch (e) {\n        return e;\n    }\n    return count;\n}\nexports.randomHook = randomHook;\nfunction sha256Hook(input, output) {\n    let result;\n    try {\n        result = crypto.createHash('sha256').update(input).digest();\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.sha256Hook = sha256Hook;\nfunction makeHmacHook(algorithm) {\n    return (key, input, output) => {\n        let result;\n        try {\n            result = crypto.createHmac(algorithm, key).update(input).digest();\n        }\n        catch (e) {\n            return e;\n        }\n        result.copy(output);\n        return result.length;\n    };\n}\nexports.makeHmacHook = makeHmacHook;\nfunction signRsaSha256Hook(key, input, output) {\n    let result;\n    try {\n        const signer = crypto.createSign('sha256WithRSAEncryption');\n        const privateKey = Buffer.from(`-----BEGIN PRIVATE KEY-----\\n${key.toString('base64')}\\n-----END PRIVATE KEY-----\\n`);\n        result = signer.update(input).end().sign(privateKey);\n    }\n    catch (e) {\n        return e;\n    }\n    result.copy(output);\n    return result.length;\n}\nexports.signRsaSha256Hook = signRsaSha256Hook;\nexports.aes256CbcEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-cbc');\nexports.aes256CbcDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-cbc');\nexports.aes256CtrEncryptHook = makeAES256Hook('createCipheriv', 'aes-256-ctr');\nexports.aes256CtrDecryptHook = makeAES256Hook('createDecipheriv', 'aes-256-ctr');\nexports.hmacSha512Hook = makeHmacHook('sha512');\nexports.hmacSha256Hook = makeHmacHook('sha256');\n//# sourceMappingURL=crypto_callbacks.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/crypto_callbacks.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/errors.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/errors.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptAzureKMSRequestError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @public\n * An error indicating that something went wrong specifically with MongoDB Client Encryption\n */\nclass MongoCryptError extends error_1.MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options = {}) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoCryptError';\n    }\n}\nexports.MongoCryptError = MongoCryptError;\n/**\n * @public\n *\n * An error indicating an invalid argument was provided to an encryption API.\n */\nclass MongoCryptInvalidArgumentError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCryptInvalidArgumentError';\n    }\n}\nexports.MongoCryptInvalidArgumentError = MongoCryptInvalidArgumentError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create data keys\n */\nclass MongoCryptCreateDataKeyError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to complete creating data keys: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateDataKeyError';\n    }\n}\nexports.MongoCryptCreateDataKeyError = MongoCryptCreateDataKeyError;\n/**\n * @public\n * An error indicating that `ClientEncryption.createEncryptedCollection()` failed to create a collection\n */\nclass MongoCryptCreateEncryptedCollectionError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(encryptedFields, { cause }) {\n        super(`Unable to create collection: ${cause.message}`, { cause });\n        this.encryptedFields = encryptedFields;\n    }\n    get name() {\n        return 'MongoCryptCreateEncryptedCollectionError';\n    }\n}\nexports.MongoCryptCreateEncryptedCollectionError = MongoCryptCreateEncryptedCollectionError;\n/**\n * @public\n * An error indicating that mongodb-client-encryption failed to auto-refresh Azure KMS credentials.\n */\nclass MongoCryptAzureKMSRequestError extends MongoCryptError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, body) {\n        super(message);\n        this.body = body;\n    }\n    get name() {\n        return 'MongoCryptAzureKMSRequestError';\n    }\n}\nexports.MongoCryptAzureKMSRequestError = MongoCryptAzureKMSRequestError;\n/** @public */\nclass MongoCryptKMSRequestNetworkTimeoutError extends MongoCryptError {\n    get name() {\n        return 'MongoCryptKMSRequestNetworkTimeoutError';\n    }\n}\nexports.MongoCryptKMSRequestNetworkTimeoutError = MongoCryptKMSRequestNetworkTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongocryptdManager = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * @internal\n * An internal class that handles spawning a mongocryptd.\n */\nclass MongocryptdManager {\n    constructor(extraOptions = {}) {\n        this.uri =\n            typeof extraOptions.mongocryptdURI === 'string' && extraOptions.mongocryptdURI.length > 0\n                ? extraOptions.mongocryptdURI\n                : MongocryptdManager.DEFAULT_MONGOCRYPTD_URI;\n        this.bypassSpawn = !!extraOptions.mongocryptdBypassSpawn;\n        this.spawnPath = extraOptions.mongocryptdSpawnPath || '';\n        this.spawnArgs = [];\n        if (Array.isArray(extraOptions.mongocryptdSpawnArgs)) {\n            this.spawnArgs = this.spawnArgs.concat(extraOptions.mongocryptdSpawnArgs);\n        }\n        if (this.spawnArgs\n            .filter(arg => typeof arg === 'string')\n            .every(arg => arg.indexOf('--idleShutdownTimeoutSecs') < 0)) {\n            this.spawnArgs.push('--idleShutdownTimeoutSecs', '60');\n        }\n    }\n    /**\n     * Will check to see if a mongocryptd is up. If it is not up, it will attempt\n     * to spawn a mongocryptd in a detached process, and then wait for it to be up.\n     */\n    async spawn() {\n        const cmdName = this.spawnPath || 'mongocryptd';\n        // eslint-disable-next-line @typescript-eslint/no-var-requires\n        const { spawn } = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'child_process'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        // Spawned with stdio: ignore and detached: true\n        // to ensure child can outlive parent.\n        this._child = spawn(cmdName, this.spawnArgs, {\n            stdio: 'ignore',\n            detached: true\n        });\n        this._child.on('error', () => {\n            // From the FLE spec:\n            // \"The stdout and stderr of the spawned process MUST not be exposed in the driver\n            // (e.g. redirect to /dev/null). Users can pass the argument --logpath to\n            // extraOptions.mongocryptdSpawnArgs if they need to inspect mongocryptd logs.\n            // If spawning is necessary, the driver MUST spawn mongocryptd whenever server\n            // selection on the MongoClient to mongocryptd fails. If the MongoClient fails to\n            // connect after spawning, the server selection error is propagated to the user.\"\n            // The AutoEncrypter and MongoCryptdManager should work together to spawn\n            // mongocryptd whenever necessary.  Additionally, the `mongocryptd` intentionally\n            // shuts down after 60s and gets respawned when necessary.  We rely on server\n            // selection timeouts when connecting to the `mongocryptd` to inform users that something\n            // has been configured incorrectly.  For those reasons, we suppress stderr from\n            // the `mongocryptd` process and immediately unref the process.\n        });\n        // unref child to remove handle from event loop\n        this._child.unref();\n    }\n    /**\n     * @returns the result of `fn` or rejects with an error.\n     */\n    async withRespawn(fn) {\n        try {\n            const result = await fn();\n            return result;\n        }\n        catch (err) {\n            // If we are not bypassing spawning, then we should retry once on a MongoTimeoutError (server selection error)\n            const shouldSpawn = err instanceof error_1.MongoNetworkTimeoutError && !this.bypassSpawn;\n            if (!shouldSpawn) {\n                throw err;\n            }\n        }\n        await this.spawn();\n        const result = await fn();\n        return result;\n    }\n}\nMongocryptdManager.DEFAULT_MONGOCRYPTD_URI = 'mongodb://localhost:27020';\nexports.MongocryptdManager = MongocryptdManager;\n//# sourceMappingURL=mongocryptd_manager.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/mongocryptd_manager.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/aws.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/aws.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAWSCredentials = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\n/**\n * @internal\n */\nasync function loadAWSCredentials(kmsProviders) {\n    const credentialProvider = (0, deps_1.getAwsCredentialProvider)();\n    if ('kModuleError' in credentialProvider) {\n        return kmsProviders;\n    }\n    const { fromNodeProviderChain } = credentialProvider;\n    const provider = fromNodeProviderChain();\n    // The state machine is the only place calling this so it will\n    // catch if there is a rejection here.\n    const aws = await provider();\n    return { ...kmsProviders, aws };\n}\nexports.loadAWSCredentials = loadAWSCredentials;\n//# sourceMappingURL=aws.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/providers/aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/azure.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/azure.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadAzureCredentials = exports.fetchAzureKMSToken = exports.prepareRequest = exports.tokenCache = exports.AzureCredentialCache = void 0;\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/client-side-encryption/providers/utils.js\");\nconst MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS = 6000;\n/**\n * @internal\n */\nclass AzureCredentialCache {\n    constructor() {\n        this.cachedToken = null;\n    }\n    async getToken() {\n        if (this.cachedToken == null || this.needsRefresh(this.cachedToken)) {\n            this.cachedToken = await this._getToken();\n        }\n        return { accessToken: this.cachedToken.accessToken };\n    }\n    needsRefresh(token) {\n        const timeUntilExpirationMS = token.expiresOnTimestamp - Date.now();\n        return timeUntilExpirationMS <= MINIMUM_TOKEN_REFRESH_IN_MILLISECONDS;\n    }\n    /**\n     * exposed for testing\n     */\n    resetCache() {\n        this.cachedToken = null;\n    }\n    /**\n     * exposed for testing\n     */\n    _getToken() {\n        return fetchAzureKMSToken();\n    }\n}\nexports.AzureCredentialCache = AzureCredentialCache;\n/** @internal */\nexports.tokenCache = new AzureCredentialCache();\n/** @internal */\nasync function parseResponse(response) {\n    const { status, body: rawBody } = response;\n    const body = (() => {\n        try {\n            return JSON.parse(rawBody);\n        }\n        catch {\n            throw new errors_1.MongoCryptAzureKMSRequestError('Malformed JSON body in GET request.');\n        }\n    })();\n    if (status !== 200) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Unable to complete request.', body);\n    }\n    if (!body.access_token) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `access_token`.');\n    }\n    if (!body.expires_in) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - missing field `expires_in`.');\n    }\n    const expiresInMS = Number(body.expires_in) * 1000;\n    if (Number.isNaN(expiresInMS)) {\n        throw new errors_1.MongoCryptAzureKMSRequestError('Malformed response body - unable to parse int from `expires_in` field.');\n    }\n    return {\n        accessToken: body.access_token,\n        expiresOnTimestamp: Date.now() + expiresInMS\n    };\n}\n/**\n * @internal\n *\n * parses any options provided by prose tests to `fetchAzureKMSToken` and merges them with\n * the default values for headers and the request url.\n */\nfunction prepareRequest(options) {\n    const url = new URL(options.url?.toString() ?? 'http://169.254.169.254/metadata/identity/oauth2/token');\n    url.searchParams.append('api-version', '2018-02-01');\n    url.searchParams.append('resource', 'https://vault.azure.net');\n    const headers = { ...options.headers, 'Content-Type': 'application/json', Metadata: true };\n    return { headers, url };\n}\nexports.prepareRequest = prepareRequest;\n/**\n * @internal\n *\n * `AzureKMSRequestOptions` allows prose tests to modify the http request sent to the idms\n * servers.  This is required to simulate different server conditions.  No options are expected to\n * be set outside of tests.\n *\n * exposed for CSFLE\n * [prose test 18](https://github.com/mongodb/specifications/tree/master/source/client-side-encryption/tests#azure-imds-credentials)\n */\nasync function fetchAzureKMSToken(options = {}) {\n    const { headers, url } = prepareRequest(options);\n    const response = await (0, utils_1.get)(url, { headers }).catch(error => {\n        if (error instanceof errors_1.MongoCryptKMSRequestNetworkTimeoutError) {\n            throw new errors_1.MongoCryptAzureKMSRequestError(`[Azure KMS] ${error.message}`);\n        }\n        throw error;\n    });\n    return parseResponse(response);\n}\nexports.fetchAzureKMSToken = fetchAzureKMSToken;\n/**\n * @internal\n *\n * @throws Will reject with a `MongoCryptError` if the http request fails or the http response is malformed.\n */\nasync function loadAzureCredentials(kmsProviders) {\n    const azure = await exports.tokenCache.getToken();\n    return { ...kmsProviders, azure };\n}\nexports.loadAzureCredentials = loadAzureCredentials;\n//# sourceMappingURL=azure.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/providers/azure.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.loadGCPCredentials = void 0;\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\n/** @internal */\nasync function loadGCPCredentials(kmsProviders) {\n    const gcpMetadata = (0, deps_1.getGcpMetadata)();\n    if ('kModuleError' in gcpMetadata) {\n        return kmsProviders;\n    }\n    const { access_token: accessToken } = await gcpMetadata.instance({\n        property: 'service-accounts/default/token'\n    });\n    return { ...kmsProviders, gcp: { accessToken } };\n}\nexports.loadGCPCredentials = loadGCPCredentials;\n//# sourceMappingURL=gcp.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/index.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.refreshKMSCredentials = exports.isEmptyCredentials = void 0;\nconst aws_1 = __webpack_require__(/*! ./aws */ \"./node_modules/mongodb/lib/client-side-encryption/providers/aws.js\");\nconst azure_1 = __webpack_require__(/*! ./azure */ \"./node_modules/mongodb/lib/client-side-encryption/providers/azure.js\");\nconst gcp_1 = __webpack_require__(/*! ./gcp */ \"./node_modules/mongodb/lib/client-side-encryption/providers/gcp.js\");\n/**\n * Auto credential fetching should only occur when the provider is defined on the kmsProviders map\n * and the settings are an empty object.\n *\n * This is distinct from a nullish provider key.\n *\n * @internal - exposed for testing purposes only\n */\nfunction isEmptyCredentials(providerName, kmsProviders) {\n    const provider = kmsProviders[providerName];\n    if (provider == null) {\n        return false;\n    }\n    return typeof provider === 'object' && Object.keys(provider).length === 0;\n}\nexports.isEmptyCredentials = isEmptyCredentials;\n/**\n * Load cloud provider credentials for the user provided KMS providers.\n * Credentials will only attempt to get loaded if they do not exist\n * and no existing credentials will get overwritten.\n *\n * @internal\n */\nasync function refreshKMSCredentials(kmsProviders) {\n    let finalKMSProviders = kmsProviders;\n    if (isEmptyCredentials('aws', kmsProviders)) {\n        finalKMSProviders = await (0, aws_1.loadAWSCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('gcp', kmsProviders)) {\n        finalKMSProviders = await (0, gcp_1.loadGCPCredentials)(finalKMSProviders);\n    }\n    if (isEmptyCredentials('azure', kmsProviders)) {\n        finalKMSProviders = await (0, azure_1.loadAzureCredentials)(finalKMSProviders);\n    }\n    return finalKMSProviders;\n}\nexports.refreshKMSCredentials = refreshKMSCredentials;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/providers/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/providers/utils.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/providers/utils.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.get = void 0;\nconst http = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'http'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\n/**\n * @internal\n */\nfunction get(url, options = {}) {\n    return new Promise((resolve, reject) => {\n        /* eslint-disable prefer-const */\n        let timeoutId;\n        const request = http\n            .get(url, options, response => {\n            response.setEncoding('utf8');\n            let body = '';\n            response.on('data', chunk => (body += chunk));\n            response.on('end', () => {\n                (0, timers_1.clearTimeout)(timeoutId);\n                resolve({ status: response.statusCode, body });\n            });\n        })\n            .on('error', error => {\n            (0, timers_1.clearTimeout)(timeoutId);\n            reject(error);\n        })\n            .end();\n        timeoutId = (0, timers_1.setTimeout)(() => {\n            request.destroy(new errors_1.MongoCryptKMSRequestNetworkTimeoutError(`request timed out after 10 seconds`));\n        }, 10000);\n    });\n}\nexports.get = get;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/providers/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/client-side-encryption/state_machine.js":
/*!**************************************************************************!*\
  !*** ./node_modules/mongodb/lib/client-side-encryption/state_machine.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StateMachine = void 0;\nconst fs = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'fs/promises'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst net = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'net'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst tls = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'tls'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\n// libmongocrypt states\nconst MONGOCRYPT_CTX_ERROR = 0;\nconst MONGOCRYPT_CTX_NEED_MONGO_COLLINFO = 1;\nconst MONGOCRYPT_CTX_NEED_MONGO_MARKINGS = 2;\nconst MONGOCRYPT_CTX_NEED_MONGO_KEYS = 3;\nconst MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS = 7;\nconst MONGOCRYPT_CTX_NEED_KMS = 4;\nconst MONGOCRYPT_CTX_READY = 5;\nconst MONGOCRYPT_CTX_DONE = 6;\nconst HTTPS_PORT = 443;\nconst stateToString = new Map([\n    [MONGOCRYPT_CTX_ERROR, 'MONGOCRYPT_CTX_ERROR'],\n    [MONGOCRYPT_CTX_NEED_MONGO_COLLINFO, 'MONGOCRYPT_CTX_NEED_MONGO_COLLINFO'],\n    [MONGOCRYPT_CTX_NEED_MONGO_MARKINGS, 'MONGOCRYPT_CTX_NEED_MONGO_MARKINGS'],\n    [MONGOCRYPT_CTX_NEED_MONGO_KEYS, 'MONGOCRYPT_CTX_NEED_MONGO_KEYS'],\n    [MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS, 'MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS'],\n    [MONGOCRYPT_CTX_NEED_KMS, 'MONGOCRYPT_CTX_NEED_KMS'],\n    [MONGOCRYPT_CTX_READY, 'MONGOCRYPT_CTX_READY'],\n    [MONGOCRYPT_CTX_DONE, 'MONGOCRYPT_CTX_DONE']\n]);\nconst INSECURE_TLS_OPTIONS = [\n    'tlsInsecure',\n    'tlsAllowInvalidCertificates',\n    'tlsAllowInvalidHostnames',\n    // These options are disallowed by the spec, so we explicitly filter them out if provided, even\n    // though the StateMachine does not declare support for these options.\n    'tlsDisableOCSPEndpointCheck',\n    'tlsDisableCertificateRevocationCheck'\n];\n/**\n * Helper function for logging. Enabled by setting the environment flag MONGODB_CRYPT_DEBUG.\n * @param msg - Anything you want to be logged.\n */\nfunction debug(msg) {\n    if (process.env.MONGODB_CRYPT_DEBUG) {\n        // eslint-disable-next-line no-console\n        console.error(msg);\n    }\n}\n/**\n * @internal\n * An internal class that executes across a MongoCryptContext until either\n * a finishing state or an error is reached. Do not instantiate directly.\n */\nclass StateMachine {\n    constructor(options, bsonOptions = (0, bson_1.pluckBSONSerializeOptions)(options)) {\n        this.options = options;\n        this.bsonOptions = bsonOptions;\n    }\n    /**\n     * Executes the state machine according to the specification\n     */\n    async execute(executor, context) {\n        const keyVaultNamespace = executor._keyVaultNamespace;\n        const keyVaultClient = executor._keyVaultClient;\n        const metaDataClient = executor._metaDataClient;\n        const mongocryptdClient = executor._mongocryptdClient;\n        const mongocryptdManager = executor._mongocryptdManager;\n        let result = null;\n        while (context.state !== MONGOCRYPT_CTX_DONE && context.state !== MONGOCRYPT_CTX_ERROR) {\n            debug(`[context#${context.id}] ${stateToString.get(context.state) || context.state}`);\n            switch (context.state) {\n                case MONGOCRYPT_CTX_NEED_MONGO_COLLINFO: {\n                    const filter = (0, bson_1.deserialize)(context.nextMongoOperation());\n                    if (!metaDataClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_COLLINFO but metadata client is undefined');\n                    }\n                    const collInfo = await this.fetchCollectionInfo(metaDataClient, context.ns, filter);\n                    if (collInfo) {\n                        context.addMongoOperationResponse(collInfo);\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_MARKINGS: {\n                    const command = context.nextMongoOperation();\n                    if (!mongocryptdClient) {\n                        throw new errors_1.MongoCryptError('unreachable state machine state: entered MONGOCRYPT_CTX_NEED_MONGO_MARKINGS but mongocryptdClient is undefined');\n                    }\n                    // When we are using the shared library, we don't have a mongocryptd manager.\n                    const markedCommand = mongocryptdManager\n                        ? await mongocryptdManager.withRespawn(this.markCommand.bind(this, mongocryptdClient, context.ns, command))\n                        : await this.markCommand(mongocryptdClient, context.ns, command);\n                    context.addMongoOperationResponse(markedCommand);\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_MONGO_KEYS: {\n                    const filter = context.nextMongoOperation();\n                    const keys = await this.fetchKeys(keyVaultClient, keyVaultNamespace, filter);\n                    if (keys.length === 0) {\n                        // This is kind of a hack.  For `rewrapManyDataKey`, we have tests that\n                        // guarantee that when there are no matching keys, `rewrapManyDataKey` returns\n                        // nothing.  We also have tests for auto encryption that guarantee for `encrypt`\n                        // we return an error when there are no matching keys.  This error is generated in\n                        // subsequent iterations of the state machine.\n                        // Some apis (`encrypt`) throw if there are no filter matches and others (`rewrapManyDataKey`)\n                        // do not.  We set the result manually here, and let the state machine continue.  `libmongocrypt`\n                        // will inform us if we need to error by setting the state to `MONGOCRYPT_CTX_ERROR` but\n                        // otherwise we'll return `{ v: [] }`.\n                        result = { v: [] };\n                    }\n                    for await (const key of keys) {\n                        context.addMongoOperationResponse((0, bson_1.serialize)(key));\n                    }\n                    context.finishMongoOperation();\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS_CREDENTIALS: {\n                    const kmsProviders = await executor.askForKMSCredentials();\n                    context.provideKMSProviders((0, bson_1.serialize)(kmsProviders));\n                    break;\n                }\n                case MONGOCRYPT_CTX_NEED_KMS: {\n                    const requests = Array.from(this.requests(context));\n                    await Promise.all(requests);\n                    context.finishKMSRequests();\n                    break;\n                }\n                case MONGOCRYPT_CTX_READY: {\n                    const finalizedContext = context.finalize();\n                    // @ts-expect-error finalize can change the state, check for error\n                    if (context.state === MONGOCRYPT_CTX_ERROR) {\n                        const message = context.status.message || 'Finalization error';\n                        throw new errors_1.MongoCryptError(message);\n                    }\n                    result = (0, bson_1.deserialize)(finalizedContext, this.options);\n                    break;\n                }\n                default:\n                    throw new errors_1.MongoCryptError(`Unknown state: ${context.state}`);\n            }\n        }\n        if (context.state === MONGOCRYPT_CTX_ERROR || result == null) {\n            const message = context.status.message;\n            if (!message) {\n                debug(`unidentifiable error in MongoCrypt - received an error status from \\`libmongocrypt\\` but received no error message.`);\n            }\n            throw new errors_1.MongoCryptError(message ??\n                'unidentifiable error in MongoCrypt - received an error status from `libmongocrypt` but received no error message.');\n        }\n        return result;\n    }\n    /**\n     * Handles the request to the KMS service. Exposed for testing purposes. Do not directly invoke.\n     * @param kmsContext - A C++ KMS context returned from the bindings\n     * @returns A promise that resolves when the KMS reply has be fully parsed\n     */\n    kmsRequest(request) {\n        const parsedUrl = request.endpoint.split(':');\n        const port = parsedUrl[1] != null ? Number.parseInt(parsedUrl[1], 10) : HTTPS_PORT;\n        const options = {\n            host: parsedUrl[0],\n            servername: parsedUrl[0],\n            port\n        };\n        const message = request.message;\n        // TODO(NODE-3959): We can adopt `for-await on(socket, 'data')` with logic to control abort\n        // eslint-disable-next-line @typescript-eslint/no-misused-promises, no-async-promise-executor\n        return new Promise(async (resolve, reject) => {\n            const buffer = new utils_1.BufferPool();\n            // eslint-disable-next-line prefer-const\n            let socket;\n            let rawSocket;\n            function destroySockets() {\n                for (const sock of [socket, rawSocket]) {\n                    if (sock) {\n                        sock.removeAllListeners();\n                        sock.destroy();\n                    }\n                }\n            }\n            function ontimeout() {\n                destroySockets();\n                reject(new errors_1.MongoCryptError('KMS request timed out'));\n            }\n            function onerror(err) {\n                destroySockets();\n                const mcError = new errors_1.MongoCryptError('KMS request failed', { cause: err });\n                reject(mcError);\n            }\n            if (this.options.proxyOptions && this.options.proxyOptions.proxyHost) {\n                rawSocket = net.connect({\n                    host: this.options.proxyOptions.proxyHost,\n                    port: this.options.proxyOptions.proxyPort || 1080\n                });\n                rawSocket.on('timeout', ontimeout);\n                rawSocket.on('error', onerror);\n                try {\n                    // eslint-disable-next-line @typescript-eslint/no-var-requires\n                    const events = __webpack_require__(/*! events */ \"./node_modules/events/events.js\");\n                    await events.once(rawSocket, 'connect');\n                    socks ??= loadSocks();\n                    options.socket = (await socks.SocksClient.createConnection({\n                        existing_socket: rawSocket,\n                        command: 'connect',\n                        destination: { host: options.host, port: options.port },\n                        proxy: {\n                            // host and port are ignored because we pass existing_socket\n                            host: 'iLoveJavaScript',\n                            port: 0,\n                            type: 5,\n                            userId: this.options.proxyOptions.proxyUsername,\n                            password: this.options.proxyOptions.proxyPassword\n                        }\n                    })).socket;\n                }\n                catch (err) {\n                    return onerror(err);\n                }\n            }\n            const tlsOptions = this.options.tlsOptions;\n            if (tlsOptions) {\n                const kmsProvider = request.kmsProvider;\n                const providerTlsOptions = tlsOptions[kmsProvider];\n                if (providerTlsOptions) {\n                    const error = this.validateTlsOptions(kmsProvider, providerTlsOptions);\n                    if (error)\n                        reject(error);\n                    try {\n                        await this.setTlsOptions(providerTlsOptions, options);\n                    }\n                    catch (error) {\n                        return onerror(error);\n                    }\n                }\n            }\n            socket = tls.connect(options, () => {\n                socket.write(message);\n            });\n            socket.once('timeout', ontimeout);\n            socket.once('error', onerror);\n            socket.on('data', data => {\n                buffer.append(data);\n                while (request.bytesNeeded > 0 && buffer.length) {\n                    const bytesNeeded = Math.min(request.bytesNeeded, buffer.length);\n                    request.addResponse(buffer.read(bytesNeeded));\n                }\n                if (request.bytesNeeded <= 0) {\n                    // There's no need for any more activity on this socket at this point.\n                    destroySockets();\n                    resolve();\n                }\n            });\n        });\n    }\n    *requests(context) {\n        for (let request = context.nextKMSRequest(); request != null; request = context.nextKMSRequest()) {\n            yield this.kmsRequest(request);\n        }\n    }\n    /**\n     * Validates the provided TLS options are secure.\n     *\n     * @param kmsProvider - The KMS provider name.\n     * @param tlsOptions - The client TLS options for the provider.\n     *\n     * @returns An error if any option is invalid.\n     */\n    validateTlsOptions(kmsProvider, tlsOptions) {\n        const tlsOptionNames = Object.keys(tlsOptions);\n        for (const option of INSECURE_TLS_OPTIONS) {\n            if (tlsOptionNames.includes(option)) {\n                return new errors_1.MongoCryptError(`Insecure TLS options prohibited for ${kmsProvider}: ${option}`);\n            }\n        }\n    }\n    /**\n     * Sets only the valid secure TLS options.\n     *\n     * @param tlsOptions - The client TLS options for the provider.\n     * @param options - The existing connection options.\n     */\n    async setTlsOptions(tlsOptions, options) {\n        if (tlsOptions.tlsCertificateKeyFile) {\n            const cert = await fs.readFile(tlsOptions.tlsCertificateKeyFile);\n            options.cert = options.key = cert;\n        }\n        if (tlsOptions.tlsCAFile) {\n            options.ca = await fs.readFile(tlsOptions.tlsCAFile);\n        }\n        if (tlsOptions.tlsCertificateKeyFilePassword) {\n            options.passphrase = tlsOptions.tlsCertificateKeyFilePassword;\n        }\n    }\n    /**\n     * Fetches collection info for a provided namespace, when libmongocrypt\n     * enters the `MONGOCRYPT_CTX_NEED_MONGO_COLLINFO` state. The result is\n     * used to inform libmongocrypt of the schema associated with this\n     * namespace. Exposed for testing purposes. Do not directly invoke.\n     *\n     * @param client - A MongoClient connected to the topology\n     * @param ns - The namespace to list collections from\n     * @param filter - A filter for the listCollections command\n     * @param callback - Invoked with the info of the requested collection, or with an error\n     */\n    async fetchCollectionInfo(client, ns, filter) {\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const collections = await client\n            .db(db)\n            .listCollections(filter, {\n            promoteLongs: false,\n            promoteValues: false\n        })\n            .toArray();\n        const info = collections.length > 0 ? (0, bson_1.serialize)(collections[0]) : null;\n        return info;\n    }\n    /**\n     * Calls to the mongocryptd to provide markings for a command.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to a mongocryptd\n     * @param ns - The namespace (database.collection) the command is being executed on\n     * @param command - The command to execute.\n     * @param callback - Invoked with the serialized and marked bson command, or with an error\n     */\n    async markCommand(client, ns, command) {\n        const options = { promoteLongs: false, promoteValues: false };\n        const { db } = utils_1.MongoDBCollectionNamespace.fromString(ns);\n        const rawCommand = (0, bson_1.deserialize)(command, options);\n        const response = await client.db(db).command(rawCommand, options);\n        return (0, bson_1.serialize)(response, this.bsonOptions);\n    }\n    /**\n     * Requests keys from the keyVault collection on the topology.\n     * Exposed for testing purposes. Do not directly invoke.\n     * @param client - A MongoClient connected to the topology\n     * @param keyVaultNamespace - The namespace (database.collection) of the keyVault Collection\n     * @param filter - The filter for the find query against the keyVault Collection\n     * @param callback - Invoked with the found keys, or with an error\n     */\n    fetchKeys(client, keyVaultNamespace, filter) {\n        const { db: dbName, collection: collectionName } = utils_1.MongoDBCollectionNamespace.fromString(keyVaultNamespace);\n        return client\n            .db(dbName)\n            .collection(collectionName, { readConcern: { level: 'majority' } })\n            .find((0, bson_1.deserialize)(filter))\n            .toArray();\n    }\n}\nexports.StateMachine = StateMachine;\n//# sourceMappingURL=state_machine.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/client-side-encryption/state_machine.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/auth_provider.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/auth_provider.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AuthProvider = exports.AuthContext = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * Context used during authentication\n * @internal\n */\nclass AuthContext {\n    constructor(connection, credentials, options) {\n        /** If the context is for reauthentication. */\n        this.reauthenticating = false;\n        this.connection = connection;\n        this.credentials = credentials;\n        this.options = options;\n    }\n}\nexports.AuthContext = AuthContext;\nclass AuthProvider {\n    /**\n     * Prepare the handshake document before the initial handshake.\n     *\n     * @param handshakeDoc - The document used for the initial handshake on a connection\n     * @param authContext - Context for authentication flow\n     */\n    async prepare(handshakeDoc, _authContext) {\n        return handshakeDoc;\n    }\n    /**\n     * Reauthenticate.\n     * @param context - The shared auth context.\n     */\n    async reauth(context) {\n        if (context.reauthenticating) {\n            throw new error_1.MongoRuntimeError('Reauthentication already in progress.');\n        }\n        try {\n            context.reauthenticating = true;\n            await this.auth(context);\n        }\n        finally {\n            context.reauthenticating = false;\n        }\n    }\n}\nexports.AuthProvider = AuthProvider;\n//# sourceMappingURL=auth_provider.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/auth_provider.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/gssapi.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/gssapi.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.resolveCname = exports.performGSSAPICanonicalizeHostName = exports.GSSAPI = exports.GSSAPICanonicalizationValue = void 0;\nconst dns = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'dns'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\n/** @public */\nexports.GSSAPICanonicalizationValue = Object.freeze({\n    on: true,\n    off: false,\n    none: 'none',\n    forward: 'forward',\n    forwardAndReverse: 'forwardAndReverse'\n});\nasync function externalCommand(connection, command) {\n    return connection.commandAsync((0, utils_1.ns)('$external.$cmd'), command, undefined);\n}\nlet krb;\nclass GSSAPI extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (credentials == null) {\n            throw new error_1.MongoMissingCredentialsError('Credentials required for GSSAPI authentication');\n        }\n        const { username } = credentials;\n        const client = await makeKerberosClient(authContext);\n        const payload = await client.step('');\n        const saslStartResponse = await externalCommand(connection, saslStart(payload));\n        const negotiatedPayload = await negotiate(client, 10, saslStartResponse.payload);\n        const saslContinueResponse = await externalCommand(connection, saslContinue(negotiatedPayload, saslStartResponse.conversationId));\n        const finalizePayload = await finalize(client, username, saslContinueResponse.payload);\n        await externalCommand(connection, {\n            saslContinue: 1,\n            conversationId: saslContinueResponse.conversationId,\n            payload: finalizePayload\n        });\n    }\n}\nexports.GSSAPI = GSSAPI;\nasync function makeKerberosClient(authContext) {\n    const { hostAddress } = authContext.options;\n    const { credentials } = authContext;\n    if (!hostAddress || typeof hostAddress.host !== 'string' || !credentials) {\n        throw new error_1.MongoInvalidArgumentError('Connection must have host and port and credentials defined.');\n    }\n    loadKrb();\n    if ('kModuleError' in krb) {\n        throw krb['kModuleError'];\n    }\n    const { initializeClient } = krb;\n    const { username, password } = credentials;\n    const mechanismProperties = credentials.mechanismProperties;\n    const serviceName = mechanismProperties.SERVICE_NAME ?? 'mongodb';\n    const host = await performGSSAPICanonicalizeHostName(hostAddress.host, mechanismProperties);\n    const initOptions = {};\n    if (password != null) {\n        // TODO(NODE-5139): These do not match the typescript options in initializeClient\n        Object.assign(initOptions, { user: username, password: password });\n    }\n    const spnHost = mechanismProperties.SERVICE_HOST ?? host;\n    let spn = `${serviceName}${process.platform === 'win32' ? '/' : '@'}${spnHost}`;\n    if ('SERVICE_REALM' in mechanismProperties) {\n        spn = `${spn}@${mechanismProperties.SERVICE_REALM}`;\n    }\n    return initializeClient(spn, initOptions);\n}\nfunction saslStart(payload) {\n    return {\n        saslStart: 1,\n        mechanism: 'GSSAPI',\n        payload,\n        autoAuthorize: 1\n    };\n}\nfunction saslContinue(payload, conversationId) {\n    return {\n        saslContinue: 1,\n        conversationId,\n        payload\n    };\n}\nasync function negotiate(client, retries, payload) {\n    try {\n        const response = await client.step(payload);\n        return response || '';\n    }\n    catch (error) {\n        if (retries === 0) {\n            // Retries exhausted, raise error\n            throw error;\n        }\n        // Adjust number of retries and call step again\n        return negotiate(client, retries - 1, payload);\n    }\n}\nasync function finalize(client, user, payload) {\n    // GSS Client Unwrap\n    const response = await client.unwrap(payload);\n    return client.wrap(response || '', { user });\n}\nasync function performGSSAPICanonicalizeHostName(host, mechanismProperties) {\n    const mode = mechanismProperties.CANONICALIZE_HOST_NAME;\n    if (!mode || mode === exports.GSSAPICanonicalizationValue.none) {\n        return host;\n    }\n    // If forward and reverse or true\n    if (mode === exports.GSSAPICanonicalizationValue.on ||\n        mode === exports.GSSAPICanonicalizationValue.forwardAndReverse) {\n        // Perform the lookup of the ip address.\n        const { address } = await dns.promises.lookup(host);\n        try {\n            // Perform a reverse ptr lookup on the ip address.\n            const results = await dns.promises.resolvePtr(address);\n            // If the ptr did not error but had no results, return the host.\n            return results.length > 0 ? results[0] : host;\n        }\n        catch (error) {\n            // This can error as ptr records may not exist for all ips. In this case\n            // fallback to a cname lookup as dns.lookup() does not return the\n            // cname.\n            return resolveCname(host);\n        }\n    }\n    else {\n        // The case for forward is just to resolve the cname as dns.lookup()\n        // will not return it.\n        return resolveCname(host);\n    }\n}\nexports.performGSSAPICanonicalizeHostName = performGSSAPICanonicalizeHostName;\nasync function resolveCname(host) {\n    // Attempt to resolve the host name\n    try {\n        const results = await dns.promises.resolveCname(host);\n        // Get the first resolved host id\n        return results.length > 0 ? results[0] : host;\n    }\n    catch {\n        return host;\n    }\n}\nexports.resolveCname = resolveCname;\n/**\n * Load the Kerberos library.\n */\nfunction loadKrb() {\n    if (!krb) {\n        krb = (0, deps_1.getKerberos)();\n    }\n}\n//# sourceMappingURL=gssapi.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/gssapi.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCredentials = exports.DEFAULT_ALLOWED_HOSTS = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst gssapi_1 = __webpack_require__(/*! ./gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n// https://github.com/mongodb/specifications/blob/master/source/auth/auth.rst\nfunction getDefaultAuthMechanism(hello) {\n    if (hello) {\n        // If hello contains saslSupportedMechs, use scram-sha-256\n        // if it is available, else scram-sha-1\n        if (Array.isArray(hello.saslSupportedMechs)) {\n            return hello.saslSupportedMechs.includes(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256)\n                ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA256\n                : providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n        // Fallback to legacy selection method. If wire version >= 3, use scram-sha-1\n        if (hello.maxWireVersion >= 3) {\n            return providers_1.AuthMechanism.MONGODB_SCRAM_SHA1;\n        }\n    }\n    // Default for wireprotocol < 3\n    return providers_1.AuthMechanism.MONGODB_CR;\n}\nconst ALLOWED_PROVIDER_NAMES = ['aws', 'azure'];\nconst ALLOWED_HOSTS_ERROR = 'Auth mechanism property ALLOWED_HOSTS must be an array of strings.';\n/** @internal */\nexports.DEFAULT_ALLOWED_HOSTS = [\n    '*.mongodb.net',\n    '*.mongodb-dev.net',\n    '*.mongodbgov.net',\n    'localhost',\n    '127.0.0.1',\n    '::1'\n];\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_AUDIENCE_MISSING_ERROR = 'TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.';\n/**\n * A representation of the credentials used by MongoDB\n * @public\n */\nclass MongoCredentials {\n    constructor(options) {\n        this.username = options.username ?? '';\n        this.password = options.password;\n        this.source = options.source;\n        if (!this.source && options.db) {\n            this.source = options.db;\n        }\n        this.mechanism = options.mechanism || providers_1.AuthMechanism.MONGODB_DEFAULT;\n        this.mechanismProperties = options.mechanismProperties || {};\n        if (this.mechanism.match(/MONGODB-AWS/i)) {\n            if (!this.username && process.env.AWS_ACCESS_KEY_ID) {\n                this.username = process.env.AWS_ACCESS_KEY_ID;\n            }\n            if (!this.password && process.env.AWS_SECRET_ACCESS_KEY) {\n                this.password = process.env.AWS_SECRET_ACCESS_KEY;\n            }\n            if (this.mechanismProperties.AWS_SESSION_TOKEN == null &&\n                process.env.AWS_SESSION_TOKEN != null) {\n                this.mechanismProperties = {\n                    ...this.mechanismProperties,\n                    AWS_SESSION_TOKEN: process.env.AWS_SESSION_TOKEN\n                };\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC && !this.mechanismProperties.ALLOWED_HOSTS) {\n            this.mechanismProperties = {\n                ...this.mechanismProperties,\n                ALLOWED_HOSTS: exports.DEFAULT_ALLOWED_HOSTS\n            };\n        }\n        Object.freeze(this.mechanismProperties);\n        Object.freeze(this);\n    }\n    /** Determines if two MongoCredentials objects are equivalent */\n    equals(other) {\n        return (this.mechanism === other.mechanism &&\n            this.username === other.username &&\n            this.password === other.password &&\n            this.source === other.source);\n    }\n    /**\n     * If the authentication mechanism is set to \"default\", resolves the authMechanism\n     * based on the server version and server supported sasl mechanisms.\n     *\n     * @param hello - A hello response from the server\n     */\n    resolveAuthMechanism(hello) {\n        // If the mechanism is not \"default\", then it does not need to be resolved\n        if (this.mechanism.match(/DEFAULT/i)) {\n            return new MongoCredentials({\n                username: this.username,\n                password: this.password,\n                source: this.source,\n                mechanism: getDefaultAuthMechanism(hello),\n                mechanismProperties: this.mechanismProperties\n            });\n        }\n        return this;\n    }\n    validate() {\n        if ((this.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_CR ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 ||\n            this.mechanism === providers_1.AuthMechanism.MONGODB_SCRAM_SHA256) &&\n            !this.username) {\n            throw new error_1.MongoMissingCredentialsError(`Username required for mechanism '${this.mechanism}'`);\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            if (this.username && this.mechanismProperties.PROVIDER_NAME) {\n                throw new error_1.MongoInvalidArgumentError(`username and PROVIDER_NAME may not be used together for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.PROVIDER_NAME === 'azure' &&\n                !this.mechanismProperties.TOKEN_AUDIENCE) {\n                throw new error_1.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);\n            }\n            if (this.mechanismProperties.PROVIDER_NAME &&\n                !ALLOWED_PROVIDER_NAMES.includes(this.mechanismProperties.PROVIDER_NAME)) {\n                throw new error_1.MongoInvalidArgumentError(`Currently only a PROVIDER_NAME in ${ALLOWED_PROVIDER_NAMES.join(',')} is supported for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.REFRESH_TOKEN_CALLBACK &&\n                !this.mechanismProperties.REQUEST_TOKEN_CALLBACK) {\n                throw new error_1.MongoInvalidArgumentError(`A REQUEST_TOKEN_CALLBACK must be provided when using a REFRESH_TOKEN_CALLBACK for mechanism '${this.mechanism}'`);\n            }\n            if (!this.mechanismProperties.PROVIDER_NAME &&\n                !this.mechanismProperties.REQUEST_TOKEN_CALLBACK) {\n                throw new error_1.MongoInvalidArgumentError(`Either a PROVIDER_NAME or a REQUEST_TOKEN_CALLBACK must be specified for mechanism '${this.mechanism}'.`);\n            }\n            if (this.mechanismProperties.ALLOWED_HOSTS) {\n                const hosts = this.mechanismProperties.ALLOWED_HOSTS;\n                if (!Array.isArray(hosts)) {\n                    throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                }\n                for (const host of hosts) {\n                    if (typeof host !== 'string') {\n                        throw new error_1.MongoInvalidArgumentError(ALLOWED_HOSTS_ERROR);\n                    }\n                }\n            }\n        }\n        if (providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(this.mechanism)) {\n            if (this.source != null && this.source !== '$external') {\n                // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n                throw new error_1.MongoAPIError(`Invalid source '${this.source}' for mechanism '${this.mechanism}' specified.`);\n            }\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_PLAIN && this.source == null) {\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError('PLAIN Authentication Mechanism needs an auth source');\n        }\n        if (this.mechanism === providers_1.AuthMechanism.MONGODB_X509 && this.password != null) {\n            if (this.password === '') {\n                Reflect.set(this, 'password', undefined);\n                return;\n            }\n            // TODO(NODE-3485): Replace this with a MongoAuthValidationError\n            throw new error_1.MongoAPIError(`Password not allowed for mechanism MONGODB-X509`);\n        }\n        const canonicalization = this.mechanismProperties.CANONICALIZE_HOST_NAME ?? false;\n        if (!Object.values(gssapi_1.GSSAPICanonicalizationValue).includes(canonicalization)) {\n            throw new error_1.MongoAPIError(`Invalid CANONICALIZE_HOST_NAME value: ${canonicalization}`);\n        }\n    }\n    static merge(creds, options) {\n        return new MongoCredentials({\n            username: options.username ?? creds?.username ?? '',\n            password: options.password ?? creds?.password ?? '',\n            mechanism: options.mechanism ?? creds?.mechanism ?? providers_1.AuthMechanism.MONGODB_DEFAULT,\n            mechanismProperties: options.mechanismProperties ?? creds?.mechanismProperties ?? {},\n            source: options.source ?? options.db ?? creds?.source ?? 'admin'\n        });\n    }\n}\nexports.MongoCredentials = MongoCredentials;\n//# sourceMappingURL=mongo_credentials.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongocr.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongocr.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoCR = void 0;\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass MongoCR extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password, source } = credentials;\n        const { nonce } = await connection.commandAsync((0, utils_1.ns)(`${source}.$cmd`), { getnonce: 1 }, undefined);\n        const hashPassword = crypto\n            .createHash('md5')\n            .update(`${username}:mongo:${password}`, 'utf8')\n            .digest('hex');\n        // Final key\n        const key = crypto\n            .createHash('md5')\n            .update(`${nonce}${username}${hashPassword}`, 'utf8')\n            .digest('hex');\n        const authenticateCommand = {\n            authenticate: 1,\n            user: username,\n            nonce,\n            key\n        };\n        await connection.commandAsync((0, utils_1.ns)(`${source}.$cmd`), authenticateCommand, undefined);\n    }\n}\nexports.MongoCR = MongoCR;\n//# sourceMappingURL=mongocr.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongocr.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBAWS = void 0;\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst process = __webpack_require__(/*! process */ \"../../node_modules/process/browser.js\");\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst BSON = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n/**\n * The following regions use the global AWS STS endpoint, sts.amazonaws.com, by default\n * https://docs.aws.amazon.com/sdkref/latest/guide/feature-sts-regionalized-endpoints.html\n */\nconst LEGACY_REGIONS = new Set([\n    'ap-northeast-1',\n    'ap-south-1',\n    'ap-southeast-1',\n    'ap-southeast-2',\n    'aws-global',\n    'ca-central-1',\n    'eu-central-1',\n    'eu-north-1',\n    'eu-west-1',\n    'eu-west-2',\n    'eu-west-3',\n    'sa-east-1',\n    'us-east-1',\n    'us-east-2',\n    'us-west-1',\n    'us-west-2'\n]);\nconst ASCII_N = 110;\nconst AWS_RELATIVE_URI = 'http://169.254.170.2';\nconst AWS_EC2_URI = 'http://169.254.169.254';\nconst AWS_EC2_PATH = '/latest/meta-data/iam/security-credentials';\nconst bsonOptions = {\n    useBigInt64: false,\n    promoteLongs: true,\n    promoteValues: true,\n    promoteBuffers: false,\n    bsonRegExp: false\n};\nclass MongoDBAWS extends auth_provider_1.AuthProvider {\n    constructor() {\n        super();\n        this.randomBytesAsync = (0, util_1.promisify)(crypto.randomBytes);\n    }\n    async auth(authContext) {\n        const { connection } = authContext;\n        if (!authContext.credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        if ('kModuleError' in deps_1.aws4) {\n            throw deps_1.aws4['kModuleError'];\n        }\n        const { sign } = deps_1.aws4;\n        if ((0, utils_1.maxWireVersion)(connection) < 9) {\n            throw new error_1.MongoCompatibilityError('MONGODB-AWS authentication requires MongoDB version 4.4 or later');\n        }\n        if (!authContext.credentials.username) {\n            authContext.credentials = await makeTempCredentials(authContext.credentials);\n        }\n        const { credentials } = authContext;\n        const accessKeyId = credentials.username;\n        const secretAccessKey = credentials.password;\n        const sessionToken = credentials.mechanismProperties.AWS_SESSION_TOKEN;\n        // If all three defined, include sessionToken, else include username and pass, else no credentials\n        const awsCredentials = accessKeyId && secretAccessKey && sessionToken\n            ? { accessKeyId, secretAccessKey, sessionToken }\n            : accessKeyId && secretAccessKey\n                ? { accessKeyId, secretAccessKey }\n                : undefined;\n        const db = credentials.source;\n        const nonce = await this.randomBytesAsync(32);\n        const saslStart = {\n            saslStart: 1,\n            mechanism: 'MONGODB-AWS',\n            payload: BSON.serialize({ r: nonce, p: ASCII_N }, bsonOptions)\n        };\n        const saslStartResponse = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslStart, undefined);\n        const serverResponse = BSON.deserialize(saslStartResponse.payload.buffer, bsonOptions);\n        const host = serverResponse.h;\n        const serverNonce = serverResponse.s.buffer;\n        if (serverNonce.length !== 64) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Invalid server nonce length ${serverNonce.length}, expected 64`);\n        }\n        if (!utils_1.ByteUtils.equals(serverNonce.subarray(0, nonce.byteLength), nonce)) {\n            // throw because the serverNonce's leading 32 bytes must equal the client nonce's 32 bytes\n            // https://github.com/mongodb/specifications/blob/875446db44aade414011731840831f38a6c668df/source/auth/auth.rst#id11\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('Server nonce does not begin with client nonce');\n        }\n        if (host.length < 1 || host.length > 255 || host.indexOf('..') !== -1) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError(`Server returned an invalid host: \"${host}\"`);\n        }\n        const body = 'Action=GetCallerIdentity&Version=2011-06-15';\n        const options = sign({\n            method: 'POST',\n            host,\n            region: deriveRegion(serverResponse.h),\n            service: 'sts',\n            headers: {\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Content-Length': body.length,\n                'X-MongoDB-Server-Nonce': utils_1.ByteUtils.toBase64(serverNonce),\n                'X-MongoDB-GS2-CB-Flag': 'n'\n            },\n            path: '/',\n            body\n        }, awsCredentials);\n        const payload = {\n            a: options.headers.Authorization,\n            d: options.headers['X-Amz-Date']\n        };\n        if (sessionToken) {\n            payload.t = sessionToken;\n        }\n        const saslContinue = {\n            saslContinue: 1,\n            conversationId: 1,\n            payload: BSON.serialize(payload, bsonOptions)\n        };\n        await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslContinue, undefined);\n    }\n}\nMongoDBAWS.credentialProvider = null;\nexports.MongoDBAWS = MongoDBAWS;\nasync function makeTempCredentials(credentials) {\n    function makeMongoCredentialsFromAWSTemp(creds) {\n        if (!creds.AccessKeyId || !creds.SecretAccessKey || !creds.Token) {\n            throw new error_1.MongoMissingCredentialsError('Could not obtain temporary MONGODB-AWS credentials');\n        }\n        return new mongo_credentials_1.MongoCredentials({\n            username: creds.AccessKeyId,\n            password: creds.SecretAccessKey,\n            source: credentials.source,\n            mechanism: providers_1.AuthMechanism.MONGODB_AWS,\n            mechanismProperties: {\n                AWS_SESSION_TOKEN: creds.Token\n            }\n        });\n    }\n    MongoDBAWS.credentialProvider ??= (0, deps_1.getAwsCredentialProvider)();\n    // Check if the AWS credential provider from the SDK is present. If not,\n    // use the old method.\n    if ('kModuleError' in MongoDBAWS.credentialProvider) {\n        // If the environment variable AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\n        // is set then drivers MUST assume that it was set by an AWS ECS agent\n        if (process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI) {\n            return makeMongoCredentialsFromAWSTemp(await (0, utils_1.request)(`${AWS_RELATIVE_URI}${process.env.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI}`));\n        }\n        // Otherwise assume we are on an EC2 instance\n        // get a token\n        const token = await (0, utils_1.request)(`${AWS_EC2_URI}/latest/api/token`, {\n            method: 'PUT',\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token-ttl-seconds': 30 }\n        });\n        // get role name\n        const roleName = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}`, {\n            json: false,\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        // get temp credentials\n        const creds = await (0, utils_1.request)(`${AWS_EC2_URI}/${AWS_EC2_PATH}/${roleName}`, {\n            headers: { 'X-aws-ec2-metadata-token': token }\n        });\n        return makeMongoCredentialsFromAWSTemp(creds);\n    }\n    else {\n        let { AWS_STS_REGIONAL_ENDPOINTS = '', AWS_REGION = '' } = process.env;\n        AWS_STS_REGIONAL_ENDPOINTS = AWS_STS_REGIONAL_ENDPOINTS.toLowerCase();\n        AWS_REGION = AWS_REGION.toLowerCase();\n        /** The option setting should work only for users who have explicit settings in their environment, the driver should not encode \"defaults\" */\n        const awsRegionSettingsExist = AWS_REGION.length !== 0 && AWS_STS_REGIONAL_ENDPOINTS.length !== 0;\n        /**\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to regional, users are opting into the new behavior of respecting the region settings\n         *\n         * If AWS_STS_REGIONAL_ENDPOINTS is set to legacy, then \"old\" regions need to keep using the global setting.\n         * Technically the SDK gets this wrong, it reaches out to 'sts.us-east-1.amazonaws.com' when it should be 'sts.amazonaws.com'.\n         * That is not our bug to fix here. We leave that up to the SDK.\n         */\n        const useRegionalSts = AWS_STS_REGIONAL_ENDPOINTS === 'regional' ||\n            (AWS_STS_REGIONAL_ENDPOINTS === 'legacy' && !LEGACY_REGIONS.has(AWS_REGION));\n        const provider = awsRegionSettingsExist && useRegionalSts\n            ? MongoDBAWS.credentialProvider.fromNodeProviderChain({\n                clientConfig: { region: AWS_REGION }\n            })\n            : MongoDBAWS.credentialProvider.fromNodeProviderChain();\n        /*\n         * Creates a credential provider that will attempt to find credentials from the\n         * following sources (listed in order of precedence):\n         *\n         * - Environment variables exposed via process.env\n         * - SSO credentials from token cache\n         * - Web identity token credentials\n         * - Shared credentials and config ini files\n         * - The EC2/ECS Instance Metadata Service\n         */\n        try {\n            const creds = await provider();\n            return makeMongoCredentialsFromAWSTemp({\n                AccessKeyId: creds.accessKeyId,\n                SecretAccessKey: creds.secretAccessKey,\n                Token: creds.sessionToken,\n                Expiration: creds.expiration\n            });\n        }\n        catch (error) {\n            throw new error_1.MongoAWSError(error.message);\n        }\n    }\n}\nfunction deriveRegion(host) {\n    const parts = host.split('.');\n    if (parts.length === 1 || parts[1] === 'amazonaws') {\n        return 'us-east-1';\n    }\n    return parts[1];\n}\n//# sourceMappingURL=mongodb_aws.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoDBOIDC = exports.OIDC_WORKFLOWS = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst aws_service_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/aws_service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js\");\nconst azure_service_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/azure_service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js\");\nconst callback_workflow_1 = __webpack_require__(/*! ./mongodb_oidc/callback_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js\");\n/** Error when credentials are missing. */\nconst MISSING_CREDENTIALS_ERROR = 'AuthContext must provide credentials.';\n/** @internal */\nexports.OIDC_WORKFLOWS = new Map();\nexports.OIDC_WORKFLOWS.set('callback', new callback_workflow_1.CallbackWorkflow());\nexports.OIDC_WORKFLOWS.set('aws', new aws_service_workflow_1.AwsServiceWorkflow());\nexports.OIDC_WORKFLOWS.set('azure', new azure_service_workflow_1.AzureServiceWorkflow());\n/**\n * OIDC auth provider.\n * @experimental\n */\nclass MongoDBOIDC extends auth_provider_1.AuthProvider {\n    /**\n     * Instantiate the auth provider.\n     */\n    constructor() {\n        super();\n    }\n    /**\n     * Authenticate using OIDC\n     */\n    async auth(authContext) {\n        const { connection, reauthenticating, response } = authContext;\n        const credentials = getCredentials(authContext);\n        const workflow = getWorkflow(credentials);\n        await workflow.execute(connection, credentials, reauthenticating, response);\n    }\n    /**\n     * Add the speculative auth for the initial handshake.\n     */\n    async prepare(handshakeDoc, authContext) {\n        const credentials = getCredentials(authContext);\n        const workflow = getWorkflow(credentials);\n        const result = await workflow.speculativeAuth(credentials);\n        return { ...handshakeDoc, ...result };\n    }\n}\nexports.MongoDBOIDC = MongoDBOIDC;\n/**\n * Get credentials from the auth context, throwing if they do not exist.\n */\nfunction getCredentials(authContext) {\n    const { credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError(MISSING_CREDENTIALS_ERROR);\n    }\n    return credentials;\n}\n/**\n * Gets either a device workflow or callback workflow.\n */\nfunction getWorkflow(credentials) {\n    const providerName = credentials.mechanismProperties.PROVIDER_NAME;\n    const workflow = exports.OIDC_WORKFLOWS.get(providerName || 'callback');\n    if (!workflow) {\n        throw new error_1.MongoInvalidArgumentError(`Could not load workflow for provider ${credentials.mechanismProperties.PROVIDER_NAME}`);\n    }\n    return workflow;\n}\n//# sourceMappingURL=mongodb_oidc.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js ***!
  \*********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AwsServiceWorkflow = void 0;\nconst fs = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'fs'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst service_workflow_1 = __webpack_require__(/*! ./service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js\");\n/** Error for when the token is missing in the environment. */\nconst TOKEN_MISSING_ERROR = 'AWS_WEB_IDENTITY_TOKEN_FILE must be set in the environment.';\n/**\n * Device workflow implementation for AWS.\n *\n * @internal\n */\nclass AwsServiceWorkflow extends service_workflow_1.ServiceWorkflow {\n    constructor() {\n        super();\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken() {\n        const tokenFile = process.env.AWS_WEB_IDENTITY_TOKEN_FILE;\n        if (!tokenFile) {\n            throw new error_1.MongoAWSError(TOKEN_MISSING_ERROR);\n        }\n        return fs.promises.readFile(tokenFile, 'utf8');\n    }\n}\nexports.AwsServiceWorkflow = AwsServiceWorkflow;\n//# sourceMappingURL=aws_service_workflow.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/aws_service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AzureServiceWorkflow = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst azure_token_cache_1 = __webpack_require__(/*! ./azure_token_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js\");\nconst service_workflow_1 = __webpack_require__(/*! ./service_workflow */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js\");\n/** Base URL for getting Azure tokens. */\nconst AZURE_BASE_URL = 'http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01';\n/** Azure request headers. */\nconst AZURE_HEADERS = Object.freeze({ Metadata: 'true', Accept: 'application/json' });\n/** Invalid endpoint result error. */\nconst ENDPOINT_RESULT_ERROR = 'Azure endpoint did not return a value with only access_token and expires_in properties';\n/** Error for when the token audience is missing in the environment. */\nconst TOKEN_AUDIENCE_MISSING_ERROR = 'TOKEN_AUDIENCE must be set in the auth mechanism properties when PROVIDER_NAME is azure.';\n/**\n * Device workflow implementation for Azure.\n *\n * @internal\n */\nclass AzureServiceWorkflow extends service_workflow_1.ServiceWorkflow {\n    constructor() {\n        super(...arguments);\n        this.cache = new azure_token_cache_1.AzureTokenCache();\n    }\n    /**\n     * Get the token from the environment.\n     */\n    async getToken(credentials) {\n        const tokenAudience = credentials?.mechanismProperties.TOKEN_AUDIENCE;\n        if (!tokenAudience) {\n            throw new error_1.MongoAzureError(TOKEN_AUDIENCE_MISSING_ERROR);\n        }\n        let token;\n        const entry = this.cache.getEntry(tokenAudience);\n        if (entry?.isValid()) {\n            token = entry.token;\n        }\n        else {\n            this.cache.deleteEntry(tokenAudience);\n            const response = await getAzureTokenData(tokenAudience);\n            if (!isEndpointResultValid(response)) {\n                throw new error_1.MongoAzureError(ENDPOINT_RESULT_ERROR);\n            }\n            this.cache.addEntry(tokenAudience, response);\n            token = response.access_token;\n        }\n        return token;\n    }\n}\nexports.AzureServiceWorkflow = AzureServiceWorkflow;\n/**\n * Hit the Azure endpoint to get the token data.\n */\nasync function getAzureTokenData(tokenAudience) {\n    const url = `${AZURE_BASE_URL}&resource=${tokenAudience}`;\n    const data = await (0, utils_1.request)(url, {\n        json: true,\n        headers: AZURE_HEADERS\n    });\n    return data;\n}\n/**\n * Determines if a result returned from the endpoint is valid.\n * This means the result is not nullish, contains the access_token required field\n * and the expires_in required field.\n */\nfunction isEndpointResultValid(token) {\n    if (token == null || typeof token !== 'object')\n        return false;\n    return 'access_token' in token && 'expires_in' in token;\n}\n//# sourceMappingURL=azure_service_workflow.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AzureTokenCache = exports.AzureTokenEntry = void 0;\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/** @internal */\nclass AzureTokenEntry extends cache_1.ExpiringCacheEntry {\n    /**\n     * Instantiate the entry.\n     */\n    constructor(token, expiration) {\n        super(expiration);\n        this.token = token;\n    }\n}\nexports.AzureTokenEntry = AzureTokenEntry;\n/**\n * A cache of access tokens from Azure.\n * @internal\n */\nclass AzureTokenCache extends cache_1.Cache {\n    /**\n     * Add an entry to the cache.\n     */\n    addEntry(tokenAudience, token) {\n        const entry = new AzureTokenEntry(token.access_token, token.expires_in);\n        this.entries.set(tokenAudience, entry);\n        return entry;\n    }\n    /**\n     * Create a cache key.\n     */\n    cacheKey(tokenAudience) {\n        return tokenAudience;\n    }\n    /**\n     * Delete an entry from the cache.\n     */\n    deleteEntry(tokenAudience) {\n        this.entries.delete(tokenAudience);\n    }\n    /**\n     * Get an Azure token entry from the cache.\n     */\n    getEntry(tokenAudience) {\n        return this.entries.get(tokenAudience);\n    }\n}\nexports.AzureTokenCache = AzureTokenCache;\n//# sourceMappingURL=azure_token_cache.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/azure_token_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Cache = exports.ExpiringCacheEntry = void 0;\n/* 5 minutes in milliseconds */\nconst EXPIRATION_BUFFER_MS = 300000;\n/**\n * An entry in a cache that can expire in a certain amount of time.\n */\nclass ExpiringCacheEntry {\n    /**\n     * Create a new expiring token entry.\n     */\n    constructor(expiration) {\n        this.expiration = this.expirationTime(expiration);\n    }\n    /**\n     * The entry is still valid if the expiration is more than\n     * 5 minutes from the expiration time.\n     */\n    isValid() {\n        return this.expiration - Date.now() > EXPIRATION_BUFFER_MS;\n    }\n    /**\n     * Get an expiration time in milliseconds past epoch.\n     */\n    expirationTime(expiresInSeconds) {\n        return Date.now() + expiresInSeconds * 1000;\n    }\n}\nexports.ExpiringCacheEntry = ExpiringCacheEntry;\n/**\n * Base class for OIDC caches.\n */\nclass Cache {\n    /**\n     * Create a new cache.\n     */\n    constructor() {\n        this.entries = new Map();\n    }\n    /**\n     * Clear the cache.\n     */\n    clear() {\n        this.entries.clear();\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    hashedCacheKey(address, username, callbackHash) {\n        return JSON.stringify([address, username, callbackHash]);\n    }\n}\nexports.Cache = Cache;\n//# sourceMappingURL=cache.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js":
/*!********************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js ***!
  \********************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CallbackLockCache = void 0;\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/** Error message for when request callback is missing. */\nconst REQUEST_CALLBACK_REQUIRED_ERROR = 'Auth mechanism property REQUEST_TOKEN_CALLBACK is required.';\n/* Counter for function \"hashes\".*/\nlet FN_HASH_COUNTER = 0;\n/* No function present function */\nconst NO_FUNCTION = async () => ({ accessToken: 'test' });\n/* The map of function hashes */\nconst FN_HASHES = new WeakMap();\n/* Put the no function hash in the map. */\nFN_HASHES.set(NO_FUNCTION, FN_HASH_COUNTER);\n/**\n * A cache of request and refresh callbacks per server/user.\n */\nclass CallbackLockCache extends cache_1.Cache {\n    /**\n     * Get the callbacks for the connection and credentials. If an entry does not\n     * exist a new one will get set.\n     */\n    getEntry(connection, credentials) {\n        const requestCallback = credentials.mechanismProperties.REQUEST_TOKEN_CALLBACK;\n        const refreshCallback = credentials.mechanismProperties.REFRESH_TOKEN_CALLBACK;\n        if (!requestCallback) {\n            throw new error_1.MongoInvalidArgumentError(REQUEST_CALLBACK_REQUIRED_ERROR);\n        }\n        const callbackHash = hashFunctions(requestCallback, refreshCallback);\n        const key = this.cacheKey(connection.address, credentials.username, callbackHash);\n        const entry = this.entries.get(key);\n        if (entry) {\n            return entry;\n        }\n        return this.addEntry(key, callbackHash, requestCallback, refreshCallback);\n    }\n    /**\n     * Set locked callbacks on for connection and credentials.\n     */\n    addEntry(key, callbackHash, requestCallback, refreshCallback) {\n        const entry = {\n            requestCallback: withLock(requestCallback),\n            refreshCallback: refreshCallback ? withLock(refreshCallback) : undefined,\n            callbackHash: callbackHash\n        };\n        this.entries.set(key, entry);\n        return entry;\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    cacheKey(address, username, callbackHash) {\n        return this.hashedCacheKey(address, username, callbackHash);\n    }\n}\nexports.CallbackLockCache = CallbackLockCache;\n/**\n * Ensure the callback is only executed one at a time.\n */\nfunction withLock(callback) {\n    let lock = Promise.resolve();\n    return async (info, context) => {\n        await lock;\n        lock = lock.then(() => callback(info, context));\n        return lock;\n    };\n}\n/**\n * Get the hash string for the request and refresh functions.\n */\nfunction hashFunctions(requestFn, refreshFn) {\n    let requestHash = FN_HASHES.get(requestFn);\n    let refreshHash = FN_HASHES.get(refreshFn ?? NO_FUNCTION);\n    if (requestHash == null) {\n        // Create a new one for the function and put it in the map.\n        FN_HASH_COUNTER++;\n        requestHash = FN_HASH_COUNTER;\n        FN_HASHES.set(requestFn, FN_HASH_COUNTER);\n    }\n    if (refreshHash == null && refreshFn) {\n        // Create a new one for the function and put it in the map.\n        FN_HASH_COUNTER++;\n        refreshHash = FN_HASH_COUNTER;\n        FN_HASHES.set(refreshFn, FN_HASH_COUNTER);\n    }\n    return `${requestHash}-${refreshHash}`;\n}\n//# sourceMappingURL=callback_lock_cache.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CallbackWorkflow = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst error_1 = __webpack_require__(/*! ../../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst providers_1 = __webpack_require__(/*! ../providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst callback_lock_cache_1 = __webpack_require__(/*! ./callback_lock_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_lock_cache.js\");\nconst token_entry_cache_1 = __webpack_require__(/*! ./token_entry_cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js\");\n/** The current version of OIDC implementation. */\nconst OIDC_VERSION = 0;\n/** 5 minutes in seconds */\nconst TIMEOUT_S = 300;\n/** Properties allowed on results of callbacks. */\nconst RESULT_PROPERTIES = ['accessToken', 'expiresInSeconds', 'refreshToken'];\n/** Error message when the callback result is invalid. */\nconst CALLBACK_RESULT_ERROR = 'User provided OIDC callbacks must return a valid object with an accessToken.';\n/**\n * OIDC implementation of a callback based workflow.\n * @internal\n */\nclass CallbackWorkflow {\n    /**\n     * Instantiate the workflow\n     */\n    constructor() {\n        this.cache = new token_entry_cache_1.TokenEntryCache();\n        this.callbackCache = new callback_lock_cache_1.CallbackLockCache();\n    }\n    /**\n     * Get the document to add for speculative authentication. This also needs\n     * to add a db field from the credentials source.\n     */\n    async speculativeAuth(credentials) {\n        const document = startCommandDocument(credentials);\n        document.db = credentials.source;\n        return { speculativeAuthenticate: document };\n    }\n    /**\n     * Execute the OIDC callback workflow.\n     */\n    async execute(connection, credentials, reauthenticating, response) {\n        // Get the callbacks with locks from the callback lock cache.\n        const { requestCallback, refreshCallback, callbackHash } = this.callbackCache.getEntry(connection, credentials);\n        // Look for an existing entry in the cache.\n        const entry = this.cache.getEntry(connection.address, credentials.username, callbackHash);\n        let result;\n        if (entry) {\n            // Reauthentication cannot use a token from the cache since the server has\n            // stated it is invalid by the request for reauthentication.\n            if (entry.isValid() && !reauthenticating) {\n                // Presence of a valid cache entry means we can skip to the finishing step.\n                result = await this.finishAuthentication(connection, credentials, entry.tokenResult, response?.speculativeAuthenticate?.conversationId);\n            }\n            else {\n                // Presence of an expired cache entry means we must fetch a new one and\n                // then execute the final step.\n                const tokenResult = await this.fetchAccessToken(connection, credentials, entry.serverInfo, reauthenticating, callbackHash, requestCallback, refreshCallback);\n                try {\n                    result = await this.finishAuthentication(connection, credentials, tokenResult, reauthenticating ? undefined : response?.speculativeAuthenticate?.conversationId);\n                }\n                catch (error) {\n                    // If we are reauthenticating and this errors with reauthentication\n                    // required, we need to do the entire process over again and clear\n                    // the cache entry.\n                    if (reauthenticating &&\n                        error instanceof error_1.MongoError &&\n                        error.code === error_1.MONGODB_ERROR_CODES.Reauthenticate) {\n                        this.cache.deleteEntry(connection.address, credentials.username, callbackHash);\n                        result = await this.execute(connection, credentials, reauthenticating);\n                    }\n                    else {\n                        throw error;\n                    }\n                }\n            }\n        }\n        else {\n            // No entry in the cache requires us to do all authentication steps\n            // from start to finish, including getting a fresh token for the cache.\n            const startDocument = await this.startAuthentication(connection, credentials, reauthenticating, response);\n            const conversationId = startDocument.conversationId;\n            const serverResult = bson_1.BSON.deserialize(startDocument.payload.buffer);\n            const tokenResult = await this.fetchAccessToken(connection, credentials, serverResult, reauthenticating, callbackHash, requestCallback, refreshCallback);\n            result = await this.finishAuthentication(connection, credentials, tokenResult, conversationId);\n        }\n        return result;\n    }\n    /**\n     * Starts the callback authentication process. If there is a speculative\n     * authentication document from the initial handshake, then we will use that\n     * value to get the issuer, otherwise we will send the saslStart command.\n     */\n    async startAuthentication(connection, credentials, reauthenticating, response) {\n        let result;\n        if (!reauthenticating && response?.speculativeAuthenticate) {\n            result = response.speculativeAuthenticate;\n        }\n        else {\n            result = await connection.commandAsync((0, utils_1.ns)(credentials.source), startCommandDocument(credentials), undefined);\n        }\n        return result;\n    }\n    /**\n     * Finishes the callback authentication process.\n     */\n    async finishAuthentication(connection, credentials, tokenResult, conversationId) {\n        const result = await connection.commandAsync((0, utils_1.ns)(credentials.source), finishCommandDocument(tokenResult.accessToken, conversationId), undefined);\n        return result;\n    }\n    /**\n     * Fetches an access token using either the request or refresh callbacks and\n     * puts it in the cache.\n     */\n    async fetchAccessToken(connection, credentials, serverInfo, reauthenticating, callbackHash, requestCallback, refreshCallback) {\n        // Get the token from the cache.\n        const entry = this.cache.getEntry(connection.address, credentials.username, callbackHash);\n        let result;\n        const context = { timeoutSeconds: TIMEOUT_S, version: OIDC_VERSION };\n        // Check if there's a token in the cache.\n        if (entry) {\n            // If the cache entry is valid, return the token result.\n            if (entry.isValid() && !reauthenticating) {\n                return entry.tokenResult;\n            }\n            // If the cache entry is not valid, remove it from the cache and first attempt\n            // to use the refresh callback to get a new token. If no refresh callback\n            // exists, then fallback to the request callback.\n            if (refreshCallback) {\n                context.refreshToken = entry.tokenResult.refreshToken;\n                result = await refreshCallback(serverInfo, context);\n            }\n            else {\n                result = await requestCallback(serverInfo, context);\n            }\n        }\n        else {\n            // With no token in the cache we use the request callback.\n            result = await requestCallback(serverInfo, context);\n        }\n        // Validate that the result returned by the callback is acceptable. If it is not\n        // we must clear the token result from the cache.\n        if (isCallbackResultInvalid(result)) {\n            this.cache.deleteEntry(connection.address, credentials.username, callbackHash);\n            throw new error_1.MongoMissingCredentialsError(CALLBACK_RESULT_ERROR);\n        }\n        // Cleanup the cache.\n        this.cache.deleteExpiredEntries();\n        // Put the new entry into the cache.\n        this.cache.addEntry(connection.address, credentials.username || '', callbackHash, result, serverInfo);\n        return result;\n    }\n}\nexports.CallbackWorkflow = CallbackWorkflow;\n/**\n * Generate the finishing command document for authentication. Will be a\n * saslStart or saslContinue depending on the presence of a conversation id.\n */\nfunction finishCommandDocument(token, conversationId) {\n    if (conversationId != null && typeof conversationId === 'number') {\n        return {\n            saslContinue: 1,\n            conversationId: conversationId,\n            payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n        };\n    }\n    // saslContinue requires a conversationId in the command to be valid so in this\n    // case the server allows \"step two\" to actually be a saslStart with the token\n    // as the jwt since the use of the cached value has no correlating conversating\n    // on the particular connection.\n    return {\n        saslStart: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize({ jwt: token }))\n    };\n}\n/**\n * Determines if a result returned from a request or refresh callback\n * function is invalid. This means the result is nullish, doesn't contain\n * the accessToken required field, and does not contain extra fields.\n */\nfunction isCallbackResultInvalid(tokenResult) {\n    if (tokenResult == null || typeof tokenResult !== 'object')\n        return true;\n    if (!('accessToken' in tokenResult))\n        return true;\n    return !Object.getOwnPropertyNames(tokenResult).every(prop => RESULT_PROPERTIES.includes(prop));\n}\n/**\n * Generate the saslStart command document.\n */\nfunction startCommandDocument(credentials) {\n    const payload = {};\n    if (credentials.username) {\n        payload.n = credentials.username;\n    }\n    return {\n        saslStart: 1,\n        autoAuthorize: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: new bson_1.Binary(bson_1.BSON.serialize(payload))\n    };\n}\n//# sourceMappingURL=callback_workflow.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/callback_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.commandDocument = exports.ServiceWorkflow = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst utils_1 = __webpack_require__(/*! ../../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst providers_1 = __webpack_require__(/*! ../providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\n/**\n * Common behaviour for OIDC device workflows.\n * @internal\n */\nclass ServiceWorkflow {\n    /**\n     * Execute the workflow. Looks for AWS_WEB_IDENTITY_TOKEN_FILE in the environment\n     * and then attempts to read the token from that path.\n     */\n    async execute(connection, credentials) {\n        const token = await this.getToken(credentials);\n        const command = commandDocument(token);\n        return connection.commandAsync((0, utils_1.ns)(credentials.source), command, undefined);\n    }\n    /**\n     * Get the document to add for speculative authentication.\n     */\n    async speculativeAuth(credentials) {\n        const token = await this.getToken(credentials);\n        const document = commandDocument(token);\n        document.db = credentials.source;\n        return { speculativeAuthenticate: document };\n    }\n}\nexports.ServiceWorkflow = ServiceWorkflow;\n/**\n * Create the saslStart command document.\n */\nfunction commandDocument(token) {\n    return {\n        saslStart: 1,\n        mechanism: providers_1.AuthMechanism.MONGODB_OIDC,\n        payload: bson_1.BSON.serialize({ jwt: token })\n    };\n}\nexports.commandDocument = commandDocument;\n//# sourceMappingURL=service_workflow.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/service_workflow.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TokenEntryCache = exports.TokenEntry = void 0;\nconst cache_1 = __webpack_require__(/*! ./cache */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/cache.js\");\n/* Default expiration is now for when no expiration provided */\nconst DEFAULT_EXPIRATION_SECS = 0;\n/** @internal */\nclass TokenEntry extends cache_1.ExpiringCacheEntry {\n    /**\n     * Instantiate the entry.\n     */\n    constructor(tokenResult, serverInfo, expiration) {\n        super(expiration);\n        this.tokenResult = tokenResult;\n        this.serverInfo = serverInfo;\n    }\n}\nexports.TokenEntry = TokenEntry;\n/**\n * Cache of OIDC token entries.\n * @internal\n */\nclass TokenEntryCache extends cache_1.Cache {\n    /**\n     * Set an entry in the token cache.\n     */\n    addEntry(address, username, callbackHash, tokenResult, serverInfo) {\n        const entry = new TokenEntry(tokenResult, serverInfo, tokenResult.expiresInSeconds ?? DEFAULT_EXPIRATION_SECS);\n        this.entries.set(this.cacheKey(address, username, callbackHash), entry);\n        return entry;\n    }\n    /**\n     * Delete an entry from the cache.\n     */\n    deleteEntry(address, username, callbackHash) {\n        this.entries.delete(this.cacheKey(address, username, callbackHash));\n    }\n    /**\n     * Get an entry from the cache.\n     */\n    getEntry(address, username, callbackHash) {\n        return this.entries.get(this.cacheKey(address, username, callbackHash));\n    }\n    /**\n     * Delete all expired entries from the cache.\n     */\n    deleteExpiredEntries() {\n        for (const [key, entry] of this.entries) {\n            if (!entry.isValid()) {\n                this.entries.delete(key);\n            }\n        }\n    }\n    /**\n     * Create a cache key from the address and username.\n     */\n    cacheKey(address, username, callbackHash) {\n        return this.hashedCacheKey(address, username, callbackHash);\n    }\n}\nexports.TokenEntryCache = TokenEntryCache;\n//# sourceMappingURL=token_entry_cache.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/mongodb_oidc/token_entry_cache.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/plain.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/plain.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Plain = void 0;\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass Plain extends auth_provider_1.AuthProvider {\n    async auth(authContext) {\n        const { connection, credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const { username, password } = credentials;\n        const payload = new bson_1.Binary(Buffer.from(`\\x00${username}\\x00${password}`));\n        const command = {\n            saslStart: 1,\n            mechanism: 'PLAIN',\n            payload: payload,\n            autoAuthorize: 1\n        };\n        await connection.commandAsync((0, utils_1.ns)('$external.$cmd'), command, undefined);\n    }\n}\nexports.Plain = Plain;\n//# sourceMappingURL=plain.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/plain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/providers.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/providers.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = exports.AuthMechanism = void 0;\n/** @public */\nexports.AuthMechanism = Object.freeze({\n    MONGODB_AWS: 'MONGODB-AWS',\n    MONGODB_CR: 'MONGODB-CR',\n    MONGODB_DEFAULT: 'DEFAULT',\n    MONGODB_GSSAPI: 'GSSAPI',\n    MONGODB_PLAIN: 'PLAIN',\n    MONGODB_SCRAM_SHA1: 'SCRAM-SHA-1',\n    MONGODB_SCRAM_SHA256: 'SCRAM-SHA-256',\n    MONGODB_X509: 'MONGODB-X509',\n    /** @experimental */\n    MONGODB_OIDC: 'MONGODB-OIDC'\n});\n/** @internal */\nexports.AUTH_MECHS_AUTH_SRC_EXTERNAL = new Set([\n    exports.AuthMechanism.MONGODB_GSSAPI,\n    exports.AuthMechanism.MONGODB_AWS,\n    exports.AuthMechanism.MONGODB_OIDC,\n    exports.AuthMechanism.MONGODB_X509\n]);\n//# sourceMappingURL=providers.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/providers.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/scram.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/scram.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ScramSHA256 = exports.ScramSHA1 = void 0;\nconst saslprep_1 = __webpack_require__(/*! @mongodb-js/saslprep */ \"./node_modules/@mongodb-js/saslprep/dist/index.js\");\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst providers_1 = __webpack_require__(/*! ./providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nclass ScramSHA extends auth_provider_1.AuthProvider {\n    constructor(cryptoMethod) {\n        super();\n        this.cryptoMethod = cryptoMethod || 'sha1';\n        this.randomBytesAsync = (0, util_1.promisify)(crypto.randomBytes);\n    }\n    async prepare(handshakeDoc, authContext) {\n        const cryptoMethod = this.cryptoMethod;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const nonce = await this.randomBytesAsync(24);\n        // store the nonce for later use\n        authContext.nonce = nonce;\n        const request = {\n            ...handshakeDoc,\n            speculativeAuthenticate: {\n                ...makeFirstMessage(cryptoMethod, credentials, nonce),\n                db: credentials.source\n            }\n        };\n        return request;\n    }\n    async auth(authContext) {\n        const { reauthenticating, response } = authContext;\n        if (response?.speculativeAuthenticate && !reauthenticating) {\n            return continueScramConversation(this.cryptoMethod, response.speculativeAuthenticate, authContext);\n        }\n        return executeScram(this.cryptoMethod, authContext);\n    }\n}\nfunction cleanUsername(username) {\n    return username.replace('=', '=3D').replace(',', '=2C');\n}\nfunction clientFirstMessageBare(username, nonce) {\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return Buffer.concat([\n        Buffer.from('n=', 'utf8'),\n        Buffer.from(username, 'utf8'),\n        Buffer.from(',r=', 'utf8'),\n        Buffer.from(nonce.toString('base64'), 'utf8')\n    ]);\n}\nfunction makeFirstMessage(cryptoMethod, credentials, nonce) {\n    const username = cleanUsername(credentials.username);\n    const mechanism = cryptoMethod === 'sha1' ? providers_1.AuthMechanism.MONGODB_SCRAM_SHA1 : providers_1.AuthMechanism.MONGODB_SCRAM_SHA256;\n    // NOTE: This is done b/c Javascript uses UTF-16, but the server is hashing in UTF-8.\n    // Since the username is not sasl-prep-d, we need to do this here.\n    return {\n        saslStart: 1,\n        mechanism,\n        payload: new bson_1.Binary(Buffer.concat([Buffer.from('n,,', 'utf8'), clientFirstMessageBare(username, nonce)])),\n        autoAuthorize: 1,\n        options: { skipEmptyExchange: true }\n    };\n}\nasync function executeScram(cryptoMethod, authContext) {\n    const { connection, credentials } = authContext;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('AuthContext must contain a valid nonce property');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const saslStartCmd = makeFirstMessage(cryptoMethod, credentials, nonce);\n    const response = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslStartCmd, undefined);\n    await continueScramConversation(cryptoMethod, response, authContext);\n}\nasync function continueScramConversation(cryptoMethod, response, authContext) {\n    const connection = authContext.connection;\n    const credentials = authContext.credentials;\n    if (!credentials) {\n        throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n    }\n    if (!authContext.nonce) {\n        throw new error_1.MongoInvalidArgumentError('Unable to continue SCRAM without valid nonce');\n    }\n    const nonce = authContext.nonce;\n    const db = credentials.source;\n    const username = cleanUsername(credentials.username);\n    const password = credentials.password;\n    const processedPassword = cryptoMethod === 'sha256' ? (0, saslprep_1.saslprep)(password) : passwordDigest(username, password);\n    const payload = Buffer.isBuffer(response.payload)\n        ? new bson_1.Binary(response.payload)\n        : response.payload;\n    const dict = parsePayload(payload);\n    const iterations = parseInt(dict.i, 10);\n    if (iterations && iterations < 4096) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid iteration count ${iterations}`);\n    }\n    const salt = dict.s;\n    const rnonce = dict.r;\n    if (rnonce.startsWith('nonce')) {\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Server returned an invalid nonce: ${rnonce}`);\n    }\n    // Set up start of proof\n    const withoutProof = `c=biws,r=${rnonce}`;\n    const saltedPassword = HI(processedPassword, Buffer.from(salt, 'base64'), iterations, cryptoMethod);\n    const clientKey = HMAC(cryptoMethod, saltedPassword, 'Client Key');\n    const serverKey = HMAC(cryptoMethod, saltedPassword, 'Server Key');\n    const storedKey = H(cryptoMethod, clientKey);\n    const authMessage = [\n        clientFirstMessageBare(username, nonce),\n        payload.toString('utf8'),\n        withoutProof\n    ].join(',');\n    const clientSignature = HMAC(cryptoMethod, storedKey, authMessage);\n    const clientProof = `p=${xor(clientKey, clientSignature)}`;\n    const clientFinal = [withoutProof, clientProof].join(',');\n    const serverSignature = HMAC(cryptoMethod, serverKey, authMessage);\n    const saslContinueCmd = {\n        saslContinue: 1,\n        conversationId: response.conversationId,\n        payload: new bson_1.Binary(Buffer.from(clientFinal))\n    };\n    const r = await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), saslContinueCmd, undefined);\n    const parsedResponse = parsePayload(r.payload);\n    if (!compareDigest(Buffer.from(parsedResponse.v, 'base64'), serverSignature)) {\n        throw new error_1.MongoRuntimeError('Server returned an invalid signature');\n    }\n    if (r.done !== false) {\n        // If the server sends r.done === true we can save one RTT\n        return;\n    }\n    const retrySaslContinueCmd = {\n        saslContinue: 1,\n        conversationId: r.conversationId,\n        payload: Buffer.alloc(0)\n    };\n    await connection.commandAsync((0, utils_1.ns)(`${db}.$cmd`), retrySaslContinueCmd, undefined);\n}\nfunction parsePayload(payload) {\n    const payloadStr = payload.toString('utf8');\n    const dict = {};\n    const parts = payloadStr.split(',');\n    for (let i = 0; i < parts.length; i++) {\n        const valueParts = parts[i].split('=');\n        dict[valueParts[0]] = valueParts[1];\n    }\n    return dict;\n}\nfunction passwordDigest(username, password) {\n    if (typeof username !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Username must be a string');\n    }\n    if (typeof password !== 'string') {\n        throw new error_1.MongoInvalidArgumentError('Password must be a string');\n    }\n    if (password.length === 0) {\n        throw new error_1.MongoInvalidArgumentError('Password cannot be empty');\n    }\n    let md5;\n    try {\n        md5 = crypto.createHash('md5');\n    }\n    catch (err) {\n        if (crypto.getFips()) {\n            // This error is (slightly) more helpful than what comes from OpenSSL directly, e.g.\n            // 'Error: error:060800C8:digital envelope routines:EVP_DigestInit_ex:disabled for FIPS'\n            throw new Error('Auth mechanism SCRAM-SHA-1 is not supported in FIPS mode');\n        }\n        throw err;\n    }\n    md5.update(`${username}:mongo:${password}`, 'utf8');\n    return md5.digest('hex');\n}\n// XOR two buffers\nfunction xor(a, b) {\n    if (!Buffer.isBuffer(a)) {\n        a = Buffer.from(a);\n    }\n    if (!Buffer.isBuffer(b)) {\n        b = Buffer.from(b);\n    }\n    const length = Math.max(a.length, b.length);\n    const res = [];\n    for (let i = 0; i < length; i += 1) {\n        res.push(a[i] ^ b[i]);\n    }\n    return Buffer.from(res).toString('base64');\n}\nfunction H(method, text) {\n    return crypto.createHash(method).update(text).digest();\n}\nfunction HMAC(method, key, text) {\n    return crypto.createHmac(method, key).update(text).digest();\n}\nlet _hiCache = {};\nlet _hiCacheCount = 0;\nfunction _hiCachePurge() {\n    _hiCache = {};\n    _hiCacheCount = 0;\n}\nconst hiLengthMap = {\n    sha256: 32,\n    sha1: 20\n};\nfunction HI(data, salt, iterations, cryptoMethod) {\n    // omit the work if already generated\n    const key = [data, salt.toString('base64'), iterations].join('_');\n    if (_hiCache[key] != null) {\n        return _hiCache[key];\n    }\n    // generate the salt\n    const saltedData = crypto.pbkdf2Sync(data, salt, iterations, hiLengthMap[cryptoMethod], cryptoMethod);\n    // cache a copy to speed up the next lookup, but prevent unbounded cache growth\n    if (_hiCacheCount >= 200) {\n        _hiCachePurge();\n    }\n    _hiCache[key] = saltedData;\n    _hiCacheCount += 1;\n    return saltedData;\n}\nfunction compareDigest(lhs, rhs) {\n    if (lhs.length !== rhs.length) {\n        return false;\n    }\n    if (typeof crypto.timingSafeEqual === 'function') {\n        return crypto.timingSafeEqual(lhs, rhs);\n    }\n    let result = 0;\n    for (let i = 0; i < lhs.length; i++) {\n        result |= lhs[i] ^ rhs[i];\n    }\n    return result === 0;\n}\nclass ScramSHA1 extends ScramSHA {\n    constructor() {\n        super('sha1');\n    }\n}\nexports.ScramSHA1 = ScramSHA1;\nclass ScramSHA256 extends ScramSHA {\n    constructor() {\n        super('sha256');\n    }\n}\nexports.ScramSHA256 = ScramSHA256;\n//# sourceMappingURL=scram.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/scram.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/auth/x509.js":
/*!****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/auth/x509.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.X509 = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nclass X509 extends auth_provider_1.AuthProvider {\n    async prepare(handshakeDoc, authContext) {\n        const { credentials } = authContext;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        return { ...handshakeDoc, speculativeAuthenticate: x509AuthenticateCommand(credentials) };\n    }\n    async auth(authContext) {\n        const connection = authContext.connection;\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            throw new error_1.MongoMissingCredentialsError('AuthContext must provide credentials.');\n        }\n        const response = authContext.response;\n        if (response?.speculativeAuthenticate) {\n            return;\n        }\n        await connection.commandAsync((0, utils_1.ns)('$external.$cmd'), x509AuthenticateCommand(credentials), undefined);\n    }\n}\nexports.X509 = X509;\nfunction x509AuthenticateCommand(credentials) {\n    const command = { authenticate: 1, mechanism: 'MONGODB-X509' };\n    if (credentials.username) {\n        command.user = credentials.username;\n    }\n    return command;\n}\n//# sourceMappingURL=x509.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/auth/x509.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/command_monitoring_events.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/command_monitoring_events.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SENSITIVE_COMMANDS = exports.CommandFailedEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\n/**\n * An event indicating the start of a given command\n * @public\n * @category Event\n */\nclass CommandStartedEvent {\n    /**\n     * Create a started event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     */\n    constructor(connection, command) {\n        /** @internal */\n        this.name = constants_1.COMMAND_STARTED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        // TODO: remove in major revision, this is not spec behavior\n        if (exports.SENSITIVE_COMMANDS.has(commandName)) {\n            this.commandObj = {};\n            this.commandObj[commandName] = true;\n        }\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.databaseName = command.databaseName;\n        this.commandName = commandName;\n        this.command = maybeRedact(commandName, cmd, cmd);\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandStartedEvent = CommandStartedEvent;\n/**\n * An event indicating the success of a given command\n * @public\n * @category Event\n */\nclass CommandSucceededEvent {\n    /**\n     * Create a succeeded event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param reply - the reply for this command from the server\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, reply, started) {\n        /** @internal */\n        this.name = constants_1.COMMAND_SUCCEEDED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.reply = maybeRedact(commandName, cmd, extractReply(command, reply));\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandSucceededEvent = CommandSucceededEvent;\n/**\n * An event indicating the failure of a given command\n * @public\n * @category Event\n */\nclass CommandFailedEvent {\n    /**\n     * Create a failure event\n     *\n     * @internal\n     * @param pool - the pool that originated the command\n     * @param command - the command\n     * @param error - the generated error or a server error response\n     * @param started - a high resolution tuple timestamp of when the command was first sent, to calculate duration\n     */\n    constructor(connection, command, error, started) {\n        /** @internal */\n        this.name = constants_1.COMMAND_FAILED;\n        const cmd = extractCommand(command);\n        const commandName = extractCommandName(cmd);\n        const { address, connectionId, serviceId } = extractConnectionDetails(connection);\n        this.address = address;\n        this.connectionId = connectionId;\n        this.serviceId = serviceId;\n        this.requestId = command.requestId;\n        this.commandName = commandName;\n        this.duration = (0, utils_1.calculateDurationInMs)(started);\n        this.failure = maybeRedact(commandName, cmd, error);\n    }\n    /* @internal */\n    get hasServiceId() {\n        return !!this.serviceId;\n    }\n}\nexports.CommandFailedEvent = CommandFailedEvent;\n/**\n * Commands that we want to redact because of the sensitive nature of their contents\n * @internal\n */\nexports.SENSITIVE_COMMANDS = new Set([\n    'authenticate',\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'createUser',\n    'updateUser',\n    'copydbgetnonce',\n    'copydbsaslstart',\n    'copydb'\n]);\nconst HELLO_COMMANDS = new Set(['hello', constants_1.LEGACY_HELLO_COMMAND, constants_1.LEGACY_HELLO_COMMAND_CAMEL_CASE]);\n// helper methods\nconst extractCommandName = (commandDoc) => Object.keys(commandDoc)[0];\nconst namespace = (command) => command.ns;\nconst collectionName = (command) => command.ns.split('.')[1];\nconst maybeRedact = (commandName, commandDoc, result) => exports.SENSITIVE_COMMANDS.has(commandName) ||\n    (HELLO_COMMANDS.has(commandName) && commandDoc.speculativeAuthenticate)\n    ? {}\n    : result;\nconst LEGACY_FIND_QUERY_MAP = {\n    $query: 'filter',\n    $orderby: 'sort',\n    $hint: 'hint',\n    $comment: 'comment',\n    $maxScan: 'maxScan',\n    $max: 'max',\n    $min: 'min',\n    $returnKey: 'returnKey',\n    $showDiskLoc: 'showRecordId',\n    $maxTimeMS: 'maxTimeMS',\n    $snapshot: 'snapshot'\n};\nconst LEGACY_FIND_OPTIONS_MAP = {\n    numberToSkip: 'skip',\n    numberToReturn: 'batchSize',\n    returnFieldSelector: 'projection'\n};\nconst OP_QUERY_KEYS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'partial',\n    'exhaust'\n];\n/** Extract the actual command from the query, possibly up-converting if it's a legacy format */\nfunction extractCommand(command) {\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(command.command);\n    }\n    if (command.query?.$query) {\n        let result;\n        if (command.ns === 'admin.$cmd') {\n            // up-convert legacy command\n            result = Object.assign({}, command.query.$query);\n        }\n        else {\n            // up-convert legacy find command\n            result = { find: collectionName(command) };\n            Object.keys(LEGACY_FIND_QUERY_MAP).forEach(key => {\n                if (command.query[key] != null) {\n                    result[LEGACY_FIND_QUERY_MAP[key]] = (0, utils_1.deepCopy)(command.query[key]);\n                }\n            });\n        }\n        Object.keys(LEGACY_FIND_OPTIONS_MAP).forEach(key => {\n            const legacyKey = key;\n            if (command[legacyKey] != null) {\n                result[LEGACY_FIND_OPTIONS_MAP[legacyKey]] = (0, utils_1.deepCopy)(command[legacyKey]);\n            }\n        });\n        OP_QUERY_KEYS.forEach(key => {\n            if (command[key]) {\n                result[key] = command[key];\n            }\n        });\n        if (command.pre32Limit != null) {\n            result.limit = command.pre32Limit;\n        }\n        if (command.query.$explain) {\n            return { explain: result };\n        }\n        return result;\n    }\n    const clonedQuery = {};\n    const clonedCommand = {};\n    if (command.query) {\n        for (const k in command.query) {\n            clonedQuery[k] = (0, utils_1.deepCopy)(command.query[k]);\n        }\n        clonedCommand.query = clonedQuery;\n    }\n    for (const k in command) {\n        if (k === 'query')\n            continue;\n        clonedCommand[k] = (0, utils_1.deepCopy)(command[k]);\n    }\n    return command.query ? clonedQuery : clonedCommand;\n}\nfunction extractReply(command, reply) {\n    if (!reply) {\n        return reply;\n    }\n    if (command instanceof commands_1.OpMsgRequest) {\n        return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n    }\n    // is this a legacy find command?\n    if (command.query && command.query.$query != null) {\n        return {\n            ok: 1,\n            cursor: {\n                id: (0, utils_1.deepCopy)(reply.cursorId),\n                ns: namespace(command),\n                firstBatch: (0, utils_1.deepCopy)(reply.documents)\n            }\n        };\n    }\n    return (0, utils_1.deepCopy)(reply.result ? reply.result : reply);\n}\nfunction extractConnectionDetails(connection) {\n    let connectionId;\n    if ('id' in connection) {\n        connectionId = connection.id;\n    }\n    return {\n        address: connection.address,\n        serviceId: connection.serviceId,\n        connectionId\n    };\n}\n//# sourceMappingURL=command_monitoring_events.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/command_monitoring_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/commands.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/commands.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OpCompressedRequest = exports.OpMsgResponse = exports.OpMsgRequest = exports.OpQueryResponse = exports.OpQueryRequest = void 0;\nconst BSON = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst constants_1 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n// Incrementing request id\nlet _requestId = 0;\n// Query flags\nconst OPTS_TAILABLE_CURSOR = 2;\nconst OPTS_SECONDARY = 4;\nconst OPTS_OPLOG_REPLAY = 8;\nconst OPTS_NO_CURSOR_TIMEOUT = 16;\nconst OPTS_AWAIT_DATA = 32;\nconst OPTS_EXHAUST = 64;\nconst OPTS_PARTIAL = 128;\n// Response flags\nconst CURSOR_NOT_FOUND = 1;\nconst QUERY_FAILURE = 2;\nconst SHARD_CONFIG_STALE = 4;\nconst AWAIT_CAPABLE = 8;\n/**************************************************************\n * QUERY\n **************************************************************/\n/** @internal */\nclass OpQueryRequest {\n    constructor(databaseName, query, options) {\n        this.databaseName = databaseName;\n        this.query = query;\n        // Basic options needed to be passed in\n        // TODO(NODE-3483): Replace with MongoCommandError\n        const ns = `${databaseName}.$cmd`;\n        if (typeof databaseName !== 'string') {\n            throw new error_1.MongoRuntimeError('Database name must be a string for a query');\n        }\n        // TODO(NODE-3483): Replace with MongoCommandError\n        if (query == null)\n            throw new error_1.MongoRuntimeError('A query document must be specified for query');\n        // Validate that we are not passing 0x00 in the collection name\n        if (ns.indexOf('\\x00') !== -1) {\n            // TODO(NODE-3483): Use MongoNamespace static method\n            throw new error_1.MongoRuntimeError('Namespace cannot contain a null character');\n        }\n        // Basic options\n        this.ns = ns;\n        // Additional options\n        this.numberToSkip = options.numberToSkip || 0;\n        this.numberToReturn = options.numberToReturn || 0;\n        this.returnFieldSelector = options.returnFieldSelector || undefined;\n        this.requestId = options.requestId ?? OpQueryRequest.getRequestId();\n        // special case for pre-3.2 find commands, delete ASAP\n        this.pre32Limit = options.pre32Limit;\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.batchSize = this.numberToReturn;\n        // Flags\n        this.tailable = false;\n        this.secondaryOk = typeof options.secondaryOk === 'boolean' ? options.secondaryOk : false;\n        this.oplogReplay = false;\n        this.noCursorTimeout = false;\n        this.awaitData = false;\n        this.exhaust = false;\n        this.partial = false;\n    }\n    /** Assign next request Id. */\n    incRequestId() {\n        this.requestId = _requestId++;\n    }\n    /** Peek next request Id. */\n    nextRequestId() {\n        return _requestId + 1;\n    }\n    /** Increment then return next request Id. */\n    static getRequestId() {\n        return ++_requestId;\n    }\n    // Uses a single allocated buffer for the process, avoiding multiple memory allocations\n    toBin() {\n        const buffers = [];\n        let projection = null;\n        // Set up the flags\n        let flags = 0;\n        if (this.tailable) {\n            flags |= OPTS_TAILABLE_CURSOR;\n        }\n        if (this.secondaryOk) {\n            flags |= OPTS_SECONDARY;\n        }\n        if (this.oplogReplay) {\n            flags |= OPTS_OPLOG_REPLAY;\n        }\n        if (this.noCursorTimeout) {\n            flags |= OPTS_NO_CURSOR_TIMEOUT;\n        }\n        if (this.awaitData) {\n            flags |= OPTS_AWAIT_DATA;\n        }\n        if (this.exhaust) {\n            flags |= OPTS_EXHAUST;\n        }\n        if (this.partial) {\n            flags |= OPTS_PARTIAL;\n        }\n        // If batchSize is different to this.numberToReturn\n        if (this.batchSize !== this.numberToReturn)\n            this.numberToReturn = this.batchSize;\n        // Allocate write protocol header buffer\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 + // Flags\n            Buffer.byteLength(this.ns) +\n            1 + // namespace\n            4 + // numberToSkip\n            4 // numberToReturn\n        );\n        // Add header to buffers\n        buffers.push(header);\n        // Serialize the query\n        const query = BSON.serialize(this.query, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n        // Add query document\n        buffers.push(query);\n        if (this.returnFieldSelector && Object.keys(this.returnFieldSelector).length > 0) {\n            // Serialize the projection document\n            projection = BSON.serialize(this.returnFieldSelector, {\n                checkKeys: this.checkKeys,\n                serializeFunctions: this.serializeFunctions,\n                ignoreUndefined: this.ignoreUndefined\n            });\n            // Add projection document\n            buffers.push(projection);\n        }\n        // Total message size\n        const totalLength = header.length + query.length + (projection ? projection.length : 0);\n        // Set up the index\n        let index = 4;\n        // Write total document length\n        header[3] = (totalLength >> 24) & 0xff;\n        header[2] = (totalLength >> 16) & 0xff;\n        header[1] = (totalLength >> 8) & 0xff;\n        header[0] = totalLength & 0xff;\n        // Write header information requestId\n        header[index + 3] = (this.requestId >> 24) & 0xff;\n        header[index + 2] = (this.requestId >> 16) & 0xff;\n        header[index + 1] = (this.requestId >> 8) & 0xff;\n        header[index] = this.requestId & 0xff;\n        index = index + 4;\n        // Write header information responseTo\n        header[index + 3] = (0 >> 24) & 0xff;\n        header[index + 2] = (0 >> 16) & 0xff;\n        header[index + 1] = (0 >> 8) & 0xff;\n        header[index] = 0 & 0xff;\n        index = index + 4;\n        // Write header information OP_QUERY\n        header[index + 3] = (constants_1.OP_QUERY >> 24) & 0xff;\n        header[index + 2] = (constants_1.OP_QUERY >> 16) & 0xff;\n        header[index + 1] = (constants_1.OP_QUERY >> 8) & 0xff;\n        header[index] = constants_1.OP_QUERY & 0xff;\n        index = index + 4;\n        // Write header information flags\n        header[index + 3] = (flags >> 24) & 0xff;\n        header[index + 2] = (flags >> 16) & 0xff;\n        header[index + 1] = (flags >> 8) & 0xff;\n        header[index] = flags & 0xff;\n        index = index + 4;\n        // Write collection name\n        index = index + header.write(this.ns, index, 'utf8') + 1;\n        header[index - 1] = 0;\n        // Write header information flags numberToSkip\n        header[index + 3] = (this.numberToSkip >> 24) & 0xff;\n        header[index + 2] = (this.numberToSkip >> 16) & 0xff;\n        header[index + 1] = (this.numberToSkip >> 8) & 0xff;\n        header[index] = this.numberToSkip & 0xff;\n        index = index + 4;\n        // Write header information flags numberToReturn\n        header[index + 3] = (this.numberToReturn >> 24) & 0xff;\n        header[index + 2] = (this.numberToReturn >> 16) & 0xff;\n        header[index + 1] = (this.numberToReturn >> 8) & 0xff;\n        header[index] = this.numberToReturn & 0xff;\n        index = index + 4;\n        // Return the buffers\n        return buffers;\n    }\n}\nexports.OpQueryRequest = OpQueryRequest;\n/** @internal */\nclass OpQueryResponse {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.documents = new Array(0);\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Flag values\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse(options) {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return;\n        options = options ?? {};\n        // Allow the return of raw documents instead of parsing\n        const raw = options.raw || false;\n        const documentsReturnedIn = options.documentsReturnedIn || null;\n        const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;\n        const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;\n        const promoteValues = options.promoteValues ?? this.opts.promoteValues;\n        const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;\n        const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;\n        let bsonSize;\n        // Set up the options\n        const _options = {\n            useBigInt64,\n            promoteLongs,\n            promoteValues,\n            promoteBuffers,\n            bsonRegExp\n        };\n        // Position within OP_REPLY at which documents start\n        // (See https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#wire-op-reply)\n        this.index = 20;\n        // Read the message body\n        this.responseFlags = this.data.readInt32LE(0);\n        this.cursorId = new BSON.Long(this.data.readInt32LE(4), this.data.readInt32LE(8));\n        this.startingFrom = this.data.readInt32LE(12);\n        this.numberReturned = this.data.readInt32LE(16);\n        // Preallocate document array\n        this.documents = new Array(this.numberReturned);\n        this.cursorNotFound = (this.responseFlags & CURSOR_NOT_FOUND) !== 0;\n        this.queryFailure = (this.responseFlags & QUERY_FAILURE) !== 0;\n        this.shardConfigStale = (this.responseFlags & SHARD_CONFIG_STALE) !== 0;\n        this.awaitCapable = (this.responseFlags & AWAIT_CAPABLE) !== 0;\n        // Parse Body\n        for (let i = 0; i < this.numberReturned; i++) {\n            bsonSize =\n                this.data[this.index] |\n                    (this.data[this.index + 1] << 8) |\n                    (this.data[this.index + 2] << 16) |\n                    (this.data[this.index + 3] << 24);\n            // If we have raw results specified slice the return document\n            if (raw) {\n                this.documents[i] = this.data.slice(this.index, this.index + bsonSize);\n            }\n            else {\n                this.documents[i] = BSON.deserialize(this.data.slice(this.index, this.index + bsonSize), _options);\n            }\n            // Adjust the index\n            this.index = this.index + bsonSize;\n        }\n        if (this.documents.length === 1 && documentsReturnedIn != null && raw) {\n            const fieldsAsRaw = {};\n            fieldsAsRaw[documentsReturnedIn] = true;\n            _options.fieldsAsRaw = fieldsAsRaw;\n            const doc = BSON.deserialize(this.documents[0], _options);\n            this.documents = [doc];\n        }\n        // Set parsed\n        this.parsed = true;\n    }\n}\nexports.OpQueryResponse = OpQueryResponse;\n// Implementation of OP_MSG spec:\n// https://github.com/mongodb/specifications/blob/master/source/message/OP_MSG.rst\n//\n// struct Section {\n//   uint8 payloadType;\n//   union payload {\n//       document  document; // payloadType == 0\n//       struct sequence { // payloadType == 1\n//           int32      size;\n//           cstring    identifier;\n//           document*  documents;\n//       };\n//   };\n// };\n// struct OP_MSG {\n//   struct MsgHeader {\n//       int32  messageLength;\n//       int32  requestID;\n//       int32  responseTo;\n//       int32  opCode = 2013;\n//   };\n//   uint32      flagBits;\n//   Section+    sections;\n//   [uint32     checksum;]\n// };\n// Msg Flags\nconst OPTS_CHECKSUM_PRESENT = 1;\nconst OPTS_MORE_TO_COME = 2;\nconst OPTS_EXHAUST_ALLOWED = 1 << 16;\n/** @internal */\nclass OpMsgRequest {\n    constructor(databaseName, command, options) {\n        this.databaseName = databaseName;\n        this.command = command;\n        this.options = options;\n        // Basic options needed to be passed in\n        if (command == null)\n            throw new error_1.MongoInvalidArgumentError('Query document must be specified for query');\n        // Basic options\n        this.command.$db = databaseName;\n        if (options.readPreference && options.readPreference.mode !== read_preference_1.ReadPreference.PRIMARY) {\n            this.command.$readPreference = options.readPreference.toJSON();\n        }\n        // Ensure empty options\n        this.options = options ?? {};\n        // Additional options\n        this.requestId = options.requestId ? options.requestId : OpMsgRequest.getRequestId();\n        // Serialization option\n        this.serializeFunctions =\n            typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n        this.ignoreUndefined =\n            typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : false;\n        this.checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n        this.maxBsonSize = options.maxBsonSize || 1024 * 1024 * 16;\n        // flags\n        this.checksumPresent = false;\n        this.moreToCome = options.moreToCome || false;\n        this.exhaustAllowed =\n            typeof options.exhaustAllowed === 'boolean' ? options.exhaustAllowed : false;\n    }\n    toBin() {\n        const buffers = [];\n        let flags = 0;\n        if (this.checksumPresent) {\n            flags |= OPTS_CHECKSUM_PRESENT;\n        }\n        if (this.moreToCome) {\n            flags |= OPTS_MORE_TO_COME;\n        }\n        if (this.exhaustAllowed) {\n            flags |= OPTS_EXHAUST_ALLOWED;\n        }\n        const header = Buffer.alloc(4 * 4 + // Header\n            4 // Flags\n        );\n        buffers.push(header);\n        let totalLength = header.length;\n        const command = this.command;\n        totalLength += this.makeDocumentSegment(buffers, command);\n        header.writeInt32LE(totalLength, 0); // messageLength\n        header.writeInt32LE(this.requestId, 4); // requestID\n        header.writeInt32LE(0, 8); // responseTo\n        header.writeInt32LE(constants_1.OP_MSG, 12); // opCode\n        header.writeUInt32LE(flags, 16); // flags\n        return buffers;\n    }\n    makeDocumentSegment(buffers, document) {\n        const payloadTypeBuffer = Buffer.alloc(1);\n        payloadTypeBuffer[0] = 0;\n        const documentBuffer = this.serializeBson(document);\n        buffers.push(payloadTypeBuffer);\n        buffers.push(documentBuffer);\n        return payloadTypeBuffer.length + documentBuffer.length;\n    }\n    serializeBson(document) {\n        return BSON.serialize(document, {\n            checkKeys: this.checkKeys,\n            serializeFunctions: this.serializeFunctions,\n            ignoreUndefined: this.ignoreUndefined\n        });\n    }\n    static getRequestId() {\n        _requestId = (_requestId + 1) & 0x7fffffff;\n        return _requestId;\n    }\n}\nexports.OpMsgRequest = OpMsgRequest;\n/** @internal */\nclass OpMsgResponse {\n    constructor(message, msgHeader, msgBody, opts) {\n        this.parsed = false;\n        this.raw = message;\n        this.data = msgBody;\n        this.opts = opts ?? {\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: false,\n            bsonRegExp: false\n        };\n        // Read the message header\n        this.length = msgHeader.length;\n        this.requestId = msgHeader.requestId;\n        this.responseTo = msgHeader.responseTo;\n        this.opCode = msgHeader.opCode;\n        this.fromCompressed = msgHeader.fromCompressed;\n        // Read response flags\n        this.responseFlags = msgBody.readInt32LE(0);\n        this.checksumPresent = (this.responseFlags & OPTS_CHECKSUM_PRESENT) !== 0;\n        this.moreToCome = (this.responseFlags & OPTS_MORE_TO_COME) !== 0;\n        this.exhaustAllowed = (this.responseFlags & OPTS_EXHAUST_ALLOWED) !== 0;\n        this.useBigInt64 = typeof this.opts.useBigInt64 === 'boolean' ? this.opts.useBigInt64 : false;\n        this.promoteLongs = typeof this.opts.promoteLongs === 'boolean' ? this.opts.promoteLongs : true;\n        this.promoteValues =\n            typeof this.opts.promoteValues === 'boolean' ? this.opts.promoteValues : true;\n        this.promoteBuffers =\n            typeof this.opts.promoteBuffers === 'boolean' ? this.opts.promoteBuffers : false;\n        this.bsonRegExp = typeof this.opts.bsonRegExp === 'boolean' ? this.opts.bsonRegExp : false;\n        this.documents = [];\n    }\n    isParsed() {\n        return this.parsed;\n    }\n    parse(options) {\n        // Don't parse again if not needed\n        if (this.parsed)\n            return;\n        options = options ?? {};\n        this.index = 4;\n        // Allow the return of raw documents instead of parsing\n        const raw = options.raw || false;\n        const documentsReturnedIn = options.documentsReturnedIn || null;\n        const useBigInt64 = options.useBigInt64 ?? this.opts.useBigInt64;\n        const promoteLongs = options.promoteLongs ?? this.opts.promoteLongs;\n        const promoteValues = options.promoteValues ?? this.opts.promoteValues;\n        const promoteBuffers = options.promoteBuffers ?? this.opts.promoteBuffers;\n        const bsonRegExp = options.bsonRegExp ?? this.opts.bsonRegExp;\n        const validation = this.parseBsonSerializationOptions(options);\n        // Set up the options\n        const bsonOptions = {\n            useBigInt64,\n            promoteLongs,\n            promoteValues,\n            promoteBuffers,\n            bsonRegExp,\n            validation\n            // Due to the strictness of the BSON libraries validation option we need this cast\n        };\n        while (this.index < this.data.length) {\n            const payloadType = this.data.readUInt8(this.index++);\n            if (payloadType === 0) {\n                const bsonSize = this.data.readUInt32LE(this.index);\n                const bin = this.data.slice(this.index, this.index + bsonSize);\n                this.documents.push(raw ? bin : BSON.deserialize(bin, bsonOptions));\n                this.index += bsonSize;\n            }\n            else if (payloadType === 1) {\n                // It was decided that no driver makes use of payload type 1\n                // TODO(NODE-3483): Replace with MongoDeprecationError\n                throw new error_1.MongoRuntimeError('OP_MSG Payload Type 1 detected unsupported protocol');\n            }\n        }\n        if (this.documents.length === 1 && documentsReturnedIn != null && raw) {\n            const fieldsAsRaw = {};\n            fieldsAsRaw[documentsReturnedIn] = true;\n            bsonOptions.fieldsAsRaw = fieldsAsRaw;\n            const doc = BSON.deserialize(this.documents[0], bsonOptions);\n            this.documents = [doc];\n        }\n        this.parsed = true;\n    }\n    parseBsonSerializationOptions({ enableUtf8Validation }) {\n        if (enableUtf8Validation === false) {\n            return { utf8: false };\n        }\n        return { utf8: { writeErrors: false } };\n    }\n}\nexports.OpMsgResponse = OpMsgResponse;\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\n/**\n * @internal\n *\n * An OP_COMPRESSED request wraps either an OP_QUERY or OP_MSG message.\n */\nclass OpCompressedRequest {\n    constructor(command, options) {\n        this.command = command;\n        this.options = options;\n    }\n    // Return whether a command contains an uncompressible command term\n    // Will return true if command contains no uncompressible command terms\n    static canCompress(command) {\n        const commandDoc = command instanceof OpMsgRequest ? command.command : command.query;\n        const commandName = Object.keys(commandDoc)[0];\n        return !compression_1.uncompressibleCommands.has(commandName);\n    }\n    async toBin() {\n        const concatenatedOriginalCommandBuffer = Buffer.concat(this.command.toBin());\n        // otherwise, compress the message\n        const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n        // Extract information needed for OP_COMPRESSED from the uncompressed message\n        const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n        // Compress the message body\n        const compressedMessage = await (0, compression_1.compress)(this.options, messageToBeCompressed);\n        // Create the msgHeader of OP_COMPRESSED\n        const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n        msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n        msgHeader.writeInt32LE(this.command.requestId, 4); // requestID\n        msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n        msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n        // Create the compression details of OP_COMPRESSED\n        const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n        compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n        compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n        compressionDetails.writeUInt8(compression_1.Compressor[this.options.agreedCompressor], 8); // compressorID\n        return [msgHeader, compressionDetails, compressedMessage];\n    }\n}\nexports.OpCompressedRequest = OpCompressedRequest;\n//# sourceMappingURL=commands.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/commands.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connect.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connect.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.LEGAL_TCP_SOCKET_OPTIONS = exports.LEGAL_TLS_SOCKET_OPTIONS = exports.prepareHandshakeDocument = exports.connect = exports.AUTH_PROVIDERS = void 0;\nconst net = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'net'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst tls = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'tls'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst auth_provider_1 = __webpack_require__(/*! ./auth/auth_provider */ \"./node_modules/mongodb/lib/cmap/auth/auth_provider.js\");\nconst gssapi_1 = __webpack_require__(/*! ./auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nconst mongocr_1 = __webpack_require__(/*! ./auth/mongocr */ \"./node_modules/mongodb/lib/cmap/auth/mongocr.js\");\nconst mongodb_aws_1 = __webpack_require__(/*! ./auth/mongodb_aws */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_aws.js\");\nconst mongodb_oidc_1 = __webpack_require__(/*! ./auth/mongodb_oidc */ \"./node_modules/mongodb/lib/cmap/auth/mongodb_oidc.js\");\nconst plain_1 = __webpack_require__(/*! ./auth/plain */ \"./node_modules/mongodb/lib/cmap/auth/plain.js\");\nconst providers_1 = __webpack_require__(/*! ./auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst scram_1 = __webpack_require__(/*! ./auth/scram */ \"./node_modules/mongodb/lib/cmap/auth/scram.js\");\nconst x509_1 = __webpack_require__(/*! ./auth/x509 */ \"./node_modules/mongodb/lib/cmap/auth/x509.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst constants_2 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n/** @internal */\nexports.AUTH_PROVIDERS = new Map([\n    [providers_1.AuthMechanism.MONGODB_AWS, new mongodb_aws_1.MongoDBAWS()],\n    [providers_1.AuthMechanism.MONGODB_CR, new mongocr_1.MongoCR()],\n    [providers_1.AuthMechanism.MONGODB_GSSAPI, new gssapi_1.GSSAPI()],\n    [providers_1.AuthMechanism.MONGODB_OIDC, new mongodb_oidc_1.MongoDBOIDC()],\n    [providers_1.AuthMechanism.MONGODB_PLAIN, new plain_1.Plain()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA1, new scram_1.ScramSHA1()],\n    [providers_1.AuthMechanism.MONGODB_SCRAM_SHA256, new scram_1.ScramSHA256()],\n    [providers_1.AuthMechanism.MONGODB_X509, new x509_1.X509()]\n]);\nfunction connect(options, callback) {\n    makeConnection({ ...options, existingSocket: undefined }, (err, socket) => {\n        if (err || !socket) {\n            return callback(err);\n        }\n        let ConnectionType = options.connectionType ?? connection_1.Connection;\n        if (options.autoEncrypter) {\n            ConnectionType = connection_1.CryptoConnection;\n        }\n        const connection = new ConnectionType(socket, options);\n        performInitialHandshake(connection, options).then(() => callback(undefined, connection), error => {\n            connection.destroy({ force: false });\n            callback(error);\n        });\n    });\n}\nexports.connect = connect;\nfunction checkSupportedServer(hello, options) {\n    const maxWireVersion = Number(hello.maxWireVersion);\n    const minWireVersion = Number(hello.minWireVersion);\n    const serverVersionHighEnough = !Number.isNaN(maxWireVersion) && maxWireVersion >= constants_2.MIN_SUPPORTED_WIRE_VERSION;\n    const serverVersionLowEnough = !Number.isNaN(minWireVersion) && minWireVersion <= constants_2.MAX_SUPPORTED_WIRE_VERSION;\n    if (serverVersionHighEnough) {\n        if (serverVersionLowEnough) {\n            return null;\n        }\n        const message = `Server at ${options.hostAddress} reports minimum wire version ${JSON.stringify(hello.minWireVersion)}, but this version of the Node.js Driver requires at most ${constants_2.MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MAX_SUPPORTED_SERVER_VERSION})`;\n        return new error_1.MongoCompatibilityError(message);\n    }\n    const message = `Server at ${options.hostAddress} reports maximum wire version ${JSON.stringify(hello.maxWireVersion) ?? 0}, but this version of the Node.js Driver requires at least ${constants_2.MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${constants_2.MIN_SUPPORTED_SERVER_VERSION})`;\n    return new error_1.MongoCompatibilityError(message);\n}\nasync function performInitialHandshake(conn, options) {\n    const credentials = options.credentials;\n    if (credentials) {\n        if (!(credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT) &&\n            !exports.AUTH_PROVIDERS.get(credentials.mechanism)) {\n            throw new error_1.MongoInvalidArgumentError(`AuthMechanism '${credentials.mechanism}' not supported`);\n        }\n    }\n    const authContext = new auth_provider_1.AuthContext(conn, credentials, options);\n    conn.authContext = authContext;\n    const handshakeDoc = await prepareHandshakeDocument(authContext);\n    // @ts-expect-error: TODO(NODE-5141): The options need to be filtered properly, Connection options differ from Command options\n    const handshakeOptions = { ...options };\n    if (typeof options.connectTimeoutMS === 'number') {\n        // The handshake technically is a monitoring check, so its socket timeout should be connectTimeoutMS\n        handshakeOptions.socketTimeoutMS = options.connectTimeoutMS;\n    }\n    const start = new Date().getTime();\n    const response = await conn.commandAsync((0, utils_1.ns)('admin.$cmd'), handshakeDoc, handshakeOptions);\n    if (!('isWritablePrimary' in response)) {\n        // Provide hello-style response document.\n        response.isWritablePrimary = response[constants_1.LEGACY_HELLO_COMMAND];\n    }\n    if (response.helloOk) {\n        conn.helloOk = true;\n    }\n    const supportedServerErr = checkSupportedServer(response, options);\n    if (supportedServerErr) {\n        throw supportedServerErr;\n    }\n    if (options.loadBalanced) {\n        if (!response.serviceId) {\n            throw new error_1.MongoCompatibilityError('Driver attempted to initialize in load balancing mode, ' +\n                'but the server does not support this mode.');\n        }\n    }\n    // NOTE: This is metadata attached to the connection while porting away from\n    //       handshake being done in the `Server` class. Likely, it should be\n    //       relocated, or at very least restructured.\n    conn.hello = response;\n    conn.lastHelloMS = new Date().getTime() - start;\n    if (!response.arbiterOnly && credentials) {\n        // store the response on auth context\n        authContext.response = response;\n        const resolvedCredentials = credentials.resolveAuthMechanism(response);\n        const provider = exports.AUTH_PROVIDERS.get(resolvedCredentials.mechanism);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${resolvedCredentials.mechanism} defined.`);\n        }\n        try {\n            await provider.auth(authContext);\n        }\n        catch (error) {\n            if (error instanceof error_1.MongoError) {\n                error.addErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n                if ((0, error_1.needsRetryableWriteLabel)(error, response.maxWireVersion)) {\n                    error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n                }\n            }\n            throw error;\n        }\n    }\n}\n/**\n * @internal\n *\n * This function is only exposed for testing purposes.\n */\nasync function prepareHandshakeDocument(authContext) {\n    const options = authContext.options;\n    const compressors = options.compressors ? options.compressors : [];\n    const { serverApi } = authContext.connection;\n    const handshakeDoc = {\n        [serverApi?.version || options.loadBalanced === true ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n        helloOk: true,\n        client: options.metadata,\n        compression: compressors\n    };\n    if (options.loadBalanced === true) {\n        handshakeDoc.loadBalanced = true;\n    }\n    const credentials = authContext.credentials;\n    if (credentials) {\n        if (credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT && credentials.username) {\n            handshakeDoc.saslSupportedMechs = `${credentials.source}.${credentials.username}`;\n            const provider = exports.AUTH_PROVIDERS.get(providers_1.AuthMechanism.MONGODB_SCRAM_SHA256);\n            if (!provider) {\n                // This auth mechanism is always present.\n                throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${providers_1.AuthMechanism.MONGODB_SCRAM_SHA256} defined.`);\n            }\n            return provider.prepare(handshakeDoc, authContext);\n        }\n        const provider = exports.AUTH_PROVIDERS.get(credentials.mechanism);\n        if (!provider) {\n            throw new error_1.MongoInvalidArgumentError(`No AuthProvider for ${credentials.mechanism} defined.`);\n        }\n        return provider.prepare(handshakeDoc, authContext);\n    }\n    return handshakeDoc;\n}\nexports.prepareHandshakeDocument = prepareHandshakeDocument;\n/** @public */\nexports.LEGAL_TLS_SOCKET_OPTIONS = [\n    'ALPNProtocols',\n    'ca',\n    'cert',\n    'checkServerIdentity',\n    'ciphers',\n    'crl',\n    'ecdhCurve',\n    'key',\n    'minDHSize',\n    'passphrase',\n    'pfx',\n    'rejectUnauthorized',\n    'secureContext',\n    'secureProtocol',\n    'servername',\n    'session'\n];\n/** @public */\nexports.LEGAL_TCP_SOCKET_OPTIONS = [\n    'family',\n    'hints',\n    'localAddress',\n    'localPort',\n    'lookup'\n];\nfunction parseConnectOptions(options) {\n    const hostAddress = options.hostAddress;\n    if (!hostAddress)\n        throw new error_1.MongoInvalidArgumentError('Option \"hostAddress\" is required');\n    const result = {};\n    for (const name of exports.LEGAL_TCP_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (typeof hostAddress.socketPath === 'string') {\n        result.path = hostAddress.socketPath;\n        return result;\n    }\n    else if (typeof hostAddress.host === 'string') {\n        result.host = hostAddress.host;\n        result.port = hostAddress.port;\n        return result;\n    }\n    else {\n        // This should never happen since we set up HostAddresses\n        // But if we don't throw here the socket could hang until timeout\n        // TODO(NODE-3483)\n        throw new error_1.MongoRuntimeError(`Unexpected HostAddress ${JSON.stringify(hostAddress)}`);\n    }\n}\nfunction parseSslOptions(options) {\n    const result = parseConnectOptions(options);\n    // Merge in valid SSL options\n    for (const name of exports.LEGAL_TLS_SOCKET_OPTIONS) {\n        if (options[name] != null) {\n            result[name] = options[name];\n        }\n    }\n    if (options.existingSocket) {\n        result.socket = options.existingSocket;\n    }\n    // Set default sni servername to be the same as host\n    if (result.servername == null && result.host && !net.isIP(result.host)) {\n        result.servername = result.host;\n    }\n    return result;\n}\nconst SOCKET_ERROR_EVENT_LIST = ['error', 'close', 'timeout', 'parseError'];\nconst SOCKET_ERROR_EVENTS = new Set(SOCKET_ERROR_EVENT_LIST);\nfunction makeConnection(options, _callback) {\n    const useTLS = options.tls ?? false;\n    const noDelay = options.noDelay ?? true;\n    const connectTimeoutMS = options.connectTimeoutMS ?? 30000;\n    const rejectUnauthorized = options.rejectUnauthorized ?? true;\n    const existingSocket = options.existingSocket;\n    let socket;\n    const callback = function (err, ret) {\n        if (err && socket) {\n            socket.destroy();\n        }\n        _callback(err, ret);\n    };\n    if (options.proxyHost != null) {\n        // Currently, only Socks5 is supported.\n        return makeSocks5Connection({\n            ...options,\n            connectTimeoutMS // Should always be present for Socks5\n        }, callback);\n    }\n    if (useTLS) {\n        const tlsSocket = tls.connect(parseSslOptions(options));\n        if (typeof tlsSocket.disableRenegotiation === 'function') {\n            tlsSocket.disableRenegotiation();\n        }\n        socket = tlsSocket;\n    }\n    else if (existingSocket) {\n        // In the TLS case, parseSslOptions() sets options.socket to existingSocket,\n        // so we only need to handle the non-TLS case here (where existingSocket\n        // gives us all we need out of the box).\n        socket = existingSocket;\n    }\n    else {\n        socket = net.createConnection(parseConnectOptions(options));\n    }\n    socket.setKeepAlive(true, 300000);\n    socket.setTimeout(connectTimeoutMS);\n    socket.setNoDelay(noDelay);\n    const connectEvent = useTLS ? 'secureConnect' : 'connect';\n    let cancellationHandler;\n    function errorHandler(eventName) {\n        return (err) => {\n            SOCKET_ERROR_EVENTS.forEach(event => socket.removeAllListeners(event));\n            if (cancellationHandler && options.cancellationToken) {\n                options.cancellationToken.removeListener('cancel', cancellationHandler);\n            }\n            socket.removeListener(connectEvent, connectHandler);\n            callback(connectionFailureError(eventName, err));\n        };\n    }\n    function connectHandler() {\n        SOCKET_ERROR_EVENTS.forEach(event => socket.removeAllListeners(event));\n        if (cancellationHandler && options.cancellationToken) {\n            options.cancellationToken.removeListener('cancel', cancellationHandler);\n        }\n        if ('authorizationError' in socket) {\n            if (socket.authorizationError && rejectUnauthorized) {\n                // TODO(NODE-5192): wrap this with a MongoError subclass\n                return callback(socket.authorizationError);\n            }\n        }\n        socket.setTimeout(0);\n        callback(undefined, socket);\n    }\n    SOCKET_ERROR_EVENTS.forEach(event => socket.once(event, errorHandler(event)));\n    if (options.cancellationToken) {\n        cancellationHandler = errorHandler('cancel');\n        options.cancellationToken.once('cancel', cancellationHandler);\n    }\n    if (existingSocket) {\n        process.nextTick(connectHandler);\n    }\n    else {\n        socket.once(connectEvent, connectHandler);\n    }\n}\nlet socks = null;\nfunction loadSocks() {\n    if (socks == null) {\n        const socksImport = (0, deps_1.getSocks)();\n        if ('kModuleError' in socksImport) {\n            throw socksImport.kModuleError;\n        }\n        socks = socksImport;\n    }\n    return socks;\n}\nfunction makeSocks5Connection(options, callback) {\n    const hostAddress = utils_1.HostAddress.fromHostPort(options.proxyHost ?? '', // proxyHost is guaranteed to set here\n    options.proxyPort ?? 1080);\n    // First, connect to the proxy server itself:\n    makeConnection({\n        ...options,\n        hostAddress,\n        tls: false,\n        proxyHost: undefined\n    }, (err, rawSocket) => {\n        if (err || !rawSocket) {\n            return callback(err);\n        }\n        const destination = parseConnectOptions(options);\n        if (typeof destination.host !== 'string' || typeof destination.port !== 'number') {\n            return callback(new error_1.MongoInvalidArgumentError('Can only make Socks5 connections to TCP hosts'));\n        }\n        try {\n            socks ??= loadSocks();\n        }\n        catch (error) {\n            return callback(error);\n        }\n        // Then, establish the Socks5 proxy connection:\n        socks.SocksClient.createConnection({\n            existing_socket: rawSocket,\n            timeout: options.connectTimeoutMS,\n            command: 'connect',\n            destination: {\n                host: destination.host,\n                port: destination.port\n            },\n            proxy: {\n                // host and port are ignored because we pass existing_socket\n                host: 'iLoveJavaScript',\n                port: 0,\n                type: 5,\n                userId: options.proxyUsername || undefined,\n                password: options.proxyPassword || undefined\n            }\n        }).then(({ socket }) => {\n            // Finally, now treat the resulting duplex stream as the\n            // socket over which we send and receive wire protocol messages:\n            makeConnection({\n                ...options,\n                existingSocket: socket,\n                proxyHost: undefined\n            }, callback);\n        }, error => callback(connectionFailureError('error', error)));\n    });\n}\nfunction connectionFailureError(type, err) {\n    switch (type) {\n        case 'error':\n            return new error_1.MongoNetworkError(error_1.MongoError.buildErrorMessage(err), { cause: err });\n        case 'timeout':\n            return new error_1.MongoNetworkTimeoutError('connection timed out');\n        case 'close':\n            return new error_1.MongoNetworkError('connection closed');\n        case 'cancel':\n            return new error_1.MongoNetworkError('connection establishment was cancelled');\n        default:\n            return new error_1.MongoNetworkError('unknown network error');\n    }\n}\n//# sourceMappingURL=connect.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/connect.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.read = exports.readMany = exports.writeCommand = exports.readWireProtocolMessages = exports.ModernConnection = exports.hasSessionSupport = exports.CryptoConnection = exports.Connection = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"./node_modules/events/events.js\");\nconst stream_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_monitoring_events_1 = __webpack_require__(/*! ./command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst message_stream_1 = __webpack_require__(/*! ./message_stream */ \"./node_modules/mongodb/lib/cmap/message_stream.js\");\nconst stream_description_1 = __webpack_require__(/*! ./stream_description */ \"./node_modules/mongodb/lib/cmap/stream_description.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst shared_1 = __webpack_require__(/*! ./wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\n/** @internal */\nconst kStream = Symbol('stream');\n/** @internal */\nconst kQueue = Symbol('queue');\n/** @internal */\nconst kMessageStream = Symbol('messageStream');\n/** @internal */\nconst kGeneration = Symbol('generation');\n/** @internal */\nconst kLastUseTime = Symbol('lastUseTime');\n/** @internal */\nconst kClusterTime = Symbol('clusterTime');\n/** @internal */\nconst kDescription = Symbol('description');\n/** @internal */\nconst kHello = Symbol('hello');\n/** @internal */\nconst kAutoEncrypter = Symbol('autoEncrypter');\n/** @internal */\nconst kDelayedTimeoutId = Symbol('delayedTimeoutId');\nconst INVALID_QUEUE_SIZE = 'Connection internal queue contains more than 1 operation description';\n/** @internal */\nclass Connection extends mongo_types_1.TypedEventEmitter {\n    constructor(stream, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, callback) => this.command(ns, cmd, options, callback));\n        this.id = options.id;\n        this.address = streamIdentifier(stream, options);\n        this.socketTimeoutMS = options.socketTimeoutMS ?? 0;\n        this.monitorCommands = options.monitorCommands;\n        this.serverApi = options.serverApi;\n        this.closed = false;\n        this[kHello] = null;\n        this[kClusterTime] = null;\n        this[kDescription] = new stream_description_1.StreamDescription(this.address, options);\n        this[kGeneration] = options.generation;\n        this[kLastUseTime] = (0, utils_1.now)();\n        // setup parser stream and message handling\n        this[kQueue] = new Map();\n        this[kMessageStream] = new message_stream_1.MessageStream({\n            ...options,\n            maxBsonMessageSize: this.hello?.maxBsonMessageSize\n        });\n        this[kStream] = stream;\n        this[kDelayedTimeoutId] = null;\n        this[kMessageStream].on('message', message => this.onMessage(message));\n        this[kMessageStream].on('error', error => this.onError(error));\n        this[kStream].on('close', () => this.onClose());\n        this[kStream].on('timeout', () => this.onTimeout());\n        this[kStream].on('error', () => {\n            /* ignore errors, listen to `close` instead */\n        });\n        // hook the message stream up to the passed in stream\n        this[kStream].pipe(this[kMessageStream]);\n        this[kMessageStream].pipe(this[kStream]);\n    }\n    get description() {\n        return this[kDescription];\n    }\n    get hello() {\n        return this[kHello];\n    }\n    // the `connect` method stores the result of the handshake hello on the connection\n    set hello(response) {\n        this[kDescription].receiveResponse(response);\n        this[kDescription] = Object.freeze(this[kDescription]);\n        // TODO: remove this, and only use the `StreamDescription` in the future\n        this[kHello] = response;\n    }\n    // Set the whether the message stream is for a monitoring connection.\n    set isMonitoringConnection(value) {\n        this[kMessageStream].isMonitoringConnection = value;\n    }\n    get isMonitoringConnection() {\n        return this[kMessageStream].isMonitoringConnection;\n    }\n    get serviceId() {\n        return this.hello?.serviceId;\n    }\n    get loadBalanced() {\n        return this.description.loadBalanced;\n    }\n    get generation() {\n        return this[kGeneration] || 0;\n    }\n    set generation(generation) {\n        this[kGeneration] = generation;\n    }\n    get idleTime() {\n        return (0, utils_1.calculateDurationInMs)(this[kLastUseTime]);\n    }\n    get clusterTime() {\n        return this[kClusterTime];\n    }\n    get stream() {\n        return this[kStream];\n    }\n    markAvailable() {\n        this[kLastUseTime] = (0, utils_1.now)();\n    }\n    onError(error) {\n        this.cleanup(true, error);\n    }\n    onClose() {\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(true, new error_1.MongoNetworkError(message));\n    }\n    onTimeout() {\n        this[kDelayedTimeoutId] = (0, timers_1.setTimeout)(() => {\n            const message = `connection ${this.id} to ${this.address} timed out`;\n            const beforeHandshake = this.hello == null;\n            this.cleanup(true, new error_1.MongoNetworkTimeoutError(message, { beforeHandshake }));\n        }, 1).unref(); // No need for this timer to hold the event loop open\n    }\n    onMessage(message) {\n        const delayedTimeoutId = this[kDelayedTimeoutId];\n        if (delayedTimeoutId != null) {\n            (0, timers_1.clearTimeout)(delayedTimeoutId);\n            this[kDelayedTimeoutId] = null;\n        }\n        const socketTimeoutMS = this[kStream].timeout ?? 0;\n        this[kStream].setTimeout(0);\n        // always emit the message, in case we are streaming\n        this.emit('message', message);\n        let operationDescription = this[kQueue].get(message.responseTo);\n        if (!operationDescription && this.isMonitoringConnection) {\n            // This is how we recover when the initial hello's requestId is not\n            // the responseTo when hello responses have been skipped:\n            // First check if the map is of invalid size\n            if (this[kQueue].size > 1) {\n                this.cleanup(true, new error_1.MongoRuntimeError(INVALID_QUEUE_SIZE));\n            }\n            else {\n                // Get the first orphaned operation description.\n                const entry = this[kQueue].entries().next();\n                if (entry.value != null) {\n                    const [requestId, orphaned] = entry.value;\n                    // If the orphaned operation description exists then set it.\n                    operationDescription = orphaned;\n                    // Remove the entry with the bad request id from the queue.\n                    this[kQueue].delete(requestId);\n                }\n            }\n        }\n        if (!operationDescription) {\n            return;\n        }\n        const callback = operationDescription.cb;\n        // SERVER-45775: For exhaust responses we should be able to use the same requestId to\n        // track response, however the server currently synthetically produces remote requests\n        // making the `responseTo` change on each response\n        this[kQueue].delete(message.responseTo);\n        if ('moreToCome' in message && message.moreToCome) {\n            // If the operation description check above does find an orphaned\n            // description and sets the operationDescription then this line will put one\n            // back in the queue with the correct requestId and will resolve not being able\n            // to find the next one via the responseTo of the next streaming hello.\n            this[kQueue].set(message.requestId, operationDescription);\n            this[kStream].setTimeout(socketTimeoutMS);\n        }\n        try {\n            // Pass in the entire description because it has BSON parsing options\n            message.parse(operationDescription);\n        }\n        catch (err) {\n            // If this error is generated by our own code, it will already have the correct class applied\n            // if it is not, then it is coming from a catastrophic data parse failure or the BSON library\n            // in either case, it should not be wrapped\n            callback(err);\n            return;\n        }\n        if (message.documents[0]) {\n            const document = message.documents[0];\n            const session = operationDescription.session;\n            if (session) {\n                (0, sessions_1.updateSessionFromResponse)(session, document);\n            }\n            if (document.$clusterTime) {\n                this[kClusterTime] = document.$clusterTime;\n                this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);\n            }\n            if (document.writeConcernError) {\n                callback(new error_1.MongoWriteConcernError(document.writeConcernError, document), document);\n                return;\n            }\n            if (document.ok === 0 || document.$err || document.errmsg || document.code) {\n                callback(new error_1.MongoServerError(document));\n                return;\n            }\n        }\n        callback(undefined, message.documents[0]);\n    }\n    destroy(options, callback) {\n        if (this.closed) {\n            process.nextTick(() => callback?.());\n            return;\n        }\n        if (typeof callback === 'function') {\n            this.once('close', () => process.nextTick(() => callback()));\n        }\n        // load balanced mode requires that these listeners remain on the connection\n        // after cleanup on timeouts, errors or close so we remove them before calling\n        // cleanup.\n        this.removeAllListeners(Connection.PINNED);\n        this.removeAllListeners(Connection.UNPINNED);\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(options.force, new error_1.MongoNetworkError(message));\n    }\n    /**\n     * A method that cleans up the connection.  When `force` is true, this method\n     * forcibly destroys the socket.\n     *\n     * If an error is provided, any in-flight operations will be closed with the error.\n     *\n     * This method does nothing if the connection is already closed.\n     */\n    cleanup(force, error) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n        const completeCleanup = () => {\n            for (const op of this[kQueue].values()) {\n                op.cb(error);\n            }\n            this[kQueue].clear();\n            this.emit(Connection.CLOSE);\n        };\n        this[kStream].removeAllListeners();\n        this[kMessageStream].removeAllListeners();\n        this[kMessageStream].destroy();\n        if (force) {\n            this[kStream].destroy();\n            completeCleanup();\n            return;\n        }\n        if (!this[kStream].writableEnded) {\n            this[kStream].end(() => {\n                this[kStream].destroy();\n                completeCleanup();\n            });\n        }\n        else {\n            completeCleanup();\n        }\n    }\n    command(ns, command, options, callback) {\n        let cmd = { ...command };\n        const readPreference = (0, shared_1.getReadPreference)(options);\n        const shouldUseOpMsg = supportsOpMsg(this);\n        const session = options?.session;\n        let clusterTime = this.clusterTime;\n        if (this.serverApi) {\n            const { version, strict, deprecationErrors } = this.serverApi;\n            cmd.apiVersion = version;\n            if (strict != null)\n                cmd.apiStrict = strict;\n            if (deprecationErrors != null)\n                cmd.apiDeprecationErrors = deprecationErrors;\n        }\n        if (hasSessionSupport(this) && session) {\n            if (session.clusterTime &&\n                clusterTime &&\n                session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)) {\n                clusterTime = session.clusterTime;\n            }\n            const err = (0, sessions_1.applySession)(session, cmd, options);\n            if (err) {\n                return callback(err);\n            }\n        }\n        else if (session?.explicit) {\n            return callback(new error_1.MongoCompatibilityError('Current topology does not support sessions'));\n        }\n        // if we have a known cluster time, gossip it\n        if (clusterTime) {\n            cmd.$clusterTime = clusterTime;\n        }\n        if ((0, shared_1.isSharded)(this) && !shouldUseOpMsg && readPreference && readPreference.mode !== 'primary') {\n            cmd = {\n                $query: cmd,\n                $readPreference: readPreference.toJSON()\n            };\n        }\n        const commandOptions = Object.assign({\n            numberToSkip: 0,\n            numberToReturn: -1,\n            checkKeys: false,\n            // This value is not overridable\n            secondaryOk: readPreference.secondaryOk()\n        }, options);\n        const message = shouldUseOpMsg\n            ? new commands_1.OpMsgRequest(ns.db, cmd, commandOptions)\n            : new commands_1.OpQueryRequest(ns.db, cmd, commandOptions);\n        try {\n            write(this, message, commandOptions, callback);\n        }\n        catch (err) {\n            callback(err);\n        }\n    }\n}\n/** @event */\nConnection.COMMAND_STARTED = constants_1.COMMAND_STARTED;\n/** @event */\nConnection.COMMAND_SUCCEEDED = constants_1.COMMAND_SUCCEEDED;\n/** @event */\nConnection.COMMAND_FAILED = constants_1.COMMAND_FAILED;\n/** @event */\nConnection.CLUSTER_TIME_RECEIVED = constants_1.CLUSTER_TIME_RECEIVED;\n/** @event */\nConnection.CLOSE = constants_1.CLOSE;\n/** @event */\nConnection.MESSAGE = constants_1.MESSAGE;\n/** @event */\nConnection.PINNED = constants_1.PINNED;\n/** @event */\nConnection.UNPINNED = constants_1.UNPINNED;\nexports.Connection = Connection;\n/** @internal */\nclass CryptoConnection extends Connection {\n    constructor(stream, options) {\n        super(stream, options);\n        this[kAutoEncrypter] = options.autoEncrypter;\n    }\n    /** @internal @override */\n    command(ns, cmd, options, callback) {\n        const autoEncrypter = this[kAutoEncrypter];\n        if (!autoEncrypter) {\n            return callback(new error_1.MongoMissingDependencyError('No AutoEncrypter available for encryption'));\n        }\n        const serverWireVersion = (0, utils_1.maxWireVersion)(this);\n        if (serverWireVersion === 0) {\n            // This means the initial handshake hasn't happened yet\n            return super.command(ns, cmd, options, callback);\n        }\n        if (serverWireVersion < 8) {\n            callback(new error_1.MongoCompatibilityError('Auto-encryption requires a minimum MongoDB version of 4.2'));\n            return;\n        }\n        // Save sort or indexKeys based on the command being run\n        // the encrypt API serializes our JS objects to BSON to pass to the native code layer\n        // and then deserializes the encrypted result, the protocol level components\n        // of the command (ex. sort) are then converted to JS objects potentially losing\n        // import key order information. These fields are never encrypted so we can save the values\n        // from before the encryption and replace them after encryption has been performed\n        const sort = cmd.find || cmd.findAndModify ? cmd.sort : null;\n        const indexKeys = cmd.createIndexes\n            ? cmd.indexes.map((index) => index.key)\n            : null;\n        autoEncrypter.encrypt(ns.toString(), cmd, options).then(encrypted => {\n            // Replace the saved values\n            if (sort != null && (cmd.find || cmd.findAndModify)) {\n                encrypted.sort = sort;\n            }\n            if (indexKeys != null && cmd.createIndexes) {\n                for (const [offset, index] of indexKeys.entries()) {\n                    // @ts-expect-error `encrypted` is a generic \"command\", but we've narrowed for only `createIndexes` commands here\n                    encrypted.indexes[offset].key = index;\n                }\n            }\n            super.command(ns, encrypted, options, (err, response) => {\n                if (err || response == null) {\n                    callback(err, response);\n                    return;\n                }\n                autoEncrypter.decrypt(response, options).then(res => callback(undefined, res), err => callback(err));\n            });\n        }, err => {\n            if (err) {\n                callback(err, null);\n            }\n        });\n    }\n}\nexports.CryptoConnection = CryptoConnection;\n/** @internal */\nfunction hasSessionSupport(conn) {\n    const description = conn.description;\n    return description.logicalSessionTimeoutMinutes != null;\n}\nexports.hasSessionSupport = hasSessionSupport;\nfunction supportsOpMsg(conn) {\n    const description = conn.description;\n    if (description == null) {\n        return false;\n    }\n    return (0, utils_1.maxWireVersion)(conn) >= 6 && !description.__nodejs_mock_server__;\n}\nfunction streamIdentifier(stream, options) {\n    if (options.proxyHost) {\n        // If proxy options are specified, the properties of `stream` itself\n        // will not accurately reflect what endpoint this is connected to.\n        return options.hostAddress.toString();\n    }\n    const { remoteAddress, remotePort } = stream;\n    if (typeof remoteAddress === 'string' && typeof remotePort === 'number') {\n        return utils_1.HostAddress.fromHostPort(remoteAddress, remotePort).toString();\n    }\n    return (0, utils_1.uuidV4)().toString('hex');\n}\nfunction write(conn, command, options, callback) {\n    options = options ?? {};\n    const operationDescription = {\n        requestId: command.requestId,\n        cb: callback,\n        session: options.session,\n        noResponse: typeof options.noResponse === 'boolean' ? options.noResponse : false,\n        documentsReturnedIn: options.documentsReturnedIn,\n        // for BSON parsing\n        useBigInt64: typeof options.useBigInt64 === 'boolean' ? options.useBigInt64 : false,\n        promoteLongs: typeof options.promoteLongs === 'boolean' ? options.promoteLongs : true,\n        promoteValues: typeof options.promoteValues === 'boolean' ? options.promoteValues : true,\n        promoteBuffers: typeof options.promoteBuffers === 'boolean' ? options.promoteBuffers : false,\n        bsonRegExp: typeof options.bsonRegExp === 'boolean' ? options.bsonRegExp : false,\n        enableUtf8Validation: typeof options.enableUtf8Validation === 'boolean' ? options.enableUtf8Validation : true,\n        raw: typeof options.raw === 'boolean' ? options.raw : false,\n        started: 0\n    };\n    if (conn[kDescription] && conn[kDescription].compressor) {\n        operationDescription.agreedCompressor = conn[kDescription].compressor;\n        if (conn[kDescription].zlibCompressionLevel) {\n            operationDescription.zlibCompressionLevel = conn[kDescription].zlibCompressionLevel;\n        }\n    }\n    if (typeof options.socketTimeoutMS === 'number') {\n        conn[kStream].setTimeout(options.socketTimeoutMS);\n    }\n    else if (conn.socketTimeoutMS !== 0) {\n        conn[kStream].setTimeout(conn.socketTimeoutMS);\n    }\n    // if command monitoring is enabled we need to modify the callback here\n    if (conn.monitorCommands) {\n        conn.emit(Connection.COMMAND_STARTED, new command_monitoring_events_1.CommandStartedEvent(conn, command));\n        operationDescription.started = (0, utils_1.now)();\n        operationDescription.cb = (err, reply) => {\n            // Command monitoring spec states that if ok is 1, then we must always emit\n            // a command succeeded event, even if there's an error. Write concern errors\n            // will have an ok: 1 in their reply.\n            if (err && reply?.ok !== 1) {\n                conn.emit(Connection.COMMAND_FAILED, new command_monitoring_events_1.CommandFailedEvent(conn, command, err, operationDescription.started));\n            }\n            else {\n                if (reply && (reply.ok === 0 || reply.$err)) {\n                    conn.emit(Connection.COMMAND_FAILED, new command_monitoring_events_1.CommandFailedEvent(conn, command, reply, operationDescription.started));\n                }\n                else {\n                    conn.emit(Connection.COMMAND_SUCCEEDED, new command_monitoring_events_1.CommandSucceededEvent(conn, command, reply, operationDescription.started));\n                }\n            }\n            if (typeof callback === 'function') {\n                // Since we're passing through the reply with the write concern error now, we\n                // need it not to be provided to the original callback in this case so\n                // retryability does not get tricked into thinking the command actually\n                // succeeded.\n                callback(err, err instanceof error_1.MongoWriteConcernError ? undefined : reply);\n            }\n        };\n    }\n    if (!operationDescription.noResponse) {\n        conn[kQueue].set(operationDescription.requestId, operationDescription);\n    }\n    try {\n        conn[kMessageStream].writeCommand(command, operationDescription);\n    }\n    catch (e) {\n        if (!operationDescription.noResponse) {\n            conn[kQueue].delete(operationDescription.requestId);\n            operationDescription.cb(e);\n            return;\n        }\n    }\n    if (operationDescription.noResponse) {\n        operationDescription.cb();\n    }\n}\n/** in-progress connection layer */\n/** @internal */\nclass ModernConnection extends mongo_types_1.TypedEventEmitter {\n    constructor(stream, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, callback) => this.command(ns, cmd, options, callback));\n        this.id = options.id;\n        this.address = streamIdentifier(stream, options);\n        this.socketTimeoutMS = options.socketTimeoutMS ?? 0;\n        this.monitorCommands = options.monitorCommands;\n        this.serverApi = options.serverApi;\n        this.closed = false;\n        this[kHello] = null;\n        this[kClusterTime] = null;\n        this[kDescription] = new stream_description_1.StreamDescription(this.address, options);\n        this[kGeneration] = options.generation;\n        this[kLastUseTime] = (0, utils_1.now)();\n        // setup parser stream and message handling\n        this[kQueue] = new Map();\n        this[kMessageStream] = new message_stream_1.MessageStream({\n            ...options,\n            maxBsonMessageSize: this.hello?.maxBsonMessageSize\n        });\n        this.socket = stream;\n        this[kDelayedTimeoutId] = null;\n        this[kMessageStream].on('message', message => this.onMessage(message));\n        this[kMessageStream].on('error', error => this.onError(error));\n        this.socket.on('close', () => this.onClose());\n        this.socket.on('timeout', () => this.onTimeout());\n        this.socket.on('error', () => {\n            /* ignore errors, listen to `close` instead */\n        });\n        // hook the message stream up to the passed in stream\n        this.socket.pipe(this[kMessageStream]);\n        this[kMessageStream].pipe(this.socket);\n    }\n    get description() {\n        return this[kDescription];\n    }\n    get hello() {\n        return this[kHello];\n    }\n    // the `connect` method stores the result of the handshake hello on the connection\n    set hello(response) {\n        this[kDescription].receiveResponse(response);\n        this[kDescription] = Object.freeze(this[kDescription]);\n        // TODO: remove this, and only use the `StreamDescription` in the future\n        this[kHello] = response;\n    }\n    // Set the whether the message stream is for a monitoring connection.\n    set isMonitoringConnection(value) {\n        this[kMessageStream].isMonitoringConnection = value;\n    }\n    get isMonitoringConnection() {\n        return this[kMessageStream].isMonitoringConnection;\n    }\n    get serviceId() {\n        return this.hello?.serviceId;\n    }\n    get loadBalanced() {\n        return this.description.loadBalanced;\n    }\n    get generation() {\n        return this[kGeneration] || 0;\n    }\n    set generation(generation) {\n        this[kGeneration] = generation;\n    }\n    get idleTime() {\n        return (0, utils_1.calculateDurationInMs)(this[kLastUseTime]);\n    }\n    get clusterTime() {\n        return this[kClusterTime];\n    }\n    get stream() {\n        return this.socket;\n    }\n    get hasSessionSupport() {\n        return this.description.logicalSessionTimeoutMinutes != null;\n    }\n    get supportsOpMsg() {\n        return (this.description != null &&\n            (0, utils_1.maxWireVersion)(this) >= 6 &&\n            !this.description.__nodejs_mock_server__);\n    }\n    markAvailable() {\n        this[kLastUseTime] = (0, utils_1.now)();\n    }\n    onError(error) {\n        this.cleanup(true, error);\n    }\n    onClose() {\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(true, new error_1.MongoNetworkError(message));\n    }\n    onTimeout() {\n        this[kDelayedTimeoutId] = (0, timers_1.setTimeout)(() => {\n            const message = `connection ${this.id} to ${this.address} timed out`;\n            const beforeHandshake = this.hello == null;\n            this.cleanup(true, new error_1.MongoNetworkTimeoutError(message, { beforeHandshake }));\n        }, 1).unref(); // No need for this timer to hold the event loop open\n    }\n    onMessage(message) {\n        const delayedTimeoutId = this[kDelayedTimeoutId];\n        if (delayedTimeoutId != null) {\n            (0, timers_1.clearTimeout)(delayedTimeoutId);\n            this[kDelayedTimeoutId] = null;\n        }\n        const socketTimeoutMS = this.socket.timeout ?? 0;\n        this.socket.setTimeout(0);\n        // always emit the message, in case we are streaming\n        this.emit('message', message);\n        let operationDescription = this[kQueue].get(message.responseTo);\n        if (!operationDescription && this.isMonitoringConnection) {\n            // This is how we recover when the initial hello's requestId is not\n            // the responseTo when hello responses have been skipped:\n            // First check if the map is of invalid size\n            if (this[kQueue].size > 1) {\n                this.cleanup(true, new error_1.MongoRuntimeError(INVALID_QUEUE_SIZE));\n            }\n            else {\n                // Get the first orphaned operation description.\n                const entry = this[kQueue].entries().next();\n                if (entry.value != null) {\n                    const [requestId, orphaned] = entry.value;\n                    // If the orphaned operation description exists then set it.\n                    operationDescription = orphaned;\n                    // Remove the entry with the bad request id from the queue.\n                    this[kQueue].delete(requestId);\n                }\n            }\n        }\n        if (!operationDescription) {\n            return;\n        }\n        const callback = operationDescription.cb;\n        // SERVER-45775: For exhaust responses we should be able to use the same requestId to\n        // track response, however the server currently synthetically produces remote requests\n        // making the `responseTo` change on each response\n        this[kQueue].delete(message.responseTo);\n        if ('moreToCome' in message && message.moreToCome) {\n            // If the operation description check above does find an orphaned\n            // description and sets the operationDescription then this line will put one\n            // back in the queue with the correct requestId and will resolve not being able\n            // to find the next one via the responseTo of the next streaming hello.\n            this[kQueue].set(message.requestId, operationDescription);\n            this.socket.setTimeout(socketTimeoutMS);\n        }\n        try {\n            // Pass in the entire description because it has BSON parsing options\n            message.parse(operationDescription);\n        }\n        catch (err) {\n            // If this error is generated by our own code, it will already have the correct class applied\n            // if it is not, then it is coming from a catastrophic data parse failure or the BSON library\n            // in either case, it should not be wrapped\n            callback(err);\n            return;\n        }\n        if (message.documents[0]) {\n            const document = message.documents[0];\n            const session = operationDescription.session;\n            if (session) {\n                (0, sessions_1.updateSessionFromResponse)(session, document);\n            }\n            if (document.$clusterTime) {\n                this[kClusterTime] = document.$clusterTime;\n                this.emit(Connection.CLUSTER_TIME_RECEIVED, document.$clusterTime);\n            }\n            if (document.writeConcernError) {\n                callback(new error_1.MongoWriteConcernError(document.writeConcernError, document), document);\n                return;\n            }\n            if (document.ok === 0 || document.$err || document.errmsg || document.code) {\n                callback(new error_1.MongoServerError(document));\n                return;\n            }\n        }\n        callback(undefined, message.documents[0]);\n    }\n    destroy(options, callback) {\n        if (this.closed) {\n            process.nextTick(() => callback?.());\n            return;\n        }\n        if (typeof callback === 'function') {\n            this.once('close', () => process.nextTick(() => callback()));\n        }\n        // load balanced mode requires that these listeners remain on the connection\n        // after cleanup on timeouts, errors or close so we remove them before calling\n        // cleanup.\n        this.removeAllListeners(Connection.PINNED);\n        this.removeAllListeners(Connection.UNPINNED);\n        const message = `connection ${this.id} to ${this.address} closed`;\n        this.cleanup(options.force, new error_1.MongoNetworkError(message));\n    }\n    /**\n     * A method that cleans up the connection.  When `force` is true, this method\n     * forcibly destroys the socket.\n     *\n     * If an error is provided, any in-flight operations will be closed with the error.\n     *\n     * This method does nothing if the connection is already closed.\n     */\n    cleanup(force, error) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n        const completeCleanup = () => {\n            for (const op of this[kQueue].values()) {\n                op.cb(error);\n            }\n            this[kQueue].clear();\n            this.emit(Connection.CLOSE);\n        };\n        this.socket.removeAllListeners();\n        this[kMessageStream].removeAllListeners();\n        this[kMessageStream].destroy();\n        if (force) {\n            this.socket.destroy();\n            completeCleanup();\n            return;\n        }\n        if (!this.socket.writableEnded) {\n            this.socket.end(() => {\n                this.socket.destroy();\n                completeCleanup();\n            });\n        }\n        else {\n            completeCleanup();\n        }\n    }\n    command(ns, command, options, callback) {\n        let cmd = { ...command };\n        const readPreference = (0, shared_1.getReadPreference)(options);\n        const session = options?.session;\n        let clusterTime = this.clusterTime;\n        if (this.serverApi) {\n            const { version, strict, deprecationErrors } = this.serverApi;\n            cmd.apiVersion = version;\n            if (strict != null)\n                cmd.apiStrict = strict;\n            if (deprecationErrors != null)\n                cmd.apiDeprecationErrors = deprecationErrors;\n        }\n        if (this.hasSessionSupport && session) {\n            if (session.clusterTime &&\n                clusterTime &&\n                session.clusterTime.clusterTime.greaterThan(clusterTime.clusterTime)) {\n                clusterTime = session.clusterTime;\n            }\n            const err = (0, sessions_1.applySession)(session, cmd, options);\n            if (err) {\n                return callback(err);\n            }\n        }\n        else if (session?.explicit) {\n            return callback(new error_1.MongoCompatibilityError('Current topology does not support sessions'));\n        }\n        // if we have a known cluster time, gossip it\n        if (clusterTime) {\n            cmd.$clusterTime = clusterTime;\n        }\n        if (\n        // @ts-expect-error ModernConnections cannot be passed as connections\n        (0, shared_1.isSharded)(this) &&\n            !this.supportsOpMsg &&\n            readPreference &&\n            readPreference.mode !== 'primary') {\n            cmd = {\n                $query: cmd,\n                $readPreference: readPreference.toJSON()\n            };\n        }\n        const commandOptions = Object.assign({\n            numberToSkip: 0,\n            numberToReturn: -1,\n            checkKeys: false,\n            // This value is not overridable\n            secondaryOk: readPreference.secondaryOk()\n        }, options);\n        const message = this.supportsOpMsg\n            ? new commands_1.OpMsgRequest(ns.db, cmd, commandOptions)\n            : new commands_1.OpQueryRequest(ns.db, cmd, commandOptions);\n        try {\n            write(this, message, commandOptions, callback);\n        }\n        catch (err) {\n            callback(err);\n        }\n    }\n}\n/** @event */\nModernConnection.COMMAND_STARTED = constants_1.COMMAND_STARTED;\n/** @event */\nModernConnection.COMMAND_SUCCEEDED = constants_1.COMMAND_SUCCEEDED;\n/** @event */\nModernConnection.COMMAND_FAILED = constants_1.COMMAND_FAILED;\n/** @event */\nModernConnection.CLUSTER_TIME_RECEIVED = constants_1.CLUSTER_TIME_RECEIVED;\n/** @event */\nModernConnection.CLOSE = constants_1.CLOSE;\n/** @event */\nModernConnection.MESSAGE = constants_1.MESSAGE;\n/** @event */\nModernConnection.PINNED = constants_1.PINNED;\n/** @event */\nModernConnection.UNPINNED = constants_1.UNPINNED;\nexports.ModernConnection = ModernConnection;\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/**\n * @internal\n *\n * This helper reads chucks of data out of a socket and buffers them until it has received a\n * full wire protocol message.\n *\n * By itself, produces an infinite async generator of wire protocol messages and consumers must end\n * the stream by calling `return` on the generator.\n *\n * Note that `for-await` loops call `return` automatically when the loop is exited.\n */\nasync function* readWireProtocolMessages(connection) {\n    const bufferPool = new utils_1.BufferPool();\n    const maxBsonMessageSize = connection.hello?.maxBsonMessageSize ?? kDefaultMaxBsonMessageSize;\n    for await (const [chunk] of (0, stream_1.on)(connection.socket, 'data')) {\n        bufferPool.append(chunk);\n        const sizeOfMessage = bufferPool.getInt32();\n        if (sizeOfMessage == null) {\n            continue;\n        }\n        if (sizeOfMessage < 0) {\n            throw new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`);\n        }\n        if (sizeOfMessage > maxBsonMessageSize) {\n            throw new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${maxBsonMessageSize}`);\n        }\n        if (sizeOfMessage > bufferPool.length) {\n            continue;\n        }\n        yield bufferPool.read(sizeOfMessage);\n    }\n}\nexports.readWireProtocolMessages = readWireProtocolMessages;\n/**\n * @internal\n *\n * Writes an OP_MSG or OP_QUERY request to the socket, optionally compressing the command. This method\n * waits until the socket's buffer has emptied (the Nodejs socket `drain` event has fired).\n */\nasync function writeCommand(connection, command, options) {\n    const drained = (0, events_1.once)(connection.socket, 'drain');\n    const finalCommand = options.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n        ? command\n        : new commands_1.OpCompressedRequest(command, {\n            agreedCompressor: options.agreedCompressor ?? 'none',\n            zlibCompressionLevel: options.zlibCompressionLevel ?? 0\n        });\n    const buffer = Buffer.concat(await finalCommand.toBin());\n    connection.socket.push(buffer);\n    await drained;\n}\nexports.writeCommand = writeCommand;\n/**\n * @internal\n *\n * Returns an async generator that yields full wire protocol messages from the underlying socket.  This function\n * yields messages until `moreToCome` is false or not present in a response, or the caller cancels the request\n * by calling `return` on the generator.\n *\n * Note that `for-await` loops call `return` automatically when the loop is exited.\n */\nasync function* readMany(connection) {\n    for await (const message of readWireProtocolMessages(connection)) {\n        const response = await (0, compression_1.decompressResponse)(message);\n        yield response;\n        if (!('moreToCome' in response) || !response.moreToCome) {\n            return;\n        }\n    }\n}\nexports.readMany = readMany;\n/**\n * @internal\n *\n * Reads a single wire protocol message out of a connection.\n */\nasync function read(connection) {\n    for await (const value of readMany(connection)) {\n        return value;\n    }\n    throw new error_1.MongoRuntimeError('unable to read message off of connection');\n}\nexports.read = read;\n//# sourceMappingURL=connection.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/connection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPool = exports.PoolState = void 0;\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst connect_1 = __webpack_require__(/*! ./connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst connection_1 = __webpack_require__(/*! ./connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_events_1 = __webpack_require__(/*! ./connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst metrics_1 = __webpack_require__(/*! ./metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kConnections = Symbol('connections');\n/** @internal */\nconst kPending = Symbol('pending');\n/** @internal */\nconst kCheckedOut = Symbol('checkedOut');\n/** @internal */\nconst kMinPoolSizeTimer = Symbol('minPoolSizeTimer');\n/** @internal */\nconst kGeneration = Symbol('generation');\n/** @internal */\nconst kServiceGenerations = Symbol('serviceGenerations');\n/** @internal */\nconst kConnectionCounter = Symbol('connectionCounter');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kMetrics = Symbol('metrics');\n/** @internal */\nconst kProcessingWaitQueue = Symbol('processingWaitQueue');\n/** @internal */\nconst kPoolState = Symbol('poolState');\n/** @internal */\nexports.PoolState = Object.freeze({\n    paused: 'paused',\n    ready: 'ready',\n    closed: 'closed'\n});\n/**\n * A pool of connections which dynamically resizes, and emit events related to pool activity\n * @internal\n */\nclass ConnectionPool extends mongo_types_1.TypedEventEmitter {\n    constructor(server, options) {\n        super();\n        this.options = Object.freeze({\n            ...options,\n            connectionType: connection_1.Connection,\n            maxPoolSize: options.maxPoolSize ?? 100,\n            minPoolSize: options.minPoolSize ?? 0,\n            maxConnecting: options.maxConnecting ?? 2,\n            maxIdleTimeMS: options.maxIdleTimeMS ?? 0,\n            waitQueueTimeoutMS: options.waitQueueTimeoutMS ?? 0,\n            minPoolSizeCheckFrequencyMS: options.minPoolSizeCheckFrequencyMS ?? 100,\n            autoEncrypter: options.autoEncrypter,\n            metadata: options.metadata\n        });\n        if (this.options.minPoolSize > this.options.maxPoolSize) {\n            throw new error_1.MongoInvalidArgumentError('Connection pool minimum size must not be greater than maximum pool size');\n        }\n        this[kPoolState] = exports.PoolState.paused;\n        this[kServer] = server;\n        this[kConnections] = new utils_1.List();\n        this[kPending] = 0;\n        this[kCheckedOut] = new Set();\n        this[kMinPoolSizeTimer] = undefined;\n        this[kGeneration] = 0;\n        this[kServiceGenerations] = new Map();\n        this[kConnectionCounter] = (0, utils_1.makeCounter)(1);\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kWaitQueue] = new utils_1.List();\n        this[kMetrics] = new metrics_1.ConnectionPoolMetrics();\n        this[kProcessingWaitQueue] = false;\n        this.mongoLogger = this[kServer].topology.client.mongoLogger;\n        this.component = 'connection';\n        process.nextTick(() => {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CREATED, new connection_pool_events_1.ConnectionPoolCreatedEvent(this));\n        });\n    }\n    /** The address of the endpoint the pool is connected to */\n    get address() {\n        return this.options.hostAddress.toString();\n    }\n    /**\n     * Check if the pool has been closed\n     *\n     * TODO(NODE-3263): We can remove this property once shell no longer needs it\n     */\n    get closed() {\n        return this[kPoolState] === exports.PoolState.closed;\n    }\n    /** An integer representing the SDAM generation of the pool */\n    get generation() {\n        return this[kGeneration];\n    }\n    /** An integer expressing how many total connections (available + pending + in use) the pool currently has */\n    get totalConnectionCount() {\n        return (this.availableConnectionCount + this.pendingConnectionCount + this.currentCheckedOutCount);\n    }\n    /** An integer expressing how many connections are currently available in the pool. */\n    get availableConnectionCount() {\n        return this[kConnections].length;\n    }\n    get pendingConnectionCount() {\n        return this[kPending];\n    }\n    get currentCheckedOutCount() {\n        return this[kCheckedOut].size;\n    }\n    get waitQueueSize() {\n        return this[kWaitQueue].length;\n    }\n    get loadBalanced() {\n        return this.options.loadBalanced;\n    }\n    get serviceGenerations() {\n        return this[kServiceGenerations];\n    }\n    get serverError() {\n        return this[kServer].description.error;\n    }\n    /**\n     * This is exposed ONLY for use in mongosh, to enable\n     * killing all connections if a user quits the shell with\n     * operations in progress.\n     *\n     * This property may be removed as a part of NODE-3263.\n     */\n    get checkedOutConnections() {\n        return this[kCheckedOut];\n    }\n    /**\n     * Get the metrics information for the pool when a wait queue timeout occurs.\n     */\n    waitQueueErrorMetrics() {\n        return this[kMetrics].info(this.options.maxPoolSize);\n    }\n    /**\n     * Set the pool state to \"ready\"\n     */\n    ready() {\n        if (this[kPoolState] !== exports.PoolState.paused) {\n            return;\n        }\n        this[kPoolState] = exports.PoolState.ready;\n        this.emitAndLog(ConnectionPool.CONNECTION_POOL_READY, new connection_pool_events_1.ConnectionPoolReadyEvent(this));\n        (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n        this.ensureMinPoolSize();\n    }\n    /**\n     * Check a connection out of this pool. The connection will continue to be tracked, but no reference to it\n     * will be held by the pool. This means that if a connection is checked out it MUST be checked back in or\n     * explicitly destroyed by the new owner.\n     */\n    checkOut(callback) {\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_STARTED, new connection_pool_events_1.ConnectionCheckOutStartedEvent(this));\n        const waitQueueTimeoutMS = this.options.waitQueueTimeoutMS;\n        const waitQueueMember = {\n            callback,\n            timeoutController: new utils_1.TimeoutController(waitQueueTimeoutMS)\n        };\n        waitQueueMember.timeoutController.signal.addEventListener('abort', () => {\n            waitQueueMember[kCancelled] = true;\n            waitQueueMember.timeoutController.clear();\n            this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'timeout'));\n            waitQueueMember.callback(new errors_1.WaitQueueTimeoutError(this.loadBalanced\n                ? this.waitQueueErrorMetrics()\n                : 'Timed out while checking out a connection from connection pool', this.address));\n        });\n        this[kWaitQueue].push(waitQueueMember);\n        process.nextTick(() => this.processWaitQueue());\n    }\n    /**\n     * Check a connection into the pool.\n     *\n     * @param connection - The connection to check in\n     */\n    checkIn(connection) {\n        if (!this[kCheckedOut].has(connection)) {\n            return;\n        }\n        const poolClosed = this.closed;\n        const stale = this.connectionIsStale(connection);\n        const willDestroy = !!(poolClosed || stale || connection.closed);\n        if (!willDestroy) {\n            connection.markAvailable();\n            this[kConnections].unshift(connection);\n        }\n        this[kCheckedOut].delete(connection);\n        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_IN, new connection_pool_events_1.ConnectionCheckedInEvent(this, connection));\n        if (willDestroy) {\n            const reason = connection.closed ? 'error' : poolClosed ? 'poolClosed' : 'stale';\n            this.destroyConnection(connection, reason);\n        }\n        process.nextTick(() => this.processWaitQueue());\n    }\n    /**\n     * Clear the pool\n     *\n     * Pool reset is handled by incrementing the pool's generation count. Any existing connection of a\n     * previous generation will eventually be pruned during subsequent checkouts.\n     */\n    clear(options = {}) {\n        if (this.closed) {\n            return;\n        }\n        // handle load balanced case\n        if (this.loadBalanced) {\n            const { serviceId } = options;\n            if (!serviceId) {\n                throw new error_1.MongoRuntimeError('ConnectionPool.clear() called in load balanced mode with no serviceId.');\n            }\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            // Only need to worry if the generation exists, since it should\n            // always be there but typescript needs the check.\n            if (generation == null) {\n                throw new error_1.MongoRuntimeError('Service generations are required in load balancer mode.');\n            }\n            else {\n                // Increment the generation for the service id.\n                this.serviceGenerations.set(sid, generation + 1);\n            }\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, { serviceId }));\n            return;\n        }\n        // handle non load-balanced case\n        const interruptInUseConnections = options.interruptInUseConnections ?? false;\n        const oldGeneration = this[kGeneration];\n        this[kGeneration] += 1;\n        const alreadyPaused = this[kPoolState] === exports.PoolState.paused;\n        this[kPoolState] = exports.PoolState.paused;\n        this.clearMinPoolSizeTimer();\n        if (!alreadyPaused) {\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLEARED, new connection_pool_events_1.ConnectionPoolClearedEvent(this, {\n                interruptInUseConnections\n            }));\n        }\n        if (interruptInUseConnections) {\n            process.nextTick(() => this.interruptInUseConnections(oldGeneration));\n        }\n        this.processWaitQueue();\n    }\n    /**\n     * Closes all stale in-use connections in the pool with a resumable PoolClearedOnNetworkError.\n     *\n     * Only connections where `connection.generation <= minGeneration` are killed.\n     */\n    interruptInUseConnections(minGeneration) {\n        for (const connection of this[kCheckedOut]) {\n            if (connection.generation <= minGeneration) {\n                this.checkIn(connection);\n                connection.onError(new errors_1.PoolClearedOnNetworkError(this));\n            }\n        }\n    }\n    close(_options, _cb) {\n        let options = _options;\n        const callback = (_cb ?? _options);\n        if (typeof options === 'function') {\n            options = {};\n        }\n        options = Object.assign({ force: false }, options);\n        if (this.closed) {\n            return callback();\n        }\n        // immediately cancel any in-flight connections\n        this[kCancellationToken].emit('cancel');\n        // end the connection counter\n        if (typeof this[kConnectionCounter].return === 'function') {\n            this[kConnectionCounter].return(undefined);\n        }\n        this[kPoolState] = exports.PoolState.closed;\n        this.clearMinPoolSizeTimer();\n        this.processWaitQueue();\n        (0, utils_1.eachAsync)(this[kConnections].toArray(), (conn, cb) => {\n            this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, conn, 'poolClosed'));\n            conn.destroy({ force: !!options.force }, cb);\n        }, err => {\n            this[kConnections].clear();\n            this.emitAndLog(ConnectionPool.CONNECTION_POOL_CLOSED, new connection_pool_events_1.ConnectionPoolClosedEvent(this));\n            callback(err);\n        });\n    }\n    /**\n     * Runs a lambda with an implicitly checked out connection, checking that connection back in when the lambda\n     * has completed by calling back.\n     *\n     * NOTE: please note the required signature of `fn`\n     *\n     * @remarks When in load balancer mode, connections can be pinned to cursors or transactions.\n     *   In these cases we pass the connection in to this method to ensure it is used and a new\n     *   connection is not checked out.\n     *\n     * @param conn - A pinned connection for use in load balancing mode.\n     * @param fn - A function which operates on a managed connection\n     * @param callback - The original callback\n     */\n    withConnection(conn, fn, callback) {\n        if (conn) {\n            // use the provided connection, and do _not_ check it in after execution\n            fn(undefined, conn, (fnErr, result) => {\n                if (fnErr) {\n                    return this.withReauthentication(fnErr, conn, fn, callback);\n                }\n                callback(undefined, result);\n            });\n            return;\n        }\n        this.checkOut((err, conn) => {\n            // don't callback with `err` here, we might want to act upon it inside `fn`\n            fn(err, conn, (fnErr, result) => {\n                if (fnErr) {\n                    if (conn) {\n                        this.withReauthentication(fnErr, conn, fn, callback);\n                    }\n                    else {\n                        callback(fnErr);\n                    }\n                }\n                else {\n                    callback(undefined, result);\n                }\n                if (conn) {\n                    this.checkIn(conn);\n                }\n            });\n        });\n    }\n    withReauthentication(fnErr, conn, fn, callback) {\n        if (fnErr instanceof error_1.MongoError && fnErr.code === error_1.MONGODB_ERROR_CODES.Reauthenticate) {\n            this.reauthenticate(conn, fn, (error, res) => {\n                if (error) {\n                    return callback(error);\n                }\n                callback(undefined, res);\n            });\n        }\n        else {\n            callback(fnErr);\n        }\n    }\n    /**\n     * Reauthenticate on the same connection and then retry the operation.\n     */\n    reauthenticate(connection, fn, callback) {\n        const authContext = connection.authContext;\n        if (!authContext) {\n            return callback(new error_1.MongoRuntimeError('No auth context found on connection.'));\n        }\n        const credentials = authContext.credentials;\n        if (!credentials) {\n            return callback(new error_1.MongoMissingCredentialsError('Connection is missing credentials when asked to reauthenticate'));\n        }\n        const resolvedCredentials = credentials.resolveAuthMechanism(connection.hello || undefined);\n        const provider = connect_1.AUTH_PROVIDERS.get(resolvedCredentials.mechanism);\n        if (!provider) {\n            return callback(new error_1.MongoMissingCredentialsError(`Reauthenticate failed due to no auth provider for ${credentials.mechanism}`));\n        }\n        provider.reauth(authContext).then(() => {\n            fn(undefined, connection, (fnErr, fnResult) => {\n                if (fnErr) {\n                    return callback(fnErr);\n                }\n                callback(undefined, fnResult);\n            });\n        }, error => callback(error));\n    }\n    /** Clear the min pool size timer */\n    clearMinPoolSizeTimer() {\n        const minPoolSizeTimer = this[kMinPoolSizeTimer];\n        if (minPoolSizeTimer) {\n            (0, timers_1.clearTimeout)(minPoolSizeTimer);\n        }\n    }\n    destroyConnection(connection, reason) {\n        this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, connection, reason));\n        // destroy the connection\n        process.nextTick(() => connection.destroy({ force: false }));\n    }\n    connectionIsStale(connection) {\n        const serviceId = connection.serviceId;\n        if (this.loadBalanced && serviceId) {\n            const sid = serviceId.toHexString();\n            const generation = this.serviceGenerations.get(sid);\n            return connection.generation !== generation;\n        }\n        return connection.generation !== this[kGeneration];\n    }\n    connectionIsIdle(connection) {\n        return !!(this.options.maxIdleTimeMS && connection.idleTime > this.options.maxIdleTimeMS);\n    }\n    /**\n     * Destroys a connection if the connection is perished.\n     *\n     * @returns `true` if the connection was destroyed, `false` otherwise.\n     */\n    destroyConnectionIfPerished(connection) {\n        const isStale = this.connectionIsStale(connection);\n        const isIdle = this.connectionIsIdle(connection);\n        if (!isStale && !isIdle && !connection.closed) {\n            return false;\n        }\n        const reason = connection.closed ? 'error' : isStale ? 'stale' : 'idle';\n        this.destroyConnection(connection, reason);\n        return true;\n    }\n    createConnection(callback) {\n        const connectOptions = {\n            ...this.options,\n            id: this[kConnectionCounter].next().value,\n            generation: this[kGeneration],\n            cancellationToken: this[kCancellationToken]\n        };\n        this[kPending]++;\n        // This is our version of a \"virtual\" no-I/O connection as the spec requires\n        this.emitAndLog(ConnectionPool.CONNECTION_CREATED, new connection_pool_events_1.ConnectionCreatedEvent(this, { id: connectOptions.id }));\n        (0, connect_1.connect)(connectOptions, (err, connection) => {\n            if (err || !connection) {\n                this[kPending]--;\n                this.emitAndLog(ConnectionPool.CONNECTION_CLOSED, new connection_pool_events_1.ConnectionClosedEvent(this, { id: connectOptions.id, serviceId: undefined }, 'error', \n                // TODO(NODE-5192): Remove this cast\n                err));\n                if (err instanceof error_1.MongoNetworkError || err instanceof error_1.MongoServerError) {\n                    err.connectionGeneration = connectOptions.generation;\n                }\n                callback(err ?? new error_1.MongoRuntimeError('Connection creation failed without error'));\n                return;\n            }\n            // The pool might have closed since we started trying to create a connection\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                this[kPending]--;\n                connection.destroy({ force: true });\n                callback(this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this));\n                return;\n            }\n            // forward all events from the connection to the pool\n            for (const event of [...constants_1.APM_EVENTS, connection_1.Connection.CLUSTER_TIME_RECEIVED]) {\n                connection.on(event, (e) => this.emit(event, e));\n            }\n            if (this.loadBalanced) {\n                connection.on(connection_1.Connection.PINNED, pinType => this[kMetrics].markPinned(pinType));\n                connection.on(connection_1.Connection.UNPINNED, pinType => this[kMetrics].markUnpinned(pinType));\n                const serviceId = connection.serviceId;\n                if (serviceId) {\n                    let generation;\n                    const sid = serviceId.toHexString();\n                    if ((generation = this.serviceGenerations.get(sid))) {\n                        connection.generation = generation;\n                    }\n                    else {\n                        this.serviceGenerations.set(sid, 0);\n                        connection.generation = 0;\n                    }\n                }\n            }\n            connection.markAvailable();\n            this.emitAndLog(ConnectionPool.CONNECTION_READY, new connection_pool_events_1.ConnectionReadyEvent(this, connection));\n            this[kPending]--;\n            callback(undefined, connection);\n            return;\n        });\n    }\n    ensureMinPoolSize() {\n        const minPoolSize = this.options.minPoolSize;\n        if (this[kPoolState] !== exports.PoolState.ready || minPoolSize === 0) {\n            return;\n        }\n        this[kConnections].prune(connection => this.destroyConnectionIfPerished(connection));\n        if (this.totalConnectionCount < minPoolSize &&\n            this.pendingConnectionCount < this.options.maxConnecting) {\n            // NOTE: ensureMinPoolSize should not try to get all the pending\n            // connection permits because that potentially delays the availability of\n            // the connection to a checkout request\n            this.createConnection((err, connection) => {\n                if (err) {\n                    this[kServer].handleError(err);\n                }\n                if (!err && connection) {\n                    this[kConnections].push(connection);\n                    process.nextTick(() => this.processWaitQueue());\n                }\n                if (this[kPoolState] === exports.PoolState.ready) {\n                    (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n                    this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n                }\n            });\n        }\n        else {\n            (0, timers_1.clearTimeout)(this[kMinPoolSizeTimer]);\n            this[kMinPoolSizeTimer] = (0, timers_1.setTimeout)(() => this.ensureMinPoolSize(), this.options.minPoolSizeCheckFrequencyMS);\n        }\n    }\n    processWaitQueue() {\n        if (this[kProcessingWaitQueue]) {\n            return;\n        }\n        this[kProcessingWaitQueue] = true;\n        while (this.waitQueueSize) {\n            const waitQueueMember = this[kWaitQueue].first();\n            if (!waitQueueMember) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (waitQueueMember[kCancelled]) {\n                this[kWaitQueue].shift();\n                continue;\n            }\n            if (this[kPoolState] !== exports.PoolState.ready) {\n                const reason = this.closed ? 'poolClosed' : 'connectionError';\n                const error = this.closed ? new errors_1.PoolClosedError(this) : new errors_1.PoolClearedError(this);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, reason, error));\n                waitQueueMember.timeoutController.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.callback(error);\n                continue;\n            }\n            if (!this.availableConnectionCount) {\n                break;\n            }\n            const connection = this[kConnections].shift();\n            if (!connection) {\n                break;\n            }\n            if (!this.destroyConnectionIfPerished(connection)) {\n                this[kCheckedOut].add(connection);\n                this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                waitQueueMember.timeoutController.clear();\n                this[kWaitQueue].shift();\n                waitQueueMember.callback(undefined, connection);\n            }\n        }\n        const { maxPoolSize, maxConnecting } = this.options;\n        while (this.waitQueueSize > 0 &&\n            this.pendingConnectionCount < maxConnecting &&\n            (maxPoolSize === 0 || this.totalConnectionCount < maxPoolSize)) {\n            const waitQueueMember = this[kWaitQueue].shift();\n            if (!waitQueueMember || waitQueueMember[kCancelled]) {\n                continue;\n            }\n            this.createConnection((err, connection) => {\n                if (waitQueueMember[kCancelled]) {\n                    if (!err && connection) {\n                        this[kConnections].push(connection);\n                    }\n                }\n                else {\n                    if (err) {\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECK_OUT_FAILED, \n                        // TODO(NODE-5192): Remove this cast\n                        new connection_pool_events_1.ConnectionCheckOutFailedEvent(this, 'connectionError', err));\n                    }\n                    else if (connection) {\n                        this[kCheckedOut].add(connection);\n                        this.emitAndLog(ConnectionPool.CONNECTION_CHECKED_OUT, new connection_pool_events_1.ConnectionCheckedOutEvent(this, connection));\n                    }\n                    waitQueueMember.timeoutController.clear();\n                    waitQueueMember.callback(err, connection);\n                }\n                process.nextTick(() => this.processWaitQueue());\n            });\n        }\n        this[kProcessingWaitQueue] = false;\n    }\n}\n/**\n * Emitted when the connection pool is created.\n * @event\n */\nConnectionPool.CONNECTION_POOL_CREATED = constants_1.CONNECTION_POOL_CREATED;\n/**\n * Emitted once when the connection pool is closed\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLOSED = constants_1.CONNECTION_POOL_CLOSED;\n/**\n * Emitted each time the connection pool is cleared and it's generation incremented\n * @event\n */\nConnectionPool.CONNECTION_POOL_CLEARED = constants_1.CONNECTION_POOL_CLEARED;\n/**\n * Emitted each time the connection pool is marked ready\n * @event\n */\nConnectionPool.CONNECTION_POOL_READY = constants_1.CONNECTION_POOL_READY;\n/**\n * Emitted when a connection is created.\n * @event\n */\nConnectionPool.CONNECTION_CREATED = constants_1.CONNECTION_CREATED;\n/**\n * Emitted when a connection becomes established, and is ready to use\n * @event\n */\nConnectionPool.CONNECTION_READY = constants_1.CONNECTION_READY;\n/**\n * Emitted when a connection is closed\n * @event\n */\nConnectionPool.CONNECTION_CLOSED = constants_1.CONNECTION_CLOSED;\n/**\n * Emitted when an attempt to check out a connection begins\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_STARTED = constants_1.CONNECTION_CHECK_OUT_STARTED;\n/**\n * Emitted when an attempt to check out a connection fails\n * @event\n */\nConnectionPool.CONNECTION_CHECK_OUT_FAILED = constants_1.CONNECTION_CHECK_OUT_FAILED;\n/**\n * Emitted each time a connection is successfully checked out of the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_OUT = constants_1.CONNECTION_CHECKED_OUT;\n/**\n * Emitted each time a connection is successfully checked into the connection pool\n * @event\n */\nConnectionPool.CONNECTION_CHECKED_IN = constants_1.CONNECTION_CHECKED_IN;\nexports.ConnectionPool = ConnectionPool;\n//# sourceMappingURL=connection_pool.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/connection_pool.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/connection_pool_events.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/connection_pool_events.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolClearedEvent = exports.ConnectionCheckedInEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionClosedEvent = exports.ConnectionReadyEvent = exports.ConnectionCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolReadyEvent = exports.ConnectionPoolCreatedEvent = exports.ConnectionPoolMonitoringEvent = void 0;\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\n/**\n * The base export class for all monitoring events published from the connection pool\n * @public\n * @category Event\n */\nclass ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        this.time = new Date();\n        this.address = pool.address;\n    }\n}\nexports.ConnectionPoolMonitoringEvent = ConnectionPoolMonitoringEvent;\n/**\n * An event published when a connection pool is created\n * @public\n * @category Event\n */\nclass ConnectionPoolCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CREATED;\n        const { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS } = pool.options;\n        this.options = { maxConnecting, maxPoolSize, minPoolSize, maxIdleTimeMS, waitQueueTimeoutMS };\n    }\n}\nexports.ConnectionPoolCreatedEvent = ConnectionPoolCreatedEvent;\n/**\n * An event published when a connection pool is ready\n * @public\n * @category Event\n */\nclass ConnectionPoolReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_READY;\n    }\n}\nexports.ConnectionPoolReadyEvent = ConnectionPoolReadyEvent;\n/**\n * An event published when a connection pool is closed\n * @public\n * @category Event\n */\nclass ConnectionPoolClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLOSED;\n    }\n}\nexports.ConnectionPoolClosedEvent = ConnectionPoolClosedEvent;\n/**\n * An event published when a connection pool creates a new connection\n * @public\n * @category Event\n */\nclass ConnectionCreatedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CREATED;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCreatedEvent = ConnectionCreatedEvent;\n/**\n * An event published when a connection is ready for use\n * @public\n * @category Event\n */\nclass ConnectionReadyEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_READY;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionReadyEvent = ConnectionReadyEvent;\n/**\n * An event published when a connection is closed\n * @public\n * @category Event\n */\nclass ConnectionClosedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CLOSED;\n        this.connectionId = connection.id;\n        this.reason = reason;\n        this.serviceId = connection.serviceId;\n        this.error = error ?? null;\n    }\n}\nexports.ConnectionClosedEvent = ConnectionClosedEvent;\n/**\n * An event published when a request to check a connection out begins\n * @public\n * @category Event\n */\nclass ConnectionCheckOutStartedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_STARTED;\n    }\n}\nexports.ConnectionCheckOutStartedEvent = ConnectionCheckOutStartedEvent;\n/**\n * An event published when a request to check a connection out fails\n * @public\n * @category Event\n */\nclass ConnectionCheckOutFailedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, reason, error) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECK_OUT_FAILED;\n        this.reason = reason;\n        this.error = error;\n    }\n}\nexports.ConnectionCheckOutFailedEvent = ConnectionCheckOutFailedEvent;\n/**\n * An event published when a connection is checked out of the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedOutEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_OUT;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedOutEvent = ConnectionCheckedOutEvent;\n/**\n * An event published when a connection is checked into the connection pool\n * @public\n * @category Event\n */\nclass ConnectionCheckedInEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, connection) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_CHECKED_IN;\n        this.connectionId = connection.id;\n    }\n}\nexports.ConnectionCheckedInEvent = ConnectionCheckedInEvent;\n/**\n * An event published when a connection pool is cleared\n * @public\n * @category Event\n */\nclass ConnectionPoolClearedEvent extends ConnectionPoolMonitoringEvent {\n    /** @internal */\n    constructor(pool, options = {}) {\n        super(pool);\n        /** @internal */\n        this.name = constants_1.CONNECTION_POOL_CLEARED;\n        this.serviceId = options.serviceId;\n        this.interruptInUseConnections = options.interruptInUseConnections;\n    }\n}\nexports.ConnectionPoolClearedEvent = ConnectionPoolClearedEvent;\n//# sourceMappingURL=connection_pool_events.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/connection_pool_events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/errors.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/errors.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WaitQueueTimeoutError = exports.PoolClearedOnNetworkError = exports.PoolClearedError = exports.PoolClosedError = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * An error indicating a connection pool is closed\n * @category Error\n */\nclass PoolClosedError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super('Attempted to check out a connection from closed connection pool');\n        this.address = pool.address;\n    }\n    get name() {\n        return 'MongoPoolClosedError';\n    }\n}\nexports.PoolClosedError = PoolClosedError;\n/**\n * An error indicating a connection pool is currently paused\n * @category Error\n */\nclass PoolClearedError extends error_1.MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool, message) {\n        const errorMessage = message\n            ? message\n            : `Connection pool for ${pool.address} was cleared because another operation failed with: \"${pool.serverError?.message}\"`;\n        super(errorMessage, pool.serverError ? { cause: pool.serverError } : undefined);\n        this.address = pool.address;\n        this.addErrorLabel(error_1.MongoErrorLabel.PoolRequstedRetry);\n    }\n    get name() {\n        return 'MongoPoolClearedError';\n    }\n}\nexports.PoolClearedError = PoolClearedError;\n/**\n * An error indicating that a connection pool has been cleared after the monitor for that server timed out.\n * @category Error\n */\nclass PoolClearedOnNetworkError extends PoolClearedError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(pool) {\n        super(pool, `Connection to ${pool.address} interrupted due to server monitor timeout`);\n    }\n    get name() {\n        return 'PoolClearedOnNetworkError';\n    }\n}\nexports.PoolClearedOnNetworkError = PoolClearedOnNetworkError;\n/**\n * An error thrown when a request to check out a connection times out\n * @category Error\n */\nclass WaitQueueTimeoutError extends error_1.MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, address) {\n        super(message);\n        this.address = address;\n    }\n    get name() {\n        return 'MongoWaitQueueTimeoutError';\n    }\n}\nexports.WaitQueueTimeoutError = WaitQueueTimeoutError;\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/errors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/handshake/client_metadata.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/handshake/client_metadata.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getFAASEnv = exports.makeClientMetadata = exports.LimitedSizeDocument = void 0;\nconst os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst process = __webpack_require__(/*! process */ \"../../node_modules/process/browser.js\");\nconst bson_1 = __webpack_require__(/*! ../../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\n// eslint-disable-next-line @typescript-eslint/no-var-requires\nconst NODE_DRIVER_VERSION = (__webpack_require__(/*! ../../../package.json */ \"./node_modules/mongodb/package.json\").version);\n/** @internal */\nclass LimitedSizeDocument {\n    constructor(maxSize) {\n        this.maxSize = maxSize;\n        this.document = new Map();\n        /** BSON overhead: Int32 + Null byte */\n        this.documentSize = 5;\n    }\n    /** Only adds key/value if the bsonByteLength is less than MAX_SIZE */\n    ifItFitsItSits(key, value) {\n        // The BSON byteLength of the new element is the same as serializing it to its own document\n        // subtracting the document size int32 and the null terminator.\n        const newElementSize = bson_1.BSON.serialize(new Map().set(key, value)).byteLength - 5;\n        if (newElementSize + this.documentSize > this.maxSize) {\n            return false;\n        }\n        this.documentSize += newElementSize;\n        this.document.set(key, value);\n        return true;\n    }\n    toObject() {\n        return bson_1.BSON.deserialize(bson_1.BSON.serialize(this.document), {\n            promoteLongs: false,\n            promoteBuffers: false,\n            promoteValues: false,\n            useBigInt64: false\n        });\n    }\n}\nexports.LimitedSizeDocument = LimitedSizeDocument;\n/**\n * From the specs:\n * Implementors SHOULD cumulatively update fields in the following order until the document is under the size limit:\n * 1. Omit fields from `env` except `env.name`.\n * 2. Omit fields from `os` except `os.type`.\n * 3. Omit the `env` document entirely.\n * 4. Truncate `platform`. -- special we do not truncate this field\n */\nfunction makeClientMetadata(options) {\n    const metadataDocument = new LimitedSizeDocument(512);\n    const { appName = '' } = options;\n    // Add app name first, it must be sent\n    if (appName.length > 0) {\n        const name = Buffer.byteLength(appName, 'utf8') <= 128\n            ? options.appName\n            : Buffer.from(appName, 'utf8').subarray(0, 128).toString('utf8');\n        metadataDocument.ifItFitsItSits('application', { name });\n    }\n    const { name = '', version = '', platform = '' } = options.driverInfo;\n    const driverInfo = {\n        name: name.length > 0 ? `nodejs|${name}` : 'nodejs',\n        version: version.length > 0 ? `${NODE_DRIVER_VERSION}|${version}` : NODE_DRIVER_VERSION\n    };\n    if (!metadataDocument.ifItFitsItSits('driver', driverInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo name and version, metadata cannot exceed 512 bytes');\n    }\n    let runtimeInfo = getRuntimeInfo();\n    if (platform.length > 0) {\n        runtimeInfo = `${runtimeInfo}|${platform}`;\n    }\n    if (!metadataDocument.ifItFitsItSits('platform', runtimeInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo platform, metadata cannot exceed 512 bytes');\n    }\n    // Note: order matters, os.type is last so it will be removed last if we're at maxSize\n    const osInfo = new Map()\n        .set('name', process.platform)\n        .set('architecture', process.arch)\n        .set('version', os.release())\n        .set('type', os.type());\n    if (!metadataDocument.ifItFitsItSits('os', osInfo)) {\n        for (const key of osInfo.keys()) {\n            osInfo.delete(key);\n            if (osInfo.size === 0)\n                break;\n            if (metadataDocument.ifItFitsItSits('os', osInfo))\n                break;\n        }\n    }\n    const faasEnv = getFAASEnv();\n    if (faasEnv != null) {\n        if (!metadataDocument.ifItFitsItSits('env', faasEnv)) {\n            for (const key of faasEnv.keys()) {\n                faasEnv.delete(key);\n                if (faasEnv.size === 0)\n                    break;\n                if (metadataDocument.ifItFitsItSits('env', faasEnv))\n                    break;\n            }\n        }\n    }\n    return metadataDocument.toObject();\n}\nexports.makeClientMetadata = makeClientMetadata;\n/**\n * Collects FaaS metadata.\n * - `name` MUST be the last key in the Map returned.\n */\nfunction getFAASEnv() {\n    const { AWS_EXECUTION_ENV = '', AWS_LAMBDA_RUNTIME_API = '', FUNCTIONS_WORKER_RUNTIME = '', K_SERVICE = '', FUNCTION_NAME = '', VERCEL = '', AWS_LAMBDA_FUNCTION_MEMORY_SIZE = '', AWS_REGION = '', FUNCTION_MEMORY_MB = '', FUNCTION_REGION = '', FUNCTION_TIMEOUT_SEC = '', VERCEL_REGION = '' } = process.env;\n    const isAWSFaaS = AWS_EXECUTION_ENV.startsWith('AWS_Lambda_') || AWS_LAMBDA_RUNTIME_API.length > 0;\n    const isAzureFaaS = FUNCTIONS_WORKER_RUNTIME.length > 0;\n    const isGCPFaaS = K_SERVICE.length > 0 || FUNCTION_NAME.length > 0;\n    const isVercelFaaS = VERCEL.length > 0;\n    // Note: order matters, name must always be the last key\n    const faasEnv = new Map();\n    // When isVercelFaaS is true so is isAWSFaaS; Vercel inherits the AWS env\n    if (isVercelFaaS && !(isAzureFaaS || isGCPFaaS)) {\n        if (VERCEL_REGION.length > 0) {\n            faasEnv.set('region', VERCEL_REGION);\n        }\n        faasEnv.set('name', 'vercel');\n        return faasEnv;\n    }\n    if (isAWSFaaS && !(isAzureFaaS || isGCPFaaS || isVercelFaaS)) {\n        if (AWS_REGION.length > 0) {\n            faasEnv.set('region', AWS_REGION);\n        }\n        if (AWS_LAMBDA_FUNCTION_MEMORY_SIZE.length > 0 &&\n            Number.isInteger(+AWS_LAMBDA_FUNCTION_MEMORY_SIZE)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(AWS_LAMBDA_FUNCTION_MEMORY_SIZE));\n        }\n        faasEnv.set('name', 'aws.lambda');\n        return faasEnv;\n    }\n    if (isAzureFaaS && !(isGCPFaaS || isAWSFaaS || isVercelFaaS)) {\n        faasEnv.set('name', 'azure.func');\n        return faasEnv;\n    }\n    if (isGCPFaaS && !(isAzureFaaS || isAWSFaaS || isVercelFaaS)) {\n        if (FUNCTION_REGION.length > 0) {\n            faasEnv.set('region', FUNCTION_REGION);\n        }\n        if (FUNCTION_MEMORY_MB.length > 0 && Number.isInteger(+FUNCTION_MEMORY_MB)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(FUNCTION_MEMORY_MB));\n        }\n        if (FUNCTION_TIMEOUT_SEC.length > 0 && Number.isInteger(+FUNCTION_TIMEOUT_SEC)) {\n            faasEnv.set('timeout_sec', new bson_1.Int32(FUNCTION_TIMEOUT_SEC));\n        }\n        faasEnv.set('name', 'gcp.func');\n        return faasEnv;\n    }\n    return null;\n}\nexports.getFAASEnv = getFAASEnv;\n/**\n * @internal\n * Get current JavaScript runtime platform\n *\n * NOTE: The version information fetching is intentionally written defensively\n * to avoid having a released driver version that becomes incompatible\n * with a future change to these global objects.\n */\nfunction getRuntimeInfo() {\n    if ('Deno' in globalThis) {\n        const version = typeof Deno?.version?.deno === 'string' ? Deno?.version?.deno : '0.0.0-unknown';\n        return `Deno v${version}, ${os.endianness()}`;\n    }\n    if ('Bun' in globalThis) {\n        const version = typeof Bun?.version === 'string' ? Bun?.version : '0.0.0-unknown';\n        return `Bun v${version}, ${os.endianness()}`;\n    }\n    return `Node.js ${process.version}, ${os.endianness()}`;\n}\n//# sourceMappingURL=client_metadata.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/handshake/client_metadata.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/message_stream.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/message_stream.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MessageStream = void 0;\nconst stream_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst commands_1 = __webpack_require__(/*! ./commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst compression_1 = __webpack_require__(/*! ./wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst constants_1 = __webpack_require__(/*! ./wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst MESSAGE_HEADER_SIZE = 16;\nconst COMPRESSION_DETAILS_SIZE = 9; // originalOpcode + uncompressedSize, compressorID\nconst kDefaultMaxBsonMessageSize = 1024 * 1024 * 16 * 4;\n/** @internal */\nconst kBuffer = Symbol('buffer');\n/**\n * A duplex stream that is capable of reading and writing raw wire protocol messages, with\n * support for optional compression\n * @internal\n */\nclass MessageStream extends stream_1.Duplex {\n    constructor(options = {}) {\n        super(options);\n        /** @internal */\n        this.isMonitoringConnection = false;\n        this.maxBsonMessageSize = options.maxBsonMessageSize || kDefaultMaxBsonMessageSize;\n        this[kBuffer] = new utils_1.BufferPool();\n    }\n    get buffer() {\n        return this[kBuffer];\n    }\n    _write(chunk, _, callback) {\n        this[kBuffer].append(chunk);\n        processIncomingData(this, callback);\n    }\n    _read( /* size */) {\n        // NOTE: This implementation is empty because we explicitly push data to be read\n        //       when `writeMessage` is called.\n        return;\n    }\n    writeCommand(command, operationDescription) {\n        const agreedCompressor = operationDescription.agreedCompressor ?? 'none';\n        if (agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)) {\n            const data = command.toBin();\n            this.push(Array.isArray(data) ? Buffer.concat(data) : data);\n            return;\n        }\n        // otherwise, compress the message\n        const concatenatedOriginalCommandBuffer = Buffer.concat(command.toBin());\n        const messageToBeCompressed = concatenatedOriginalCommandBuffer.slice(MESSAGE_HEADER_SIZE);\n        // Extract information needed for OP_COMPRESSED from the uncompressed message\n        const originalCommandOpCode = concatenatedOriginalCommandBuffer.readInt32LE(12);\n        const options = {\n            agreedCompressor,\n            zlibCompressionLevel: operationDescription.zlibCompressionLevel ?? 0\n        };\n        // Compress the message body\n        (0, compression_1.compress)(options, messageToBeCompressed).then(compressedMessage => {\n            // Create the msgHeader of OP_COMPRESSED\n            const msgHeader = Buffer.alloc(MESSAGE_HEADER_SIZE);\n            msgHeader.writeInt32LE(MESSAGE_HEADER_SIZE + COMPRESSION_DETAILS_SIZE + compressedMessage.length, 0); // messageLength\n            msgHeader.writeInt32LE(command.requestId, 4); // requestID\n            msgHeader.writeInt32LE(0, 8); // responseTo (zero)\n            msgHeader.writeInt32LE(constants_1.OP_COMPRESSED, 12); // opCode\n            // Create the compression details of OP_COMPRESSED\n            const compressionDetails = Buffer.alloc(COMPRESSION_DETAILS_SIZE);\n            compressionDetails.writeInt32LE(originalCommandOpCode, 0); // originalOpcode\n            compressionDetails.writeInt32LE(messageToBeCompressed.length, 4); // Size of the uncompressed compressedMessage, excluding the MsgHeader\n            compressionDetails.writeUInt8(compression_1.Compressor[agreedCompressor], 8); // compressorID\n            this.push(Buffer.concat([msgHeader, compressionDetails, compressedMessage]));\n        }, error => {\n            operationDescription.cb(error);\n        });\n    }\n}\nexports.MessageStream = MessageStream;\nfunction processIncomingData(stream, callback) {\n    const buffer = stream[kBuffer];\n    const sizeOfMessage = buffer.getInt32();\n    if (sizeOfMessage == null) {\n        return callback();\n    }\n    if (sizeOfMessage < 0) {\n        return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}`));\n    }\n    if (sizeOfMessage > stream.maxBsonMessageSize) {\n        return callback(new error_1.MongoParseError(`Invalid message size: ${sizeOfMessage}, max allowed: ${stream.maxBsonMessageSize}`));\n    }\n    if (sizeOfMessage > buffer.length) {\n        return callback();\n    }\n    const message = buffer.read(sizeOfMessage);\n    const messageHeader = {\n        length: message.readInt32LE(0),\n        requestId: message.readInt32LE(4),\n        responseTo: message.readInt32LE(8),\n        opCode: message.readInt32LE(12)\n    };\n    const monitorHasAnotherHello = () => {\n        if (stream.isMonitoringConnection) {\n            // Can we read the next message size?\n            const sizeOfMessage = buffer.getInt32();\n            if (sizeOfMessage != null && sizeOfMessage <= buffer.length) {\n                return true;\n            }\n        }\n        return false;\n    };\n    let ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    if (messageHeader.opCode !== constants_1.OP_COMPRESSED) {\n        const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n        // If we are a monitoring connection message stream and\n        // there is more in the buffer that can be read, skip processing since we\n        // want the last hello command response that is in the buffer.\n        if (monitorHasAnotherHello()) {\n            return processIncomingData(stream, callback);\n        }\n        stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n        if (buffer.length >= 4) {\n            return processIncomingData(stream, callback);\n        }\n        return callback();\n    }\n    messageHeader.fromCompressed = true;\n    messageHeader.opCode = message.readInt32LE(MESSAGE_HEADER_SIZE);\n    messageHeader.length = message.readInt32LE(MESSAGE_HEADER_SIZE + 4);\n    const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n    const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n    // recalculate based on wrapped opcode\n    ResponseType = messageHeader.opCode === constants_1.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    (0, compression_1.decompress)(compressorID, compressedBuffer).then(messageBody => {\n        if (messageBody.length !== messageHeader.length) {\n            return callback(new error_1.MongoDecompressionError('Message body and message header must be the same length'));\n        }\n        // If we are a monitoring connection message stream and\n        // there is more in the buffer that can be read, skip processing since we\n        // want the last hello command response that is in the buffer.\n        if (monitorHasAnotherHello()) {\n            return processIncomingData(stream, callback);\n        }\n        stream.emit('message', new ResponseType(message, messageHeader, messageBody));\n        if (buffer.length >= 4) {\n            return processIncomingData(stream, callback);\n        }\n        return callback();\n    }, error => {\n        return callback(error);\n    });\n}\n//# sourceMappingURL=message_stream.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/message_stream.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/metrics.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/metrics.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ConnectionPoolMetrics = void 0;\n/** @internal */\nclass ConnectionPoolMetrics {\n    constructor() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n    /**\n     * Mark a connection as pinned for a specific operation.\n     */\n    markPinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections += 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections += 1;\n        }\n        else {\n            this.otherConnections += 1;\n        }\n    }\n    /**\n     * Unmark a connection as pinned for an operation.\n     */\n    markUnpinned(pinType) {\n        if (pinType === ConnectionPoolMetrics.TXN) {\n            this.txnConnections -= 1;\n        }\n        else if (pinType === ConnectionPoolMetrics.CURSOR) {\n            this.cursorConnections -= 1;\n        }\n        else {\n            this.otherConnections -= 1;\n        }\n    }\n    /**\n     * Return information about the cmap metrics as a string.\n     */\n    info(maxPoolSize) {\n        return ('Timed out while checking out a connection from connection pool: ' +\n            `maxPoolSize: ${maxPoolSize}, ` +\n            `connections in use by cursors: ${this.cursorConnections}, ` +\n            `connections in use by transactions: ${this.txnConnections}, ` +\n            `connections in use by other operations: ${this.otherConnections}`);\n    }\n    /**\n     * Reset the metrics to the initial values.\n     */\n    reset() {\n        this.txnConnections = 0;\n        this.cursorConnections = 0;\n        this.otherConnections = 0;\n    }\n}\nConnectionPoolMetrics.TXN = 'txn';\nConnectionPoolMetrics.CURSOR = 'cursor';\nConnectionPoolMetrics.OTHER = 'other';\nexports.ConnectionPoolMetrics = ConnectionPoolMetrics;\n//# sourceMappingURL=metrics.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/metrics.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/stream_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/stream_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.StreamDescription = void 0;\nconst common_1 = __webpack_require__(/*! ../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ../sdam/server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst RESPONSE_FIELDS = [\n    'minWireVersion',\n    'maxWireVersion',\n    'maxBsonObjectSize',\n    'maxMessageSizeBytes',\n    'maxWriteBatchSize',\n    'logicalSessionTimeoutMinutes'\n];\n/** @public */\nclass StreamDescription {\n    constructor(address, options) {\n        this.address = address;\n        this.type = common_1.ServerType.Unknown;\n        this.minWireVersion = undefined;\n        this.maxWireVersion = undefined;\n        this.maxBsonObjectSize = 16777216;\n        this.maxMessageSizeBytes = 48000000;\n        this.maxWriteBatchSize = 100000;\n        this.logicalSessionTimeoutMinutes = options?.logicalSessionTimeoutMinutes;\n        this.loadBalanced = !!options?.loadBalanced;\n        this.compressors =\n            options && options.compressors && Array.isArray(options.compressors)\n                ? options.compressors\n                : [];\n    }\n    receiveResponse(response) {\n        if (response == null) {\n            return;\n        }\n        this.type = (0, server_description_1.parseServerType)(response);\n        for (const field of RESPONSE_FIELDS) {\n            if (response[field] != null) {\n                this[field] = response[field];\n            }\n            // testing case\n            if ('__nodejs_mock_server__' in response) {\n                this.__nodejs_mock_server__ = response['__nodejs_mock_server__'];\n            }\n        }\n        if (response.compression) {\n            this.compressor = this.compressors.filter(c => response.compression?.includes(c))[0];\n        }\n    }\n}\nexports.StreamDescription = StreamDescription;\n//# sourceMappingURL=stream_description.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/stream_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/compression.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/compression.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.decompressResponse = exports.compressCommand = exports.decompress = exports.compress = exports.uncompressibleCommands = exports.Compressor = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst zlib = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'zlib'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst constants_1 = __webpack_require__(/*! ../../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ../../deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst commands_1 = __webpack_require__(/*! ../commands */ \"./node_modules/mongodb/lib/cmap/commands.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\n/** @public */\nexports.Compressor = Object.freeze({\n    none: 0,\n    snappy: 1,\n    zlib: 2,\n    zstd: 3\n});\nexports.uncompressibleCommands = new Set([\n    constants_1.LEGACY_HELLO_COMMAND,\n    'saslStart',\n    'saslContinue',\n    'getnonce',\n    'authenticate',\n    'createUser',\n    'updateUser',\n    'copydbSaslStart',\n    'copydbgetnonce',\n    'copydb'\n]);\nconst ZSTD_COMPRESSION_LEVEL = 3;\nconst zlibInflate = (0, util_1.promisify)(zlib.inflate.bind(zlib));\nconst zlibDeflate = (0, util_1.promisify)(zlib.deflate.bind(zlib));\nlet zstd;\nlet Snappy = null;\nfunction loadSnappy() {\n    if (Snappy == null) {\n        const snappyImport = (0, deps_1.getSnappy)();\n        if ('kModuleError' in snappyImport) {\n            throw snappyImport.kModuleError;\n        }\n        Snappy = snappyImport;\n    }\n    return Snappy;\n}\n// Facilitate compressing a message using an agreed compressor\nasync function compress(options, dataToBeCompressed) {\n    const zlibOptions = {};\n    switch (options.agreedCompressor) {\n        case 'snappy': {\n            Snappy ??= loadSnappy();\n            return Snappy.compress(dataToBeCompressed);\n        }\n        case 'zstd': {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return zstd.compress(dataToBeCompressed, ZSTD_COMPRESSION_LEVEL);\n        }\n        case 'zlib': {\n            if (options.zlibCompressionLevel) {\n                zlibOptions.level = options.zlibCompressionLevel;\n            }\n            return zlibDeflate(dataToBeCompressed, zlibOptions);\n        }\n        default: {\n            throw new error_1.MongoInvalidArgumentError(`Unknown compressor ${options.agreedCompressor} failed to compress`);\n        }\n    }\n}\nexports.compress = compress;\n// Decompress a message using the given compressor\nasync function decompress(compressorID, compressedData) {\n    if (compressorID !== exports.Compressor.snappy &&\n        compressorID !== exports.Compressor.zstd &&\n        compressorID !== exports.Compressor.zlib &&\n        compressorID !== exports.Compressor.none) {\n        throw new error_1.MongoDecompressionError(`Server sent message compressed using an unsupported compressor. (Received compressor ID ${compressorID})`);\n    }\n    switch (compressorID) {\n        case exports.Compressor.snappy: {\n            Snappy ??= loadSnappy();\n            return Snappy.uncompress(compressedData, { asBuffer: true });\n        }\n        case exports.Compressor.zstd: {\n            loadZstd();\n            if ('kModuleError' in zstd) {\n                throw zstd['kModuleError'];\n            }\n            return zstd.decompress(compressedData);\n        }\n        case exports.Compressor.zlib: {\n            return zlibInflate(compressedData);\n        }\n        default: {\n            return compressedData;\n        }\n    }\n}\nexports.decompress = decompress;\n/**\n * Load ZStandard if it is not already set.\n */\nfunction loadZstd() {\n    if (!zstd) {\n        zstd = (0, deps_1.getZstdLibrary)();\n    }\n}\nconst MESSAGE_HEADER_SIZE = 16;\n/**\n * @internal\n *\n * Compresses an OP_MSG or OP_QUERY message, if compression is configured.  This method\n * also serializes the command to BSON.\n */\nasync function compressCommand(command, description) {\n    const finalCommand = description.agreedCompressor === 'none' || !commands_1.OpCompressedRequest.canCompress(command)\n        ? command\n        : new commands_1.OpCompressedRequest(command, {\n            agreedCompressor: description.agreedCompressor ?? 'none',\n            zlibCompressionLevel: description.zlibCompressionLevel ?? 0\n        });\n    const data = await finalCommand.toBin();\n    return Buffer.concat(data);\n}\nexports.compressCommand = compressCommand;\n/**\n * @internal\n *\n * Decompresses an OP_MSG or OP_QUERY response from the server, if compression is configured.\n *\n * This method does not parse the response's BSON.\n */\nasync function decompressResponse(message) {\n    const messageHeader = {\n        length: message.readInt32LE(0),\n        requestId: message.readInt32LE(4),\n        responseTo: message.readInt32LE(8),\n        opCode: message.readInt32LE(12)\n    };\n    if (messageHeader.opCode !== constants_2.OP_COMPRESSED) {\n        const ResponseType = messageHeader.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n        const messageBody = message.subarray(MESSAGE_HEADER_SIZE);\n        return new ResponseType(message, messageHeader, messageBody);\n    }\n    const header = {\n        ...messageHeader,\n        fromCompressed: true,\n        opCode: message.readInt32LE(MESSAGE_HEADER_SIZE),\n        length: message.readInt32LE(MESSAGE_HEADER_SIZE + 4)\n    };\n    const compressorID = message[MESSAGE_HEADER_SIZE + 8];\n    const compressedBuffer = message.slice(MESSAGE_HEADER_SIZE + 9);\n    // recalculate based on wrapped opcode\n    const ResponseType = header.opCode === constants_2.OP_MSG ? commands_1.OpMsgResponse : commands_1.OpQueryResponse;\n    const messageBody = await decompress(compressorID, compressedBuffer);\n    if (messageBody.length !== header.length) {\n        throw new error_1.MongoDecompressionError('Message body and message header must be the same length');\n    }\n    return new ResponseType(message, header, messageBody);\n}\nexports.decompressResponse = decompressResponse;\n//# sourceMappingURL=compression.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/wire_protocol/compression.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/constants.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/constants.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OP_MSG = exports.OP_COMPRESSED = exports.OP_DELETE = exports.OP_QUERY = exports.OP_INSERT = exports.OP_UPDATE = exports.OP_REPLY = exports.MIN_SUPPORTED_QE_SERVER_VERSION = exports.MIN_SUPPORTED_QE_WIRE_VERSION = exports.MAX_SUPPORTED_WIRE_VERSION = exports.MIN_SUPPORTED_WIRE_VERSION = exports.MAX_SUPPORTED_SERVER_VERSION = exports.MIN_SUPPORTED_SERVER_VERSION = void 0;\nexports.MIN_SUPPORTED_SERVER_VERSION = '3.6';\nexports.MAX_SUPPORTED_SERVER_VERSION = '7.0';\nexports.MIN_SUPPORTED_WIRE_VERSION = 6;\nexports.MAX_SUPPORTED_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_WIRE_VERSION = 21;\nexports.MIN_SUPPORTED_QE_SERVER_VERSION = '7.0';\nexports.OP_REPLY = 1;\nexports.OP_UPDATE = 2001;\nexports.OP_INSERT = 2002;\nexports.OP_QUERY = 2004;\nexports.OP_DELETE = 2006;\nexports.OP_COMPRESSED = 2012;\nexports.OP_MSG = 2013;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/wire_protocol/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cmap/wire_protocol/shared.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cmap/wire_protocol/shared.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isSharded = exports.getReadPreference = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ../../sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst topology_description_1 = __webpack_require__(/*! ../../sdam/topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\nfunction getReadPreference(options) {\n    // Default to command version of the readPreference\n    let readPreference = options?.readPreference ?? read_preference_1.ReadPreference.primary;\n    // If we have an option readPreference override the command one\n    if (options?.readPreference) {\n        readPreference = options.readPreference;\n    }\n    if (typeof readPreference === 'string') {\n        readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n    }\n    if (!(readPreference instanceof read_preference_1.ReadPreference)) {\n        throw new error_1.MongoInvalidArgumentError('Option \"readPreference\" must be a ReadPreference instance');\n    }\n    return readPreference;\n}\nexports.getReadPreference = getReadPreference;\nfunction isSharded(topologyOrServer) {\n    if (topologyOrServer == null) {\n        return false;\n    }\n    if (topologyOrServer.description && topologyOrServer.description.type === common_1.ServerType.Mongos) {\n        return true;\n    }\n    // NOTE: This is incredibly inefficient, and should be removed once command construction\n    //       happens based on `Server` not `Topology`.\n    if (topologyOrServer.description && topologyOrServer.description instanceof topology_description_1.TopologyDescription) {\n        const servers = Array.from(topologyOrServer.description.servers.values());\n        return servers.some((server) => server.type === common_1.ServerType.Mongos);\n    }\n    return false;\n}\nexports.isSharded = isSharded;\n//# sourceMappingURL=shared.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cmap/wire_protocol/shared.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/collection.js":
/*!************************************************!*\
  !*** ./node_modules/mongodb/lib/collection.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Collection = void 0;\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nconst list_search_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_search_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./operations/bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst count_1 = __webpack_require__(/*! ./operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst count_documents_1 = __webpack_require__(/*! ./operations/count_documents */ \"./node_modules/mongodb/lib/operations/count_documents.js\");\nconst delete_1 = __webpack_require__(/*! ./operations/delete */ \"./node_modules/mongodb/lib/operations/delete.js\");\nconst distinct_1 = __webpack_require__(/*! ./operations/distinct */ \"./node_modules/mongodb/lib/operations/distinct.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst estimated_document_count_1 = __webpack_require__(/*! ./operations/estimated_document_count */ \"./node_modules/mongodb/lib/operations/estimated_document_count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst insert_1 = __webpack_require__(/*! ./operations/insert */ \"./node_modules/mongodb/lib/operations/insert.js\");\nconst is_capped_1 = __webpack_require__(/*! ./operations/is_capped */ \"./node_modules/mongodb/lib/operations/is_capped.js\");\nconst options_operation_1 = __webpack_require__(/*! ./operations/options_operation */ \"./node_modules/mongodb/lib/operations/options_operation.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst create_1 = __webpack_require__(/*! ./operations/search_indexes/create */ \"./node_modules/mongodb/lib/operations/search_indexes/create.js\");\nconst drop_2 = __webpack_require__(/*! ./operations/search_indexes/drop */ \"./node_modules/mongodb/lib/operations/search_indexes/drop.js\");\nconst update_1 = __webpack_require__(/*! ./operations/search_indexes/update */ \"./node_modules/mongodb/lib/operations/search_indexes/update.js\");\nconst update_2 = __webpack_require__(/*! ./operations/update */ \"./node_modules/mongodb/lib/operations/update.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nclass Collection {\n    /**\n     * Create a new Collection instance\n     * @internal\n     */\n    constructor(db, name, options) {\n        // Internal state\n        this.s = {\n            db,\n            options,\n            namespace: new utils_1.MongoDBCollectionNamespace(db.databaseName, name),\n            pkFactory: db.options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, db),\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.client = db.client;\n    }\n    /**\n     * The name of the database this collection belongs to\n     */\n    get dbName() {\n        return this.s.namespace.db;\n    }\n    /**\n     * The name of this collection\n     */\n    get collectionName() {\n        return this.s.namespace.collection;\n    }\n    /**\n     * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n     */\n    get namespace() {\n        return this.fullNamespace.toString();\n    }\n    /**\n     *  @internal\n     *\n     * The `MongoDBNamespace` for the collection.\n     */\n    get fullNamespace() {\n        return this.s.namespace;\n    }\n    /**\n     * The current readConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readConcern() {\n        if (this.s.readConcern == null) {\n            return this.s.db.readConcern;\n        }\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.s.db.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * The current writeConcern of the collection. If not explicitly defined for\n     * this collection, will be inherited from the parent DB\n     */\n    get writeConcern() {\n        if (this.s.writeConcern == null) {\n            return this.s.db.writeConcern;\n        }\n        return this.s.writeConcern;\n    }\n    /** The current index hint for the collection */\n    get hint() {\n        return this.s.collectionHint;\n    }\n    set hint(v) {\n        this.s.collectionHint = (0, utils_1.normalizeHintField)(v);\n    }\n    /**\n     * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param doc - The document to insert\n     * @param options - Optional settings for the command\n     */\n    async insertOne(doc, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertOneOperation(this, doc, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param docs - The documents to insert\n     * @param options - Optional settings for the command\n     */\n    async insertMany(docs, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new insert_1.InsertManyOperation(this, docs, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Perform a bulkWrite operation without a fluent API\n     *\n     * Legal operation types are\n     * - `insertOne`\n     * - `replaceOne`\n     * - `updateOne`\n     * - `updateMany`\n     * - `deleteOne`\n     * - `deleteMany`\n     *\n     * If documents passed in do not contain the **_id** field,\n     * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n     * can be overridden by setting the **forceServerObjectId** flag.\n     *\n     * @param operations - Bulk operations to perform\n     * @param options - Optional settings for the command\n     * @throws MongoDriverError if operations is not an array\n     */\n    async bulkWrite(operations, options) {\n        if (!Array.isArray(operations)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n        }\n        return (0, execute_operation_1.executeOperation)(this.client, new bulk_write_1.BulkWriteOperation(this, operations, (0, utils_1.resolveOptions)(this, options ?? { ordered: true })));\n    }\n    /**\n     * Update a single document in a collection\n     *\n     * @param filter - The filter used to select the document to update\n     * @param update - The update operations to be applied to the document\n     * @param options - Optional settings for the command\n     */\n    async updateOne(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateOneOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Replace a document in a collection with another document\n     *\n     * @param filter - The filter used to select the document to replace\n     * @param replacement - The Document that replaces the matching document\n     * @param options - Optional settings for the command\n     */\n    async replaceOne(filter, replacement, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.ReplaceOneOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Update multiple documents in a collection\n     *\n     * @param filter - The filter used to select the documents to update\n     * @param update - The update operations to be applied to the documents\n     * @param options - Optional settings for the command\n     */\n    async updateMany(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_2.UpdateManyOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete a document from a collection\n     *\n     * @param filter - The filter used to select the document to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteOne(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteOneOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Delete multiple documents from a collection\n     *\n     * @param filter - The filter used to select the documents to remove\n     * @param options - Optional settings for the command\n     */\n    async deleteMany(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new delete_1.DeleteManyOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Rename the collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the Db or MongoClient.\n     *\n     * @param newName - New name of of the collection.\n     * @param options - Optional settings for the command\n     */\n    async rename(newName, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this, newName, {\n            ...options,\n            readPreference: read_preference_1.ReadPreference.PRIMARY\n        }));\n    }\n    /**\n     * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async drop(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this.s.db, this.collectionName, options));\n    }\n    async findOne(filter = {}, options = {}) {\n        const cursor = this.find(filter, options).limit(-1).batchSize(1);\n        const res = await cursor.next();\n        await cursor.close();\n        return res;\n    }\n    find(filter = {}, options = {}) {\n        return new find_cursor_1.FindCursor(this.client, this.s.namespace, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Returns the options of the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async options(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new options_operation_1.OptionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Returns if the collection is a capped collection\n     *\n     * @param options - Optional settings for the command\n     */\n    async isCapped(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new is_capped_1.IsCappedOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection collection.\n     *\n     * @param indexSpec - The field name or index specification to create an index for\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     *\n     * await collection.createIndex({ a: 1, b: -1 });\n     *\n     * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n     * await collection.createIndex([ [c, 1], [d, -1] ]);\n     *\n     * // Equivalent to { e: 1 }\n     * await collection.createIndex('e');\n     *\n     * // Equivalent to { f: 1, g: 1 }\n     * await collection.createIndex(['f', 'g'])\n     *\n     * // Equivalent to { h: 1, i: -1 }\n     * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n     *\n     * // Equivalent to { j: 1, k: -1, l: 2d }\n     * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n     * ```\n     */\n    async createIndex(indexSpec, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexOperation(this, this.collectionName, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates multiple indexes in the collection, this method is only supported for\n     * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n     * error.\n     *\n     * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n     * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n     *\n     * @param indexSpecs - An array of index specifications to be created\n     * @param options - Optional settings for the command\n     *\n     * @example\n     * ```ts\n     * const collection = client.db('foo').collection('bar');\n     * await collection.createIndexes([\n     *   // Simple index on field fizz\n     *   {\n     *     key: { fizz: 1 },\n     *   }\n     *   // wildcard index\n     *   {\n     *     key: { '$**': 1 }\n     *   },\n     *   // named index on darmok and jalad\n     *   {\n     *     key: { darmok: 1, jalad: -1 }\n     *     name: 'tanagra'\n     *   }\n     * ]);\n     * ```\n     */\n    async createIndexes(indexSpecs, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexesOperation(this, this.collectionName, indexSpecs, (0, utils_1.resolveOptions)(this, { ...options, maxTimeMS: undefined })));\n    }\n    /**\n     * Drops an index from this collection.\n     *\n     * @param indexName - Name of the index to drop.\n     * @param options - Optional settings for the command\n     */\n    async dropIndex(indexName, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, indexName, {\n            ...(0, utils_1.resolveOptions)(this, options),\n            readPreference: read_preference_1.ReadPreference.primary\n        }));\n    }\n    /**\n     * Drops all indexes from this collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropIndexes(options) {\n        try {\n            await (0, execute_operation_1.executeOperation)(this.client, new indexes_1.DropIndexOperation(this, '*', (0, utils_1.resolveOptions)(this, options)));\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    /**\n     * Get the list of all indexes information for the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    listIndexes(options) {\n        return new list_indexes_cursor_1.ListIndexesCursor(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Checks if one or more indexes exist on the collection, fails on first non-existing index\n     *\n     * @param indexes - One or more index names to check.\n     * @param options - Optional settings for the command\n     */\n    async indexExists(indexes, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexExistsOperation(this, indexes, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieves this collections index info.\n     *\n     * @param options - Optional settings for the command\n     */\n    async indexInformation(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexInformationOperation(this.s.db, this.collectionName, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Gets an estimate of the count of documents in a collection using collection metadata.\n     * This will always run a count command on all server versions.\n     *\n     * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n     * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n     * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n     * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n     * encountering errors.\n     *\n     * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n     * @param options - Optional settings for the command\n     */\n    async estimatedDocumentCount(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new estimated_document_count_1.EstimatedDocumentCountOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Gets the number of documents matching the filter.\n     * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n     * the following query operators must be replaced:\n     *\n     * | Operator | Replacement |\n     * | -------- | ----------- |\n     * | `$where`   | [`$expr`][1] |\n     * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n     * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n     *\n     * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     *\n     * @param filter - The filter for the count\n     * @param options - Optional settings for the command\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n     * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n     */\n    async countDocuments(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new count_documents_1.CountDocumentsOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async distinct(key, filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new distinct_1.DistinctOperation(this, key, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieve all the indexes on the collection.\n     *\n     * @param options - Optional settings for the command\n     */\n    async indexes(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexesOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndDelete(filter, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndDeleteOperation(this, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndReplace(filter, replacement, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndReplaceOperation(this, filter, replacement, (0, utils_1.resolveOptions)(this, options)));\n    }\n    async findOneAndUpdate(filter, update, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_and_modify_1.FindOneAndUpdateOperation(this, filter, update, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n     *\n     * @param pipeline - An array of aggregation pipelines to execute\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        if (!Array.isArray(pipeline)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"pipeline\" must be an array of aggregation stages');\n        }\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to override the schema that may be defined for this specific collection\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     * @example\n     * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n     * ```ts\n     * collection.watch<{ _id: number }>()\n     *   .on('change', change => console.log(change._id.toFixed(4)));\n     * ```\n     *\n     * @example\n     * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n     * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n     * No need start from scratch on the ChangeStreamInsertDocument type!\n     * By using an intersection we can save time and ensure defaults remain the same type!\n     * ```ts\n     * collection\n     *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n     *     { $addFields: { comment: 'big changes' } },\n     *     { $match: { operationType: 'insert' } }\n     *   ])\n     *   .on('change', change => {\n     *     change.comment.startsWith('big');\n     *     change.operationType === 'insert';\n     *     // No need to narrow in code because the generics did that for us!\n     *     expectType<Schema>(change.fullDocument);\n     *   });\n     * ```\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TLocal - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeUnorderedBulkOp(options) {\n        return new unordered_1.UnorderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n     *\n     * @throws MongoNotConnectedError\n     * @remarks\n     * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n     * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n     */\n    initializeOrderedBulkOp(options) {\n        return new ordered_1.OrderedBulkOperation(this, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * An estimated count of matching documents in the db to a filter.\n     *\n     * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n     * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n     * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n     *\n     * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n     *\n     * @param filter - The filter for the count.\n     * @param options - Optional settings for the command\n     */\n    async count(filter = {}, options = {}) {\n        return (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.fullNamespace, filter, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listSearchIndexes(indexNameOrOptions, options) {\n        options =\n            typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n        const indexName = indexNameOrOptions == null\n            ? null\n            : typeof indexNameOrOptions === 'object'\n                ? null\n                : indexNameOrOptions;\n        return new list_search_indexes_cursor_1.ListSearchIndexesCursor(this, indexName, options);\n    }\n    /**\n     * Creates a single search index for the collection.\n     *\n     * @param description - The index description for the new search index.\n     * @returns A promise that resolves to the name of the new search index.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async createSearchIndex(description) {\n        const [index] = await this.createSearchIndexes([description]);\n        return index;\n    }\n    /**\n     * Creates multiple search indexes for the current collection.\n     *\n     * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n     * @returns A promise that resolves to an array of the newly created search index names.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     * @returns\n     */\n    async createSearchIndexes(descriptions) {\n        return (0, execute_operation_1.executeOperation)(this.client, new create_1.CreateSearchIndexesOperation(this, descriptions));\n    }\n    /**\n     * Deletes a search index by index name.\n     *\n     * @param name - The name of the search index to be deleted.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async dropSearchIndex(name) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_2.DropSearchIndexOperation(this, name));\n    }\n    /**\n     * Updates a search index by replacing the existing index definition with the provided definition.\n     *\n     * @param name - The name of the search index to update.\n     * @param definition - The new search index definition.\n     *\n     * @remarks Only available when used against a 7.0+ Atlas cluster.\n     */\n    async updateSearchIndex(name, definition) {\n        return (0, execute_operation_1.executeOperation)(this.client, new update_1.UpdateSearchIndexOperation(this, name, definition));\n    }\n}\nexports.Collection = Collection;\n//# sourceMappingURL=collection.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/connection_string.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/connection_string.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FEATURE_FLAGS = exports.DEFAULT_OPTIONS = exports.OPTIONS = exports.parseOptions = exports.resolveSRVRecord = void 0;\nconst dns = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'dns'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst mongodb_connection_string_url_1 = __webpack_require__(/*! mongodb-connection-string-url */ \"./node_modules/mongodb-connection-string-url/lib/index.js\");\nconst url_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'url'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst client_metadata_1 = __webpack_require__(/*! ./cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nconst encrypter_1 = __webpack_require__(/*! ./encrypter */ \"./node_modules/mongodb/lib/encrypter.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst monitor_1 = __webpack_require__(/*! ./sdam/monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst VALID_TXT_RECORDS = ['authSource', 'replicaSet', 'loadBalanced'];\nconst LB_SINGLE_HOST_ERROR = 'loadBalanced option only supported with a single host in the URI';\nconst LB_REPLICA_SET_ERROR = 'loadBalanced option not supported with a replicaSet option';\nconst LB_DIRECT_CONNECTION_ERROR = 'loadBalanced option not supported when directConnection is provided';\n/**\n * Lookup a `mongodb+srv` connection string, combine the parts and reparse it as a normal\n * connection string.\n *\n * @param uri - The connection string to parse\n * @param options - Optional user provided connection string options\n */\nasync function resolveSRVRecord(options) {\n    if (typeof options.srvHost !== 'string') {\n        throw new error_1.MongoAPIError('Option \"srvHost\" must not be empty');\n    }\n    if (options.srvHost.split('.').length < 3) {\n        // TODO(NODE-3484): Replace with MongoConnectionStringError\n        throw new error_1.MongoAPIError('URI must include hostname, domain name, and tld');\n    }\n    // Resolve the SRV record and use the result as the list of hosts to connect to.\n    const lookupAddress = options.srvHost;\n    const addresses = await dns.promises.resolveSrv(`_${options.srvServiceName}._tcp.${lookupAddress}`);\n    if (addresses.length === 0) {\n        throw new error_1.MongoAPIError('No addresses found at host');\n    }\n    for (const { name } of addresses) {\n        if (!(0, utils_1.matchesParentDomain)(name, lookupAddress)) {\n            throw new error_1.MongoAPIError('Server record does not share hostname with parent URI');\n        }\n    }\n    const hostAddresses = addresses.map(r => utils_1.HostAddress.fromString(`${r.name}:${r.port ?? 27017}`));\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    // Resolve TXT record and add options from there if they exist.\n    let record;\n    try {\n        record = await dns.promises.resolveTxt(lookupAddress);\n    }\n    catch (error) {\n        if (error.code !== 'ENODATA' && error.code !== 'ENOTFOUND') {\n            throw error;\n        }\n        return hostAddresses;\n    }\n    if (record.length > 1) {\n        throw new error_1.MongoParseError('Multiple text records not allowed');\n    }\n    const txtRecordOptions = new url_1.URLSearchParams(record[0].join(''));\n    const txtRecordOptionKeys = [...txtRecordOptions.keys()];\n    if (txtRecordOptionKeys.some(key => !VALID_TXT_RECORDS.includes(key))) {\n        throw new error_1.MongoParseError(`Text record may only set any of: ${VALID_TXT_RECORDS.join(', ')}`);\n    }\n    if (VALID_TXT_RECORDS.some(option => txtRecordOptions.get(option) === '')) {\n        throw new error_1.MongoParseError('Cannot have empty URI params in DNS TXT Record');\n    }\n    const source = txtRecordOptions.get('authSource') ?? undefined;\n    const replicaSet = txtRecordOptions.get('replicaSet') ?? undefined;\n    const loadBalanced = txtRecordOptions.get('loadBalanced') ?? undefined;\n    if (!options.userSpecifiedAuthSource &&\n        source &&\n        options.credentials &&\n        !providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(options.credentials.mechanism)) {\n        options.credentials = mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n    }\n    if (!options.userSpecifiedReplicaSet && replicaSet) {\n        options.replicaSet = replicaSet;\n    }\n    if (loadBalanced === 'true') {\n        options.loadBalanced = true;\n    }\n    if (options.replicaSet && options.srvMaxHosts > 0) {\n        throw new error_1.MongoParseError('Cannot combine replicaSet option with srvMaxHosts');\n    }\n    validateLoadBalancedOptions(hostAddresses, options, true);\n    return hostAddresses;\n}\nexports.resolveSRVRecord = resolveSRVRecord;\n/**\n * Checks if TLS options are valid\n *\n * @param allOptions - All options provided by user or included in default options map\n * @throws MongoAPIError if TLS options are invalid\n */\nfunction checkTLSOptions(allOptions) {\n    if (!allOptions)\n        return;\n    const check = (a, b) => {\n        if (allOptions.has(a) && allOptions.has(b)) {\n            throw new error_1.MongoAPIError(`The '${a}' option cannot be used with the '${b}' option`);\n        }\n    };\n    check('tlsInsecure', 'tlsAllowInvalidCertificates');\n    check('tlsInsecure', 'tlsAllowInvalidHostnames');\n    check('tlsInsecure', 'tlsDisableCertificateRevocationCheck');\n    check('tlsInsecure', 'tlsDisableOCSPEndpointCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableCertificateRevocationCheck');\n    check('tlsAllowInvalidCertificates', 'tlsDisableOCSPEndpointCheck');\n    check('tlsDisableCertificateRevocationCheck', 'tlsDisableOCSPEndpointCheck');\n}\nfunction getBoolean(name, value) {\n    if (typeof value === 'boolean')\n        return value;\n    switch (value) {\n        case 'true':\n            return true;\n        case 'false':\n            return false;\n        default:\n            throw new error_1.MongoParseError(`${name} must be either \"true\" or \"false\"`);\n    }\n}\nfunction getIntFromOptions(name, value) {\n    const parsedInt = (0, utils_1.parseInteger)(value);\n    if (parsedInt != null) {\n        return parsedInt;\n    }\n    throw new error_1.MongoParseError(`Expected ${name} to be stringified int value, got: ${value}`);\n}\nfunction getUIntFromOptions(name, value) {\n    const parsedValue = getIntFromOptions(name, value);\n    if (parsedValue < 0) {\n        throw new error_1.MongoParseError(`${name} can only be a positive int value, got: ${value}`);\n    }\n    return parsedValue;\n}\nfunction* entriesFromString(value) {\n    if (value === '') {\n        return;\n    }\n    const keyValuePairs = value.split(',');\n    for (const keyValue of keyValuePairs) {\n        const [key, value] = keyValue.split(/:(.*)/);\n        if (value == null) {\n            throw new error_1.MongoParseError('Cannot have undefined values in key value pairs');\n        }\n        yield [key, value];\n    }\n}\nclass CaseInsensitiveMap extends Map {\n    constructor(entries = []) {\n        super(entries.map(([k, v]) => [k.toLowerCase(), v]));\n    }\n    has(k) {\n        return super.has(k.toLowerCase());\n    }\n    get(k) {\n        return super.get(k.toLowerCase());\n    }\n    set(k, v) {\n        return super.set(k.toLowerCase(), v);\n    }\n    delete(k) {\n        return super.delete(k.toLowerCase());\n    }\n}\nfunction parseOptions(uri, mongoClient = undefined, options = {}) {\n    if (mongoClient != null && !(mongoClient instanceof mongo_client_1.MongoClient)) {\n        options = mongoClient;\n        mongoClient = undefined;\n    }\n    // validate BSONOptions\n    if (options.useBigInt64 && typeof options.promoteLongs === 'boolean' && !options.promoteLongs) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    if (options.useBigInt64 && typeof options.promoteValues === 'boolean' && !options.promoteValues) {\n        throw new error_1.MongoAPIError('Must request either bigint or Long for int64 deserialization');\n    }\n    const url = new mongodb_connection_string_url_1.default(uri);\n    const { hosts, isSRV } = url;\n    const mongoOptions = Object.create(null);\n    // Feature flags\n    for (const flag of Object.getOwnPropertySymbols(options)) {\n        if (exports.FEATURE_FLAGS.has(flag)) {\n            mongoOptions[flag] = options[flag];\n        }\n    }\n    mongoOptions.hosts = isSRV ? [] : hosts.map(utils_1.HostAddress.fromString);\n    const urlOptions = new CaseInsensitiveMap();\n    if (url.pathname !== '/' && url.pathname !== '') {\n        const dbName = decodeURIComponent(url.pathname[0] === '/' ? url.pathname.slice(1) : url.pathname);\n        if (dbName) {\n            urlOptions.set('dbName', [dbName]);\n        }\n    }\n    if (url.username !== '') {\n        const auth = {\n            username: decodeURIComponent(url.username)\n        };\n        if (typeof url.password === 'string') {\n            auth.password = decodeURIComponent(url.password);\n        }\n        urlOptions.set('auth', [auth]);\n    }\n    for (const key of url.searchParams.keys()) {\n        const values = url.searchParams.getAll(key);\n        const isReadPreferenceTags = /readPreferenceTags/i.test(key);\n        if (!isReadPreferenceTags && values.length > 1) {\n            throw new error_1.MongoInvalidArgumentError(`URI option \"${key}\" cannot appear more than once in the connection string`);\n        }\n        if (!isReadPreferenceTags && values.includes('')) {\n            throw new error_1.MongoAPIError(`URI option \"${key}\" cannot be specified with no value`);\n        }\n        if (!urlOptions.has(key)) {\n            urlOptions.set(key, values);\n        }\n    }\n    const objectOptions = new CaseInsensitiveMap(Object.entries(options).filter(([, v]) => v != null));\n    // Validate options that can only be provided by one of uri or object\n    if (urlOptions.has('serverApi')) {\n        throw new error_1.MongoParseError('URI cannot contain `serverApi`, it can only be passed to the client');\n    }\n    const uriMechanismProperties = urlOptions.get('authMechanismProperties');\n    if (uriMechanismProperties) {\n        for (const property of uriMechanismProperties) {\n            if (/(^|,)ALLOWED_HOSTS:/.test(property)) {\n                throw new error_1.MongoParseError('Auth mechanism property ALLOWED_HOSTS is not allowed in the connection string.');\n            }\n        }\n    }\n    if (objectOptions.has('loadBalanced')) {\n        throw new error_1.MongoParseError('loadBalanced is only a valid option in the URI');\n    }\n    // All option collection\n    const allProvidedOptions = new CaseInsensitiveMap();\n    const allProvidedKeys = new Set([...urlOptions.keys(), ...objectOptions.keys()]);\n    for (const key of allProvidedKeys) {\n        const values = [];\n        const objectOptionValue = objectOptions.get(key);\n        if (objectOptionValue != null) {\n            values.push(objectOptionValue);\n        }\n        const urlValues = urlOptions.get(key) ?? [];\n        values.push(...urlValues);\n        allProvidedOptions.set(key, values);\n    }\n    if (allProvidedOptions.has('tls') || allProvidedOptions.has('ssl')) {\n        const tlsAndSslOpts = (allProvidedOptions.get('tls') || [])\n            .concat(allProvidedOptions.get('ssl') || [])\n            .map(getBoolean.bind(null, 'tls/ssl'));\n        if (new Set(tlsAndSslOpts).size !== 1) {\n            throw new error_1.MongoParseError('All values of tls/ssl must be the same.');\n        }\n    }\n    checkTLSOptions(allProvidedOptions);\n    const unsupportedOptions = (0, utils_1.setDifference)(allProvidedKeys, Array.from(Object.keys(exports.OPTIONS)).map(s => s.toLowerCase()));\n    if (unsupportedOptions.size !== 0) {\n        const optionWord = unsupportedOptions.size > 1 ? 'options' : 'option';\n        const isOrAre = unsupportedOptions.size > 1 ? 'are' : 'is';\n        throw new error_1.MongoParseError(`${optionWord} ${Array.from(unsupportedOptions).join(', ')} ${isOrAre} not supported`);\n    }\n    // Option parsing and setting\n    for (const [key, descriptor] of Object.entries(exports.OPTIONS)) {\n        const values = allProvidedOptions.get(key);\n        if (!values || values.length === 0) {\n            if (exports.DEFAULT_OPTIONS.has(key)) {\n                setOption(mongoOptions, key, descriptor, [exports.DEFAULT_OPTIONS.get(key)]);\n            }\n        }\n        else {\n            const { deprecated } = descriptor;\n            if (deprecated) {\n                const deprecatedMsg = typeof deprecated === 'string' ? `: ${deprecated}` : '';\n                (0, utils_1.emitWarning)(`${key} is a deprecated option${deprecatedMsg}`);\n            }\n            setOption(mongoOptions, key, descriptor, values);\n        }\n    }\n    if (mongoOptions.credentials) {\n        const isGssapi = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_GSSAPI;\n        const isX509 = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_X509;\n        const isAws = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_AWS;\n        const isOidc = mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_OIDC;\n        if ((isGssapi || isX509) &&\n            allProvidedOptions.has('authSource') &&\n            mongoOptions.credentials.source !== '$external') {\n            // If authSource was explicitly given and its incorrect, we error\n            throw new error_1.MongoParseError(`authMechanism ${mongoOptions.credentials.mechanism} requires an authSource of '$external'`);\n        }\n        if (!(isGssapi || isX509 || isAws || isOidc) &&\n            mongoOptions.dbName &&\n            !allProvidedOptions.has('authSource')) {\n            // inherit the dbName unless GSSAPI or X509, then silently ignore dbName\n            // and there was no specific authSource given\n            mongoOptions.credentials = mongo_credentials_1.MongoCredentials.merge(mongoOptions.credentials, {\n                source: mongoOptions.dbName\n            });\n        }\n        if (isAws && mongoOptions.credentials.username && !mongoOptions.credentials.password) {\n            throw new error_1.MongoMissingCredentialsError(`When using ${mongoOptions.credentials.mechanism} password must be set when a username is specified`);\n        }\n        mongoOptions.credentials.validate();\n        // Check if the only auth related option provided was authSource, if so we can remove credentials\n        if (mongoOptions.credentials.password === '' &&\n            mongoOptions.credentials.username === '' &&\n            mongoOptions.credentials.mechanism === providers_1.AuthMechanism.MONGODB_DEFAULT &&\n            Object.keys(mongoOptions.credentials.mechanismProperties).length === 0) {\n            delete mongoOptions.credentials;\n        }\n    }\n    if (!mongoOptions.dbName) {\n        // dbName default is applied here because of the credential validation above\n        mongoOptions.dbName = 'test';\n    }\n    validateLoadBalancedOptions(hosts, mongoOptions, isSRV);\n    if (mongoClient && mongoOptions.autoEncryption) {\n        encrypter_1.Encrypter.checkForMongoCrypt();\n        mongoOptions.encrypter = new encrypter_1.Encrypter(mongoClient, uri, options);\n        mongoOptions.autoEncrypter = mongoOptions.encrypter.autoEncrypter;\n    }\n    // Potential SRV Overrides and SRV connection string validations\n    mongoOptions.userSpecifiedAuthSource =\n        objectOptions.has('authSource') || urlOptions.has('authSource');\n    mongoOptions.userSpecifiedReplicaSet =\n        objectOptions.has('replicaSet') || urlOptions.has('replicaSet');\n    if (isSRV) {\n        // SRV Record is resolved upon connecting\n        mongoOptions.srvHost = hosts[0];\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoAPIError('SRV URI does not support directConnection');\n        }\n        if (mongoOptions.srvMaxHosts > 0 && typeof mongoOptions.replicaSet === 'string') {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts option with replicaSet');\n        }\n        // SRV turns on TLS by default, but users can override and turn it off\n        const noUserSpecifiedTLS = !objectOptions.has('tls') && !urlOptions.has('tls');\n        const noUserSpecifiedSSL = !objectOptions.has('ssl') && !urlOptions.has('ssl');\n        if (noUserSpecifiedTLS && noUserSpecifiedSSL) {\n            mongoOptions.tls = true;\n        }\n    }\n    else {\n        const userSpecifiedSrvOptions = urlOptions.has('srvMaxHosts') ||\n            objectOptions.has('srvMaxHosts') ||\n            urlOptions.has('srvServiceName') ||\n            objectOptions.has('srvServiceName');\n        if (userSpecifiedSrvOptions) {\n            throw new error_1.MongoParseError('Cannot use srvMaxHosts or srvServiceName with a non-srv connection string');\n        }\n    }\n    if (mongoOptions.directConnection && mongoOptions.hosts.length !== 1) {\n        throw new error_1.MongoParseError('directConnection option requires exactly one host');\n    }\n    if (!mongoOptions.proxyHost &&\n        (mongoOptions.proxyPort || mongoOptions.proxyUsername || mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Must specify proxyHost if other proxy options are passed');\n    }\n    if ((mongoOptions.proxyUsername && !mongoOptions.proxyPassword) ||\n        (!mongoOptions.proxyUsername && mongoOptions.proxyPassword)) {\n        throw new error_1.MongoParseError('Can only specify both of proxy username/password or neither');\n    }\n    const proxyOptions = ['proxyHost', 'proxyPort', 'proxyUsername', 'proxyPassword'].map(key => urlOptions.get(key) ?? []);\n    if (proxyOptions.some(options => options.length > 1)) {\n        throw new error_1.MongoParseError('Proxy options cannot be specified multiple times in the connection string');\n    }\n    const loggerFeatureFlag = Symbol.for('@@mdb.enableMongoLogger');\n    mongoOptions[loggerFeatureFlag] = mongoOptions[loggerFeatureFlag] ?? false;\n    let loggerEnvOptions = {};\n    let loggerClientOptions = {};\n    if (mongoOptions[loggerFeatureFlag]) {\n        loggerEnvOptions = {\n            MONGODB_LOG_COMMAND: process.env.MONGODB_LOG_COMMAND,\n            MONGODB_LOG_TOPOLOGY: process.env.MONGODB_LOG_TOPOLOGY,\n            MONGODB_LOG_SERVER_SELECTION: process.env.MONGODB_LOG_SERVER_SELECTION,\n            MONGODB_LOG_CONNECTION: process.env.MONGODB_LOG_CONNECTION,\n            MONGODB_LOG_CLIENT: process.env.MONGODB_LOG_CLIENT,\n            MONGODB_LOG_ALL: process.env.MONGODB_LOG_ALL,\n            MONGODB_LOG_MAX_DOCUMENT_LENGTH: process.env.MONGODB_LOG_MAX_DOCUMENT_LENGTH,\n            MONGODB_LOG_PATH: process.env.MONGODB_LOG_PATH,\n            ...mongoOptions[Symbol.for('@@mdb.internalLoggerConfig')]\n        };\n        loggerClientOptions = {\n            mongodbLogPath: mongoOptions.mongodbLogPath,\n            mongodbLogComponentSeverities: mongoOptions.mongodbLogComponentSeverities,\n            mongodbLogMaxDocumentLength: mongoOptions.mongodbLogMaxDocumentLength\n        };\n    }\n    mongoOptions.mongoLoggerOptions = mongo_logger_1.MongoLogger.resolveOptions(loggerEnvOptions, loggerClientOptions);\n    mongoOptions.metadata = (0, client_metadata_1.makeClientMetadata)(mongoOptions);\n    return mongoOptions;\n}\nexports.parseOptions = parseOptions;\n/**\n * #### Throws if LB mode is true:\n * - hosts contains more than one host\n * - there is a replicaSet name set\n * - directConnection is set\n * - if srvMaxHosts is used when an srv connection string is passed in\n *\n * @throws MongoParseError\n */\nfunction validateLoadBalancedOptions(hosts, mongoOptions, isSrv) {\n    if (mongoOptions.loadBalanced) {\n        if (hosts.length > 1) {\n            throw new error_1.MongoParseError(LB_SINGLE_HOST_ERROR);\n        }\n        if (mongoOptions.replicaSet) {\n            throw new error_1.MongoParseError(LB_REPLICA_SET_ERROR);\n        }\n        if (mongoOptions.directConnection) {\n            throw new error_1.MongoParseError(LB_DIRECT_CONNECTION_ERROR);\n        }\n        if (isSrv && mongoOptions.srvMaxHosts > 0) {\n            throw new error_1.MongoParseError('Cannot limit srv hosts with loadBalanced enabled');\n        }\n    }\n    return;\n}\nfunction setOption(mongoOptions, key, descriptor, values) {\n    const { target, type, transform } = descriptor;\n    const name = target ?? key;\n    switch (type) {\n        case 'boolean':\n            mongoOptions[name] = getBoolean(name, values[0]);\n            break;\n        case 'int':\n            mongoOptions[name] = getIntFromOptions(name, values[0]);\n            break;\n        case 'uint':\n            mongoOptions[name] = getUIntFromOptions(name, values[0]);\n            break;\n        case 'string':\n            if (values[0] == null) {\n                break;\n            }\n            mongoOptions[name] = String(values[0]);\n            break;\n        case 'record':\n            if (!(0, utils_1.isRecord)(values[0])) {\n                throw new error_1.MongoParseError(`${name} must be an object`);\n            }\n            mongoOptions[name] = values[0];\n            break;\n        case 'any':\n            mongoOptions[name] = values[0];\n            break;\n        default: {\n            if (!transform) {\n                throw new error_1.MongoParseError('Descriptors missing a type must define a transform');\n            }\n            const transformValue = transform({ name, options: mongoOptions, values });\n            mongoOptions[name] = transformValue;\n            break;\n        }\n    }\n}\nexports.OPTIONS = {\n    appName: {\n        type: 'string'\n    },\n    auth: {\n        target: 'credentials',\n        transform({ name, options, values: [value] }) {\n            if (!(0, utils_1.isRecord)(value, ['username', 'password'])) {\n                throw new error_1.MongoParseError(`${name} must be an object with 'username' and 'password' properties`);\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                username: value.username,\n                password: value.password\n            });\n        }\n    },\n    authMechanism: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const mechanisms = Object.values(providers_1.AuthMechanism);\n            const [mechanism] = mechanisms.filter(m => m.match(RegExp(String.raw `\\b${value}\\b`, 'i')));\n            if (!mechanism) {\n                throw new error_1.MongoParseError(`authMechanism one of ${mechanisms}, got ${value}`);\n            }\n            let source = options.credentials?.source;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_PLAIN ||\n                providers_1.AUTH_MECHS_AUTH_SRC_EXTERNAL.has(mechanism)) {\n                // some mechanisms have '$external' as the Auth Source\n                source = '$external';\n            }\n            let password = options.credentials?.password;\n            if (mechanism === providers_1.AuthMechanism.MONGODB_X509 && password === '') {\n                password = undefined;\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanism,\n                source,\n                password\n            });\n        }\n    },\n    authMechanismProperties: {\n        target: 'credentials',\n        transform({ options, values }) {\n            // We can have a combination of options passed in the URI and options passed\n            // as an object to the MongoClient. So we must transform the string options\n            // as well as merge them together with a potentially provided object.\n            let mechanismProperties = Object.create(null);\n            for (const optionValue of values) {\n                if (typeof optionValue === 'string') {\n                    for (const [key, value] of entriesFromString(optionValue)) {\n                        try {\n                            mechanismProperties[key] = getBoolean(key, value);\n                        }\n                        catch {\n                            mechanismProperties[key] = value;\n                        }\n                    }\n                }\n                else {\n                    if (!(0, utils_1.isRecord)(optionValue)) {\n                        throw new error_1.MongoParseError('AuthMechanismProperties must be an object');\n                    }\n                    mechanismProperties = { ...optionValue };\n                }\n            }\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, {\n                mechanismProperties\n            });\n        }\n    },\n    authSource: {\n        target: 'credentials',\n        transform({ options, values: [value] }) {\n            const source = String(value);\n            return mongo_credentials_1.MongoCredentials.merge(options.credentials, { source });\n        }\n    },\n    autoEncryption: {\n        type: 'record'\n    },\n    bsonRegExp: {\n        type: 'boolean'\n    },\n    serverApi: {\n        target: 'serverApi',\n        transform({ values: [version] }) {\n            const serverApiToValidate = typeof version === 'string' ? { version } : version;\n            const versionToValidate = serverApiToValidate && serverApiToValidate.version;\n            if (!versionToValidate) {\n                throw new error_1.MongoParseError(`Invalid \\`serverApi\\` property; must specify a version from the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            if (!Object.values(mongo_client_1.ServerApiVersion).some(v => v === versionToValidate)) {\n                throw new error_1.MongoParseError(`Invalid server API version=${versionToValidate}; must be in the following enum: [\"${Object.values(mongo_client_1.ServerApiVersion).join('\", \"')}\"]`);\n            }\n            return serverApiToValidate;\n        }\n    },\n    checkKeys: {\n        type: 'boolean'\n    },\n    compressors: {\n        default: 'none',\n        target: 'compressors',\n        transform({ values }) {\n            const compressionList = new Set();\n            for (const compVal of values) {\n                const compValArray = typeof compVal === 'string' ? compVal.split(',') : compVal;\n                if (!Array.isArray(compValArray)) {\n                    throw new error_1.MongoInvalidArgumentError('compressors must be an array or a comma-delimited list of strings');\n                }\n                for (const c of compValArray) {\n                    if (Object.keys(compression_1.Compressor).includes(String(c))) {\n                        compressionList.add(String(c));\n                    }\n                    else {\n                        throw new error_1.MongoInvalidArgumentError(`${c} is not a valid compression mechanism. Must be one of: ${Object.keys(compression_1.Compressor)}.`);\n                    }\n                }\n            }\n            return [...compressionList];\n        }\n    },\n    connectTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    dbName: {\n        type: 'string'\n    },\n    directConnection: {\n        default: false,\n        type: 'boolean'\n    },\n    driverInfo: {\n        default: {},\n        type: 'record'\n    },\n    enableUtf8Validation: { type: 'boolean', default: true },\n    family: {\n        transform({ name, values: [value] }) {\n            const transformValue = getIntFromOptions(name, value);\n            if (transformValue === 4 || transformValue === 6) {\n                return transformValue;\n            }\n            throw new error_1.MongoParseError(`Option 'family' must be 4 or 6 got ${transformValue}.`);\n        }\n    },\n    fieldsAsRaw: {\n        type: 'record'\n    },\n    forceServerObjectId: {\n        default: false,\n        type: 'boolean'\n    },\n    fsync: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    fsync: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from fsync=${value}`);\n            return wc;\n        }\n    },\n    heartbeatFrequencyMS: {\n        default: 10000,\n        type: 'uint'\n    },\n    ignoreUndefined: {\n        type: 'boolean'\n    },\n    j: {\n        deprecated: 'Please use journal instead',\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    journal: {\n        target: 'writeConcern',\n        transform({ name, options, values: [value] }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    journal: getBoolean(name, value)\n                }\n            });\n            if (!wc)\n                throw new error_1.MongoParseError(`Unable to make a writeConcern from journal=${value}`);\n            return wc;\n        }\n    },\n    loadBalanced: {\n        default: false,\n        type: 'boolean'\n    },\n    localThresholdMS: {\n        default: 15,\n        type: 'uint'\n    },\n    maxConnecting: {\n        default: 2,\n        transform({ name, values: [value] }) {\n            const maxConnecting = getUIntFromOptions(name, value);\n            if (maxConnecting === 0) {\n                throw new error_1.MongoInvalidArgumentError('maxConnecting must be > 0 if specified');\n            }\n            return maxConnecting;\n        }\n    },\n    maxIdleTimeMS: {\n        default: 0,\n        type: 'uint'\n    },\n    maxPoolSize: {\n        default: 100,\n        type: 'uint'\n    },\n    maxStalenessSeconds: {\n        target: 'readPreference',\n        transform({ name, options, values: [value] }) {\n            const maxStalenessSeconds = getUIntFromOptions(name, value);\n            if (options.readPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, maxStalenessSeconds }\n                });\n            }\n            else {\n                return new read_preference_1.ReadPreference('secondary', undefined, { maxStalenessSeconds });\n            }\n        }\n    },\n    minInternalBufferSize: {\n        type: 'uint'\n    },\n    minPoolSize: {\n        default: 0,\n        type: 'uint'\n    },\n    minHeartbeatFrequencyMS: {\n        default: 500,\n        type: 'uint'\n    },\n    monitorCommands: {\n        default: false,\n        type: 'boolean'\n    },\n    name: {\n        target: 'driverInfo',\n        transform({ values: [value], options }) {\n            return { ...options.driverInfo, name: String(value) };\n        }\n    },\n    noDelay: {\n        default: true,\n        type: 'boolean'\n    },\n    pkFactory: {\n        default: utils_1.DEFAULT_PK_FACTORY,\n        transform({ values: [value] }) {\n            if ((0, utils_1.isRecord)(value, ['createPk']) && typeof value.createPk === 'function') {\n                return value;\n            }\n            throw new error_1.MongoParseError(`Option pkFactory must be an object with a createPk function, got ${value}`);\n        }\n    },\n    promoteBuffers: {\n        type: 'boolean'\n    },\n    promoteLongs: {\n        type: 'boolean'\n    },\n    promoteValues: {\n        type: 'boolean'\n    },\n    useBigInt64: {\n        type: 'boolean'\n    },\n    proxyHost: {\n        type: 'string'\n    },\n    proxyPassword: {\n        type: 'string'\n    },\n    proxyPort: {\n        type: 'uint'\n    },\n    proxyUsername: {\n        type: 'string'\n    },\n    raw: {\n        default: false,\n        type: 'boolean'\n    },\n    readConcern: {\n        transform({ values: [value], options }) {\n            if (value instanceof read_concern_1.ReadConcern || (0, utils_1.isRecord)(value, ['level'])) {\n                return read_concern_1.ReadConcern.fromOptions({ ...options.readConcern, ...value });\n            }\n            throw new error_1.MongoParseError(`ReadConcern must be an object, got ${JSON.stringify(value)}`);\n        }\n    },\n    readConcernLevel: {\n        target: 'readConcern',\n        transform({ values: [level], options }) {\n            return read_concern_1.ReadConcern.fromOptions({\n                ...options.readConcern,\n                level: level\n            });\n        }\n    },\n    readPreference: {\n        default: read_preference_1.ReadPreference.primary,\n        transform({ values: [value], options }) {\n            if (value instanceof read_preference_1.ReadPreference) {\n                return read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n            }\n            if ((0, utils_1.isRecord)(value, ['mode'])) {\n                const rp = read_preference_1.ReadPreference.fromOptions({\n                    readPreference: { ...options.readPreference, ...value },\n                    ...value\n                });\n                if (rp)\n                    return rp;\n                else\n                    throw new error_1.MongoParseError(`Cannot make read preference from ${JSON.stringify(value)}`);\n            }\n            if (typeof value === 'string') {\n                const rpOpts = {\n                    hedge: options.readPreference?.hedge,\n                    maxStalenessSeconds: options.readPreference?.maxStalenessSeconds\n                };\n                return new read_preference_1.ReadPreference(value, options.readPreference?.tags, rpOpts);\n            }\n            throw new error_1.MongoParseError(`Unknown ReadPreference value: ${value}`);\n        }\n    },\n    readPreferenceTags: {\n        target: 'readPreference',\n        transform({ values, options }) {\n            const tags = Array.isArray(values[0])\n                ? values[0]\n                : values;\n            const readPreferenceTags = [];\n            for (const tag of tags) {\n                const readPreferenceTag = Object.create(null);\n                if (typeof tag === 'string') {\n                    for (const [k, v] of entriesFromString(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                if ((0, utils_1.isRecord)(tag)) {\n                    for (const [k, v] of Object.entries(tag)) {\n                        readPreferenceTag[k] = v;\n                    }\n                }\n                readPreferenceTags.push(readPreferenceTag);\n            }\n            return read_preference_1.ReadPreference.fromOptions({\n                readPreference: options.readPreference,\n                readPreferenceTags\n            });\n        }\n    },\n    replicaSet: {\n        type: 'string'\n    },\n    retryReads: {\n        default: true,\n        type: 'boolean'\n    },\n    retryWrites: {\n        default: true,\n        type: 'boolean'\n    },\n    serializeFunctions: {\n        type: 'boolean'\n    },\n    serverMonitoringMode: {\n        default: 'auto',\n        transform({ values: [value] }) {\n            if (!Object.values(monitor_1.ServerMonitoringMode).includes(value)) {\n                throw new error_1.MongoParseError('serverMonitoringMode must be one of `auto`, `poll`, or `stream`');\n            }\n            return value;\n        }\n    },\n    serverSelectionTimeoutMS: {\n        default: 30000,\n        type: 'uint'\n    },\n    servername: {\n        type: 'string'\n    },\n    socketTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    srvMaxHosts: {\n        type: 'uint',\n        default: 0\n    },\n    srvServiceName: {\n        type: 'string',\n        default: 'mongodb'\n    },\n    ssl: {\n        target: 'tls',\n        type: 'boolean'\n    },\n    tls: {\n        type: 'boolean'\n    },\n    tlsAllowInvalidCertificates: {\n        target: 'rejectUnauthorized',\n        transform({ name, values: [value] }) {\n            // allowInvalidCertificates is the inverse of rejectUnauthorized\n            return !getBoolean(name, value);\n        }\n    },\n    tlsAllowInvalidHostnames: {\n        target: 'checkServerIdentity',\n        transform({ name, values: [value] }) {\n            // tlsAllowInvalidHostnames means setting the checkServerIdentity function to a noop\n            return getBoolean(name, value) ? () => undefined : undefined;\n        }\n    },\n    tlsCAFile: {\n        type: 'string'\n    },\n    tlsCRLFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFile: {\n        type: 'string'\n    },\n    tlsCertificateKeyFilePassword: {\n        target: 'passphrase',\n        type: 'any'\n    },\n    tlsInsecure: {\n        transform({ name, options, values: [value] }) {\n            const tlsInsecure = getBoolean(name, value);\n            if (tlsInsecure) {\n                options.checkServerIdentity = () => undefined;\n                options.rejectUnauthorized = false;\n            }\n            else {\n                options.checkServerIdentity = options.tlsAllowInvalidHostnames\n                    ? () => undefined\n                    : undefined;\n                options.rejectUnauthorized = options.tlsAllowInvalidCertificates ? false : true;\n            }\n            return tlsInsecure;\n        }\n    },\n    w: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            return write_concern_1.WriteConcern.fromOptions({ writeConcern: { ...options.writeConcern, w: value } });\n        }\n    },\n    waitQueueTimeoutMS: {\n        default: 0,\n        type: 'uint'\n    },\n    writeConcern: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            if ((0, utils_1.isRecord)(value) || value instanceof write_concern_1.WriteConcern) {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        ...value\n                    }\n                });\n            }\n            else if (value === 'majority' || typeof value === 'number') {\n                return write_concern_1.WriteConcern.fromOptions({\n                    writeConcern: {\n                        ...options.writeConcern,\n                        w: value\n                    }\n                });\n            }\n            throw new error_1.MongoParseError(`Invalid WriteConcern cannot parse: ${JSON.stringify(value)}`);\n        }\n    },\n    wtimeout: {\n        deprecated: 'Please use wtimeoutMS instead',\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeout: getUIntFromOptions('wtimeout', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    wtimeoutMS: {\n        target: 'writeConcern',\n        transform({ values: [value], options }) {\n            const wc = write_concern_1.WriteConcern.fromOptions({\n                writeConcern: {\n                    ...options.writeConcern,\n                    wtimeoutMS: getUIntFromOptions('wtimeoutMS', value)\n                }\n            });\n            if (wc)\n                return wc;\n            throw new error_1.MongoParseError(`Cannot make WriteConcern from wtimeout`);\n        }\n    },\n    zlibCompressionLevel: {\n        default: 0,\n        type: 'int'\n    },\n    // Custom types for modifying core behavior\n    connectionType: { type: 'any' },\n    srvPoller: { type: 'any' },\n    // Accepted NodeJS Options\n    minDHSize: { type: 'any' },\n    pskCallback: { type: 'any' },\n    secureContext: { type: 'any' },\n    enableTrace: { type: 'any' },\n    requestCert: { type: 'any' },\n    rejectUnauthorized: { type: 'any' },\n    checkServerIdentity: { type: 'any' },\n    ALPNProtocols: { type: 'any' },\n    SNICallback: { type: 'any' },\n    session: { type: 'any' },\n    requestOCSP: { type: 'any' },\n    localAddress: { type: 'any' },\n    localPort: { type: 'any' },\n    hints: { type: 'any' },\n    lookup: { type: 'any' },\n    ca: { type: 'any' },\n    cert: { type: 'any' },\n    ciphers: { type: 'any' },\n    crl: { type: 'any' },\n    ecdhCurve: { type: 'any' },\n    key: { type: 'any' },\n    passphrase: { type: 'any' },\n    pfx: { type: 'any' },\n    secureProtocol: { type: 'any' },\n    index: { type: 'any' },\n    // Legacy options from v3 era\n    useNewUrlParser: {\n        type: 'boolean',\n        deprecated: 'useNewUrlParser has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    useUnifiedTopology: {\n        type: 'boolean',\n        deprecated: 'useUnifiedTopology has no effect since Node.js Driver version 4.0.0 and will be removed in the next major version'\n    },\n    // MongoLogger\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogPath: { type: 'any' },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogComponentSeverities: { type: 'any' },\n    /**\n     * @internal\n     * TODO: NODE-5671 - remove internal flag\n     */\n    mongodbLogMaxDocumentLength: { type: 'uint' }\n};\nexports.DEFAULT_OPTIONS = new CaseInsensitiveMap(Object.entries(exports.OPTIONS)\n    .filter(([, descriptor]) => descriptor.default != null)\n    .map(([k, d]) => [k, d.default]));\n/**\n * Set of permitted feature flags\n * @internal\n */\nexports.FEATURE_FLAGS = new Set([\n    Symbol.for('@@mdb.skipPingOnConnect'),\n    Symbol.for('@@mdb.enableMongoLogger'),\n    Symbol.for('@@mdb.internalLoggerConfig')\n]);\n//# sourceMappingURL=connection_string.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/connection_string.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/constants.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/constants.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TOPOLOGY_EVENTS = exports.CMAP_EVENTS = exports.HEARTBEAT_EVENTS = exports.RESUME_TOKEN_CHANGED = exports.END = exports.CHANGE = exports.INIT = exports.MORE = exports.RESPONSE = exports.SERVER_HEARTBEAT_FAILED = exports.SERVER_HEARTBEAT_SUCCEEDED = exports.SERVER_HEARTBEAT_STARTED = exports.COMMAND_FAILED = exports.COMMAND_SUCCEEDED = exports.COMMAND_STARTED = exports.CLUSTER_TIME_RECEIVED = exports.CONNECTION_CHECKED_IN = exports.CONNECTION_CHECKED_OUT = exports.CONNECTION_CHECK_OUT_FAILED = exports.CONNECTION_CHECK_OUT_STARTED = exports.CONNECTION_CLOSED = exports.CONNECTION_READY = exports.CONNECTION_CREATED = exports.CONNECTION_POOL_READY = exports.CONNECTION_POOL_CLEARED = exports.CONNECTION_POOL_CLOSED = exports.CONNECTION_POOL_CREATED = exports.TOPOLOGY_DESCRIPTION_CHANGED = exports.TOPOLOGY_CLOSED = exports.TOPOLOGY_OPENING = exports.SERVER_DESCRIPTION_CHANGED = exports.SERVER_CLOSED = exports.SERVER_OPENING = exports.DESCRIPTION_RECEIVED = exports.UNPINNED = exports.PINNED = exports.MESSAGE = exports.ENDED = exports.CLOSED = exports.CONNECT = exports.OPEN = exports.CLOSE = exports.TIMEOUT = exports.ERROR = exports.SYSTEM_JS_COLLECTION = exports.SYSTEM_COMMAND_COLLECTION = exports.SYSTEM_USER_COLLECTION = exports.SYSTEM_PROFILE_COLLECTION = exports.SYSTEM_INDEX_COLLECTION = exports.SYSTEM_NAMESPACE_COLLECTION = void 0;\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = exports.LEGACY_HELLO_COMMAND = exports.MONGO_CLIENT_EVENTS = exports.LOCAL_SERVER_EVENTS = exports.SERVER_RELAY_EVENTS = exports.APM_EVENTS = void 0;\nexports.SYSTEM_NAMESPACE_COLLECTION = 'system.namespaces';\nexports.SYSTEM_INDEX_COLLECTION = 'system.indexes';\nexports.SYSTEM_PROFILE_COLLECTION = 'system.profile';\nexports.SYSTEM_USER_COLLECTION = 'system.users';\nexports.SYSTEM_COMMAND_COLLECTION = '$cmd';\nexports.SYSTEM_JS_COLLECTION = 'system.js';\n// events\nexports.ERROR = 'error';\nexports.TIMEOUT = 'timeout';\nexports.CLOSE = 'close';\nexports.OPEN = 'open';\nexports.CONNECT = 'connect';\nexports.CLOSED = 'closed';\nexports.ENDED = 'ended';\nexports.MESSAGE = 'message';\nexports.PINNED = 'pinned';\nexports.UNPINNED = 'unpinned';\nexports.DESCRIPTION_RECEIVED = 'descriptionReceived';\nexports.SERVER_OPENING = 'serverOpening';\nexports.SERVER_CLOSED = 'serverClosed';\nexports.SERVER_DESCRIPTION_CHANGED = 'serverDescriptionChanged';\nexports.TOPOLOGY_OPENING = 'topologyOpening';\nexports.TOPOLOGY_CLOSED = 'topologyClosed';\nexports.TOPOLOGY_DESCRIPTION_CHANGED = 'topologyDescriptionChanged';\n/** @internal */\nexports.CONNECTION_POOL_CREATED = 'connectionPoolCreated';\n/** @internal */\nexports.CONNECTION_POOL_CLOSED = 'connectionPoolClosed';\n/** @internal */\nexports.CONNECTION_POOL_CLEARED = 'connectionPoolCleared';\n/** @internal */\nexports.CONNECTION_POOL_READY = 'connectionPoolReady';\n/** @internal */\nexports.CONNECTION_CREATED = 'connectionCreated';\n/** @internal */\nexports.CONNECTION_READY = 'connectionReady';\n/** @internal */\nexports.CONNECTION_CLOSED = 'connectionClosed';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_STARTED = 'connectionCheckOutStarted';\n/** @internal */\nexports.CONNECTION_CHECK_OUT_FAILED = 'connectionCheckOutFailed';\n/** @internal */\nexports.CONNECTION_CHECKED_OUT = 'connectionCheckedOut';\n/** @internal */\nexports.CONNECTION_CHECKED_IN = 'connectionCheckedIn';\nexports.CLUSTER_TIME_RECEIVED = 'clusterTimeReceived';\nexports.COMMAND_STARTED = 'commandStarted';\nexports.COMMAND_SUCCEEDED = 'commandSucceeded';\nexports.COMMAND_FAILED = 'commandFailed';\nexports.SERVER_HEARTBEAT_STARTED = 'serverHeartbeatStarted';\nexports.SERVER_HEARTBEAT_SUCCEEDED = 'serverHeartbeatSucceeded';\nexports.SERVER_HEARTBEAT_FAILED = 'serverHeartbeatFailed';\nexports.RESPONSE = 'response';\nexports.MORE = 'more';\nexports.INIT = 'init';\nexports.CHANGE = 'change';\nexports.END = 'end';\nexports.RESUME_TOKEN_CHANGED = 'resumeTokenChanged';\n/** @public */\nexports.HEARTBEAT_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED\n]);\n/** @public */\nexports.CMAP_EVENTS = Object.freeze([\n    exports.CONNECTION_POOL_CREATED,\n    exports.CONNECTION_POOL_READY,\n    exports.CONNECTION_POOL_CLEARED,\n    exports.CONNECTION_POOL_CLOSED,\n    exports.CONNECTION_CREATED,\n    exports.CONNECTION_READY,\n    exports.CONNECTION_CLOSED,\n    exports.CONNECTION_CHECK_OUT_STARTED,\n    exports.CONNECTION_CHECK_OUT_FAILED,\n    exports.CONNECTION_CHECKED_OUT,\n    exports.CONNECTION_CHECKED_IN\n]);\n/** @public */\nexports.TOPOLOGY_EVENTS = Object.freeze([\n    exports.SERVER_OPENING,\n    exports.SERVER_CLOSED,\n    exports.SERVER_DESCRIPTION_CHANGED,\n    exports.TOPOLOGY_OPENING,\n    exports.TOPOLOGY_CLOSED,\n    exports.TOPOLOGY_DESCRIPTION_CHANGED,\n    exports.ERROR,\n    exports.TIMEOUT,\n    exports.CLOSE\n]);\n/** @public */\nexports.APM_EVENTS = Object.freeze([\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED\n]);\n/**\n * All events that we relay to the `Topology`\n * @internal\n */\nexports.SERVER_RELAY_EVENTS = Object.freeze([\n    exports.SERVER_HEARTBEAT_STARTED,\n    exports.SERVER_HEARTBEAT_SUCCEEDED,\n    exports.SERVER_HEARTBEAT_FAILED,\n    exports.COMMAND_STARTED,\n    exports.COMMAND_SUCCEEDED,\n    exports.COMMAND_FAILED,\n    ...exports.CMAP_EVENTS\n]);\n/**\n * All events we listen to from `Server` instances, but do not forward to the client\n * @internal\n */\nexports.LOCAL_SERVER_EVENTS = Object.freeze([\n    exports.CONNECT,\n    exports.DESCRIPTION_RECEIVED,\n    exports.CLOSED,\n    exports.ENDED\n]);\n/** @public */\nexports.MONGO_CLIENT_EVENTS = Object.freeze([\n    ...exports.CMAP_EVENTS,\n    ...exports.APM_EVENTS,\n    ...exports.TOPOLOGY_EVENTS,\n    ...exports.HEARTBEAT_EVENTS\n]);\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND = 'ismaster';\n/**\n * @internal\n * The legacy hello command that was deprecated in MongoDB 5.0.\n */\nexports.LEGACY_HELLO_COMMAND_CAMEL_CASE = 'isMaster';\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/constants.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/abstract_cursor.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/abstract_cursor.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.assertUninitialized = exports.AbstractCursor = exports.CURSOR_FLAGS = void 0;\nconst stream_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst kill_cursors_1 = __webpack_require__(/*! ../operations/kill_cursors */ \"./node_modules/mongodb/lib/operations/kill_cursors.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sessions_1 = __webpack_require__(/*! ../sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nconst kId = Symbol('id');\n/** @internal */\nconst kDocuments = Symbol('documents');\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kNamespace = Symbol('namespace');\n/** @internal */\nconst kClient = Symbol('client');\n/** @internal */\nconst kSession = Symbol('session');\n/** @internal */\nconst kOptions = Symbol('options');\n/** @internal */\nconst kTransform = Symbol('transform');\n/** @internal */\nconst kInitialized = Symbol('initialized');\n/** @internal */\nconst kClosed = Symbol('closed');\n/** @internal */\nconst kKilled = Symbol('killed');\n/** @internal */\nconst kInit = Symbol('kInit');\n/** @public */\nexports.CURSOR_FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass AbstractCursor extends mongo_types_1.TypedEventEmitter {\n    /** @internal */\n    constructor(client, namespace, options = {}) {\n        super();\n        if (!client.s.isMongoClient) {\n            throw new error_1.MongoRuntimeError('Cursor must be constructed with MongoClient');\n        }\n        this[kClient] = client;\n        this[kNamespace] = namespace;\n        this[kId] = null;\n        this[kDocuments] = new utils_1.List();\n        this[kInitialized] = false;\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kOptions] = {\n            readPreference: options.readPreference && options.readPreference instanceof read_preference_1.ReadPreference\n                ? options.readPreference\n                : read_preference_1.ReadPreference.primary,\n            ...(0, bson_1.pluckBSONSerializeOptions)(options)\n        };\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        if (readConcern) {\n            this[kOptions].readConcern = readConcern;\n        }\n        if (typeof options.batchSize === 'number') {\n            this[kOptions].batchSize = options.batchSize;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this[kOptions].comment = options.comment;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            this[kOptions].maxTimeMS = options.maxTimeMS;\n        }\n        if (typeof options.maxAwaitTimeMS === 'number') {\n            this[kOptions].maxAwaitTimeMS = options.maxAwaitTimeMS;\n        }\n        if (options.session instanceof sessions_1.ClientSession) {\n            this[kSession] = options.session;\n        }\n        else {\n            this[kSession] = this[kClient].startSession({ owner: this, explicit: false });\n        }\n    }\n    get id() {\n        return this[kId] ?? undefined;\n    }\n    /** @internal */\n    get isDead() {\n        return (this[kId]?.isZero() ?? false) || this[kClosed] || this[kKilled];\n    }\n    /** @internal */\n    get client() {\n        return this[kClient];\n    }\n    /** @internal */\n    get server() {\n        return this[kServer];\n    }\n    get namespace() {\n        return this[kNamespace];\n    }\n    get readPreference() {\n        return this[kOptions].readPreference;\n    }\n    get readConcern() {\n        return this[kOptions].readConcern;\n    }\n    /** @internal */\n    get session() {\n        return this[kSession];\n    }\n    set session(clientSession) {\n        this[kSession] = clientSession;\n    }\n    /** @internal */\n    get cursorOptions() {\n        return this[kOptions];\n    }\n    get closed() {\n        return this[kClosed];\n    }\n    get killed() {\n        return this[kKilled];\n    }\n    get loadBalanced() {\n        return !!this[kClient].topology?.loadBalanced;\n    }\n    /** Returns current buffered documents length */\n    bufferedCount() {\n        return this[kDocuments].length;\n    }\n    /** Returns current buffered documents */\n    readBufferedDocuments(number) {\n        const bufferedDocs = [];\n        const documentsToRead = Math.min(number ?? this[kDocuments].length, this[kDocuments].length);\n        for (let count = 0; count < documentsToRead; count++) {\n            const document = this[kDocuments].shift();\n            if (document != null) {\n                bufferedDocs.push(document);\n            }\n        }\n        return bufferedDocs;\n    }\n    async *[Symbol.asyncIterator]() {\n        if (this.closed) {\n            return;\n        }\n        try {\n            while (true) {\n                const document = await this.next();\n                // Intentional strict null check, because users can map cursors to falsey values.\n                // We allow mapping to all values except for null.\n                // eslint-disable-next-line no-restricted-syntax\n                if (document === null) {\n                    if (!this.closed) {\n                        const message = 'Cursor returned a `null` document, but the cursor is not exhausted.  Mapping documents to `null` is not supported in the cursor transform.';\n                        await cleanupCursor(this, { needsToEmitClosed: true }).catch(() => null);\n                        throw new error_1.MongoAPIError(message);\n                    }\n                    break;\n                }\n                yield document;\n                if (this[kId] === bson_1.Long.ZERO) {\n                    // Cursor exhausted\n                    break;\n                }\n            }\n        }\n        finally {\n            // Only close the cursor if it has not already been closed. This finally clause handles\n            // the case when a user would break out of a for await of loop early.\n            if (!this.closed) {\n                await this.close().catch(() => null);\n            }\n        }\n    }\n    stream(options) {\n        if (options?.transform) {\n            const transform = options.transform;\n            const readable = new ReadableCursorStream(this);\n            return readable.pipe(new stream_1.Transform({\n                objectMode: true,\n                highWaterMark: 1,\n                transform(chunk, _, callback) {\n                    try {\n                        const transformed = transform(chunk);\n                        callback(undefined, transformed);\n                    }\n                    catch (err) {\n                        callback(err);\n                    }\n                }\n            }));\n        }\n        return new ReadableCursorStream(this);\n    }\n    async hasNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            return false;\n        }\n        if (this[kDocuments].length !== 0) {\n            return true;\n        }\n        const doc = await next(this, { blocking: true, transform: false });\n        if (doc) {\n            this[kDocuments].unshift(doc);\n            return true;\n        }\n        return false;\n    }\n    /** Get the next available document from the cursor, returns null if no more documents are available. */\n    async next() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return next(this, { blocking: true, transform: true });\n    }\n    /**\n     * Try to get the next available document from the cursor or `null` if an empty batch is returned\n     */\n    async tryNext() {\n        if (this[kId] === bson_1.Long.ZERO) {\n            throw new error_1.MongoCursorExhaustedError();\n        }\n        return next(this, { blocking: false, transform: true });\n    }\n    /**\n     * Iterates over all the documents for this cursor using the iterator, callback pattern.\n     *\n     * If the iterator returns `false`, iteration will stop.\n     *\n     * @param iterator - The iteration callback.\n     * @deprecated - Will be removed in a future release. Use for await...of instead.\n     */\n    async forEach(iterator) {\n        if (typeof iterator !== 'function') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"iterator\" must be a function');\n        }\n        for await (const document of this) {\n            const result = iterator(document);\n            if (result === false) {\n                break;\n            }\n        }\n    }\n    async close() {\n        const needsToEmitClosed = !this[kClosed];\n        this[kClosed] = true;\n        await cleanupCursor(this, { needsToEmitClosed });\n    }\n    /**\n     * Returns an array of documents. The caller is responsible for making sure that there\n     * is enough memory to store the results. Note that the array only contains partial\n     * results when this cursor had been previously accessed. In that case,\n     * cursor.rewind() can be used to reset the cursor.\n     */\n    async toArray() {\n        const array = [];\n        for await (const document of this) {\n            array.push(document);\n        }\n        return array;\n    }\n    /**\n     * Add a cursor flag to the cursor\n     *\n     * @param flag - The flag to set, must be one of following ['tailable', 'oplogReplay', 'noCursorTimeout', 'awaitData', 'partial' -.\n     * @param value - The flag boolean value.\n     */\n    addCursorFlag(flag, value) {\n        assertUninitialized(this);\n        if (!exports.CURSOR_FLAGS.includes(flag)) {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} is not one of ${exports.CURSOR_FLAGS}`);\n        }\n        if (typeof value !== 'boolean') {\n            throw new error_1.MongoInvalidArgumentError(`Flag ${flag} must be a boolean value`);\n        }\n        this[kOptions][flag] = value;\n        return this;\n    }\n    /**\n     * Map all documents using the provided function\n     * If there is a transform set on the cursor, that will be called first and the result passed to\n     * this function's transform.\n     *\n     * @remarks\n     *\n     * **Note** Cursors use `null` internally to indicate that there are no more documents in the cursor. Providing a mapping\n     * function that maps values to `null` will result in the cursor closing itself before it has finished iterating\n     * all documents.  This will **not** result in a memory leak, just surprising behavior.  For example:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => null);\n     *\n     * const documents = await cursor.toArray();\n     * // documents is always [], regardless of how many documents are in the collection.\n     * ```\n     *\n     * Other falsey values are allowed:\n     *\n     * ```typescript\n     * const cursor = collection.find({});\n     * cursor.map(() => '');\n     *\n     * const documents = await cursor.toArray();\n     * // documents is now an array of empty strings\n     * ```\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling map,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<Document> = coll.find();\n     * const mappedCursor: FindCursor<number> = cursor.map(doc => Object.keys(doc).length);\n     * const keyCounts: number[] = await mappedCursor.toArray(); // cursor.toArray() still returns Document[]\n     * ```\n     * @param transform - The mapping transformation method.\n     */\n    map(transform) {\n        assertUninitialized(this);\n        const oldTransform = this[kTransform]; // TODO(NODE-3283): Improve transform typing\n        if (oldTransform) {\n            this[kTransform] = doc => {\n                return transform(oldTransform(doc));\n            };\n        }\n        else {\n            this[kTransform] = transform;\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadPreference(readPreference) {\n        assertUninitialized(this);\n        if (readPreference instanceof read_preference_1.ReadPreference) {\n            this[kOptions].readPreference = readPreference;\n        }\n        else if (typeof readPreference === 'string') {\n            this[kOptions].readPreference = read_preference_1.ReadPreference.fromString(readPreference);\n        }\n        else {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${readPreference}`);\n        }\n        return this;\n    }\n    /**\n     * Set the ReadPreference for the cursor.\n     *\n     * @param readPreference - The new read preference for the cursor.\n     */\n    withReadConcern(readConcern) {\n        assertUninitialized(this);\n        const resolvedReadConcern = read_concern_1.ReadConcern.fromOptions({ readConcern });\n        if (resolvedReadConcern) {\n            this[kOptions].readConcern = resolvedReadConcern;\n        }\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        assertUninitialized(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Set the batch size for the cursor.\n     *\n     * @param value - The number of documents to return per batch. See {@link https://www.mongodb.com/docs/manual/reference/command/find/|find command documentation}.\n     */\n    batchSize(value) {\n        assertUninitialized(this);\n        if (this[kOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support batchSize');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"batchSize\" requires an integer');\n        }\n        this[kOptions].batchSize = value;\n        return this;\n    }\n    /**\n     * Rewind this cursor to its uninitialized state. Any options that are present on the cursor will\n     * remain in effect. Iterating this cursor will cause new queries to be sent to the server, even\n     * if the resultant data has already been retrieved by this cursor.\n     */\n    rewind() {\n        if (!this[kInitialized]) {\n            return;\n        }\n        this[kId] = null;\n        this[kDocuments].clear();\n        this[kClosed] = false;\n        this[kKilled] = false;\n        this[kInitialized] = false;\n        const session = this[kSession];\n        if (session) {\n            // We only want to end this session if we created it, and it hasn't ended yet\n            if (session.explicit === false) {\n                if (!session.hasEnded) {\n                    session.endSession().catch(() => null);\n                }\n                this[kSession] = this.client.startSession({ owner: this, explicit: false });\n            }\n        }\n    }\n    /** @internal */\n    async getMore(batchSize) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this[kNamespace], this[kId], this[kServer], {\n            ...this[kOptions],\n            session: this[kSession],\n            batchSize\n        });\n        return (0, execute_operation_1.executeOperation)(this[kClient], getMoreOperation);\n    }\n    /**\n     * @internal\n     *\n     * This function is exposed for the unified test runner's createChangeStream\n     * operation.  We cannot refactor to use the abstract _initialize method without\n     * a significant refactor.\n     */\n    async [kInit]() {\n        try {\n            const state = await this._initialize(this[kSession]);\n            const response = state.response;\n            this[kServer] = state.server;\n            if (response.cursor) {\n                // TODO(NODE-2674): Preserve int64 sent from MongoDB\n                this[kId] =\n                    typeof response.cursor.id === 'number'\n                        ? bson_1.Long.fromNumber(response.cursor.id)\n                        : typeof response.cursor.id === 'bigint'\n                            ? bson_1.Long.fromBigInt(response.cursor.id)\n                            : response.cursor.id;\n                if (response.cursor.ns) {\n                    this[kNamespace] = (0, utils_1.ns)(response.cursor.ns);\n                }\n                this[kDocuments].pushMany(response.cursor.firstBatch);\n            }\n            // When server responses return without a cursor document, we close this cursor\n            // and return the raw server response. This is often the case for explain commands\n            // for example\n            if (this[kId] == null) {\n                this[kId] = bson_1.Long.ZERO;\n                // TODO(NODE-3286): ExecutionResult needs to accept a generic parameter\n                this[kDocuments].push(state.response);\n            }\n            // the cursor is now initialized, even if it is dead\n            this[kInitialized] = true;\n        }\n        catch (error) {\n            // the cursor is now initialized, even if an error occurred\n            this[kInitialized] = true;\n            await cleanupCursor(this, { error });\n            throw error;\n        }\n        if (this.isDead) {\n            await cleanupCursor(this, undefined);\n        }\n        return;\n    }\n}\n/** @event */\nAbstractCursor.CLOSE = 'close';\nexports.AbstractCursor = AbstractCursor;\n/**\n * @param cursor - the cursor on which to call `next`\n * @param blocking - a boolean indicating whether or not the cursor should `block` until data\n *     is available.  Generally, this flag is set to `false` because if the getMore returns no documents,\n *     the cursor has been exhausted.  In certain scenarios (ChangeStreams, tailable await cursors and\n *     `tryNext`, for example) blocking is necessary because a getMore returning no documents does\n *     not indicate the end of the cursor.\n * @param transform - if true, the cursor's transform function is applied to the result document (if the transform exists)\n * @returns the next document in the cursor, or `null`.  When `blocking` is `true`, a `null` document means\n * the cursor has been exhausted.  Otherwise, it means that there is no document available in the cursor's buffer.\n */\nasync function next(cursor, { blocking, transform }) {\n    if (cursor.closed) {\n        return null;\n    }\n    do {\n        if (cursor[kId] == null) {\n            // All cursors must operate within a session, one must be made implicitly if not explicitly provided\n            await cursor[kInit]();\n        }\n        if (cursor[kDocuments].length !== 0) {\n            const doc = cursor[kDocuments].shift();\n            if (doc != null && transform && cursor[kTransform]) {\n                try {\n                    return cursor[kTransform](doc);\n                }\n                catch (error) {\n                    // `cleanupCursorAsync` should never throw, but if it does we want to throw the original\n                    // error instead.\n                    await cleanupCursor(cursor, { error, needsToEmitClosed: true }).catch(() => null);\n                    throw error;\n                }\n            }\n            return doc;\n        }\n        if (cursor.isDead) {\n            // if the cursor is dead, we clean it up\n            // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n            return null;\n        }\n        // otherwise need to call getMore\n        const batchSize = cursor[kOptions].batchSize || 1000;\n        try {\n            const response = await cursor.getMore(batchSize);\n            if (response) {\n                const cursorId = typeof response.cursor.id === 'number'\n                    ? bson_1.Long.fromNumber(response.cursor.id)\n                    : typeof response.cursor.id === 'bigint'\n                        ? bson_1.Long.fromBigInt(response.cursor.id)\n                        : response.cursor.id;\n                cursor[kDocuments].pushMany(response.cursor.nextBatch);\n                cursor[kId] = cursorId;\n            }\n        }\n        catch (error) {\n            // `cleanupCursorAsync` should never throw, but if it does we want to throw the original\n            // error instead.\n            await cleanupCursor(cursor, { error }).catch(() => null);\n            throw error;\n        }\n        if (cursor.isDead) {\n            // If we successfully received a response from a cursor BUT the cursor indicates that it is exhausted,\n            // we intentionally clean up the cursor to release its session back into the pool before the cursor\n            // is iterated.  This prevents a cursor that is exhausted on the server from holding\n            // onto a session indefinitely until the AbstractCursor is iterated.\n            //\n            // cleanupCursorAsync should never throw, but if it does it indicates a bug in the driver\n            // and we should surface the error\n            await cleanupCursor(cursor, {});\n        }\n        if (cursor[kDocuments].length === 0 && blocking === false) {\n            return null;\n        }\n    } while (!cursor.isDead || cursor[kDocuments].length !== 0);\n    return null;\n}\nasync function cleanupCursor(cursor, options) {\n    const cursorId = cursor[kId];\n    const cursorNs = cursor[kNamespace];\n    const server = cursor[kServer];\n    const session = cursor[kSession];\n    const error = options?.error;\n    // Cursors only emit closed events once the client-side cursor has been exhausted fully or there\n    // was an error.  Notably, when the server returns a cursor id of 0 and a non-empty batch, we\n    // cleanup the cursor but don't emit a `close` event.\n    const needsToEmitClosed = options?.needsToEmitClosed ?? cursor[kDocuments].length === 0;\n    if (error) {\n        if (cursor.loadBalanced && error instanceof error_1.MongoNetworkError) {\n            return completeCleanup();\n        }\n    }\n    if (cursorId == null || server == null || cursorId.isZero() || cursorNs == null) {\n        if (needsToEmitClosed) {\n            cursor[kClosed] = true;\n            cursor[kId] = bson_1.Long.ZERO;\n            cursor.emit(AbstractCursor.CLOSE);\n        }\n        if (session) {\n            if (session.owner === cursor) {\n                await session.endSession({ error });\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        return;\n    }\n    async function completeCleanup() {\n        if (session) {\n            if (session.owner === cursor) {\n                try {\n                    await session.endSession({ error });\n                }\n                finally {\n                    cursor.emit(AbstractCursor.CLOSE);\n                }\n                return;\n            }\n            if (!session.inTransaction()) {\n                (0, sessions_1.maybeClearPinnedConnection)(session, { error });\n            }\n        }\n        cursor.emit(AbstractCursor.CLOSE);\n        return;\n    }\n    cursor[kKilled] = true;\n    if (session.hasEnded) {\n        return completeCleanup();\n    }\n    try {\n        await (0, execute_operation_1.executeOperation)(cursor[kClient], new kill_cursors_1.KillCursorsOperation(cursorId, cursorNs, server, { session })).catch(() => null);\n    }\n    finally {\n        await completeCleanup();\n    }\n}\n/** @internal */\nfunction assertUninitialized(cursor) {\n    if (cursor[kInitialized]) {\n        throw new error_1.MongoCursorInUseError();\n    }\n}\nexports.assertUninitialized = assertUninitialized;\nclass ReadableCursorStream extends stream_1.Readable {\n    constructor(cursor) {\n        super({\n            objectMode: true,\n            autoDestroy: false,\n            highWaterMark: 1\n        });\n        this._readInProgress = false;\n        this._cursor = cursor;\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _read(size) {\n        if (!this._readInProgress) {\n            this._readInProgress = true;\n            this._readNext();\n        }\n    }\n    _destroy(error, callback) {\n        this._cursor.close().then(() => callback(error), closeError => callback(closeError));\n    }\n    _readNext() {\n        next(this._cursor, { blocking: true, transform: true }).then(result => {\n            if (result == null) {\n                this.push(null);\n            }\n            else if (this.destroyed) {\n                this._cursor.close().catch(() => null);\n            }\n            else {\n                if (this.push(result)) {\n                    return this._readNext();\n                }\n                this._readInProgress = false;\n            }\n        }, err => {\n            // NOTE: This is questionable, but we have a test backing the behavior. It seems the\n            //       desired behavior is that a stream ends cleanly when a user explicitly closes\n            //       a client during iteration. Alternatively, we could do the \"right\" thing and\n            //       propagate the error message by removing this special case.\n            if (err.message.match(/server is closed/)) {\n                this._cursor.close().catch(() => null);\n                return this.push(null);\n            }\n            // NOTE: This is also perhaps questionable. The rationale here is that these errors tend\n            //       to be \"operation was interrupted\", where a cursor has been closed but there is an\n            //       active getMore in-flight. This used to check if the cursor was killed but once\n            //       that changed to happen in cleanup legitimate errors would not destroy the\n            //       stream. There are change streams test specifically test these cases.\n            if (err.message.match(/operation was interrupted/)) {\n                return this.push(null);\n            }\n            // NOTE: The two above checks on the message of the error will cause a null to be pushed\n            //       to the stream, thus closing the stream before the destroy call happens. This means\n            //       that either of those error messages on a change stream will not get a proper\n            //       'error' event to be emitted (the error passed to destroy). Change stream resumability\n            //       relies on that error event to be emitted to create its new cursor and thus was not\n            //       working on 4.4 servers because the error emitted on failover was \"interrupted at\n            //       shutdown\" while on 5.0+ it is \"The server is in quiesce mode and will shut down\".\n            //       See NODE-4475.\n            return this.destroy(err);\n        });\n    }\n}\n//# sourceMappingURL=abstract_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/abstract_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/aggregation_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/aggregation_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregationCursor = void 0;\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kPipeline = Symbol('pipeline');\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **AggregationCursor** class is an internal class that embodies an aggregation cursor on MongoDB\n * allowing for iteration over the results returned from the underlying query. It supports\n * one by one document iteration, conversion to an array or can be iterated as a Node 4.X\n * or higher stream\n * @public\n */\nclass AggregationCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this[kPipeline] = pipeline;\n        this[kOptions] = options;\n    }\n    get pipeline() {\n        return this[kPipeline];\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kOptions]);\n        delete clonedOptions.session;\n        return new AggregationCursor(this.client, this.namespace, this[kPipeline], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, aggregateOperation);\n        // TODO: NODE-2882\n        return { server: aggregateOperation.server, session, response };\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return (0, execute_operation_1.executeOperation)(this.client, new aggregate_1.AggregateOperation(this.namespace, this[kPipeline], {\n            ...this[kOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    group($group) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $group });\n        return this;\n    }\n    /** Add a limit stage to the aggregation pipeline */\n    limit($limit) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $limit });\n        return this;\n    }\n    /** Add a match stage to the aggregation pipeline */\n    match($match) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $match });\n        return this;\n    }\n    /** Add an out stage to the aggregation pipeline */\n    out($out) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $out });\n        return this;\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: AggregationCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: AggregationCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: AggregationCursor<{ a: number; b: string }> = coll.aggregate([]);\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.aggregate().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project($project) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $project });\n        return this;\n    }\n    /** Add a lookup stage to the aggregation pipeline */\n    lookup($lookup) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $lookup });\n        return this;\n    }\n    /** Add a redact stage to the aggregation pipeline */\n    redact($redact) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $redact });\n        return this;\n    }\n    /** Add a skip stage to the aggregation pipeline */\n    skip($skip) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $skip });\n        return this;\n    }\n    /** Add a sort stage to the aggregation pipeline */\n    sort($sort) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $sort });\n        return this;\n    }\n    /** Add a unwind stage to the aggregation pipeline */\n    unwind($unwind) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $unwind });\n        return this;\n    }\n    /** Add a geoNear stage to the aggregation pipeline */\n    geoNear($geoNear) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kPipeline].push({ $geoNear });\n        return this;\n    }\n}\nexports.AggregationCursor = AggregationCursor;\n//# sourceMappingURL=aggregation_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/aggregation_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/change_stream_cursor.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/change_stream_cursor.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChangeStreamCursor = void 0;\nconst change_stream_1 = __webpack_require__(/*! ../change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregate_1 = __webpack_require__(/*! ../operations/aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nclass ChangeStreamCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(client, namespace, pipeline = [], options = {}) {\n        super(client, namespace, options);\n        this.pipeline = pipeline;\n        this.options = options;\n        this._resumeToken = null;\n        this.startAtOperationTime = options.startAtOperationTime;\n        if (options.startAfter) {\n            this.resumeToken = options.startAfter;\n        }\n        else if (options.resumeAfter) {\n            this.resumeToken = options.resumeAfter;\n        }\n    }\n    set resumeToken(token) {\n        this._resumeToken = token;\n        this.emit(change_stream_1.ChangeStream.RESUME_TOKEN_CHANGED, token);\n    }\n    get resumeToken() {\n        return this._resumeToken;\n    }\n    get resumeOptions() {\n        const options = {\n            ...this.options\n        };\n        for (const key of ['resumeAfter', 'startAfter', 'startAtOperationTime']) {\n            delete options[key];\n        }\n        if (this.resumeToken != null) {\n            if (this.options.startAfter && !this.hasReceived) {\n                options.startAfter = this.resumeToken;\n            }\n            else {\n                options.resumeAfter = this.resumeToken;\n            }\n        }\n        else if (this.startAtOperationTime != null && (0, utils_1.maxWireVersion)(this.server) >= 7) {\n            options.startAtOperationTime = this.startAtOperationTime;\n        }\n        return options;\n    }\n    cacheResumeToken(resumeToken) {\n        if (this.bufferedCount() === 0 && this.postBatchResumeToken) {\n            this.resumeToken = this.postBatchResumeToken;\n        }\n        else {\n            this.resumeToken = resumeToken;\n        }\n        this.hasReceived = true;\n    }\n    _processBatch(response) {\n        const cursor = response.cursor;\n        if (cursor.postBatchResumeToken) {\n            this.postBatchResumeToken = response.cursor.postBatchResumeToken;\n            const batch = 'firstBatch' in response.cursor ? response.cursor.firstBatch : response.cursor.nextBatch;\n            if (batch.length === 0) {\n                this.resumeToken = cursor.postBatchResumeToken;\n            }\n        }\n    }\n    clone() {\n        return new ChangeStreamCursor(this.client, this.namespace, this.pipeline, {\n            ...this.cursorOptions\n        });\n    }\n    async _initialize(session) {\n        const aggregateOperation = new aggregate_1.AggregateOperation(this.namespace, this.pipeline, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(session.client, aggregateOperation);\n        const server = aggregateOperation.server;\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(server);\n        if (this.startAtOperationTime == null &&\n            this.resumeAfter == null &&\n            this.startAfter == null &&\n            this.maxWireVersion >= 7) {\n            this.startAtOperationTime = response.operationTime;\n        }\n        this._processBatch(response);\n        this.emit(constants_1.INIT, response);\n        this.emit(constants_1.RESPONSE);\n        // TODO: NODE-2882\n        return { server, session, response };\n    }\n    async getMore(batchSize) {\n        const response = await super.getMore(batchSize);\n        this.maxWireVersion = (0, utils_1.maxWireVersion)(this.server);\n        this._processBatch(response);\n        this.emit(change_stream_1.ChangeStream.MORE, response);\n        this.emit(change_stream_1.ChangeStream.RESPONSE);\n        return response;\n    }\n}\nexports.ChangeStreamCursor = ChangeStreamCursor;\n//# sourceMappingURL=change_stream_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/change_stream_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/find_cursor.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/find_cursor.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindCursor = exports.FLAGS = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst count_1 = __webpack_require__(/*! ../operations/count */ \"./node_modules/mongodb/lib/operations/count.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst find_1 = __webpack_require__(/*! ../operations/find */ \"./node_modules/mongodb/lib/operations/find.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @internal */\nconst kFilter = Symbol('filter');\n/** @internal */\nconst kNumReturned = Symbol('numReturned');\n/** @internal */\nconst kBuiltOptions = Symbol('builtOptions');\n/** @public Flags allowed for cursor */\nexports.FLAGS = [\n    'tailable',\n    'oplogReplay',\n    'noCursorTimeout',\n    'awaitData',\n    'exhaust',\n    'partial'\n];\n/** @public */\nclass FindCursor extends abstract_cursor_1.AbstractCursor {\n    /** @internal */\n    constructor(client, namespace, filter = {}, options = {}) {\n        super(client, namespace, options);\n        this[kFilter] = filter;\n        this[kBuiltOptions] = options;\n        if (options.sort != null) {\n            this[kBuiltOptions].sort = (0, sort_1.formatSort)(options.sort);\n        }\n    }\n    clone() {\n        const clonedOptions = (0, utils_1.mergeOptions)({}, this[kBuiltOptions]);\n        delete clonedOptions.session;\n        return new FindCursor(this.client, this.namespace, this[kFilter], {\n            ...clonedOptions\n        });\n    }\n    map(transform) {\n        return super.map(transform);\n    }\n    /** @internal */\n    async _initialize(session) {\n        const findOperation = new find_1.FindOperation(undefined, this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, findOperation);\n        // the response is not a cursor when `explain` is enabled\n        this[kNumReturned] = response.cursor?.firstBatch?.length;\n        // TODO: NODE-2882\n        return { server: findOperation.server, session, response };\n    }\n    /** @internal */\n    async getMore(batchSize) {\n        const numReturned = this[kNumReturned];\n        if (numReturned) {\n            // TODO(DRIVERS-1448): Remove logic to enforce `limit` in the driver\n            const limit = this[kBuiltOptions].limit;\n            batchSize =\n                limit && limit > 0 && numReturned + batchSize > limit ? limit - numReturned : batchSize;\n            if (batchSize <= 0) {\n                // this is an optimization for the special case of a limit for a find command to avoid an\n                // extra getMore when the limit has been reached and the limit is a multiple of the batchSize.\n                // This is a consequence of the new query engine in 5.0 having no knowledge of the limit as it\n                // produces results for the find command.  Once a batch is filled up, it is returned and only\n                // on the subsequent getMore will the query framework consider the limit, determine the cursor\n                // is exhausted and return a cursorId of zero.\n                // instead, if we determine there are no more documents to request from the server, we preemptively\n                // close the cursor\n                await this.close().catch(() => null);\n                return { cursor: { id: bson_1.Long.ZERO, nextBatch: [] } };\n            }\n        }\n        const response = await super.getMore(batchSize);\n        // TODO: wrap this in some logic to prevent it from happening if we don't need this support\n        if (response) {\n            this[kNumReturned] = this[kNumReturned] + response.cursor.nextBatch.length;\n        }\n        return response;\n    }\n    /**\n     * Get the count of documents for this cursor\n     * @deprecated Use `collection.estimatedDocumentCount` or `collection.countDocuments` instead\n     */\n    async count(options) {\n        (0, utils_1.emitWarningOnce)('cursor.count is deprecated and will be removed in the next major version, please use `collection.estimatedDocumentCount` or `collection.countDocuments` instead ');\n        if (typeof options === 'boolean') {\n            throw new error_1.MongoInvalidArgumentError('Invalid first parameter to count');\n        }\n        return (0, execute_operation_1.executeOperation)(this.client, new count_1.CountOperation(this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            ...options\n        }));\n    }\n    /** Execute the explain for the cursor */\n    async explain(verbosity) {\n        return (0, execute_operation_1.executeOperation)(this.client, new find_1.FindOperation(undefined, this.namespace, this[kFilter], {\n            ...this[kBuiltOptions],\n            ...this.cursorOptions,\n            explain: verbosity ?? true\n        }));\n    }\n    /** Set the cursor query */\n    filter(filter) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kFilter] = filter;\n        return this;\n    }\n    /**\n     * Set the cursor hint\n     *\n     * @param hint - If specified, then the query system will only consider plans using the hinted index.\n     */\n    hint(hint) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].hint = hint;\n        return this;\n    }\n    /**\n     * Set the cursor min\n     *\n     * @param min - Specify a $min value to specify the inclusive lower bound for a specific index in order to constrain the results of find(). The $min specifies the lower bound for all keys of a specific index in order.\n     */\n    min(min) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].min = min;\n        return this;\n    }\n    /**\n     * Set the cursor max\n     *\n     * @param max - Specify a $max value to specify the exclusive upper bound for a specific index in order to constrain the results of find(). The $max specifies the upper bound for all keys of a specific index in order.\n     */\n    max(max) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].max = max;\n        return this;\n    }\n    /**\n     * Set the cursor returnKey.\n     * If set to true, modifies the cursor to only return the index field or fields for the results of the query, rather than documents.\n     * If set to true and the query does not use an index to perform the read operation, the returned documents will not contain any fields.\n     *\n     * @param value - the returnKey value.\n     */\n    returnKey(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].returnKey = value;\n        return this;\n    }\n    /**\n     * Modifies the output of a query by adding a field $recordId to matching documents. $recordId is the internal key which uniquely identifies a document in a collection.\n     *\n     * @param value - The $showDiskLoc option has now been deprecated and replaced with the showRecordId field. $showDiskLoc will still be accepted for OP_QUERY stye find.\n     */\n    showRecordId(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].showRecordId = value;\n        return this;\n    }\n    /**\n     * Add a query modifier to the cursor query\n     *\n     * @param name - The query modifier (must start with $, such as $orderby etc)\n     * @param value - The modifier value.\n     */\n    addQueryModifier(name, value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (name[0] !== '$') {\n            throw new error_1.MongoInvalidArgumentError(`${name} is not a valid query modifier`);\n        }\n        // Strip of the $\n        const field = name.substr(1);\n        // NOTE: consider some TS magic for this\n        switch (field) {\n            case 'comment':\n                this[kBuiltOptions].comment = value;\n                break;\n            case 'explain':\n                this[kBuiltOptions].explain = value;\n                break;\n            case 'hint':\n                this[kBuiltOptions].hint = value;\n                break;\n            case 'max':\n                this[kBuiltOptions].max = value;\n                break;\n            case 'maxTimeMS':\n                this[kBuiltOptions].maxTimeMS = value;\n                break;\n            case 'min':\n                this[kBuiltOptions].min = value;\n                break;\n            case 'orderby':\n                this[kBuiltOptions].sort = (0, sort_1.formatSort)(value);\n                break;\n            case 'query':\n                this[kFilter] = value;\n                break;\n            case 'returnKey':\n                this[kBuiltOptions].returnKey = value;\n                break;\n            case 'showDiskLoc':\n                this[kBuiltOptions].showRecordId = value;\n                break;\n            default:\n                throw new error_1.MongoInvalidArgumentError(`Invalid query modifier: ${name}`);\n        }\n        return this;\n    }\n    /**\n     * Add a comment to the cursor query allowing for tracking the comment in the log.\n     *\n     * @param value - The comment attached to this query.\n     */\n    comment(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].comment = value;\n        return this;\n    }\n    /**\n     * Set a maxAwaitTimeMS on a tailing cursor query to allow to customize the timeout value for the option awaitData (Only supported on MongoDB 3.2 or higher, ignored otherwise)\n     *\n     * @param value - Number of milliseconds to wait before aborting the tailed query.\n     */\n    maxAwaitTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxAwaitTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxAwaitTimeMS = value;\n        return this;\n    }\n    /**\n     * Set a maxTimeMS on the cursor query, allowing for hard timeout limits on queries (Only supported on MongoDB 2.6 or higher)\n     *\n     * @param value - Number of milliseconds to wait before aborting the query.\n     */\n    maxTimeMS(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Argument for maxTimeMS must be a number');\n        }\n        this[kBuiltOptions].maxTimeMS = value;\n        return this;\n    }\n    /**\n     * Add a project stage to the aggregation pipeline\n     *\n     * @remarks\n     * In order to strictly type this function you must provide an interface\n     * that represents the effect of your projection on the result documents.\n     *\n     * By default chaining a projection to your cursor changes the returned type to the generic\n     * {@link Document} type.\n     * You should specify a parameterized type to have assertions on your final results.\n     *\n     * @example\n     * ```typescript\n     * // Best way\n     * const docs: FindCursor<{ a: number }> = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * // Flexible way\n     * const docs: FindCursor<Document> = cursor.project({ _id: 0, a: true });\n     * ```\n     *\n     * @remarks\n     *\n     * **Note for Typescript Users:** adding a transform changes the return type of the iteration of this cursor,\n     * it **does not** return a new instance of a cursor. This means when calling project,\n     * you should always assign the result to a new variable in order to get a correctly typed cursor variable.\n     * Take note of the following example:\n     *\n     * @example\n     * ```typescript\n     * const cursor: FindCursor<{ a: number; b: string }> = coll.find();\n     * const projectCursor = cursor.project<{ a: number }>({ _id: 0, a: true });\n     * const aPropOnlyArray: {a: number}[] = await projectCursor.toArray();\n     *\n     * // or always use chaining and save the final cursor\n     *\n     * const cursor = coll.find().project<{ a: string }>({\n     *   _id: 0,\n     *   a: { $convert: { input: '$a', to: 'string' }\n     * }});\n     * ```\n     */\n    project(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].projection = value;\n        return this;\n    }\n    /**\n     * Sets the sort order of the cursor query.\n     *\n     * @param sort - The key or keys set for the sort.\n     * @param direction - The direction of the sorting (1 or -1).\n     */\n    sort(sort, direction) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support sorting');\n        }\n        this[kBuiltOptions].sort = (0, sort_1.formatSort)(sort, direction);\n        return this;\n    }\n    /**\n     * Allows disk use for blocking sort operations exceeding 100MB memory. (MongoDB 3.2 or higher)\n     *\n     * @remarks\n     * {@link https://www.mongodb.com/docs/manual/reference/command/find/#find-cmd-allowdiskuse | find command allowDiskUse documentation}\n     */\n    allowDiskUse(allow = true) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (!this[kBuiltOptions].sort) {\n            throw new error_1.MongoInvalidArgumentError('Option \"allowDiskUse\" requires a sort specification');\n        }\n        // As of 6.0 the default is true. This allows users to get back to the old behavior.\n        if (!allow) {\n            this[kBuiltOptions].allowDiskUse = false;\n            return this;\n        }\n        this[kBuiltOptions].allowDiskUse = true;\n        return this;\n    }\n    /**\n     * Set the collation options for the cursor.\n     *\n     * @param value - The cursor collation options (MongoDB 3.4 or higher) settings for update operation (see 3.4 documentation for available fields).\n     */\n    collation(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        this[kBuiltOptions].collation = value;\n        return this;\n    }\n    /**\n     * Set the limit for the cursor.\n     *\n     * @param value - The limit for the cursor query.\n     */\n    limit(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support limit');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"limit\" requires an integer');\n        }\n        this[kBuiltOptions].limit = value;\n        return this;\n    }\n    /**\n     * Set the skip for the cursor.\n     *\n     * @param value - The skip for the cursor query.\n     */\n    skip(value) {\n        (0, abstract_cursor_1.assertUninitialized)(this);\n        if (this[kBuiltOptions].tailable) {\n            throw new error_1.MongoTailableCursorError('Tailable cursor does not support skip');\n        }\n        if (typeof value !== 'number') {\n            throw new error_1.MongoInvalidArgumentError('Operation \"skip\" requires an integer');\n        }\n        this[kBuiltOptions].skip = value;\n        return this;\n    }\n}\nexports.FindCursor = FindCursor;\n//# sourceMappingURL=find_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/find_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_collections_cursor.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_collections_cursor.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst list_collections_1 = __webpack_require__(/*! ../operations/list_collections */ \"./node_modules/mongodb/lib/operations/list_collections.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListCollectionsCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(db, filter, options) {\n        super(db.client, db.s.namespace, options);\n        this.parent = db;\n        this.filter = filter;\n        this.options = options;\n    }\n    clone() {\n        return new ListCollectionsCursor(this.parent, this.filter, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new list_collections_1.ListCollectionsOperation(this.parent, this.filter, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListCollectionsCursor = ListCollectionsCursor;\n//# sourceMappingURL=list_collections_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/list_collections_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_indexes_cursor.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_indexes_cursor.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListIndexesCursor = void 0;\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ../operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass ListIndexesCursor extends abstract_cursor_1.AbstractCursor {\n    constructor(collection, options) {\n        super(collection.client, collection.s.namespace, options);\n        this.parent = collection;\n        this.options = options;\n    }\n    clone() {\n        return new ListIndexesCursor(this.parent, {\n            ...this.options,\n            ...this.cursorOptions\n        });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new indexes_1.ListIndexesOperation(this.parent, {\n            ...this.cursorOptions,\n            ...this.options,\n            session\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.parent.client, operation);\n        // TODO: NODE-2882\n        return { server: operation.server, session, response };\n    }\n}\nexports.ListIndexesCursor = ListIndexesCursor;\n//# sourceMappingURL=list_indexes_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/list_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListSearchIndexesCursor = void 0;\nconst aggregation_cursor_1 = __webpack_require__(/*! ./aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\n/** @public */\nclass ListSearchIndexesCursor extends aggregation_cursor_1.AggregationCursor {\n    /** @internal */\n    constructor({ fullNamespace: ns, client }, name, options = {}) {\n        const pipeline = name == null ? [{ $listSearchIndexes: {} }] : [{ $listSearchIndexes: { name } }];\n        super(client, ns, pipeline, options);\n    }\n}\nexports.ListSearchIndexesCursor = ListSearchIndexesCursor;\n//# sourceMappingURL=list_search_indexes_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/list_search_indexes_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/cursor/run_command_cursor.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/cursor/run_command_cursor.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunCommandCursor = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst execute_operation_1 = __webpack_require__(/*! ../operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst get_more_1 = __webpack_require__(/*! ../operations/get_more */ \"./node_modules/mongodb/lib/operations/get_more.js\");\nconst run_command_1 = __webpack_require__(/*! ../operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst abstract_cursor_1 = __webpack_require__(/*! ./abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\n/** @public */\nclass RunCommandCursor extends abstract_cursor_1.AbstractCursor {\n    /**\n     * Controls the `getMore.comment` field\n     * @param comment - any BSON value\n     */\n    setComment(comment) {\n        this.getMoreOptions.comment = comment;\n        return this;\n    }\n    /**\n     * Controls the `getMore.maxTimeMS` field. Only valid when cursor is tailable await\n     * @param maxTimeMS - the number of milliseconds to wait for new data\n     */\n    setMaxTimeMS(maxTimeMS) {\n        this.getMoreOptions.maxAwaitTimeMS = maxTimeMS;\n        return this;\n    }\n    /**\n     * Controls the `getMore.batchSize` field\n     * @param maxTimeMS - the number documents to return in the `nextBatch`\n     */\n    setBatchSize(batchSize) {\n        this.getMoreOptions.batchSize = batchSize;\n        return this;\n    }\n    /** Unsupported for RunCommandCursor */\n    clone() {\n        throw new error_1.MongoAPIError('Clone not supported, create a new cursor with db.runCursorCommand');\n    }\n    /** Unsupported for RunCommandCursor: readConcern must be configured directly on command document */\n    withReadConcern(_) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support readConcern it must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: various cursor flags must be configured directly on command document */\n    addCursorFlag(_, __) {\n        throw new error_1.MongoAPIError('RunCommandCursor does not support cursor flags, they must be attached to the command being run');\n    }\n    /** Unsupported for RunCommandCursor: maxTimeMS must be configured directly on command document */\n    maxTimeMS(_) {\n        throw new error_1.MongoAPIError('maxTimeMS must be configured on the command document directly, to configure getMore.maxTimeMS use cursor.setMaxTimeMS()');\n    }\n    /** Unsupported for RunCommandCursor: batchSize must be configured directly on command document */\n    batchSize(_) {\n        throw new error_1.MongoAPIError('batchSize must be configured on the command document directly, to configure getMore.batchSize use cursor.setBatchSize()');\n    }\n    /** @internal */\n    constructor(db, command, options = {}) {\n        super(db.client, (0, utils_1.ns)(db.namespace), options);\n        this.getMoreOptions = {};\n        this.db = db;\n        this.command = Object.freeze({ ...command });\n    }\n    /** @internal */\n    async _initialize(session) {\n        const operation = new run_command_1.RunCommandOperation(this.db, this.command, {\n            ...this.cursorOptions,\n            session: session,\n            readPreference: this.cursorOptions.readPreference\n        });\n        const response = await (0, execute_operation_1.executeOperation)(this.client, operation);\n        if (response.cursor == null) {\n            throw new error_1.MongoUnexpectedServerResponseError('Expected server to respond with cursor');\n        }\n        return {\n            server: operation.server,\n            session,\n            response\n        };\n    }\n    /** @internal */\n    async getMore(_batchSize) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        const getMoreOperation = new get_more_1.GetMoreOperation(this.namespace, this.id, this.server, {\n            ...this.cursorOptions,\n            session: this.session,\n            ...this.getMoreOptions\n        });\n        return (0, execute_operation_1.executeOperation)(this.client, getMoreOperation);\n    }\n}\nexports.RunCommandCursor = RunCommandCursor;\n//# sourceMappingURL=run_command_cursor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/cursor/run_command_cursor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/db.js":
/*!****************************************!*\
  !*** ./node_modules/mongodb/lib/db.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Db = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst CONSTANTS = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nconst run_command_cursor_1 = __webpack_require__(/*! ./cursor/run_command_cursor */ \"./node_modules/mongodb/lib/cursor/run_command_cursor.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst collections_1 = __webpack_require__(/*! ./operations/collections */ \"./node_modules/mongodb/lib/operations/collections.js\");\nconst create_collection_1 = __webpack_require__(/*! ./operations/create_collection */ \"./node_modules/mongodb/lib/operations/create_collection.js\");\nconst drop_1 = __webpack_require__(/*! ./operations/drop */ \"./node_modules/mongodb/lib/operations/drop.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst indexes_1 = __webpack_require__(/*! ./operations/indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst profiling_level_1 = __webpack_require__(/*! ./operations/profiling_level */ \"./node_modules/mongodb/lib/operations/profiling_level.js\");\nconst remove_user_1 = __webpack_require__(/*! ./operations/remove_user */ \"./node_modules/mongodb/lib/operations/remove_user.js\");\nconst rename_1 = __webpack_require__(/*! ./operations/rename */ \"./node_modules/mongodb/lib/operations/rename.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nconst stats_1 = __webpack_require__(/*! ./operations/stats */ \"./node_modules/mongodb/lib/operations/stats.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n// Allowed parameters\nconst DB_OPTIONS_ALLOW_LIST = [\n    'writeConcern',\n    'readPreference',\n    'readPreferenceTags',\n    'native_parser',\n    'forceServerObjectId',\n    'pkFactory',\n    'serializeFunctions',\n    'raw',\n    'authSource',\n    'ignoreUndefined',\n    'readConcern',\n    'retryMiliSeconds',\n    'numberOfRetries',\n    'useBigInt64',\n    'promoteBuffers',\n    'promoteLongs',\n    'bsonRegExp',\n    'enableUtf8Validation',\n    'promoteValues',\n    'compression',\n    'retryWrites'\n];\n/**\n * The **Db** class is a class that represents a MongoDB Database.\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const db = client.db();\n *\n * // Create a collection that validates our union\n * await db.createCollection<Pet>('pets', {\n *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }\n * })\n * ```\n */\nclass Db {\n    /**\n     * Creates a new Db instance.\n     *\n     * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.\n     *\n     * @param client - The MongoClient for the database.\n     * @param databaseName - The name of the database this instance represents.\n     * @param options - Optional settings for Db construction.\n     */\n    constructor(client, databaseName, options) {\n        options = options ?? {};\n        // Filter the options\n        options = (0, utils_1.filterOptions)(options, DB_OPTIONS_ALLOW_LIST);\n        // Ensure there are no dots in database name\n        if (typeof databaseName === 'string' && databaseName.includes('.')) {\n            throw new error_1.MongoInvalidArgumentError(`Database names cannot contain the character '.'`);\n        }\n        // Internal state of the db object\n        this.s = {\n            // Options\n            options,\n            // Unpack read preference\n            readPreference: read_preference_1.ReadPreference.fromOptions(options),\n            // Merge bson options\n            bsonOptions: (0, bson_1.resolveBSONOptions)(options, client),\n            // Set up the primary key factory or fallback to ObjectId\n            pkFactory: options?.pkFactory ?? utils_1.DEFAULT_PK_FACTORY,\n            // ReadConcern\n            readConcern: read_concern_1.ReadConcern.fromOptions(options),\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options),\n            // Namespace\n            namespace: new utils_1.MongoDBNamespace(databaseName)\n        };\n        this.client = client;\n    }\n    get databaseName() {\n        return this.s.namespace.db;\n    }\n    // Options\n    get options() {\n        return this.s.options;\n    }\n    /**\n     * Check if a secondary can be used (because the read preference is *not* set to primary)\n     */\n    get secondaryOk() {\n        return this.s.readPreference?.preference !== 'primary' || false;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    /**\n     * The current readPreference of the Db. If not explicitly defined for\n     * this Db, will be inherited from the parent MongoClient\n     */\n    get readPreference() {\n        if (this.s.readPreference == null) {\n            return this.client.readPreference;\n        }\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    // get the write Concern\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get namespace() {\n        return this.s.namespace.toString();\n    }\n    /**\n     * Create a new collection on a server with the specified options. Use this to create capped collections.\n     * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - The name of the collection to create\n     * @param options - Optional settings for the command\n     */\n    async createCollection(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new create_collection_1.CreateCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Execute a command\n     *\n     * @remarks\n     * This command does not inherit options from the MongoClient.\n     *\n     * The driver will ensure the following fields are attached to the command sent to the server:\n     * - `lsid` - sourced from an implicit session or options.session\n     * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n     * - `$db` - sourced from the name of this database\n     *\n     * If the client has a serverApi setting:\n     * - `apiVersion`\n     * - `apiStrict`\n     * - `apiDeprecationErrors`\n     *\n     * When in a transaction:\n     * - `readConcern` - sourced from readConcern set on the TransactionOptions\n     * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n     *\n     * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n     *\n     * @param command - The command to run\n     * @param options - Optional settings for the command\n     */\n    async command(command, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new run_command_1.RunCommandOperation(this, command, {\n            ...(0, bson_1.resolveBSONOptions)(options),\n            session: options?.session,\n            readPreference: options?.readPreference\n        }));\n    }\n    /**\n     * Execute an aggregation framework pipeline against the database, needs MongoDB \\>= 3.6\n     *\n     * @param pipeline - An array of aggregation stages to be executed\n     * @param options - Optional settings for the command\n     */\n    aggregate(pipeline = [], options) {\n        return new aggregation_cursor_1.AggregationCursor(this.client, this.s.namespace, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /** Return the Admin db instance */\n    admin() {\n        return new admin_1.Admin(this);\n    }\n    /**\n     * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.\n     *\n     * Collection namespace validation is performed server-side.\n     *\n     * @param name - the collection name we wish to access.\n     * @returns return the new Collection instance\n     */\n    collection(name, options = {}) {\n        if (typeof options === 'function') {\n            throw new error_1.MongoInvalidArgumentError('The callback form of this helper has been removed.');\n        }\n        return new collection_1.Collection(this, name, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Get all the db statistics.\n     *\n     * @param options - Optional settings for the command\n     */\n    async stats(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new stats_1.DbStatsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    listCollections(filter = {}, options = {}) {\n        return new list_collections_cursor_1.ListCollectionsCursor(this, filter, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * Rename a collection.\n     *\n     * @remarks\n     * This operation does not inherit options from the MongoClient.\n     *\n     * @param fromCollection - Name of current collection to rename\n     * @param toCollection - New name of of the collection\n     * @param options - Optional settings for the command\n     */\n    async renameCollection(fromCollection, toCollection, options) {\n        // Intentionally, we do not inherit options from parent for this operation.\n        return (0, execute_operation_1.executeOperation)(this.client, new rename_1.RenameOperation(this.collection(fromCollection), toCollection, { ...options, new_collection: true, readPreference: read_preference_1.ReadPreference.primary }));\n    }\n    /**\n     * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n     *\n     * @param name - Name of collection to drop\n     * @param options - Optional settings for the command\n     */\n    async dropCollection(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropCollectionOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Drop a database, removing it permanently from the server.\n     *\n     * @param options - Optional settings for the command\n     */\n    async dropDatabase(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new drop_1.DropDatabaseOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Fetch all collections for the current db.\n     *\n     * @param options - Optional settings for the command\n     */\n    async collections(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new collections_1.CollectionsOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Creates an index on the db and collection.\n     *\n     * @param name - Name of the collection to create the index on.\n     * @param indexSpec - Specify the field to index, or an index specification\n     * @param options - Optional settings for the command\n     */\n    async createIndex(name, indexSpec, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.CreateIndexOperation(this, name, indexSpec, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Remove a user from a database\n     *\n     * @param username - The username to remove\n     * @param options - Optional settings for the command\n     */\n    async removeUser(username, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new remove_user_1.RemoveUserOperation(this, username, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Set the current profiling level of MongoDB\n     *\n     * @param level - The new profiling level (off, slow_only, all).\n     * @param options - Optional settings for the command\n     */\n    async setProfilingLevel(level, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new set_profiling_level_1.SetProfilingLevelOperation(this, level, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieve the current profiling Level for MongoDB\n     *\n     * @param options - Optional settings for the command\n     */\n    async profilingLevel(options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new profiling_level_1.ProfilingLevelOperation(this, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Retrieves this collections index info.\n     *\n     * @param name - The name of the collection.\n     * @param options - Optional settings for the command\n     */\n    async indexInformation(name, options) {\n        return (0, execute_operation_1.executeOperation)(this.client, new indexes_1.IndexInformationOperation(this, name, (0, utils_1.resolveOptions)(this, options)));\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this database. Will ignore all\n     * changes to system collections.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the collections within this database\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n    /**\n     * A low level cursor API providing basic driver functionality:\n     * - ClientSession management\n     * - ReadPreference for server selection\n     * - Running getMores automatically when a local batch is exhausted\n     *\n     * @param command - The command that will start a cursor on the server.\n     * @param options - Configurations for running the command, bson options will apply to getMores\n     */\n    runCursorCommand(command, options) {\n        return new run_command_cursor_1.RunCommandCursor(this, command, options);\n    }\n}\nDb.SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;\nDb.SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;\nDb.SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;\nDb.SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;\nDb.SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;\nDb.SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;\nexports.Db = Db;\n//# sourceMappingURL=db.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/db.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/deps.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/deps.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getMongoDBClientEncryption = exports.aws4 = exports.getSocks = exports.getSnappy = exports.getGcpMetadata = exports.getAwsCredentialProvider = exports.getZstdLibrary = exports.ZStandard = exports.getKerberos = exports.Kerberos = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nfunction makeErrorModule(error) {\n    const props = error ? { kModuleError: error } : {};\n    return new Proxy(props, {\n        get: (_, key) => {\n            if (key === 'kModuleError') {\n                return error;\n            }\n            throw error;\n        },\n        set: () => {\n            throw error;\n        }\n    });\n}\nexports.Kerberos = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `kerberos` not found. Please install it to enable kerberos authentication'));\nfunction getKerberos() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        exports.Kerberos = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'kerberos'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n        return exports.Kerberos;\n    }\n    catch {\n        return exports.Kerberos;\n    }\n}\nexports.getKerberos = getKerberos;\nexports.ZStandard = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@mongodb-js/zstd` not found. Please install it to enable zstd compression'));\nfunction getZstdLibrary() {\n    try {\n        exports.ZStandard = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@mongodb-js/zstd'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n        return exports.ZStandard;\n    }\n    catch {\n        return exports.ZStandard;\n    }\n}\nexports.getZstdLibrary = getZstdLibrary;\nfunction getAwsCredentialProvider() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@aws-sdk/credential-providers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `@aws-sdk/credential-providers` not found.' +\n            ' Please install it to enable getting aws credentials via the official sdk.'));\n    }\n}\nexports.getAwsCredentialProvider = getAwsCredentialProvider;\nfunction getGcpMetadata() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const credentialProvider = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'gcp-metadata'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return credentialProvider;\n    }\n    catch {\n        return makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `gcp-metadata` not found.' +\n            ' Please install it to enable getting gcp credentials via the official sdk.'));\n    }\n}\nexports.getGcpMetadata = getGcpMetadata;\nfunction getSnappy() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'snappy'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return value;\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `snappy` not found. Please install it to enable snappy compression', { cause });\n        return { kModuleError };\n    }\n}\nexports.getSnappy = getSnappy;\nfunction getSocks() {\n    try {\n        // Ensure you always wrap an optional require in the try block NODE-3199\n        const value = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'socks'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n        return value;\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `socks` not found. Please install it to connections over a SOCKS5 proxy', { cause });\n        return { kModuleError };\n    }\n}\nexports.getSocks = getSocks;\nexports.aws4 = makeErrorModule(new error_1.MongoMissingDependencyError('Optional module `aws4` not found. Please install it to enable AWS authentication'));\ntry {\n    // Ensure you always wrap an optional require in the try block NODE-3199\n    exports.aws4 = __webpack_require__(/*! aws4 */ \"../../node_modules/aws4/aws4.js\");\n}\ncatch { } // eslint-disable-line\n/** A utility function to get the instance of mongodb-client-encryption, if it exists. */\nfunction getMongoDBClientEncryption() {\n    let mongodbClientEncryption = null;\n    try {\n        // NOTE(NODE-3199): Ensure you always wrap an optional require literally in the try block\n        // Cannot be moved to helper utility function, bundlers search and replace the actual require call\n        // in a way that makes this line throw at bundle time, not runtime, catching here will make bundling succeed\n        mongodbClientEncryption = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'mongodb-client-encryption'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    }\n    catch (cause) {\n        const kModuleError = new error_1.MongoMissingDependencyError('Optional module `mongodb-client-encryption` not found. Please install it to use auto encryption or ClientEncryption.', { cause });\n        return { kModuleError };\n    }\n    return mongodbClientEncryption;\n}\nexports.getMongoDBClientEncryption = getMongoDBClientEncryption;\n//# sourceMappingURL=deps.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/deps.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/encrypter.js":
/*!***********************************************!*\
  !*** ./node_modules/mongodb/lib/encrypter.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Encrypter = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst deps_1 = __webpack_require__(/*! ./deps */ \"./node_modules/mongodb/lib/deps.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\n/** @internal */\nconst kInternalClient = Symbol('internalClient');\n/** @internal */\nclass Encrypter {\n    constructor(client, uri, options) {\n        if (typeof options.autoEncryption !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Option \"autoEncryption\" must be specified');\n        }\n        // initialize to null, if we call getInternalClient, we may set this it is important to not overwrite those function calls.\n        this[kInternalClient] = null;\n        this.bypassAutoEncryption = !!options.autoEncryption.bypassAutoEncryption;\n        this.needsConnecting = false;\n        if (options.maxPoolSize === 0 && options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = client;\n        }\n        else if (options.autoEncryption.keyVaultClient == null) {\n            options.autoEncryption.keyVaultClient = this.getInternalClient(client, uri, options);\n        }\n        if (this.bypassAutoEncryption) {\n            options.autoEncryption.metadataClient = undefined;\n        }\n        else if (options.maxPoolSize === 0) {\n            options.autoEncryption.metadataClient = client;\n        }\n        else {\n            options.autoEncryption.metadataClient = this.getInternalClient(client, uri, options);\n        }\n        if (options.proxyHost) {\n            options.autoEncryption.proxyOptions = {\n                proxyHost: options.proxyHost,\n                proxyPort: options.proxyPort,\n                proxyUsername: options.proxyUsername,\n                proxyPassword: options.proxyPassword\n            };\n        }\n        this.autoEncrypter = new auto_encrypter_1.AutoEncrypter(client, options.autoEncryption);\n    }\n    getInternalClient(client, uri, options) {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        let internalClient = this[kInternalClient];\n        if (internalClient == null) {\n            const clonedOptions = {};\n            for (const key of [\n                ...Object.getOwnPropertyNames(options),\n                ...Object.getOwnPropertySymbols(options)\n            ]) {\n                if (['autoEncryption', 'minPoolSize', 'servers', 'caseTranslate', 'dbName'].includes(key))\n                    continue;\n                Reflect.set(clonedOptions, key, Reflect.get(options, key));\n            }\n            clonedOptions.minPoolSize = 0;\n            internalClient = new mongo_client_1.MongoClient(uri, clonedOptions);\n            this[kInternalClient] = internalClient;\n            for (const eventName of constants_1.MONGO_CLIENT_EVENTS) {\n                for (const listener of client.listeners(eventName)) {\n                    internalClient.on(eventName, listener);\n                }\n            }\n            client.on('newListener', (eventName, listener) => {\n                internalClient?.on(eventName, listener);\n            });\n            this.needsConnecting = true;\n        }\n        return internalClient;\n    }\n    async connectInternalClient() {\n        // TODO(NODE-4144): Remove new variable for type narrowing\n        const internalClient = this[kInternalClient];\n        if (this.needsConnecting && internalClient != null) {\n            this.needsConnecting = false;\n            await internalClient.connect();\n        }\n    }\n    closeCallback(client, force, callback) {\n        (0, util_1.callbackify)(this.close.bind(this))(client, force, callback);\n    }\n    async close(client, force) {\n        const maybeError = await this.autoEncrypter.teardown(!!force).catch(e => e);\n        const internalClient = this[kInternalClient];\n        if (internalClient != null && client !== internalClient) {\n            return internalClient.close(force);\n        }\n        if (maybeError) {\n            throw maybeError;\n        }\n    }\n    static checkForMongoCrypt() {\n        const mongodbClientEncryption = (0, deps_1.getMongoDBClientEncryption)();\n        if ('kModuleError' in mongodbClientEncryption) {\n            throw new error_1.MongoMissingDependencyError('Auto-encryption requested, but the module is not installed. ' +\n                'Please add `mongodb-client-encryption` as a dependency of your project');\n        }\n    }\n}\nexports.Encrypter = Encrypter;\n//# sourceMappingURL=encrypter.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/encrypter.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/error.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/error.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isResumableError = exports.isNetworkTimeoutError = exports.isSDAMUnrecoverableError = exports.isNodeShuttingDownError = exports.isRetryableReadError = exports.isRetryableWriteError = exports.needsRetryableWriteLabel = exports.MongoWriteConcernError = exports.MongoServerSelectionError = exports.MongoSystemError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoCompatibilityError = exports.MongoInvalidArgumentError = exports.MongoParseError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.isNetworkErrorBeforeHandshake = exports.MongoTopologyClosedError = exports.MongoCursorExhaustedError = exports.MongoServerClosedError = exports.MongoCursorInUseError = exports.MongoUnexpectedServerResponseError = exports.MongoGridFSChunkError = exports.MongoGridFSStreamError = exports.MongoTailableCursorError = exports.MongoChangeStreamError = exports.MongoAzureError = exports.MongoAWSError = exports.MongoKerberosError = exports.MongoExpiredSessionError = exports.MongoTransactionError = exports.MongoNotConnectedError = exports.MongoDecompressionError = exports.MongoBatchReExecutionError = exports.MongoRuntimeError = exports.MongoAPIError = exports.MongoDriverError = exports.MongoServerError = exports.MongoError = exports.MongoErrorLabel = exports.GET_MORE_RESUMABLE_CODES = exports.MONGODB_ERROR_CODES = exports.NODE_IS_RECOVERING_ERROR_MESSAGE = exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = void 0;\n/** @internal */\nconst kErrorLabels = Symbol('errorLabels');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a writable primary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE = new RegExp('not master', 'i');\n/**\n * @internal\n * The legacy error message from the server that indicates the node is not a primary or secondary\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE = new RegExp('not master or secondary', 'i');\n/**\n * @internal\n * The error message from the server that indicates the node is recovering\n * https://github.com/mongodb/specifications/blob/b07c26dc40d04ac20349f989db531c9845fdd755/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-writable-primary-and-node-is-recovering\n */\nexports.NODE_IS_RECOVERING_ERROR_MESSAGE = new RegExp('node is recovering', 'i');\n/** @internal MongoDB Error Codes */\nexports.MONGODB_ERROR_CODES = Object.freeze({\n    HostUnreachable: 6,\n    HostNotFound: 7,\n    NetworkTimeout: 89,\n    ShutdownInProgress: 91,\n    PrimarySteppedDown: 189,\n    ExceededTimeLimit: 262,\n    SocketException: 9001,\n    NotWritablePrimary: 10107,\n    InterruptedAtShutdown: 11600,\n    InterruptedDueToReplStateChange: 11602,\n    NotPrimaryNoSecondaryOk: 13435,\n    NotPrimaryOrSecondary: 13436,\n    StaleShardVersion: 63,\n    StaleEpoch: 150,\n    StaleConfig: 13388,\n    RetryChangeStream: 234,\n    FailedToSatisfyReadPreference: 133,\n    CursorNotFound: 43,\n    LegacyNotPrimary: 10058,\n    WriteConcernFailed: 64,\n    NamespaceNotFound: 26,\n    IllegalOperation: 20,\n    MaxTimeMSExpired: 50,\n    UnknownReplWriteConcern: 79,\n    UnsatisfiableWriteConcern: 100,\n    Reauthenticate: 391\n});\n// From spec@https://github.com/mongodb/specifications/blob/f93d78191f3db2898a59013a7ed5650352ef6da8/source/change-streams/change-streams.rst#resumable-error\nexports.GET_MORE_RESUMABLE_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary,\n    exports.MONGODB_ERROR_CODES.StaleShardVersion,\n    exports.MONGODB_ERROR_CODES.StaleEpoch,\n    exports.MONGODB_ERROR_CODES.StaleConfig,\n    exports.MONGODB_ERROR_CODES.RetryChangeStream,\n    exports.MONGODB_ERROR_CODES.FailedToSatisfyReadPreference,\n    exports.MONGODB_ERROR_CODES.CursorNotFound\n]);\n/** @public */\nexports.MongoErrorLabel = Object.freeze({\n    RetryableWriteError: 'RetryableWriteError',\n    TransientTransactionError: 'TransientTransactionError',\n    UnknownTransactionCommitResult: 'UnknownTransactionCommitResult',\n    ResumableChangeStreamError: 'ResumableChangeStreamError',\n    HandshakeError: 'HandshakeError',\n    ResetPool: 'ResetPool',\n    PoolRequstedRetry: 'PoolRequstedRetry',\n    InterruptInUseConnections: 'InterruptInUseConnections',\n    NoWritesPerformed: 'NoWritesPerformed'\n});\nfunction isAggregateError(e) {\n    return 'errors' in e && Array.isArray(e.errors);\n}\n/**\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error, it uses the constructor with a string argument\n */\nclass MongoError extends Error {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n        this[kErrorLabels] = new Set();\n    }\n    /** @internal */\n    static buildErrorMessage(e) {\n        if (typeof e === 'string') {\n            return e;\n        }\n        if (isAggregateError(e) && e.message.length === 0) {\n            return e.errors.length === 0\n                ? 'AggregateError has an empty errors array. Please check the `cause` property for more information.'\n                : e.errors.map(({ message }) => message).join(', ');\n        }\n        return e.message;\n    }\n    get name() {\n        return 'MongoError';\n    }\n    /** Legacy name for server error responses */\n    get errmsg() {\n        return this.message;\n    }\n    /**\n     * Checks the error to see if it has an error label\n     *\n     * @param label - The error label to check for\n     * @returns returns true if the error has the provided error label\n     */\n    hasErrorLabel(label) {\n        return this[kErrorLabels].has(label);\n    }\n    addErrorLabel(label) {\n        this[kErrorLabels].add(label);\n    }\n    get errorLabels() {\n        return Array.from(this[kErrorLabels]);\n    }\n}\nexports.MongoError = MongoError;\n/**\n * An error coming from the mongo server\n *\n * @public\n * @category Error\n */\nclass MongoServerError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message.message || message.errmsg || message.$err || 'n/a');\n        if (message.errorLabels) {\n            this[kErrorLabels] = new Set(message.errorLabels);\n        }\n        for (const name in message) {\n            if (name !== 'errorLabels' && name !== 'errmsg' && name !== 'message')\n                this[name] = message[name];\n        }\n    }\n    get name() {\n        return 'MongoServerError';\n    }\n}\nexports.MongoServerError = MongoServerError;\n/**\n * An error generated by the driver\n *\n * @public\n * @category Error\n */\nclass MongoDriverError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoDriverError';\n    }\n}\nexports.MongoDriverError = MongoDriverError;\n/**\n * An error generated when the driver API is used incorrectly\n *\n * @privateRemarks\n * Should **never** be directly instantiated\n *\n * @public\n * @category Error\n */\nclass MongoAPIError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoAPIError';\n    }\n}\nexports.MongoAPIError = MongoAPIError;\n/**\n * An error generated when the driver encounters unexpected input\n * or reaches an unexpected/invalid internal state\n *\n * @privateRemarks\n * Should **never** be directly instantiated.\n *\n * @public\n * @category Error\n */\nclass MongoRuntimeError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoRuntimeError';\n    }\n}\nexports.MongoRuntimeError = MongoRuntimeError;\n/**\n * An error generated when a batch command is re-executed after one of the commands in the batch\n * has failed\n *\n * @public\n * @category Error\n */\nclass MongoBatchReExecutionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'This batch has already been executed, create new batch to execute') {\n        super(message);\n    }\n    get name() {\n        return 'MongoBatchReExecutionError';\n    }\n}\nexports.MongoBatchReExecutionError = MongoBatchReExecutionError;\n/**\n * An error generated when the driver fails to decompress\n * data received from the server.\n *\n * @public\n * @category Error\n */\nclass MongoDecompressionError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoDecompressionError';\n    }\n}\nexports.MongoDecompressionError = MongoDecompressionError;\n/**\n * An error thrown when the user attempts to operate on a database or collection through a MongoClient\n * that has not yet successfully called the \"connect\" method\n *\n * @public\n * @category Error\n */\nclass MongoNotConnectedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoNotConnectedError';\n    }\n}\nexports.MongoNotConnectedError = MongoNotConnectedError;\n/**\n * An error generated when the user makes a mistake in the usage of transactions.\n * (e.g. attempting to commit a transaction with a readPreference other than primary)\n *\n * @public\n * @category Error\n */\nclass MongoTransactionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoTransactionError';\n    }\n}\nexports.MongoTransactionError = MongoTransactionError;\n/**\n * An error generated when the user attempts to operate\n * on a session that has expired or has been closed.\n *\n * @public\n * @category Error\n */\nclass MongoExpiredSessionError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cannot use a session that has ended') {\n        super(message);\n    }\n    get name() {\n        return 'MongoExpiredSessionError';\n    }\n}\nexports.MongoExpiredSessionError = MongoExpiredSessionError;\n/**\n * A error generated when the user attempts to authenticate\n * via Kerberos, but fails to connect to the Kerberos client.\n *\n * @public\n * @category Error\n */\nclass MongoKerberosError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoKerberosError';\n    }\n}\nexports.MongoKerberosError = MongoKerberosError;\n/**\n * A error generated when the user attempts to authenticate\n * via AWS, but fails\n *\n * @public\n * @category Error\n */\nclass MongoAWSError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoAWSError';\n    }\n}\nexports.MongoAWSError = MongoAWSError;\n/**\n * A error generated when the user attempts to authenticate\n * via Azure, but fails.\n *\n * @public\n * @category Error\n */\nclass MongoAzureError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoAzureError';\n    }\n}\nexports.MongoAzureError = MongoAzureError;\n/**\n * An error generated when a ChangeStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoChangeStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoChangeStreamError';\n    }\n}\nexports.MongoChangeStreamError = MongoChangeStreamError;\n/**\n * An error thrown when the user calls a function or method not supported on a tailable cursor\n *\n * @public\n * @category Error\n */\nclass MongoTailableCursorError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Tailable cursor does not support this operation') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTailableCursorError';\n    }\n}\nexports.MongoTailableCursorError = MongoTailableCursorError;\n/** An error generated when a GridFSStream operation fails to execute.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSStreamError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSStreamError';\n    }\n}\nexports.MongoGridFSStreamError = MongoGridFSStreamError;\n/**\n * An error generated when a malformed or invalid chunk is\n * encountered when reading from a GridFSStream.\n *\n * @public\n * @category Error\n */\nclass MongoGridFSChunkError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoGridFSChunkError';\n    }\n}\nexports.MongoGridFSChunkError = MongoGridFSChunkError;\n/**\n * An error generated when a **parsable** unexpected response comes from the server.\n * This is generally an error where the driver in a state expecting a certain behavior to occur in\n * the next message from MongoDB but it receives something else.\n * This error **does not** represent an issue with wire message formatting.\n *\n * #### Example\n * When an operation fails, it is the driver's job to retry it. It must perform serverSelection\n * again to make sure that it attempts the operation against a server in a good state. If server\n * selection returns a server that does not support retryable operations, this error is used.\n * This scenario is unlikely as retryable support would also have been determined on the first attempt\n * but it is possible the state change could report a selectable server that does not support retries.\n *\n * @public\n * @category Error\n */\nclass MongoUnexpectedServerResponseError extends MongoRuntimeError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoUnexpectedServerResponseError';\n    }\n}\nexports.MongoUnexpectedServerResponseError = MongoUnexpectedServerResponseError;\n/**\n * An error thrown when the user attempts to add options to a cursor that has already been\n * initialized\n *\n * @public\n * @category Error\n */\nclass MongoCursorInUseError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Cursor is already initialized') {\n        super(message);\n    }\n    get name() {\n        return 'MongoCursorInUseError';\n    }\n}\nexports.MongoCursorInUseError = MongoCursorInUseError;\n/**\n * An error generated when an attempt is made to operate\n * on a closed/closing server.\n *\n * @public\n * @category Error\n */\nclass MongoServerClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Server is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoServerClosedError';\n    }\n}\nexports.MongoServerClosedError = MongoServerClosedError;\n/**\n * An error thrown when an attempt is made to read from a cursor that has been exhausted\n *\n * @public\n * @category Error\n */\nclass MongoCursorExhaustedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message || 'Cursor is exhausted');\n    }\n    get name() {\n        return 'MongoCursorExhaustedError';\n    }\n}\nexports.MongoCursorExhaustedError = MongoCursorExhaustedError;\n/**\n * An error generated when an attempt is made to operate on a\n * dropped, or otherwise unavailable, database.\n *\n * @public\n * @category Error\n */\nclass MongoTopologyClosedError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message = 'Topology is closed') {\n        super(message);\n    }\n    get name() {\n        return 'MongoTopologyClosedError';\n    }\n}\nexports.MongoTopologyClosedError = MongoTopologyClosedError;\n/** @internal */\nconst kBeforeHandshake = Symbol('beforeHandshake');\nfunction isNetworkErrorBeforeHandshake(err) {\n    return err[kBeforeHandshake] === true;\n}\nexports.isNetworkErrorBeforeHandshake = isNetworkErrorBeforeHandshake;\n/**\n * An error indicating an issue with the network, including TCP errors and timeouts.\n * @public\n * @category Error\n */\nclass MongoNetworkError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, { cause: options?.cause });\n        if (options && typeof options.beforeHandshake === 'boolean') {\n            this[kBeforeHandshake] = options.beforeHandshake;\n        }\n    }\n    get name() {\n        return 'MongoNetworkError';\n    }\n}\nexports.MongoNetworkError = MongoNetworkError;\n/**\n * An error indicating a network timeout occurred\n * @public\n * @category Error\n *\n * @privateRemarks\n * mongodb-client-encryption has a dependency on this error with an instanceof check\n */\nclass MongoNetworkTimeoutError extends MongoNetworkError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoNetworkTimeoutError';\n    }\n}\nexports.MongoNetworkTimeoutError = MongoNetworkTimeoutError;\n/**\n * An error used when attempting to parse a value (like a connection string)\n * @public\n * @category Error\n */\nclass MongoParseError extends MongoDriverError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoParseError';\n    }\n}\nexports.MongoParseError = MongoParseError;\n/**\n * An error generated when the user supplies malformed or unexpected arguments\n * or when a required argument or field is not provided.\n *\n *\n * @public\n * @category Error\n */\nclass MongoInvalidArgumentError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoInvalidArgumentError';\n    }\n}\nexports.MongoInvalidArgumentError = MongoInvalidArgumentError;\n/**\n * An error generated when a feature that is not enabled or allowed for the current server\n * configuration is used\n *\n *\n * @public\n * @category Error\n */\nclass MongoCompatibilityError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoCompatibilityError';\n    }\n}\nexports.MongoCompatibilityError = MongoCompatibilityError;\n/**\n * An error generated when the user fails to provide authentication credentials before attempting\n * to connect to a mongo server instance.\n *\n *\n * @public\n * @category Error\n */\nclass MongoMissingCredentialsError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message) {\n        super(message);\n    }\n    get name() {\n        return 'MongoMissingCredentialsError';\n    }\n}\nexports.MongoMissingCredentialsError = MongoMissingCredentialsError;\n/**\n * An error generated when a required module or dependency is not present in the local environment\n *\n * @public\n * @category Error\n */\nclass MongoMissingDependencyError extends MongoAPIError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, options = {}) {\n        super(message, options);\n    }\n    get name() {\n        return 'MongoMissingDependencyError';\n    }\n}\nexports.MongoMissingDependencyError = MongoMissingDependencyError;\n/**\n * An error signifying a general system issue\n * @public\n * @category Error\n */\nclass MongoSystemError extends MongoError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        if (reason && reason.error) {\n            super(MongoError.buildErrorMessage(reason.error.message || reason.error), {\n                cause: reason.error\n            });\n        }\n        else {\n            super(message);\n        }\n        if (reason) {\n            this.reason = reason;\n        }\n        this.code = reason.error?.code;\n    }\n    get name() {\n        return 'MongoSystemError';\n    }\n}\nexports.MongoSystemError = MongoSystemError;\n/**\n * An error signifying a client-side server selection error\n * @public\n * @category Error\n */\nclass MongoServerSelectionError extends MongoSystemError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, reason) {\n        super(message, reason);\n    }\n    get name() {\n        return 'MongoServerSelectionError';\n    }\n}\nexports.MongoServerSelectionError = MongoServerSelectionError;\nfunction makeWriteConcernResultObject(input) {\n    const output = Object.assign({}, input);\n    if (output.ok === 0) {\n        output.ok = 1;\n        delete output.errmsg;\n        delete output.code;\n        delete output.codeName;\n    }\n    return output;\n}\n/**\n * An error thrown when the server reports a writeConcernError\n * @public\n * @category Error\n */\nclass MongoWriteConcernError extends MongoServerError {\n    /**\n     * **Do not use this constructor!**\n     *\n     * Meant for internal use only.\n     *\n     * @remarks\n     * This class is only meant to be constructed within the driver. This constructor is\n     * not subject to semantic versioning compatibility guarantees and may change at any time.\n     *\n     * @public\n     **/\n    constructor(message, result) {\n        if (result && Array.isArray(result.errorLabels)) {\n            message.errorLabels = result.errorLabels;\n        }\n        super(message);\n        this.errInfo = message.errInfo;\n        if (result != null) {\n            this.result = makeWriteConcernResultObject(result);\n        }\n    }\n    get name() {\n        return 'MongoWriteConcernError';\n    }\n}\nexports.MongoWriteConcernError = MongoWriteConcernError;\n// https://github.com/mongodb/specifications/blob/master/source/retryable-reads/retryable-reads.rst#retryable-error\nconst RETRYABLE_READ_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.HostUnreachable,\n    exports.MONGODB_ERROR_CODES.HostNotFound,\n    exports.MONGODB_ERROR_CODES.NetworkTimeout,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.SocketException,\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\n// see: https://github.com/mongodb/specifications/blob/master/source/retryable-writes/retryable-writes.rst#terms\nconst RETRYABLE_WRITE_ERROR_CODES = new Set([\n    ...RETRYABLE_READ_ERROR_CODES,\n    exports.MONGODB_ERROR_CODES.ExceededTimeLimit\n]);\nfunction needsRetryableWriteLabel(error, maxWireVersion) {\n    // pre-4.4 server, then the driver adds an error label for every valid case\n    // execute operation will only inspect the label, code/message logic is handled here\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (error instanceof MongoError) {\n        if ((maxWireVersion >= 9 || isRetryableWriteError(error)) &&\n            !error.hasErrorLabel(exports.MongoErrorLabel.HandshakeError)) {\n            // If we already have the error label no need to add it again. 4.4+ servers add the label.\n            // In the case where we have a handshake error, need to fall down to the logic checking\n            // the codes.\n            return false;\n        }\n    }\n    if (error instanceof MongoWriteConcernError) {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.result?.code ?? error.code ?? 0);\n    }\n    if (error instanceof MongoError && typeof error.code === 'number') {\n        return RETRYABLE_WRITE_ERROR_CODES.has(error.code);\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.needsRetryableWriteLabel = needsRetryableWriteLabel;\nfunction isRetryableWriteError(error) {\n    return (error.hasErrorLabel(exports.MongoErrorLabel.RetryableWriteError) ||\n        error.hasErrorLabel(exports.MongoErrorLabel.PoolRequstedRetry));\n}\nexports.isRetryableWriteError = isRetryableWriteError;\n/** Determines whether an error is something the driver should attempt to retry */\nfunction isRetryableReadError(error) {\n    const hasRetryableErrorCode = typeof error.code === 'number' ? RETRYABLE_READ_ERROR_CODES.has(error.code) : false;\n    if (hasRetryableErrorCode) {\n        return true;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    const isNotWritablePrimaryError = exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(error.message);\n    if (isNotWritablePrimaryError) {\n        return true;\n    }\n    const isNodeIsRecoveringError = exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(error.message);\n    if (isNodeIsRecoveringError) {\n        return true;\n    }\n    return false;\n}\nexports.isRetryableReadError = isRetryableReadError;\nconst SDAM_RECOVERING_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress,\n    exports.MONGODB_ERROR_CODES.PrimarySteppedDown,\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.InterruptedDueToReplStateChange,\n    exports.MONGODB_ERROR_CODES.NotPrimaryOrSecondary\n]);\nconst SDAM_NOT_PRIMARY_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.NotWritablePrimary,\n    exports.MONGODB_ERROR_CODES.NotPrimaryNoSecondaryOk,\n    exports.MONGODB_ERROR_CODES.LegacyNotPrimary\n]);\nconst SDAM_NODE_SHUTTING_DOWN_ERROR_CODES = new Set([\n    exports.MONGODB_ERROR_CODES.InterruptedAtShutdown,\n    exports.MONGODB_ERROR_CODES.ShutdownInProgress\n]);\nfunction isRecoveringError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_RECOVERING_CODES.has(err.code);\n    }\n    return (exports.LEGACY_NOT_PRIMARY_OR_SECONDARY_ERROR_MESSAGE.test(err.message) ||\n        exports.NODE_IS_RECOVERING_ERROR_MESSAGE.test(err.message));\n}\nfunction isNotWritablePrimaryError(err) {\n    if (typeof err.code === 'number') {\n        // If any error code exists, we ignore the error.message\n        return SDAM_NOT_PRIMARY_CODES.has(err.code);\n    }\n    if (isRecoveringError(err)) {\n        return false;\n    }\n    return exports.LEGACY_NOT_WRITABLE_PRIMARY_ERROR_MESSAGE.test(err.message);\n}\nfunction isNodeShuttingDownError(err) {\n    return !!(typeof err.code === 'number' && SDAM_NODE_SHUTTING_DOWN_ERROR_CODES.has(err.code));\n}\nexports.isNodeShuttingDownError = isNodeShuttingDownError;\n/**\n * Determines whether SDAM can recover from a given error. If it cannot\n * then the pool will be cleared, and server state will completely reset\n * locally.\n *\n * @see https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-master-and-node-is-recovering\n */\nfunction isSDAMUnrecoverableError(error) {\n    // NOTE: null check is here for a strictly pre-CMAP world, a timeout or\n    //       close event are considered unrecoverable\n    if (error instanceof MongoParseError || error == null) {\n        return true;\n    }\n    return isRecoveringError(error) || isNotWritablePrimaryError(error);\n}\nexports.isSDAMUnrecoverableError = isSDAMUnrecoverableError;\nfunction isNetworkTimeoutError(err) {\n    return !!(err instanceof MongoNetworkError && err.message.match(/timed out/));\n}\nexports.isNetworkTimeoutError = isNetworkTimeoutError;\nfunction isResumableError(error, wireVersion) {\n    if (error == null || !(error instanceof MongoError)) {\n        return false;\n    }\n    if (error instanceof MongoNetworkError) {\n        return true;\n    }\n    if (wireVersion != null && wireVersion >= 9) {\n        // DRIVERS-1308: For 4.4 drivers running against 4.4 servers, drivers will add a special case to treat the CursorNotFound error code as resumable\n        if (error.code === exports.MONGODB_ERROR_CODES.CursorNotFound) {\n            return true;\n        }\n        return error.hasErrorLabel(exports.MongoErrorLabel.ResumableChangeStreamError);\n    }\n    if (typeof error.code === 'number') {\n        return exports.GET_MORE_RESUMABLE_CODES.has(error.code);\n    }\n    return false;\n}\nexports.isResumableError = isResumableError;\n//# sourceMappingURL=error.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/error.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/explain.js":
/*!*********************************************!*\
  !*** ./node_modules/mongodb/lib/explain.js ***!
  \*********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Explain = exports.ExplainVerbosity = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ExplainVerbosity = Object.freeze({\n    queryPlanner: 'queryPlanner',\n    queryPlannerExtended: 'queryPlannerExtended',\n    executionStats: 'executionStats',\n    allPlansExecution: 'allPlansExecution'\n});\n/** @internal */\nclass Explain {\n    constructor(verbosity) {\n        if (typeof verbosity === 'boolean') {\n            this.verbosity = verbosity\n                ? exports.ExplainVerbosity.allPlansExecution\n                : exports.ExplainVerbosity.queryPlanner;\n        }\n        else {\n            this.verbosity = verbosity;\n        }\n    }\n    static fromOptions(options) {\n        if (options?.explain == null)\n            return;\n        const explain = options.explain;\n        if (typeof explain === 'boolean' || typeof explain === 'string') {\n            return new Explain(explain);\n        }\n        throw new error_1.MongoInvalidArgumentError('Field \"explain\" must be a string or a boolean');\n    }\n}\nexports.Explain = Explain;\n//# sourceMappingURL=explain.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/explain.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/download.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/download.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketReadStream = void 0;\nconst stream_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\n/**\n * A readable stream that enables you to read buffers from GridFS.\n *\n * Do not instantiate this class directly. Use `openDownloadStream()` instead.\n * @public\n */\nclass GridFSBucketReadStream extends stream_1.Readable {\n    /**\n     * @param chunks - Handle for chunks collection\n     * @param files - Handle for files collection\n     * @param readPreference - The read preference to use\n     * @param filter - The filter to use to find the file document\n     * @internal\n     */\n    constructor(chunks, files, readPreference, filter, options) {\n        super({ emitClose: true });\n        this.s = {\n            bytesToTrim: 0,\n            bytesToSkip: 0,\n            bytesRead: 0,\n            chunks,\n            expected: 0,\n            files,\n            filter,\n            init: false,\n            expectedEnd: 0,\n            options: {\n                start: 0,\n                end: 0,\n                ...options\n            },\n            readPreference\n        };\n    }\n    /**\n     * Reads from the cursor and pushes to the stream.\n     * Private Impl, do not call directly\n     * @internal\n     */\n    _read() {\n        if (this.destroyed)\n            return;\n        waitForFile(this, () => doRead(this));\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param start - 0-based offset in bytes to start streaming from\n     */\n    start(start = 0) {\n        throwIfInitialized(this);\n        this.s.options.start = start;\n        return this;\n    }\n    /**\n     * Sets the 0-based offset in bytes to start streaming from. Throws\n     * an error if this stream has entered flowing mode\n     * (e.g. if you've already called `on('data')`)\n     *\n     * @param end - Offset in bytes to stop reading at\n     */\n    end(end = 0) {\n        throwIfInitialized(this);\n        this.s.options.end = end;\n        return this;\n    }\n    /**\n     * Marks this stream as aborted (will never push another `data` event)\n     * and kills the underlying cursor. Will emit the 'end' event, and then\n     * the 'close' event once the cursor is successfully killed.\n     */\n    async abort() {\n        this.push(null);\n        this.destroy();\n        await this.s.cursor?.close();\n    }\n}\n/**\n * Fires when the stream loaded the file document corresponding to the provided id.\n * @event\n */\nGridFSBucketReadStream.FILE = 'file';\nexports.GridFSBucketReadStream = GridFSBucketReadStream;\nfunction throwIfInitialized(stream) {\n    if (stream.s.init) {\n        throw new error_1.MongoGridFSStreamError('Options cannot be changed after the stream is initialized');\n    }\n}\nfunction doRead(stream) {\n    if (stream.destroyed)\n        return;\n    if (!stream.s.cursor)\n        return;\n    if (!stream.s.file)\n        return;\n    const handleReadResult = ({ error, doc }) => {\n        if (stream.destroyed) {\n            return;\n        }\n        if (error) {\n            stream.destroy(error);\n            return;\n        }\n        if (!doc) {\n            stream.push(null);\n            stream.s.cursor?.close().then(() => null, error => stream.destroy(error));\n            return;\n        }\n        if (!stream.s.file)\n            return;\n        const bytesRemaining = stream.s.file.length - stream.s.bytesRead;\n        const expectedN = stream.s.expected++;\n        const expectedLength = Math.min(stream.s.file.chunkSize, bytesRemaining);\n        if (doc.n > expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsMissing: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        if (doc.n < expectedN) {\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected: ${expectedN}`));\n        }\n        let buf = Buffer.isBuffer(doc.data) ? doc.data : doc.data.buffer;\n        if (buf.byteLength !== expectedLength) {\n            if (bytesRemaining <= 0) {\n                return stream.destroy(new error_1.MongoGridFSChunkError(`ExtraChunk: Got unexpected n: ${doc.n}, expected file length ${stream.s.file.length} bytes but already read ${stream.s.bytesRead} bytes`));\n            }\n            return stream.destroy(new error_1.MongoGridFSChunkError(`ChunkIsWrongSize: Got unexpected length: ${buf.byteLength}, expected: ${expectedLength}`));\n        }\n        stream.s.bytesRead += buf.byteLength;\n        if (buf.byteLength === 0) {\n            return stream.push(null);\n        }\n        let sliceStart = null;\n        let sliceEnd = null;\n        if (stream.s.bytesToSkip != null) {\n            sliceStart = stream.s.bytesToSkip;\n            stream.s.bytesToSkip = 0;\n        }\n        const atEndOfStream = expectedN === stream.s.expectedEnd - 1;\n        const bytesLeftToRead = stream.s.options.end - stream.s.bytesToSkip;\n        if (atEndOfStream && stream.s.bytesToTrim != null) {\n            sliceEnd = stream.s.file.chunkSize - stream.s.bytesToTrim;\n        }\n        else if (stream.s.options.end && bytesLeftToRead < doc.data.byteLength) {\n            sliceEnd = bytesLeftToRead;\n        }\n        if (sliceStart != null || sliceEnd != null) {\n            buf = buf.slice(sliceStart || 0, sliceEnd || buf.byteLength);\n        }\n        stream.push(buf);\n        return;\n    };\n    stream.s.cursor.next().then(doc => handleReadResult({ error: null, doc }), error => handleReadResult({ error, doc: null }));\n}\nfunction init(stream) {\n    const findOneOptions = {};\n    if (stream.s.readPreference) {\n        findOneOptions.readPreference = stream.s.readPreference;\n    }\n    if (stream.s.options && stream.s.options.sort) {\n        findOneOptions.sort = stream.s.options.sort;\n    }\n    if (stream.s.options && stream.s.options.skip) {\n        findOneOptions.skip = stream.s.options.skip;\n    }\n    const handleReadResult = ({ error, doc }) => {\n        if (error) {\n            return stream.destroy(error);\n        }\n        if (!doc) {\n            const identifier = stream.s.filter._id\n                ? stream.s.filter._id.toString()\n                : stream.s.filter.filename;\n            const errmsg = `FileNotFound: file ${identifier} was not found`;\n            // TODO(NODE-3483)\n            const err = new error_1.MongoRuntimeError(errmsg);\n            err.code = 'ENOENT'; // TODO: NODE-3338 set property as part of constructor\n            return stream.destroy(err);\n        }\n        // If document is empty, kill the stream immediately and don't\n        // execute any reads\n        if (doc.length <= 0) {\n            stream.push(null);\n            return;\n        }\n        if (stream.destroyed) {\n            // If user destroys the stream before we have a cursor, wait\n            // until the query is done to say we're 'closed' because we can't\n            // cancel a query.\n            stream.destroy();\n            return;\n        }\n        try {\n            stream.s.bytesToSkip = handleStartOption(stream, doc, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        const filter = { files_id: doc._id };\n        // Currently (MongoDB 3.4.4) skip function does not support the index,\n        // it needs to retrieve all the documents first and then skip them. (CS-25811)\n        // As work around we use $gte on the \"n\" field.\n        if (stream.s.options && stream.s.options.start != null) {\n            const skip = Math.floor(stream.s.options.start / doc.chunkSize);\n            if (skip > 0) {\n                filter['n'] = { $gte: skip };\n            }\n        }\n        stream.s.cursor = stream.s.chunks.find(filter).sort({ n: 1 });\n        if (stream.s.readPreference) {\n            stream.s.cursor.withReadPreference(stream.s.readPreference);\n        }\n        stream.s.expectedEnd = Math.ceil(doc.length / doc.chunkSize);\n        stream.s.file = doc;\n        try {\n            stream.s.bytesToTrim = handleEndOption(stream, doc, stream.s.cursor, stream.s.options);\n        }\n        catch (error) {\n            return stream.destroy(error);\n        }\n        stream.emit(GridFSBucketReadStream.FILE, doc);\n        return;\n    };\n    stream.s.files.findOne(stream.s.filter, findOneOptions).then(doc => handleReadResult({ error: null, doc }), error => handleReadResult({ error, doc: null }));\n}\nfunction waitForFile(stream, callback) {\n    if (stream.s.file) {\n        return callback();\n    }\n    if (!stream.s.init) {\n        init(stream);\n        stream.s.init = true;\n    }\n    stream.once('file', () => {\n        callback();\n    });\n}\nfunction handleStartOption(stream, doc, options) {\n    if (options && options.start != null) {\n        if (options.start > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be negative`);\n        }\n        if (options.end != null && options.end < options.start) {\n            throw new error_1.MongoInvalidArgumentError(`Stream start (${options.start}) must not be greater than stream end (${options.end})`);\n        }\n        stream.s.bytesRead = Math.floor(options.start / doc.chunkSize) * doc.chunkSize;\n        stream.s.expected = Math.floor(options.start / doc.chunkSize);\n        return options.start - stream.s.bytesRead;\n    }\n    throw new error_1.MongoInvalidArgumentError('Start option must be defined');\n}\nfunction handleEndOption(stream, doc, cursor, options) {\n    if (options && options.end != null) {\n        if (options.end > doc.length) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be more than the length of the file (${doc.length})`);\n        }\n        if (options.start == null || options.start < 0) {\n            throw new error_1.MongoInvalidArgumentError(`Stream end (${options.end}) must not be negative`);\n        }\n        const start = options.start != null ? Math.floor(options.start / doc.chunkSize) : 0;\n        cursor.limit(Math.ceil(options.end / doc.chunkSize) - start);\n        stream.s.expectedEnd = Math.ceil(options.end / doc.chunkSize);\n        return Math.ceil(options.end / doc.chunkSize) * doc.chunkSize - options.end;\n    }\n    throw new error_1.MongoInvalidArgumentError('End option must be defined');\n}\n//# sourceMappingURL=download.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/gridfs/download.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/index.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucket = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst download_1 = __webpack_require__(/*! ./download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nconst upload_1 = __webpack_require__(/*! ./upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS = {\n    bucketName: 'fs',\n    chunkSizeBytes: 255 * 1024\n};\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nclass GridFSBucket extends mongo_types_1.TypedEventEmitter {\n    constructor(db, options) {\n        super();\n        this.setMaxListeners(0);\n        const privateOptions = {\n            ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n            ...options,\n            writeConcern: write_concern_1.WriteConcern.fromOptions(options)\n        };\n        this.s = {\n            db,\n            options: privateOptions,\n            _chunksCollection: db.collection(privateOptions.bucketName + '.chunks'),\n            _filesCollection: db.collection(privateOptions.bucketName + '.files'),\n            checkedIndexes: false,\n            calledOpenUploadStream: false\n        };\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS. The stream's 'id' property contains the resulting\n     * file's id.\n     *\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     */\n    openUploadStream(filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, options);\n    }\n    /**\n     * Returns a writable stream (GridFSBucketWriteStream) for writing\n     * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n     * file's id.\n     */\n    openUploadStreamWithId(id, filename, options) {\n        return new upload_1.GridFSBucketWriteStream(this, filename, { ...options, id });\n    }\n    /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n    openDownloadStream(id, options) {\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { _id: id }, options);\n    }\n    /**\n     * Deletes a file with the given id\n     *\n     * @param id - The id of the file doc\n     */\n    async delete(id) {\n        const { deletedCount } = await this.s._filesCollection.deleteOne({ _id: id });\n        // Delete orphaned chunks before returning FileNotFound\n        await this.s._chunksCollection.deleteMany({ files_id: id });\n        if (deletedCount === 0) {\n            // TODO(NODE-3483): Replace with more appropriate error\n            // Consider creating new error MongoGridFSFileNotFoundError\n            throw new error_1.MongoRuntimeError(`File not found for id ${id}`);\n        }\n    }\n    /** Convenience wrapper around find on the files collection */\n    find(filter = {}, options = {}) {\n        return this.s._filesCollection.find(filter, options);\n    }\n    /**\n     * Returns a readable stream (GridFSBucketReadStream) for streaming the\n     * file with the given name from GridFS. If there are multiple files with\n     * the same name, this will stream the most recent file with the given name\n     * (as determined by the `uploadDate` field). You can set the `revision`\n     * option to change this behavior.\n     */\n    openDownloadStreamByName(filename, options) {\n        let sort = { uploadDate: -1 };\n        let skip = undefined;\n        if (options && options.revision != null) {\n            if (options.revision >= 0) {\n                sort = { uploadDate: 1 };\n                skip = options.revision;\n            }\n            else {\n                skip = -options.revision - 1;\n            }\n        }\n        return new download_1.GridFSBucketReadStream(this.s._chunksCollection, this.s._filesCollection, this.s.options.readPreference, { filename }, { ...options, sort, skip });\n    }\n    /**\n     * Renames the file with the given _id to the given string\n     *\n     * @param id - the id of the file to rename\n     * @param filename - new name for the file\n     */\n    async rename(id, filename) {\n        const filter = { _id: id };\n        const update = { $set: { filename } };\n        const { matchedCount } = await this.s._filesCollection.updateOne(filter, update);\n        if (matchedCount === 0) {\n            throw new error_1.MongoRuntimeError(`File with id ${id} not found`);\n        }\n    }\n    /** Removes this bucket's files collection, followed by its chunks collection. */\n    async drop() {\n        await this.s._filesCollection.drop();\n        await this.s._chunksCollection.drop();\n    }\n}\n/**\n * When the first call to openUploadStream is made, the upload stream will\n * check to see if it needs to create the proper indexes on the chunks and\n * files collections. This event is fired either when 1) it determines that\n * no index creation is necessary, 2) when it successfully creates the\n * necessary indexes.\n * @event\n */\nGridFSBucket.INDEX = 'index';\nexports.GridFSBucket = GridFSBucket;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/gridfs/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/gridfs/upload.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/gridfs/upload.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst write_concern_1 = __webpack_require__(/*! ./../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n    /**\n     * @param bucket - Handle for this stream's corresponding bucket\n     * @param filename - The value of the 'filename' key in the files doc\n     * @param options - Optional settings.\n     * @internal\n     */\n    constructor(bucket, filename, options) {\n        super();\n        /**\n         * The document containing information about the inserted file.\n         * This property is defined _after_ the finish event has been emitted.\n         * It will remain `null` if an error occurs.\n         *\n         * @example\n         * ```ts\n         * fs.createReadStream('file.txt')\n         *   .pipe(bucket.openUploadStream('file.txt'))\n         *   .on('finish', function () {\n         *     console.log(this.gridFSFile)\n         *   })\n         * ```\n         */\n        this.gridFSFile = null;\n        options = options ?? {};\n        this.bucket = bucket;\n        this.chunks = bucket.s._chunksCollection;\n        this.filename = filename;\n        this.files = bucket.s._filesCollection;\n        this.options = options;\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n        // Signals the write is all done\n        this.done = false;\n        this.id = options.id ? options.id : new bson_1.ObjectId();\n        // properly inherit the default chunksize from parent\n        this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n        this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n        this.length = 0;\n        this.n = 0;\n        this.pos = 0;\n        this.state = {\n            streamEnd: false,\n            outstandingRequests: 0,\n            errored: false,\n            aborted: false\n        };\n        if (!this.bucket.s.calledOpenUploadStream) {\n            this.bucket.s.calledOpenUploadStream = true;\n            checkIndexes(this).then(() => {\n                this.bucket.s.checkedIndexes = true;\n                this.bucket.emit('index');\n            }, () => null);\n        }\n    }\n    /**\n     * @internal\n     *\n     * The stream is considered constructed when the indexes are done being created\n     */\n    _construct(callback) {\n        if (this.bucket.s.checkedIndexes) {\n            return process.nextTick(callback);\n        }\n        this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n    _write(chunk, encoding, callback) {\n        doWrite(this, chunk, encoding, callback);\n    }\n    /** @internal */\n    _final(callback) {\n        if (this.state.streamEnd) {\n            return process.nextTick(callback);\n        }\n        this.state.streamEnd = true;\n        writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n    async abort() {\n        if (this.state.streamEnd) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n        }\n        if (this.state.aborted) {\n            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n        }\n        this.state.aborted = true;\n        await this.chunks.deleteMany({ files_id: this.id });\n    }\n}\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n    if (stream.state.errored) {\n        process.nextTick(callback);\n        return;\n    }\n    stream.state.errored = true;\n    process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n    return {\n        _id: new bson_1.ObjectId(),\n        files_id: filesId,\n        n,\n        data\n    };\n}\nasync function checkChunksIndex(stream) {\n    const index = { files_id: 1, n: 1 };\n    let indexes;\n    try {\n        indexes = await stream.chunks.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasChunksIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasChunksIndex) {\n        await stream.chunks.createIndex(index, {\n            ...stream.writeConcern,\n            background: true,\n            unique: true\n        });\n    }\n}\nfunction checkDone(stream, callback) {\n    if (stream.done) {\n        return process.nextTick(callback);\n    }\n    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n        // Set done so we do not trigger duplicate createFilesDoc\n        stream.done = true;\n        // Create a new files doc\n        const gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n        if (isAborted(stream, callback)) {\n            return;\n        }\n        stream.files.insertOne(gridFSFile, { writeConcern: stream.writeConcern }).then(() => {\n            stream.gridFSFile = gridFSFile;\n            callback();\n        }, error => handleError(stream, error, callback));\n        return;\n    }\n    process.nextTick(callback);\n}\nasync function checkIndexes(stream) {\n    const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n    if (doc != null) {\n        // If at least one document exists assume the collection has the required index\n        return;\n    }\n    const index = { filename: 1, uploadDate: 1 };\n    let indexes;\n    try {\n        indexes = await stream.files.listIndexes().toArray();\n    }\n    catch (error) {\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n            indexes = [];\n        }\n        else {\n            throw error;\n        }\n    }\n    const hasFileIndex = !!indexes.find(index => {\n        const keys = Object.keys(index.key);\n        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            return true;\n        }\n        return false;\n    });\n    if (!hasFileIndex) {\n        await stream.files.createIndex(index, { background: false });\n    }\n    await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n    const ret = {\n        _id,\n        length,\n        chunkSize,\n        uploadDate: new Date(),\n        filename\n    };\n    if (contentType) {\n        ret.contentType = contentType;\n    }\n    if (aliases) {\n        ret.aliases = aliases;\n    }\n    if (metadata) {\n        ret.metadata = metadata;\n    }\n    return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n    stream.length += inputBuf.length;\n    // Input is small enough to fit in our buffer\n    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n        inputBuf.copy(stream.bufToStore, stream.pos);\n        stream.pos += inputBuf.length;\n        process.nextTick(callback);\n        return;\n    }\n    // Otherwise, buffer is too big for current chunk, so we need to flush\n    // to MongoDB.\n    let inputBufRemaining = inputBuf.length;\n    let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n    let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n    let outstandingRequests = 0;\n    while (inputBufRemaining > 0) {\n        const inputBufPos = inputBuf.length - inputBufRemaining;\n        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n        stream.pos += numToCopy;\n        spaceRemaining -= numToCopy;\n        let doc;\n        if (spaceRemaining === 0) {\n            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n            ++stream.state.outstandingRequests;\n            ++outstandingRequests;\n            if (isAborted(stream, callback)) {\n                return;\n            }\n            stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n                --stream.state.outstandingRequests;\n                --outstandingRequests;\n                if (!outstandingRequests) {\n                    checkDone(stream, callback);\n                }\n            }, error => handleError(stream, error, callback));\n            spaceRemaining = stream.chunkSizeBytes;\n            stream.pos = 0;\n            ++stream.n;\n        }\n        inputBufRemaining -= numToCopy;\n        numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n    }\n}\nfunction writeRemnant(stream, callback) {\n    // Buffer is empty, so don't bother to insert\n    if (stream.pos === 0) {\n        return checkDone(stream, callback);\n    }\n    ++stream.state.outstandingRequests;\n    // Create a new buffer to make sure the buffer isn't bigger than it needs\n    // to be.\n    const remnant = Buffer.alloc(stream.pos);\n    stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n    const doc = createChunkDoc(stream.id, stream.n, remnant);\n    // If the stream was aborted, do not write remnant\n    if (isAborted(stream, callback)) {\n        return;\n    }\n    stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(() => {\n        --stream.state.outstandingRequests;\n        checkDone(stream, callback);\n    }, error => handleError(stream, error, callback));\n}\nfunction isAborted(stream, callback) {\n    if (stream.state.aborted) {\n        process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n        return true;\n    }\n    return false;\n}\n//# sourceMappingURL=upload.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/gridfs/upload.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/index.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoUnexpectedServerResponseError = exports.MongoTransactionError = exports.MongoTopologyClosedError = exports.MongoTailableCursorError = exports.MongoSystemError = exports.MongoServerSelectionError = exports.MongoServerError = exports.MongoServerClosedError = exports.MongoRuntimeError = exports.MongoParseError = exports.MongoNotConnectedError = exports.MongoNetworkTimeoutError = exports.MongoNetworkError = exports.MongoMissingDependencyError = exports.MongoMissingCredentialsError = exports.MongoKerberosError = exports.MongoInvalidArgumentError = exports.MongoGridFSStreamError = exports.MongoGridFSChunkError = exports.MongoExpiredSessionError = exports.MongoError = exports.MongoDriverError = exports.MongoDecompressionError = exports.MongoCursorInUseError = exports.MongoCursorExhaustedError = exports.MongoCompatibilityError = exports.MongoChangeStreamError = exports.MongoBatchReExecutionError = exports.MongoAzureError = exports.MongoAWSError = exports.MongoAPIError = exports.ChangeStreamCursor = exports.ClientEncryption = exports.MongoBulkWriteError = exports.UUID = exports.Timestamp = exports.ObjectId = exports.MinKey = exports.MaxKey = exports.Long = exports.Int32 = exports.Double = exports.Decimal128 = exports.DBRef = exports.Code = exports.BSONType = exports.BSONSymbol = exports.BSONRegExp = exports.Binary = exports.BSON = void 0;\nexports.ConnectionPoolReadyEvent = exports.ConnectionPoolMonitoringEvent = exports.ConnectionPoolCreatedEvent = exports.ConnectionPoolClosedEvent = exports.ConnectionPoolClearedEvent = exports.ConnectionCreatedEvent = exports.ConnectionClosedEvent = exports.ConnectionCheckOutStartedEvent = exports.ConnectionCheckOutFailedEvent = exports.ConnectionCheckedOutEvent = exports.ConnectionCheckedInEvent = exports.CommandSucceededEvent = exports.CommandStartedEvent = exports.CommandFailedEvent = exports.WriteConcern = exports.ReadPreference = exports.ReadConcern = exports.TopologyType = exports.ServerType = exports.ReadPreferenceMode = exports.ReadConcernLevel = exports.ProfilingLevel = exports.ReturnDocument = exports.ServerApiVersion = exports.ExplainVerbosity = exports.MongoErrorLabel = exports.CURSOR_FLAGS = exports.Compressor = exports.AuthMechanism = exports.GSSAPICanonicalizationValue = exports.AutoEncryptionLoggerLevel = exports.BatchType = exports.UnorderedBulkOperation = exports.OrderedBulkOperation = exports.MongoClient = exports.ListIndexesCursor = exports.ListCollectionsCursor = exports.GridFSBucketWriteStream = exports.GridFSBucketReadStream = exports.GridFSBucket = exports.FindCursor = exports.Db = exports.Collection = exports.ClientSession = exports.ChangeStream = exports.CancellationToken = exports.AggregationCursor = exports.Admin = exports.AbstractCursor = exports.MongoWriteConcernError = void 0;\nexports.MongoCryptKMSRequestNetworkTimeoutError = exports.MongoCryptInvalidArgumentError = exports.MongoCryptError = exports.MongoCryptCreateEncryptedCollectionError = exports.MongoCryptCreateDataKeyError = exports.MongoCryptAzureKMSRequestError = exports.SrvPollingEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.TopologyClosedEvent = exports.ServerOpeningEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.ServerHeartbeatFailedEvent = exports.ServerDescriptionChangedEvent = exports.ServerClosedEvent = exports.ConnectionReadyEvent = void 0;\nconst admin_1 = __webpack_require__(/*! ./admin */ \"./node_modules/mongodb/lib/admin.js\");\nObject.defineProperty(exports, \"Admin\", ({ enumerable: true, get: function () { return admin_1.Admin; } }));\nconst ordered_1 = __webpack_require__(/*! ./bulk/ordered */ \"./node_modules/mongodb/lib/bulk/ordered.js\");\nObject.defineProperty(exports, \"OrderedBulkOperation\", ({ enumerable: true, get: function () { return ordered_1.OrderedBulkOperation; } }));\nconst unordered_1 = __webpack_require__(/*! ./bulk/unordered */ \"./node_modules/mongodb/lib/bulk/unordered.js\");\nObject.defineProperty(exports, \"UnorderedBulkOperation\", ({ enumerable: true, get: function () { return unordered_1.UnorderedBulkOperation; } }));\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nObject.defineProperty(exports, \"ChangeStream\", ({ enumerable: true, get: function () { return change_stream_1.ChangeStream; } }));\nconst collection_1 = __webpack_require__(/*! ./collection */ \"./node_modules/mongodb/lib/collection.js\");\nObject.defineProperty(exports, \"Collection\", ({ enumerable: true, get: function () { return collection_1.Collection; } }));\nconst abstract_cursor_1 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"AbstractCursor\", ({ enumerable: true, get: function () { return abstract_cursor_1.AbstractCursor; } }));\nconst aggregation_cursor_1 = __webpack_require__(/*! ./cursor/aggregation_cursor */ \"./node_modules/mongodb/lib/cursor/aggregation_cursor.js\");\nObject.defineProperty(exports, \"AggregationCursor\", ({ enumerable: true, get: function () { return aggregation_cursor_1.AggregationCursor; } }));\nconst find_cursor_1 = __webpack_require__(/*! ./cursor/find_cursor */ \"./node_modules/mongodb/lib/cursor/find_cursor.js\");\nObject.defineProperty(exports, \"FindCursor\", ({ enumerable: true, get: function () { return find_cursor_1.FindCursor; } }));\nconst list_collections_cursor_1 = __webpack_require__(/*! ./cursor/list_collections_cursor */ \"./node_modules/mongodb/lib/cursor/list_collections_cursor.js\");\nObject.defineProperty(exports, \"ListCollectionsCursor\", ({ enumerable: true, get: function () { return list_collections_cursor_1.ListCollectionsCursor; } }));\nconst list_indexes_cursor_1 = __webpack_require__(/*! ./cursor/list_indexes_cursor */ \"./node_modules/mongodb/lib/cursor/list_indexes_cursor.js\");\nObject.defineProperty(exports, \"ListIndexesCursor\", ({ enumerable: true, get: function () { return list_indexes_cursor_1.ListIndexesCursor; } }));\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nObject.defineProperty(exports, \"Db\", ({ enumerable: true, get: function () { return db_1.Db; } }));\nconst gridfs_1 = __webpack_require__(/*! ./gridfs */ \"./node_modules/mongodb/lib/gridfs/index.js\");\nObject.defineProperty(exports, \"GridFSBucket\", ({ enumerable: true, get: function () { return gridfs_1.GridFSBucket; } }));\nconst download_1 = __webpack_require__(/*! ./gridfs/download */ \"./node_modules/mongodb/lib/gridfs/download.js\");\nObject.defineProperty(exports, \"GridFSBucketReadStream\", ({ enumerable: true, get: function () { return download_1.GridFSBucketReadStream; } }));\nconst upload_1 = __webpack_require__(/*! ./gridfs/upload */ \"./node_modules/mongodb/lib/gridfs/upload.js\");\nObject.defineProperty(exports, \"GridFSBucketWriteStream\", ({ enumerable: true, get: function () { return upload_1.GridFSBucketWriteStream; } }));\nconst mongo_client_1 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"MongoClient\", ({ enumerable: true, get: function () { return mongo_client_1.MongoClient; } }));\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nObject.defineProperty(exports, \"CancellationToken\", ({ enumerable: true, get: function () { return mongo_types_1.CancellationToken; } }));\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nObject.defineProperty(exports, \"ClientSession\", ({ enumerable: true, get: function () { return sessions_1.ClientSession; } }));\n/** @public */\nvar bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"BSON\", ({ enumerable: true, get: function () { return bson_1.BSON; } }));\nvar bson_2 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nObject.defineProperty(exports, \"Binary\", ({ enumerable: true, get: function () { return bson_2.Binary; } }));\nObject.defineProperty(exports, \"BSONRegExp\", ({ enumerable: true, get: function () { return bson_2.BSONRegExp; } }));\nObject.defineProperty(exports, \"BSONSymbol\", ({ enumerable: true, get: function () { return bson_2.BSONSymbol; } }));\nObject.defineProperty(exports, \"BSONType\", ({ enumerable: true, get: function () { return bson_2.BSONType; } }));\nObject.defineProperty(exports, \"Code\", ({ enumerable: true, get: function () { return bson_2.Code; } }));\nObject.defineProperty(exports, \"DBRef\", ({ enumerable: true, get: function () { return bson_2.DBRef; } }));\nObject.defineProperty(exports, \"Decimal128\", ({ enumerable: true, get: function () { return bson_2.Decimal128; } }));\nObject.defineProperty(exports, \"Double\", ({ enumerable: true, get: function () { return bson_2.Double; } }));\nObject.defineProperty(exports, \"Int32\", ({ enumerable: true, get: function () { return bson_2.Int32; } }));\nObject.defineProperty(exports, \"Long\", ({ enumerable: true, get: function () { return bson_2.Long; } }));\nObject.defineProperty(exports, \"MaxKey\", ({ enumerable: true, get: function () { return bson_2.MaxKey; } }));\nObject.defineProperty(exports, \"MinKey\", ({ enumerable: true, get: function () { return bson_2.MinKey; } }));\nObject.defineProperty(exports, \"ObjectId\", ({ enumerable: true, get: function () { return bson_2.ObjectId; } }));\nObject.defineProperty(exports, \"Timestamp\", ({ enumerable: true, get: function () { return bson_2.Timestamp; } }));\nObject.defineProperty(exports, \"UUID\", ({ enumerable: true, get: function () { return bson_2.UUID; } }));\nvar common_1 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"MongoBulkWriteError\", ({ enumerable: true, get: function () { return common_1.MongoBulkWriteError; } }));\nvar client_encryption_1 = __webpack_require__(/*! ./client-side-encryption/client_encryption */ \"./node_modules/mongodb/lib/client-side-encryption/client_encryption.js\");\nObject.defineProperty(exports, \"ClientEncryption\", ({ enumerable: true, get: function () { return client_encryption_1.ClientEncryption; } }));\nvar change_stream_cursor_1 = __webpack_require__(/*! ./cursor/change_stream_cursor */ \"./node_modules/mongodb/lib/cursor/change_stream_cursor.js\");\nObject.defineProperty(exports, \"ChangeStreamCursor\", ({ enumerable: true, get: function () { return change_stream_cursor_1.ChangeStreamCursor; } }));\nvar error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoAPIError\", ({ enumerable: true, get: function () { return error_1.MongoAPIError; } }));\nObject.defineProperty(exports, \"MongoAWSError\", ({ enumerable: true, get: function () { return error_1.MongoAWSError; } }));\nObject.defineProperty(exports, \"MongoAzureError\", ({ enumerable: true, get: function () { return error_1.MongoAzureError; } }));\nObject.defineProperty(exports, \"MongoBatchReExecutionError\", ({ enumerable: true, get: function () { return error_1.MongoBatchReExecutionError; } }));\nObject.defineProperty(exports, \"MongoChangeStreamError\", ({ enumerable: true, get: function () { return error_1.MongoChangeStreamError; } }));\nObject.defineProperty(exports, \"MongoCompatibilityError\", ({ enumerable: true, get: function () { return error_1.MongoCompatibilityError; } }));\nObject.defineProperty(exports, \"MongoCursorExhaustedError\", ({ enumerable: true, get: function () { return error_1.MongoCursorExhaustedError; } }));\nObject.defineProperty(exports, \"MongoCursorInUseError\", ({ enumerable: true, get: function () { return error_1.MongoCursorInUseError; } }));\nObject.defineProperty(exports, \"MongoDecompressionError\", ({ enumerable: true, get: function () { return error_1.MongoDecompressionError; } }));\nObject.defineProperty(exports, \"MongoDriverError\", ({ enumerable: true, get: function () { return error_1.MongoDriverError; } }));\nObject.defineProperty(exports, \"MongoError\", ({ enumerable: true, get: function () { return error_1.MongoError; } }));\nObject.defineProperty(exports, \"MongoExpiredSessionError\", ({ enumerable: true, get: function () { return error_1.MongoExpiredSessionError; } }));\nObject.defineProperty(exports, \"MongoGridFSChunkError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSChunkError; } }));\nObject.defineProperty(exports, \"MongoGridFSStreamError\", ({ enumerable: true, get: function () { return error_1.MongoGridFSStreamError; } }));\nObject.defineProperty(exports, \"MongoInvalidArgumentError\", ({ enumerable: true, get: function () { return error_1.MongoInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoKerberosError\", ({ enumerable: true, get: function () { return error_1.MongoKerberosError; } }));\nObject.defineProperty(exports, \"MongoMissingCredentialsError\", ({ enumerable: true, get: function () { return error_1.MongoMissingCredentialsError; } }));\nObject.defineProperty(exports, \"MongoMissingDependencyError\", ({ enumerable: true, get: function () { return error_1.MongoMissingDependencyError; } }));\nObject.defineProperty(exports, \"MongoNetworkError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkError; } }));\nObject.defineProperty(exports, \"MongoNetworkTimeoutError\", ({ enumerable: true, get: function () { return error_1.MongoNetworkTimeoutError; } }));\nObject.defineProperty(exports, \"MongoNotConnectedError\", ({ enumerable: true, get: function () { return error_1.MongoNotConnectedError; } }));\nObject.defineProperty(exports, \"MongoParseError\", ({ enumerable: true, get: function () { return error_1.MongoParseError; } }));\nObject.defineProperty(exports, \"MongoRuntimeError\", ({ enumerable: true, get: function () { return error_1.MongoRuntimeError; } }));\nObject.defineProperty(exports, \"MongoServerClosedError\", ({ enumerable: true, get: function () { return error_1.MongoServerClosedError; } }));\nObject.defineProperty(exports, \"MongoServerError\", ({ enumerable: true, get: function () { return error_1.MongoServerError; } }));\nObject.defineProperty(exports, \"MongoServerSelectionError\", ({ enumerable: true, get: function () { return error_1.MongoServerSelectionError; } }));\nObject.defineProperty(exports, \"MongoSystemError\", ({ enumerable: true, get: function () { return error_1.MongoSystemError; } }));\nObject.defineProperty(exports, \"MongoTailableCursorError\", ({ enumerable: true, get: function () { return error_1.MongoTailableCursorError; } }));\nObject.defineProperty(exports, \"MongoTopologyClosedError\", ({ enumerable: true, get: function () { return error_1.MongoTopologyClosedError; } }));\nObject.defineProperty(exports, \"MongoTransactionError\", ({ enumerable: true, get: function () { return error_1.MongoTransactionError; } }));\nObject.defineProperty(exports, \"MongoUnexpectedServerResponseError\", ({ enumerable: true, get: function () { return error_1.MongoUnexpectedServerResponseError; } }));\nObject.defineProperty(exports, \"MongoWriteConcernError\", ({ enumerable: true, get: function () { return error_1.MongoWriteConcernError; } }));\n// enums\nvar common_2 = __webpack_require__(/*! ./bulk/common */ \"./node_modules/mongodb/lib/bulk/common.js\");\nObject.defineProperty(exports, \"BatchType\", ({ enumerable: true, get: function () { return common_2.BatchType; } }));\nvar auto_encrypter_1 = __webpack_require__(/*! ./client-side-encryption/auto_encrypter */ \"./node_modules/mongodb/lib/client-side-encryption/auto_encrypter.js\");\nObject.defineProperty(exports, \"AutoEncryptionLoggerLevel\", ({ enumerable: true, get: function () { return auto_encrypter_1.AutoEncryptionLoggerLevel; } }));\nvar gssapi_1 = __webpack_require__(/*! ./cmap/auth/gssapi */ \"./node_modules/mongodb/lib/cmap/auth/gssapi.js\");\nObject.defineProperty(exports, \"GSSAPICanonicalizationValue\", ({ enumerable: true, get: function () { return gssapi_1.GSSAPICanonicalizationValue; } }));\nvar providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nObject.defineProperty(exports, \"AuthMechanism\", ({ enumerable: true, get: function () { return providers_1.AuthMechanism; } }));\nvar compression_1 = __webpack_require__(/*! ./cmap/wire_protocol/compression */ \"./node_modules/mongodb/lib/cmap/wire_protocol/compression.js\");\nObject.defineProperty(exports, \"Compressor\", ({ enumerable: true, get: function () { return compression_1.Compressor; } }));\nvar abstract_cursor_2 = __webpack_require__(/*! ./cursor/abstract_cursor */ \"./node_modules/mongodb/lib/cursor/abstract_cursor.js\");\nObject.defineProperty(exports, \"CURSOR_FLAGS\", ({ enumerable: true, get: function () { return abstract_cursor_2.CURSOR_FLAGS; } }));\nvar error_2 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nObject.defineProperty(exports, \"MongoErrorLabel\", ({ enumerable: true, get: function () { return error_2.MongoErrorLabel; } }));\nvar explain_1 = __webpack_require__(/*! ./explain */ \"./node_modules/mongodb/lib/explain.js\");\nObject.defineProperty(exports, \"ExplainVerbosity\", ({ enumerable: true, get: function () { return explain_1.ExplainVerbosity; } }));\nvar mongo_client_2 = __webpack_require__(/*! ./mongo_client */ \"./node_modules/mongodb/lib/mongo_client.js\");\nObject.defineProperty(exports, \"ServerApiVersion\", ({ enumerable: true, get: function () { return mongo_client_2.ServerApiVersion; } }));\nvar find_and_modify_1 = __webpack_require__(/*! ./operations/find_and_modify */ \"./node_modules/mongodb/lib/operations/find_and_modify.js\");\nObject.defineProperty(exports, \"ReturnDocument\", ({ enumerable: true, get: function () { return find_and_modify_1.ReturnDocument; } }));\nvar set_profiling_level_1 = __webpack_require__(/*! ./operations/set_profiling_level */ \"./node_modules/mongodb/lib/operations/set_profiling_level.js\");\nObject.defineProperty(exports, \"ProfilingLevel\", ({ enumerable: true, get: function () { return set_profiling_level_1.ProfilingLevel; } }));\nvar read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcernLevel\", ({ enumerable: true, get: function () { return read_concern_1.ReadConcernLevel; } }));\nvar read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreferenceMode\", ({ enumerable: true, get: function () { return read_preference_1.ReadPreferenceMode; } }));\nvar common_3 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nObject.defineProperty(exports, \"ServerType\", ({ enumerable: true, get: function () { return common_3.ServerType; } }));\nObject.defineProperty(exports, \"TopologyType\", ({ enumerable: true, get: function () { return common_3.TopologyType; } }));\n// Helper classes\nvar read_concern_2 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nObject.defineProperty(exports, \"ReadConcern\", ({ enumerable: true, get: function () { return read_concern_2.ReadConcern; } }));\nvar read_preference_2 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nObject.defineProperty(exports, \"ReadPreference\", ({ enumerable: true, get: function () { return read_preference_2.ReadPreference; } }));\nvar write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nObject.defineProperty(exports, \"WriteConcern\", ({ enumerable: true, get: function () { return write_concern_1.WriteConcern; } }));\n// events\nvar command_monitoring_events_1 = __webpack_require__(/*! ./cmap/command_monitoring_events */ \"./node_modules/mongodb/lib/cmap/command_monitoring_events.js\");\nObject.defineProperty(exports, \"CommandFailedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandFailedEvent; } }));\nObject.defineProperty(exports, \"CommandStartedEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandStartedEvent; } }));\nObject.defineProperty(exports, \"CommandSucceededEvent\", ({ enumerable: true, get: function () { return command_monitoring_events_1.CommandSucceededEvent; } }));\nvar connection_pool_events_1 = __webpack_require__(/*! ./cmap/connection_pool_events */ \"./node_modules/mongodb/lib/cmap/connection_pool_events.js\");\nObject.defineProperty(exports, \"ConnectionCheckedInEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedInEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckedOutEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckedOutEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutFailedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutFailedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCheckOutStartedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCheckOutStartedEvent; } }));\nObject.defineProperty(exports, \"ConnectionClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClearedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClearedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolClosedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolClosedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolCreatedEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolCreatedEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolMonitoringEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolMonitoringEvent; } }));\nObject.defineProperty(exports, \"ConnectionPoolReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionPoolReadyEvent; } }));\nObject.defineProperty(exports, \"ConnectionReadyEvent\", ({ enumerable: true, get: function () { return connection_pool_events_1.ConnectionReadyEvent; } }));\nvar events_1 = __webpack_require__(/*! ./sdam/events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nObject.defineProperty(exports, \"ServerClosedEvent\", ({ enumerable: true, get: function () { return events_1.ServerClosedEvent; } }));\nObject.defineProperty(exports, \"ServerDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.ServerDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatFailedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatFailedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatStartedEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatStartedEvent; } }));\nObject.defineProperty(exports, \"ServerHeartbeatSucceededEvent\", ({ enumerable: true, get: function () { return events_1.ServerHeartbeatSucceededEvent; } }));\nObject.defineProperty(exports, \"ServerOpeningEvent\", ({ enumerable: true, get: function () { return events_1.ServerOpeningEvent; } }));\nObject.defineProperty(exports, \"TopologyClosedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyClosedEvent; } }));\nObject.defineProperty(exports, \"TopologyDescriptionChangedEvent\", ({ enumerable: true, get: function () { return events_1.TopologyDescriptionChangedEvent; } }));\nObject.defineProperty(exports, \"TopologyOpeningEvent\", ({ enumerable: true, get: function () { return events_1.TopologyOpeningEvent; } }));\nvar srv_polling_1 = __webpack_require__(/*! ./sdam/srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nObject.defineProperty(exports, \"SrvPollingEvent\", ({ enumerable: true, get: function () { return srv_polling_1.SrvPollingEvent; } }));\nvar errors_1 = __webpack_require__(/*! ./client-side-encryption/errors */ \"./node_modules/mongodb/lib/client-side-encryption/errors.js\");\nObject.defineProperty(exports, \"MongoCryptAzureKMSRequestError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptAzureKMSRequestError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateDataKeyError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateDataKeyError; } }));\nObject.defineProperty(exports, \"MongoCryptCreateEncryptedCollectionError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptCreateEncryptedCollectionError; } }));\nObject.defineProperty(exports, \"MongoCryptError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptError; } }));\nObject.defineProperty(exports, \"MongoCryptInvalidArgumentError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptInvalidArgumentError; } }));\nObject.defineProperty(exports, \"MongoCryptKMSRequestNetworkTimeoutError\", ({ enumerable: true, get: function () { return errors_1.MongoCryptKMSRequestNetworkTimeoutError; } }));\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/index.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_client.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_client.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoClient = exports.ServerApiVersion = void 0;\nconst fs_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'fs'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst change_stream_1 = __webpack_require__(/*! ./change_stream */ \"./node_modules/mongodb/lib/change_stream.js\");\nconst mongo_credentials_1 = __webpack_require__(/*! ./cmap/auth/mongo_credentials */ \"./node_modules/mongodb/lib/cmap/auth/mongo_credentials.js\");\nconst providers_1 = __webpack_require__(/*! ./cmap/auth/providers */ \"./node_modules/mongodb/lib/cmap/auth/providers.js\");\nconst connection_string_1 = __webpack_require__(/*! ./connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst db_1 = __webpack_require__(/*! ./db */ \"./node_modules/mongodb/lib/db.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_logger_1 = __webpack_require__(/*! ./mongo_logger */ \"./node_modules/mongodb/lib/mongo_logger.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ./sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst topology_1 = __webpack_require__(/*! ./sdam/topology */ \"./node_modules/mongodb/lib/sdam/topology.js\");\nconst sessions_1 = __webpack_require__(/*! ./sessions */ \"./node_modules/mongodb/lib/sessions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @public */\nexports.ServerApiVersion = Object.freeze({\n    v1: '1'\n});\n/** @internal */\nconst kOptions = Symbol('options');\n/**\n * The **MongoClient** class is a class that allows for making Connections to MongoDB.\n * @public\n *\n * @remarks\n * The programmatically provided options take precedence over the URI options.\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * // Enable command monitoring for debugging\n * const client = new MongoClient('mongodb://localhost:27017', { monitorCommands: true });\n *\n * client.on('commandStarted', started => console.log(started));\n * client.db().collection('pets');\n * await client.insertOne({ name: 'spot', kind: 'dog' });\n * ```\n */\nclass MongoClient extends mongo_types_1.TypedEventEmitter {\n    constructor(url, options) {\n        super();\n        this[kOptions] = (0, connection_string_1.parseOptions)(url, this, options);\n        this.mongoLogger = new mongo_logger_1.MongoLogger(this[kOptions].mongoLoggerOptions);\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const client = this;\n        // The internal state\n        this.s = {\n            url,\n            bsonOptions: (0, bson_1.resolveBSONOptions)(this[kOptions]),\n            namespace: (0, utils_1.ns)('admin'),\n            hasBeenClosed: false,\n            sessionPool: new sessions_1.ServerSessionPool(this),\n            activeSessions: new Set(),\n            get options() {\n                return client[kOptions];\n            },\n            get readConcern() {\n                return client[kOptions].readConcern;\n            },\n            get writeConcern() {\n                return client[kOptions].writeConcern;\n            },\n            get readPreference() {\n                return client[kOptions].readPreference;\n            },\n            get isMongoClient() {\n                return true;\n            }\n        };\n        this.checkForNonGenuineHosts();\n    }\n    /** @internal */\n    checkForNonGenuineHosts() {\n        const documentDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, hostAddress.host));\n        const srvHostIsDocumentDB = (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, this[kOptions].srvHost);\n        const cosmosDBHostnames = this[kOptions].hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, hostAddress.host));\n        const srvHostIsCosmosDB = (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, this[kOptions].srvHost);\n        if (documentDBHostnames.length !== 0 || srvHostIsDocumentDB) {\n            this.mongoLogger.info('client', utils_1.DOCUMENT_DB_MSG);\n        }\n        else if (cosmosDBHostnames.length !== 0 || srvHostIsCosmosDB) {\n            this.mongoLogger.info('client', utils_1.COSMOS_DB_MSG);\n        }\n    }\n    /** @see MongoOptions */\n    get options() {\n        return Object.freeze({ ...this[kOptions] });\n    }\n    get serverApi() {\n        return this[kOptions].serverApi && Object.freeze({ ...this[kOptions].serverApi });\n    }\n    /**\n     * Intended for APM use only\n     * @internal\n     */\n    get monitorCommands() {\n        return this[kOptions].monitorCommands;\n    }\n    set monitorCommands(value) {\n        this[kOptions].monitorCommands = value;\n    }\n    /** @internal */\n    get autoEncrypter() {\n        return this[kOptions].autoEncrypter;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get readPreference() {\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @see docs.mongodb.org/manual/reference/connection-string/\n     */\n    async connect() {\n        if (this.connectionLock) {\n            return this.connectionLock;\n        }\n        try {\n            this.connectionLock = this._connect();\n            await this.connectionLock;\n        }\n        finally {\n            // release\n            this.connectionLock = undefined;\n        }\n        return this;\n    }\n    /**\n     * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.\n     * Locking is enforced by the connect method.\n     *\n     * @internal\n     */\n    async _connect() {\n        if (this.topology && this.topology.isConnected()) {\n            return this;\n        }\n        const options = this[kOptions];\n        if (options.tls) {\n            if (typeof options.tlsCAFile === 'string') {\n                options.ca ??= await fs_1.promises.readFile(options.tlsCAFile);\n            }\n            if (typeof options.tlsCRLFile === 'string') {\n                options.crl ??= await fs_1.promises.readFile(options.tlsCRLFile);\n            }\n            if (typeof options.tlsCertificateKeyFile === 'string') {\n                if (!options.key || !options.cert) {\n                    const contents = await fs_1.promises.readFile(options.tlsCertificateKeyFile);\n                    options.key ??= contents;\n                    options.cert ??= contents;\n                }\n            }\n        }\n        if (typeof options.srvHost === 'string') {\n            const hosts = await (0, connection_string_1.resolveSRVRecord)(options);\n            for (const [index, host] of hosts.entries()) {\n                options.hosts[index] = host;\n            }\n        }\n        // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,\n        // but BEFORE we even attempt connecting with a potentially not allowed hostname\n        if (options.credentials?.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            const allowedHosts = options.credentials?.mechanismProperties?.ALLOWED_HOSTS || mongo_credentials_1.DEFAULT_ALLOWED_HOSTS;\n            const isServiceAuth = !!options.credentials?.mechanismProperties?.PROVIDER_NAME;\n            if (!isServiceAuth) {\n                for (const host of options.hosts) {\n                    if (!(0, utils_1.hostMatchesWildcards)(host.toHostPort().host, allowedHosts)) {\n                        throw new error_1.MongoInvalidArgumentError(`Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(',')}'`);\n                    }\n                }\n            }\n        }\n        this.topology = new topology_1.Topology(this, options.hosts, options);\n        // Events can be emitted before initialization is complete so we have to\n        // save the reference to the topology on the client ASAP if the event handlers need to access it\n        this.topology.once(topology_1.Topology.OPEN, () => this.emit('open', this));\n        for (const event of constants_1.MONGO_CLIENT_EVENTS) {\n            this.topology.on(event, (...args) => this.emit(event, ...args));\n        }\n        const topologyConnect = async () => {\n            try {\n                await (0, util_1.promisify)(callback => this.topology?.connect(options, callback))();\n            }\n            catch (error) {\n                this.topology?.close({ force: true });\n                throw error;\n            }\n        };\n        if (this.autoEncrypter) {\n            await this.autoEncrypter?.init();\n            await topologyConnect();\n            await options.encrypter.connectInternalClient();\n        }\n        else {\n            await topologyConnect();\n        }\n        return this;\n    }\n    /**\n     * Close the client and its underlying connections\n     *\n     * @param force - Force close, emitting no events\n     */\n    async close(force = false) {\n        // There's no way to set hasBeenClosed back to false\n        Object.defineProperty(this.s, 'hasBeenClosed', {\n            value: true,\n            enumerable: true,\n            configurable: false,\n            writable: false\n        });\n        const activeSessionEnds = Array.from(this.s.activeSessions, session => session.endSession());\n        this.s.activeSessions.clear();\n        await Promise.all(activeSessionEnds);\n        if (this.topology == null) {\n            return;\n        }\n        // If we would attempt to select a server and get nothing back we short circuit\n        // to avoid the server selection timeout.\n        const selector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.primaryPreferred);\n        const topologyDescription = this.topology.description;\n        const serverDescriptions = Array.from(topologyDescription.servers.values());\n        const servers = selector(topologyDescription, serverDescriptions);\n        if (servers.length !== 0) {\n            const endSessions = Array.from(this.s.sessionPool.sessions, ({ id }) => id);\n            if (endSessions.length !== 0) {\n                await (0, execute_operation_1.executeOperation)(this, new run_command_1.RunAdminCommandOperation({ endSessions }, { readPreference: read_preference_1.ReadPreference.primaryPreferred, noResponse: true })).catch(() => null); // outcome does not matter;\n            }\n        }\n        // clear out references to old topology\n        const topology = this.topology;\n        this.topology = undefined;\n        await new Promise((resolve, reject) => {\n            topology.close({ force }, error => {\n                if (error)\n                    return reject(error);\n                const { encrypter } = this[kOptions];\n                if (encrypter) {\n                    return encrypter.closeCallback(this, force, error => {\n                        if (error)\n                            return reject(error);\n                        resolve();\n                    });\n                }\n                resolve();\n            });\n        });\n    }\n    /**\n     * Create a new Db instance sharing the current socket connections.\n     *\n     * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.\n     * @param options - Optional settings for Db construction\n     */\n    db(dbName, options) {\n        options = options ?? {};\n        // Default to db from connection string if not provided\n        if (!dbName) {\n            dbName = this.options.dbName;\n        }\n        // Copy the options and add out internal override of the not shared flag\n        const finalOptions = Object.assign({}, this[kOptions], options);\n        // Return the db object\n        const db = new db_1.Db(this, dbName, finalOptions);\n        // Return the database\n        return db;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @remarks\n     * The programmatically provided options take precedence over the URI options.\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/connection-string/\n     */\n    static async connect(url, options) {\n        const client = new this(url, options);\n        return client.connect();\n    }\n    /**\n     * Creates a new ClientSession. When using the returned session in an operation\n     * a corresponding ServerSession will be created.\n     *\n     * @remarks\n     * A ClientSession instance may only be passed to operations being performed on the same\n     * MongoClient it was started from.\n     */\n    startSession(options) {\n        const session = new sessions_1.ClientSession(this, this.s.sessionPool, { explicit: true, ...options }, this[kOptions]);\n        this.s.activeSessions.add(session);\n        session.once('ended', () => {\n            this.s.activeSessions.delete(session);\n        });\n        return session;\n    }\n    async withSession(optionsOrExecutor, executor) {\n        const options = {\n            // Always define an owner\n            owner: Symbol(),\n            // If it's an object inherit the options\n            ...(typeof optionsOrExecutor === 'object' ? optionsOrExecutor : {})\n        };\n        const withSessionCallback = typeof optionsOrExecutor === 'function' ? optionsOrExecutor : executor;\n        if (withSessionCallback == null) {\n            throw new error_1.MongoInvalidArgumentError('Missing required callback parameter');\n        }\n        const session = this.startSession(options);\n        try {\n            return await withSessionCallback(session);\n        }\n        finally {\n            try {\n                await session.endSession();\n            }\n            catch {\n                // We are not concerned with errors from endSession()\n            }\n        }\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this cluster. Will ignore all\n     * changes to system collections, as well as the local, admin, and config databases.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the data within the current cluster\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n}\nexports.MongoClient = MongoClient;\n//# sourceMappingURL=mongo_client.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/mongo_client.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_logger.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_logger.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MongoLogger = exports.stringifyWithMaxLen = exports.createStdioLogger = exports.MongoLoggableComponent = exports.SEVERITY_LEVEL_MAP = exports.DEFAULT_MAX_DOCUMENT_LENGTH = exports.SeverityLevel = void 0;\nconst bson_1 = __webpack_require__(/*! bson */ \"./node_modules/bson/lib/bson.cjs\");\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\n/** @internal */\nexports.SeverityLevel = Object.freeze({\n    EMERGENCY: 'emergency',\n    ALERT: 'alert',\n    CRITICAL: 'critical',\n    ERROR: 'error',\n    WARNING: 'warn',\n    NOTICE: 'notice',\n    INFORMATIONAL: 'info',\n    DEBUG: 'debug',\n    TRACE: 'trace',\n    OFF: 'off'\n});\n/** @internal */\nexports.DEFAULT_MAX_DOCUMENT_LENGTH = 1000;\n/** @internal */\nclass SeverityLevelMap extends Map {\n    constructor(entries) {\n        const newEntries = [];\n        for (const [level, value] of entries) {\n            newEntries.push([value, level]);\n        }\n        newEntries.push(...entries);\n        super(newEntries);\n    }\n    getNumericSeverityLevel(severity) {\n        return this.get(severity);\n    }\n    getSeverityLevelName(level) {\n        return this.get(level);\n    }\n}\n/** @internal */\nexports.SEVERITY_LEVEL_MAP = new SeverityLevelMap([\n    [exports.SeverityLevel.OFF, -Infinity],\n    [exports.SeverityLevel.EMERGENCY, 0],\n    [exports.SeverityLevel.ALERT, 1],\n    [exports.SeverityLevel.CRITICAL, 2],\n    [exports.SeverityLevel.ERROR, 3],\n    [exports.SeverityLevel.WARNING, 4],\n    [exports.SeverityLevel.NOTICE, 5],\n    [exports.SeverityLevel.INFORMATIONAL, 6],\n    [exports.SeverityLevel.DEBUG, 7],\n    [exports.SeverityLevel.TRACE, 8]\n]);\n/** @internal */\nexports.MongoLoggableComponent = Object.freeze({\n    COMMAND: 'command',\n    TOPOLOGY: 'topology',\n    SERVER_SELECTION: 'serverSelection',\n    CONNECTION: 'connection',\n    CLIENT: 'client'\n});\n/**\n * Parses a string as one of SeverityLevel\n *\n * @param s - the value to be parsed\n * @returns one of SeverityLevel if value can be parsed as such, otherwise null\n */\nfunction parseSeverityFromString(s) {\n    const validSeverities = Object.values(exports.SeverityLevel);\n    const lowerSeverity = s?.toLowerCase();\n    if (lowerSeverity != null && validSeverities.includes(lowerSeverity)) {\n        return lowerSeverity;\n    }\n    return null;\n}\n/** @internal */\nfunction createStdioLogger(stream) {\n    return {\n        write: (log) => {\n            stream.write((0, util_1.inspect)(log, { compact: true, breakLength: Infinity }), 'utf-8');\n            return;\n        }\n    };\n}\nexports.createStdioLogger = createStdioLogger;\n/**\n * resolves the MONGODB_LOG_PATH and mongodbLogPath options from the environment and the\n * mongo client options respectively. The mongodbLogPath can be either 'stdout', 'stderr', a NodeJS\n * Writable or an object which has a `write` method with the signature:\n * ```ts\n * write(log: Log): void\n * ```\n *\n * @returns the MongoDBLogWritable object to write logs to\n */\nfunction resolveLogPath({ MONGODB_LOG_PATH }, { mongodbLogPath }) {\n    if (typeof mongodbLogPath === 'string' && /^stderr$/i.test(mongodbLogPath)) {\n        return createStdioLogger(process.stderr);\n    }\n    if (typeof mongodbLogPath === 'string' && /^stdout$/i.test(mongodbLogPath)) {\n        return createStdioLogger(process.stdout);\n    }\n    if (typeof mongodbLogPath === 'object' && typeof mongodbLogPath?.write === 'function') {\n        return mongodbLogPath;\n    }\n    if (MONGODB_LOG_PATH && /^stderr$/i.test(MONGODB_LOG_PATH)) {\n        return createStdioLogger(process.stderr);\n    }\n    if (MONGODB_LOG_PATH && /^stdout$/i.test(MONGODB_LOG_PATH)) {\n        return createStdioLogger(process.stdout);\n    }\n    return createStdioLogger(process.stderr);\n}\nfunction resolveSeverityConfiguration(clientOption, environmentOption, defaultSeverity) {\n    return (parseSeverityFromString(clientOption) ??\n        parseSeverityFromString(environmentOption) ??\n        defaultSeverity);\n}\nfunction compareSeverity(s0, s1) {\n    const s0Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s0);\n    const s1Num = exports.SEVERITY_LEVEL_MAP.getNumericSeverityLevel(s1);\n    return s0Num < s1Num ? -1 : s0Num > s1Num ? 1 : 0;\n}\n/** @internal */\nfunction stringifyWithMaxLen(value, maxDocumentLength) {\n    const ejson = bson_1.EJSON.stringify(value);\n    return maxDocumentLength !== 0 && ejson.length > maxDocumentLength\n        ? `${ejson.slice(0, maxDocumentLength)}...`\n        : ejson;\n}\nexports.stringifyWithMaxLen = stringifyWithMaxLen;\nfunction isLogConvertible(obj) {\n    const objAsLogConvertible = obj;\n    // eslint-disable-next-line no-restricted-syntax\n    return objAsLogConvertible.toLog !== undefined && typeof objAsLogConvertible.toLog === 'function';\n}\nfunction attachCommandFields(log, commandEvent) {\n    log.commandName = commandEvent.commandName;\n    log.requestId = commandEvent.requestId;\n    log.driverConnectionId = commandEvent?.connectionId;\n    const { host, port } = utils_1.HostAddress.fromString(commandEvent.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    if (commandEvent?.serviceId) {\n        log.serviceId = commandEvent.serviceId.toHexString();\n    }\n    return log;\n}\nfunction attachConnectionFields(log, connectionPoolEvent) {\n    const { host, port } = utils_1.HostAddress.fromString(connectionPoolEvent.address).toHostPort();\n    log.serverHost = host;\n    log.serverPort = port;\n    return log;\n}\nfunction defaultLogTransform(logObject, maxDocumentLength = exports.DEFAULT_MAX_DOCUMENT_LENGTH) {\n    let log = Object.create(null);\n    switch (logObject.name) {\n        case constants_1.COMMAND_STARTED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command started';\n            log.command = stringifyWithMaxLen(logObject.command, maxDocumentLength);\n            log.databaseName = logObject.databaseName;\n            return log;\n        case constants_1.COMMAND_SUCCEEDED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command succeeded';\n            log.durationMS = logObject.duration;\n            log.reply = stringifyWithMaxLen(logObject.reply, maxDocumentLength);\n            return log;\n        case constants_1.COMMAND_FAILED:\n            log = attachCommandFields(log, logObject);\n            log.message = 'Command failed';\n            log.durationMS = logObject.duration;\n            log.failure = logObject.failure;\n            return log;\n        case constants_1.CONNECTION_POOL_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool created';\n            if (logObject.options) {\n                const { maxIdleTimeMS, minPoolSize, maxPoolSize, maxConnecting, waitQueueTimeoutMS } = logObject.options;\n                log = {\n                    ...log,\n                    maxIdleTimeMS,\n                    minPoolSize,\n                    maxPoolSize,\n                    maxConnecting,\n                    waitQueueTimeoutMS\n                };\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool ready';\n            return log;\n        case constants_1.CONNECTION_POOL_CLEARED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool cleared';\n            if (logObject.serviceId?._bsontype === 'ObjectId') {\n                log.serviceId = logObject.serviceId.toHexString();\n            }\n            return log;\n        case constants_1.CONNECTION_POOL_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection pool closed';\n            return log;\n        case constants_1.CONNECTION_CREATED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection created';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_READY:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection ready';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CLOSED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection closed';\n            log.driverConnectionId = logObject.connectionId;\n            switch (logObject.reason) {\n                case 'stale':\n                    log.reason = 'Connection became stale because the pool was cleared';\n                    break;\n                case 'idle':\n                    log.reason =\n                        'Connection has been available but unused for longer than the configured max idle time';\n                    break;\n                case 'error':\n                    log.reason = 'An error occurred while using the connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_STARTED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout started';\n            return log;\n        case constants_1.CONNECTION_CHECK_OUT_FAILED:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checkout failed';\n            switch (logObject.reason) {\n                case 'poolClosed':\n                    log.reason = 'Connection pool was closed';\n                    break;\n                case 'timeout':\n                    log.reason = 'Wait queue timeout elapsed without a connection becoming available';\n                    break;\n                case 'connectionError':\n                    log.reason = 'An error occurred while trying to establish a new connection';\n                    if (logObject.error) {\n                        log.error = logObject.error;\n                    }\n                    break;\n                default:\n                    log.reason = `Unknown close reason: ${logObject.reason}`;\n            }\n            return log;\n        case constants_1.CONNECTION_CHECKED_OUT:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked out';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        case constants_1.CONNECTION_CHECKED_IN:\n            log = attachConnectionFields(log, logObject);\n            log.message = 'Connection checked in';\n            log.driverConnectionId = logObject.connectionId;\n            return log;\n        default:\n            for (const [key, value] of Object.entries(logObject)) {\n                if (value != null)\n                    log[key] = value;\n            }\n    }\n    return log;\n}\n/** @internal */\nclass MongoLogger {\n    constructor(options) {\n        /**\n         * This method should be used when logging errors that do not have a public driver API for\n         * reporting errors.\n         */\n        this.error = this.log.bind(this, 'error');\n        /**\n         * This method should be used to log situations where undesirable application behaviour might\n         * occur. For example, failing to end sessions on `MongoClient.close`.\n         */\n        this.warn = this.log.bind(this, 'warn');\n        /**\n         * This method should be used to report high-level information about normal driver behaviour.\n         * For example, the creation of a `MongoClient`.\n         */\n        this.info = this.log.bind(this, 'info');\n        /**\n         * This method should be used to report information that would be helpful when debugging an\n         * application. For example, a command starting, succeeding or failing.\n         */\n        this.debug = this.log.bind(this, 'debug');\n        /**\n         * This method should be used to report fine-grained details related to logic flow. For example,\n         * entering and exiting a function body.\n         */\n        this.trace = this.log.bind(this, 'trace');\n        this.componentSeverities = options.componentSeverities;\n        this.maxDocumentLength = options.maxDocumentLength;\n        this.logDestination = options.logDestination;\n    }\n    log(severity, component, message) {\n        if (compareSeverity(severity, this.componentSeverities[component]) > 0)\n            return;\n        let logMessage = { t: new Date(), c: component, s: severity };\n        if (typeof message === 'string') {\n            logMessage.message = message;\n        }\n        else if (typeof message === 'object') {\n            if (isLogConvertible(message)) {\n                logMessage = { ...logMessage, ...message.toLog() };\n            }\n            else {\n                logMessage = { ...logMessage, ...defaultLogTransform(message, this.maxDocumentLength) };\n            }\n        }\n        this.logDestination.write(logMessage);\n    }\n    /**\n     * Merges options set through environment variables and the MongoClient, preferring environment\n     * variables when both are set, and substituting defaults for values not set. Options set in\n     * constructor take precedence over both environment variables and MongoClient options.\n     *\n     * @remarks\n     * When parsing component severity levels, invalid values are treated as unset and replaced with\n     * the default severity.\n     *\n     * @param envOptions - options set for the logger from the environment\n     * @param clientOptions - options set for the logger in the MongoClient options\n     * @returns a MongoLoggerOptions object to be used when instantiating a new MongoLogger\n     */\n    static resolveOptions(envOptions, clientOptions) {\n        // client options take precedence over env options\n        const combinedOptions = {\n            ...envOptions,\n            ...clientOptions,\n            mongodbLogPath: resolveLogPath(envOptions, clientOptions)\n        };\n        const defaultSeverity = resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.default, combinedOptions.MONGODB_LOG_ALL, exports.SeverityLevel.OFF);\n        return {\n            componentSeverities: {\n                command: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.command, combinedOptions.MONGODB_LOG_COMMAND, defaultSeverity),\n                topology: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.topology, combinedOptions.MONGODB_LOG_TOPOLOGY, defaultSeverity),\n                serverSelection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.serverSelection, combinedOptions.MONGODB_LOG_SERVER_SELECTION, defaultSeverity),\n                connection: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.connection, combinedOptions.MONGODB_LOG_CONNECTION, defaultSeverity),\n                client: resolveSeverityConfiguration(combinedOptions.mongodbLogComponentSeverities?.client, combinedOptions.MONGODB_LOG_CLIENT, defaultSeverity),\n                default: defaultSeverity\n            },\n            maxDocumentLength: combinedOptions.mongodbLogMaxDocumentLength ??\n                (0, utils_1.parseUnsignedInteger)(combinedOptions.MONGODB_LOG_MAX_DOCUMENT_LENGTH) ??\n                1000,\n            logDestination: combinedOptions.mongodbLogPath\n        };\n    }\n}\nexports.MongoLogger = MongoLogger;\n//# sourceMappingURL=mongo_logger.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/mongo_logger.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/mongo_types.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/mongo_types.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CancellationToken = exports.TypedEventEmitter = void 0;\nconst events_1 = __webpack_require__(/*! events */ \"./node_modules/events/events.js\");\n/**\n * Typescript type safe event emitter\n * @public\n */\nclass TypedEventEmitter extends events_1.EventEmitter {\n    /** @internal */\n    emitAndLog(event, ...args) {\n        this.emit(event, ...args);\n        if (this.component)\n            this.mongoLogger?.debug(this.component, args[0]);\n    }\n}\nexports.TypedEventEmitter = TypedEventEmitter;\n/** @public */\nclass CancellationToken extends TypedEventEmitter {\n}\nexports.CancellationToken = CancellationToken;\n//# sourceMappingURL=mongo_types.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/mongo_types.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/aggregate.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/aggregate.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AggregateOperation = exports.DB_AGGREGATE_COLLECTION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nexports.DB_AGGREGATE_COLLECTION = 1;\nconst MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT = 8;\n/** @internal */\nclass AggregateOperation extends command_1.CommandOperation {\n    constructor(ns, pipeline, options) {\n        super(undefined, { ...options, dbName: ns.db });\n        this.options = { ...options };\n        // Covers when ns.collection is null, undefined or the empty string, use DB_AGGREGATE_COLLECTION\n        this.target = ns.collection || exports.DB_AGGREGATE_COLLECTION;\n        this.pipeline = pipeline;\n        // determine if we have a write stage, override read preference if so\n        this.hasWriteStage = false;\n        if (typeof options?.out === 'string') {\n            this.pipeline = this.pipeline.concat({ $out: options.out });\n            this.hasWriteStage = true;\n        }\n        else if (pipeline.length > 0) {\n            const finalStage = pipeline[pipeline.length - 1];\n            if (finalStage.$out || finalStage.$merge) {\n                this.hasWriteStage = true;\n            }\n        }\n        if (this.hasWriteStage) {\n            this.trySecondaryWrite = true;\n        }\n        else {\n            delete this.options.writeConcern;\n        }\n        if (this.explain && this.writeConcern) {\n            throw new error_1.MongoInvalidArgumentError('Option \"explain\" cannot be used on an aggregate call with writeConcern');\n        }\n        if (options?.cursor != null && typeof options.cursor !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Cursor options must be an object');\n        }\n    }\n    get canRetryRead() {\n        return !this.hasWriteStage;\n    }\n    addToPipeline(stage) {\n        this.pipeline.push(stage);\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const command = { aggregate: this.target, pipeline: this.pipeline };\n        if (this.hasWriteStage && serverWireVersion < MIN_WIRE_VERSION_$OUT_READ_CONCERN_SUPPORT) {\n            this.readConcern = undefined;\n        }\n        if (this.hasWriteStage && this.writeConcern) {\n            write_concern_1.WriteConcern.apply(command, this.writeConcern);\n        }\n        if (options.bypassDocumentValidation === true) {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (typeof options.allowDiskUse === 'boolean') {\n            command.allowDiskUse = options.allowDiskUse;\n        }\n        if (options.hint) {\n            command.hint = options.hint;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        command.cursor = options.cursor || {};\n        if (options.batchSize && !this.hasWriteStage) {\n            command.cursor.batchSize = options.batchSize;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.AggregateOperation = AggregateOperation;\n(0, operation_1.defineAspects)(AggregateOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=aggregate.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/aggregate.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/bulk_write.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/bulk_write.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BulkWriteOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass BulkWriteOperation extends operation_1.AbstractOperation {\n    constructor(collection, operations, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n        this.operations = operations;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const operations = this.operations;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        // Create the bulk operation\n        const bulk = options.ordered === false\n            ? coll.initializeUnorderedBulkOp(options)\n            : coll.initializeOrderedBulkOp(options);\n        // for each op go through and add to the bulk\n        for (let i = 0; i < operations.length; i++) {\n            bulk.raw(operations[i]);\n        }\n        // Execute the bulk\n        const result = await bulk.execute({ ...options, session });\n        return result;\n    }\n}\nexports.BulkWriteOperation = BulkWriteOperation;\n(0, operation_1.defineAspects)(BulkWriteOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=bulk_write.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/bulk_write.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/collections.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/collections.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CollectionsOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CollectionsOperation extends operation_1.AbstractOperation {\n    constructor(db, options) {\n        super(options);\n        this.options = options;\n        this.db = db;\n    }\n    async execute(server, session) {\n        // Let's get the collection names\n        const documents = await this.db\n            .listCollections({}, { ...this.options, nameOnly: true, readPreference: this.readPreference, session })\n            .toArray();\n        const collections = [];\n        for (const { name } of documents) {\n            if (!name.includes('$')) {\n                // Filter collections removing any illegal ones\n                collections.push(new collection_1.Collection(this.db, name, this.db.s.options));\n            }\n        }\n        // Return the collection objects\n        return collections;\n    }\n}\nexports.CollectionsOperation = CollectionsOperation;\n//# sourceMappingURL=collections.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/command.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/command.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CommandOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst explain_1 = __webpack_require__(/*! ../explain */ \"./node_modules/mongodb/lib/explain.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, options) {\n        super(options);\n        this.options = options ?? {};\n        // NOTE: this was explicitly added for the add/remove user operations, it's likely\n        //       something we'd want to reconsider. Perhaps those commands can use `Admin`\n        //       as a parent?\n        const dbNameOverride = options?.dbName || options?.authdb;\n        if (dbNameOverride) {\n            this.ns = new utils_1.MongoDBNamespace(dbNameOverride, '$cmd');\n        }\n        else {\n            this.ns = parent\n                ? parent.s.namespace.withCollection('$cmd')\n                : new utils_1.MongoDBNamespace('admin', '$cmd');\n        }\n        this.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        this.writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            this.explain = explain_1.Explain.fromOptions(options);\n        }\n        else if (options?.explain != null) {\n            throw new error_1.MongoInvalidArgumentError(`Option \"explain\" is not supported on this command`);\n        }\n    }\n    get canRetryWrite() {\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE)) {\n            return this.explain == null;\n        }\n        return true;\n    }\n    async executeCommand(server, session, cmd) {\n        // TODO: consider making this a non-enumerable property\n        this.server = server;\n        const options = {\n            ...this.options,\n            ...this.bsonOptions,\n            readPreference: this.readPreference,\n            session\n        };\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const inTransaction = this.session && this.session.inTransaction();\n        if (this.readConcern && (0, utils_1.commandSupportsReadConcern)(cmd) && !inTransaction) {\n            Object.assign(cmd, { readConcern: this.readConcern });\n        }\n        if (this.trySecondaryWrite && serverWireVersion < server_selection_1.MIN_SECONDARY_WRITE_WIRE_VERSION) {\n            options.omitReadPreference = true;\n        }\n        if (this.writeConcern && this.hasAspect(operation_1.Aspect.WRITE_OPERATION) && !inTransaction) {\n            write_concern_1.WriteConcern.apply(cmd, this.writeConcern);\n        }\n        if (options.collation &&\n            typeof options.collation === 'object' &&\n            !this.hasAspect(operation_1.Aspect.SKIP_COLLATION)) {\n            Object.assign(cmd, { collation: options.collation });\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        if (this.hasAspect(operation_1.Aspect.EXPLAINABLE) && this.explain) {\n            cmd = (0, utils_1.decorateWithExplain)(cmd, this.explain);\n        }\n        return server.commandAsync(this.ns, cmd, options);\n    }\n}\nexports.CommandOperation = CommandOperation;\n//# sourceMappingURL=command.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/common_functions.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/common_functions.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.prepareDocs = exports.indexInformation = void 0;\nasync function indexInformation(db, name, options) {\n    if (options == null) {\n        options = {};\n    }\n    // If we specified full information\n    const full = options.full == null ? false : options.full;\n    // Get the list of indexes of the specified collection\n    const indexes = await db.collection(name).listIndexes(options).toArray();\n    if (full)\n        return indexes;\n    const info = {};\n    for (const index of indexes) {\n        info[index.name] = Object.entries(index.key);\n    }\n    return info;\n}\nexports.indexInformation = indexInformation;\nfunction prepareDocs(coll, docs, options) {\n    const forceServerObjectId = typeof options.forceServerObjectId === 'boolean'\n        ? options.forceServerObjectId\n        : coll.s.db.options?.forceServerObjectId;\n    // no need to modify the docs if server sets the ObjectId\n    if (forceServerObjectId === true) {\n        return docs;\n    }\n    return docs.map(doc => {\n        if (doc._id == null) {\n            doc._id = coll.s.pkFactory.createPk();\n        }\n        return doc;\n    });\n}\nexports.prepareDocs = prepareDocs;\n//# sourceMappingURL=common_functions.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/common_functions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CountOperation extends command_1.CommandOperation {\n    constructor(namespace, filter, options) {\n        super({ s: { namespace: namespace } }, options);\n        this.options = options;\n        this.collectionName = namespace.collection;\n        this.query = filter;\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const cmd = {\n            count: this.collectionName,\n            query: this.query\n        };\n        if (typeof options.limit === 'number') {\n            cmd.limit = options.limit;\n        }\n        if (typeof options.skip === 'number') {\n            cmd.skip = options.skip;\n        }\n        if (options.hint != null) {\n            cmd.hint = options.hint;\n        }\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        const result = await super.executeCommand(server, session, cmd);\n        return result ? result.n : 0;\n    }\n}\nexports.CountOperation = CountOperation;\n(0, operation_1.defineAspects)(CountOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=count.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/count_documents.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/count_documents.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CountDocumentsOperation = void 0;\nconst aggregate_1 = __webpack_require__(/*! ./aggregate */ \"./node_modules/mongodb/lib/operations/aggregate.js\");\n/** @internal */\nclass CountDocumentsOperation extends aggregate_1.AggregateOperation {\n    constructor(collection, query, options) {\n        const pipeline = [];\n        pipeline.push({ $match: query });\n        if (typeof options.skip === 'number') {\n            pipeline.push({ $skip: options.skip });\n        }\n        if (typeof options.limit === 'number') {\n            pipeline.push({ $limit: options.limit });\n        }\n        pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n        super(collection.s.namespace, pipeline, options);\n    }\n    async execute(server, session) {\n        const result = await super.execute(server, session);\n        // NOTE: We're avoiding creating a cursor here to reduce the callstack.\n        const response = result;\n        if (response.cursor == null || response.cursor.firstBatch == null) {\n            return 0;\n        }\n        const docs = response.cursor.firstBatch;\n        return docs.length ? docs[0].n : 0;\n    }\n}\nexports.CountDocumentsOperation = CountDocumentsOperation;\n//# sourceMappingURL=count_documents.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/count_documents.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/create_collection.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/create_collection.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateCollectionOperation = void 0;\nconst constants_1 = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst indexes_1 = __webpack_require__(/*! ./indexes */ \"./node_modules/mongodb/lib/operations/indexes.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst ILLEGAL_COMMAND_FIELDS = new Set([\n    'w',\n    'wtimeout',\n    'j',\n    'fsync',\n    'autoIndexId',\n    'pkFactory',\n    'raw',\n    'readPreference',\n    'session',\n    'readConcern',\n    'writeConcern',\n    'raw',\n    'fieldsAsRaw',\n    'useBigInt64',\n    'promoteLongs',\n    'promoteValues',\n    'promoteBuffers',\n    'bsonRegExp',\n    'serializeFunctions',\n    'ignoreUndefined',\n    'enableUtf8Validation'\n]);\n/* @internal */\nconst INVALID_QE_VERSION = 'Driver support of Queryable Encryption is incompatible with server. Upgrade server to use Queryable Encryption.';\n/** @internal */\nclass CreateCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.options = options;\n        this.db = db;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const encryptedFields = options.encryptedFields ??\n            db.client.options.autoEncryption?.encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (encryptedFields) {\n            // Creating a QE collection required min server of 7.0.0\n            // TODO(NODE-5353): Get wire version information from connection.\n            if (!server.loadBalanced &&\n                server.description.maxWireVersion < constants_1.MIN_SUPPORTED_QE_WIRE_VERSION) {\n                throw new error_1.MongoCompatibilityError(`${INVALID_QE_VERSION} The minimum server version required is ${constants_1.MIN_SUPPORTED_QE_SERVER_VERSION}`);\n            }\n            // Create auxilliary collections for queryable encryption support.\n            const escCollection = encryptedFields.escCollection ?? `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection ?? `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                const createOp = new CreateCollectionOperation(db, collectionName, {\n                    clusteredIndex: {\n                        key: { _id: 1 },\n                        unique: true\n                    }\n                });\n                await createOp.executeWithoutEncryptedFieldsCheck(server, session);\n            }\n            if (!options.encryptedFields) {\n                this.options = { ...this.options, encryptedFields };\n            }\n        }\n        const coll = await this.executeWithoutEncryptedFieldsCheck(server, session);\n        if (encryptedFields) {\n            // Create the required index for queryable encryption support.\n            const createIndexOp = new indexes_1.CreateIndexOperation(db, name, { __safeContent__: 1 }, {});\n            await createIndexOp.execute(server, session);\n        }\n        return coll;\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        const db = this.db;\n        const name = this.name;\n        const options = this.options;\n        const cmd = { create: name };\n        for (const n in options) {\n            if (options[n] != null &&\n                typeof options[n] !== 'function' &&\n                !ILLEGAL_COMMAND_FIELDS.has(n)) {\n                cmd[n] = options[n];\n            }\n        }\n        // otherwise just execute the command\n        await super.executeCommand(server, session, cmd);\n        return new collection_1.Collection(db, name, options);\n    }\n}\nexports.CreateCollectionOperation = CreateCollectionOperation;\n(0, operation_1.defineAspects)(CreateCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=create_collection.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/create_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/delete.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/delete.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeDeleteStatement = exports.DeleteManyOperation = exports.DeleteOneOperation = exports.DeleteOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DeleteOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => (op.limit != null ? op.limit > 0 : true));\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            delete: this.ns.collection,\n            deletes: this.statements,\n            ordered\n        };\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.DeleteOperation = DeleteOperation;\nclass DeleteOneOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, { ...options, limit: 1 })], options);\n    }\n    async execute(server, session) {\n        const res = (await super.execute(server, session));\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteOneOperation = DeleteOneOperation;\nclass DeleteManyOperation extends DeleteOperation {\n    constructor(collection, filter, options) {\n        super(collection.s.namespace, [makeDeleteStatement(filter, options)], options);\n    }\n    async execute(server, session) {\n        const res = (await super.execute(server, session));\n        if (this.explain)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            deletedCount: res.n\n        };\n    }\n}\nexports.DeleteManyOperation = DeleteManyOperation;\nfunction makeDeleteStatement(filter, options) {\n    const op = {\n        q: filter,\n        limit: typeof options.limit === 'number' ? options.limit : 0\n    };\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    return op;\n}\nexports.makeDeleteStatement = makeDeleteStatement;\n(0, operation_1.defineAspects)(DeleteOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DeleteOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(DeleteManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=delete.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/delete.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/distinct.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/distinct.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DistinctOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * Return a list of distinct values for the given key across a collection.\n * @internal\n */\nclass DistinctOperation extends command_1.CommandOperation {\n    /**\n     * Construct a Distinct operation.\n     *\n     * @param collection - Collection instance.\n     * @param key - Field of the document to find distinct values for.\n     * @param query - The query for filtering the set of documents to which we apply the distinct filter.\n     * @param options - Optional settings. See Collection.prototype.distinct for a list of options.\n     */\n    constructor(collection, key, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.key = key;\n        this.query = query;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const key = this.key;\n        const query = this.query;\n        const options = this.options;\n        // Distinct command\n        const cmd = {\n            distinct: coll.collectionName,\n            key: key,\n            query: query\n        };\n        // Add maxTimeMS if defined\n        if (typeof options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (typeof options.comment !== 'undefined') {\n            cmd.comment = options.comment;\n        }\n        // Do we have a readConcern specified\n        (0, utils_1.decorateWithReadConcern)(cmd, coll, options);\n        // Have we specified collation\n        (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        const result = await super.executeCommand(server, session, cmd);\n        return this.explain ? result : result.values;\n    }\n}\nexports.DistinctOperation = DistinctOperation;\n(0, operation_1.defineAspects)(DistinctOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE, operation_1.Aspect.EXPLAINABLE]);\n//# sourceMappingURL=distinct.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/distinct.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/drop.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/drop.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropDatabaseOperation = exports.DropCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropCollectionOperation extends command_1.CommandOperation {\n    constructor(db, name, options = {}) {\n        super(db, options);\n        this.db = db;\n        this.options = options;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const options = this.options;\n        const name = this.name;\n        const encryptedFieldsMap = db.client.options.autoEncryption?.encryptedFieldsMap;\n        let encryptedFields = options.encryptedFields ?? encryptedFieldsMap?.[`${db.databaseName}.${name}`];\n        if (!encryptedFields && encryptedFieldsMap) {\n            // If the MongoClient was configured with an encryptedFieldsMap,\n            // and no encryptedFields config was available in it or explicitly\n            // passed as an argument, the spec tells us to look one up using\n            // listCollections().\n            const listCollectionsResult = await db\n                .listCollections({ name }, { nameOnly: false })\n                .toArray();\n            encryptedFields = listCollectionsResult?.[0]?.options?.encryptedFields;\n        }\n        if (encryptedFields) {\n            const escCollection = encryptedFields.escCollection || `enxcol_.${name}.esc`;\n            const ecocCollection = encryptedFields.ecocCollection || `enxcol_.${name}.ecoc`;\n            for (const collectionName of [escCollection, ecocCollection]) {\n                // Drop auxilliary collections, ignoring potential NamespaceNotFound errors.\n                const dropOp = new DropCollectionOperation(db, collectionName);\n                try {\n                    await dropOp.executeWithoutEncryptedFieldsCheck(server, session);\n                }\n                catch (err) {\n                    if (!(err instanceof error_1.MongoServerError) ||\n                        err.code !== error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n                        throw err;\n                    }\n                }\n            }\n        }\n        return this.executeWithoutEncryptedFieldsCheck(server, session);\n    }\n    async executeWithoutEncryptedFieldsCheck(server, session) {\n        await super.executeCommand(server, session, { drop: this.name });\n        return true;\n    }\n}\nexports.DropCollectionOperation = DropCollectionOperation;\n/** @internal */\nclass DropDatabaseOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropDatabase: 1 });\n        return true;\n    }\n}\nexports.DropDatabaseOperation = DropDatabaseOperation;\n(0, operation_1.defineAspects)(DropCollectionOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropDatabaseOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/estimated_document_count.js":
/*!*************************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/estimated_document_count.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EstimatedDocumentCountOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass EstimatedDocumentCountOperation extends command_1.CommandOperation {\n    constructor(collection, options = {}) {\n        super(collection, options);\n        this.options = options;\n        this.collectionName = collection.collectionName;\n    }\n    async execute(server, session) {\n        const cmd = { count: this.collectionName };\n        if (typeof this.options.maxTimeMS === 'number') {\n            cmd.maxTimeMS = this.options.maxTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        const response = await super.executeCommand(server, session, cmd);\n        return response?.n || 0;\n    }\n}\nexports.EstimatedDocumentCountOperation = EstimatedDocumentCountOperation;\n(0, operation_1.defineAspects)(EstimatedDocumentCountOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=estimated_document_count.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/estimated_document_count.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/execute_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/execute_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.executeOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst server_selection_1 = __webpack_require__(/*! ../sdam/server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst MMAPv1_RETRY_WRITES_ERROR_CODE = error_1.MONGODB_ERROR_CODES.IllegalOperation;\nconst MMAPv1_RETRY_WRITES_ERROR_MESSAGE = 'This MongoDB deployment does not support retryable writes. Please add retryWrites=false to your connection string.';\nfunction executeOperation(client, operation, callback) {\n    return (0, utils_1.maybeCallback)(() => executeOperationAsync(client, operation), callback);\n}\nexports.executeOperation = executeOperation;\nasync function executeOperationAsync(client, operation) {\n    if (!(operation instanceof operation_1.AbstractOperation)) {\n        // TODO(NODE-3483): Extend MongoRuntimeError\n        throw new error_1.MongoRuntimeError('This method requires a valid operation instance');\n    }\n    if (client.topology == null) {\n        // Auto connect on operation\n        if (client.s.hasBeenClosed) {\n            throw new error_1.MongoNotConnectedError('Client must be connected before running operations');\n        }\n        client.s.options[Symbol.for('@@mdb.skipPingOnConnect')] = true;\n        try {\n            await client.connect();\n        }\n        finally {\n            delete client.s.options[Symbol.for('@@mdb.skipPingOnConnect')];\n        }\n    }\n    const { topology } = client;\n    if (topology == null) {\n        throw new error_1.MongoRuntimeError('client.connect did not create a topology but also did not throw');\n    }\n    // The driver sessions spec mandates that we implicitly create sessions for operations\n    // that are not explicitly provided with a session.\n    let session = operation.session;\n    let owner;\n    if (session == null) {\n        owner = Symbol();\n        session = client.startSession({ owner, explicit: false });\n    }\n    else if (session.hasEnded) {\n        throw new error_1.MongoExpiredSessionError('Use of expired sessions is not permitted');\n    }\n    else if (session.snapshotEnabled && !topology.capabilities.supportsSnapshotReads) {\n        throw new error_1.MongoCompatibilityError('Snapshot reads require MongoDB 5.0 or later');\n    }\n    else if (session.client !== client) {\n        throw new error_1.MongoInvalidArgumentError('ClientSession must be from the same MongoClient');\n    }\n    const readPreference = operation.readPreference ?? read_preference_1.ReadPreference.primary;\n    const inTransaction = !!session?.inTransaction();\n    if (inTransaction && !readPreference.equals(read_preference_1.ReadPreference.primary)) {\n        throw new error_1.MongoTransactionError(`Read preference in a transaction must be primary, not: ${readPreference.mode}`);\n    }\n    if (session?.isPinned && session.transaction.isCommitted && !operation.bypassPinningCheck) {\n        session.unpin();\n    }\n    let selector;\n    if (operation.hasAspect(operation_1.Aspect.MUST_SELECT_SAME_SERVER)) {\n        // GetMore and KillCursor operations must always select the same server, but run through\n        // server selection to potentially force monitor checks if the server is\n        // in an unknown state.\n        selector = (0, server_selection_1.sameServerSelector)(operation.server?.description);\n    }\n    else if (operation.trySecondaryWrite) {\n        // If operation should try to write to secondary use the custom server selector\n        // otherwise provide the read preference.\n        selector = (0, server_selection_1.secondaryWritableServerSelector)(topology.commonWireVersion, readPreference);\n    }\n    else {\n        selector = readPreference;\n    }\n    const server = await topology.selectServerAsync(selector, { session });\n    if (session == null) {\n        // No session also means it is not retryable, early exit\n        return operation.execute(server, undefined);\n    }\n    if (!operation.hasAspect(operation_1.Aspect.RETRYABLE)) {\n        // non-retryable operation, early exit\n        try {\n            return await operation.execute(server, session);\n        }\n        finally {\n            if (session?.owner != null && session.owner === owner) {\n                await session.endSession().catch(() => null);\n            }\n        }\n    }\n    const willRetryRead = topology.s.options.retryReads && !inTransaction && operation.canRetryRead;\n    const willRetryWrite = topology.s.options.retryWrites &&\n        !inTransaction &&\n        (0, utils_1.supportsRetryableWrites)(server) &&\n        operation.canRetryWrite;\n    const hasReadAspect = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    const hasWriteAspect = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    const willRetry = (hasReadAspect && willRetryRead) || (hasWriteAspect && willRetryWrite);\n    if (hasWriteAspect && willRetryWrite) {\n        operation.options.willRetryWrite = true;\n        session.incrementTransactionNumber();\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (operationError) {\n        if (willRetry && operationError instanceof error_1.MongoError) {\n            return await retryOperation(operation, operationError, {\n                session,\n                topology,\n                selector\n            });\n        }\n        throw operationError;\n    }\n    finally {\n        if (session?.owner != null && session.owner === owner) {\n            await session.endSession().catch(() => null);\n        }\n    }\n}\nasync function retryOperation(operation, originalError, { session, topology, selector }) {\n    const isWriteOperation = operation.hasAspect(operation_1.Aspect.WRITE_OPERATION);\n    const isReadOperation = operation.hasAspect(operation_1.Aspect.READ_OPERATION);\n    if (isWriteOperation && originalError.code === MMAPv1_RETRY_WRITES_ERROR_CODE) {\n        throw new error_1.MongoServerError({\n            message: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            errmsg: MMAPv1_RETRY_WRITES_ERROR_MESSAGE,\n            originalError\n        });\n    }\n    if (isWriteOperation && !(0, error_1.isRetryableWriteError)(originalError)) {\n        throw originalError;\n    }\n    if (isReadOperation && !(0, error_1.isRetryableReadError)(originalError)) {\n        throw originalError;\n    }\n    if (originalError instanceof error_1.MongoNetworkError &&\n        session.isPinned &&\n        !session.inTransaction() &&\n        operation.hasAspect(operation_1.Aspect.CURSOR_CREATING)) {\n        // If we have a cursor and the initial command fails with a network error,\n        // we can retry it on another connection. So we need to check it back in, clear the\n        // pool for the service id, and retry again.\n        session.unpin({ force: true, forceClear: true });\n    }\n    // select a new server, and attempt to retry the operation\n    const server = await topology.selectServerAsync(selector, { session });\n    if (isWriteOperation && !(0, utils_1.supportsRetryableWrites)(server)) {\n        throw new error_1.MongoUnexpectedServerResponseError('Selected server does not support retryable writes');\n    }\n    try {\n        return await operation.execute(server, session);\n    }\n    catch (retryError) {\n        if (retryError instanceof error_1.MongoError &&\n            retryError.hasErrorLabel(error_1.MongoErrorLabel.NoWritesPerformed)) {\n            throw originalError;\n        }\n        throw retryError;\n    }\n}\n//# sourceMappingURL=execute_operation.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/execute_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ../read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass FindOperation extends command_1.CommandOperation {\n    constructor(collection, ns, filter = {}, options = {}) {\n        super(collection, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.ns = ns;\n        if (typeof filter !== 'object' || Array.isArray(filter)) {\n            throw new error_1.MongoInvalidArgumentError('Query filter must be a plain object or ObjectId');\n        }\n        // special case passing in an ObjectId as a filter\n        this.filter = filter != null && filter._bsontype === 'ObjectId' ? { _id: filter } : filter;\n    }\n    async execute(server, session) {\n        this.server = server;\n        const options = this.options;\n        let findCommand = makeFindCommand(this.ns, this.filter, options);\n        if (this.explain) {\n            findCommand = (0, utils_1.decorateWithExplain)(findCommand, this.explain);\n        }\n        return server.commandAsync(this.ns, findCommand, {\n            ...this.options,\n            ...this.bsonOptions,\n            documentsReturnedIn: 'firstBatch',\n            session\n        });\n    }\n}\nexports.FindOperation = FindOperation;\nfunction makeFindCommand(ns, filter, options) {\n    const findCommand = {\n        find: ns.collection,\n        filter\n    };\n    if (options.sort) {\n        findCommand.sort = (0, sort_1.formatSort)(options.sort);\n    }\n    if (options.projection) {\n        let projection = options.projection;\n        if (projection && Array.isArray(projection)) {\n            projection = projection.length\n                ? projection.reduce((result, field) => {\n                    result[field] = 1;\n                    return result;\n                }, {})\n                : { _id: 1 };\n        }\n        findCommand.projection = projection;\n    }\n    if (options.hint) {\n        findCommand.hint = (0, utils_1.normalizeHintField)(options.hint);\n    }\n    if (typeof options.skip === 'number') {\n        findCommand.skip = options.skip;\n    }\n    if (typeof options.limit === 'number') {\n        if (options.limit < 0) {\n            findCommand.limit = -options.limit;\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.limit = options.limit;\n        }\n    }\n    if (typeof options.batchSize === 'number') {\n        if (options.batchSize < 0) {\n            if (options.limit &&\n                options.limit !== 0 &&\n                Math.abs(options.batchSize) < Math.abs(options.limit)) {\n                findCommand.limit = -options.batchSize;\n            }\n            findCommand.singleBatch = true;\n        }\n        else {\n            findCommand.batchSize = options.batchSize;\n        }\n    }\n    if (typeof options.singleBatch === 'boolean') {\n        findCommand.singleBatch = options.singleBatch;\n    }\n    // we check for undefined specifically here to allow falsy values\n    // eslint-disable-next-line no-restricted-syntax\n    if (options.comment !== undefined) {\n        findCommand.comment = options.comment;\n    }\n    if (typeof options.maxTimeMS === 'number') {\n        findCommand.maxTimeMS = options.maxTimeMS;\n    }\n    const readConcern = read_concern_1.ReadConcern.fromOptions(options);\n    if (readConcern) {\n        findCommand.readConcern = readConcern.toJSON();\n    }\n    if (options.max) {\n        findCommand.max = options.max;\n    }\n    if (options.min) {\n        findCommand.min = options.min;\n    }\n    if (typeof options.returnKey === 'boolean') {\n        findCommand.returnKey = options.returnKey;\n    }\n    if (typeof options.showRecordId === 'boolean') {\n        findCommand.showRecordId = options.showRecordId;\n    }\n    if (typeof options.tailable === 'boolean') {\n        findCommand.tailable = options.tailable;\n    }\n    if (typeof options.oplogReplay === 'boolean') {\n        findCommand.oplogReplay = options.oplogReplay;\n    }\n    if (typeof options.timeout === 'boolean') {\n        findCommand.noCursorTimeout = !options.timeout;\n    }\n    else if (typeof options.noCursorTimeout === 'boolean') {\n        findCommand.noCursorTimeout = options.noCursorTimeout;\n    }\n    if (typeof options.awaitData === 'boolean') {\n        findCommand.awaitData = options.awaitData;\n    }\n    if (typeof options.allowPartialResults === 'boolean') {\n        findCommand.allowPartialResults = options.allowPartialResults;\n    }\n    if (options.collation) {\n        findCommand.collation = options.collation;\n    }\n    if (typeof options.allowDiskUse === 'boolean') {\n        findCommand.allowDiskUse = options.allowDiskUse;\n    }\n    if (options.let) {\n        findCommand.let = options.let;\n    }\n    return findCommand;\n}\n(0, operation_1.defineAspects)(FindOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=find.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/find.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/find_and_modify.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/find_and_modify.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FindOneAndUpdateOperation = exports.FindOneAndReplaceOperation = exports.FindOneAndDeleteOperation = exports.ReturnDocument = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst sort_1 = __webpack_require__(/*! ../sort */ \"./node_modules/mongodb/lib/sort.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @public */\nexports.ReturnDocument = Object.freeze({\n    BEFORE: 'before',\n    AFTER: 'after'\n});\nfunction configureFindAndModifyCmdBaseUpdateOpts(cmdBase, options) {\n    cmdBase.new = options.returnDocument === exports.ReturnDocument.AFTER;\n    cmdBase.upsert = options.upsert === true;\n    if (options.bypassDocumentValidation === true) {\n        cmdBase.bypassDocumentValidation = options.bypassDocumentValidation;\n    }\n    return cmdBase;\n}\n/** @internal */\nclass FindAndModifyOperation extends command_1.CommandOperation {\n    constructor(collection, query, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.cmdBase = {\n            remove: false,\n            new: false,\n            upsert: false\n        };\n        options.includeResultMetadata ??= false;\n        const sort = (0, sort_1.formatSort)(options.sort);\n        if (sort) {\n            this.cmdBase.sort = sort;\n        }\n        if (options.projection) {\n            this.cmdBase.fields = options.projection;\n        }\n        if (options.maxTimeMS) {\n            this.cmdBase.maxTimeMS = options.maxTimeMS;\n        }\n        // Decorate the findAndModify command with the write Concern\n        if (options.writeConcern) {\n            this.cmdBase.writeConcern = options.writeConcern;\n        }\n        if (options.let) {\n            this.cmdBase.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            this.cmdBase.comment = options.comment;\n        }\n        // force primary read preference\n        this.readPreference = read_preference_1.ReadPreference.primary;\n        this.collection = collection;\n        this.query = query;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const query = this.query;\n        const options = { ...this.options, ...this.bsonOptions };\n        // Create findAndModify command object\n        const cmd = {\n            findAndModify: coll.collectionName,\n            query: query,\n            ...this.cmdBase\n        };\n        // Have we specified collation\n        try {\n            (0, utils_1.decorateWithCollation)(cmd, coll, options);\n        }\n        catch (err) {\n            return err;\n        }\n        if (options.hint) {\n            // TODO: once this method becomes a CommandOperation we will have the server\n            // in place to check.\n            const unacknowledgedWrite = this.writeConcern?.w === 0;\n            if (unacknowledgedWrite || (0, utils_1.maxWireVersion)(server) < 8) {\n                throw new error_1.MongoCompatibilityError('The current topology does not support a hint on findAndModify commands');\n            }\n            cmd.hint = options.hint;\n        }\n        // Execute the command\n        const result = await super.executeCommand(server, session, cmd);\n        return options.includeResultMetadata ? result : result.value ?? null;\n    }\n}\n/** @internal */\nclass FindOneAndDeleteOperation extends FindAndModifyOperation {\n    constructor(collection, filter, options) {\n        // Basic validation\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        super(collection, filter, options);\n        this.cmdBase.remove = true;\n    }\n}\nexports.FindOneAndDeleteOperation = FindOneAndDeleteOperation;\n/** @internal */\nclass FindOneAndReplaceOperation extends FindAndModifyOperation {\n    constructor(collection, filter, replacement, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (replacement == null || typeof replacement !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"replacement\" must be an object');\n        }\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = replacement;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n    }\n}\nexports.FindOneAndReplaceOperation = FindOneAndReplaceOperation;\n/** @internal */\nclass FindOneAndUpdateOperation extends FindAndModifyOperation {\n    constructor(collection, filter, update, options) {\n        if (filter == null || typeof filter !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"filter\" must be an object');\n        }\n        if (update == null || typeof update !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('Argument \"update\" must be an object');\n        }\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        super(collection, filter, options);\n        this.cmdBase.update = update;\n        configureFindAndModifyCmdBaseUpdateOpts(this.cmdBase, options);\n        if (options.arrayFilters) {\n            this.cmdBase.arrayFilters = options.arrayFilters;\n        }\n    }\n}\nexports.FindOneAndUpdateOperation = FindOneAndUpdateOperation;\n(0, operation_1.defineAspects)(FindAndModifyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.EXPLAINABLE\n]);\n//# sourceMappingURL=find_and_modify.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/find_and_modify.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/get_more.js":
/*!*********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/get_more.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.GetMoreOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass GetMoreOperation extends operation_1.AbstractOperation {\n    constructor(ns, cursorId, server, options) {\n        super(options);\n        this.options = options;\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    /**\n     * Although there is a server already associated with the get more operation, the signature\n     * for execute passes a server so we will just use that one.\n     */\n    async execute(server, _session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Getmore must run on the same server operation began on');\n        }\n        if (this.cursorId == null || this.cursorId.isZero()) {\n            throw new error_1.MongoRuntimeError('Unable to iterate cursor with no id');\n        }\n        const collection = this.ns.collection;\n        if (collection == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before getMore');\n        }\n        const getMoreCmd = {\n            getMore: this.cursorId,\n            collection\n        };\n        if (typeof this.options.batchSize === 'number') {\n            getMoreCmd.batchSize = Math.abs(this.options.batchSize);\n        }\n        if (typeof this.options.maxAwaitTimeMS === 'number') {\n            getMoreCmd.maxTimeMS = this.options.maxAwaitTimeMS;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (this.options.comment !== undefined && (0, utils_1.maxWireVersion)(server) >= 9) {\n            getMoreCmd.comment = this.options.comment;\n        }\n        const commandOptions = {\n            returnFieldSelector: null,\n            documentsReturnedIn: 'nextBatch',\n            ...this.options\n        };\n        return server.commandAsync(this.ns, getMoreCmd, commandOptions);\n    }\n}\nexports.GetMoreOperation = GetMoreOperation;\n(0, operation_1.defineAspects)(GetMoreOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=get_more.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/get_more.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/indexes.js":
/*!********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/indexes.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IndexInformationOperation = exports.IndexExistsOperation = exports.ListIndexesOperation = exports.DropIndexOperation = exports.EnsureIndexOperation = exports.CreateIndexOperation = exports.CreateIndexesOperation = exports.IndexesOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst common_functions_1 = __webpack_require__(/*! ./common_functions */ \"./node_modules/mongodb/lib/operations/common_functions.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nconst VALID_INDEX_OPTIONS = new Set([\n    'background',\n    'unique',\n    'name',\n    'partialFilterExpression',\n    'sparse',\n    'hidden',\n    'expireAfterSeconds',\n    'storageEngine',\n    'collation',\n    'version',\n    // text indexes\n    'weights',\n    'default_language',\n    'language_override',\n    'textIndexVersion',\n    // 2d-sphere indexes\n    '2dsphereIndexVersion',\n    // 2d indexes\n    'bits',\n    'min',\n    'max',\n    // geoHaystack Indexes\n    'bucketSize',\n    // wildcard indexes\n    'wildcardProjection'\n]);\nfunction isIndexDirection(x) {\n    return (typeof x === 'number' || x === '2d' || x === '2dsphere' || x === 'text' || x === 'geoHaystack');\n}\nfunction isSingleIndexTuple(t) {\n    return Array.isArray(t) && t.length === 2 && isIndexDirection(t[1]);\n}\nfunction makeIndexSpec(indexSpec, options) {\n    const key = new Map();\n    const indexSpecs = !Array.isArray(indexSpec) || isSingleIndexTuple(indexSpec) ? [indexSpec] : indexSpec;\n    // Iterate through array and handle different types\n    for (const spec of indexSpecs) {\n        if (typeof spec === 'string') {\n            key.set(spec, 1);\n        }\n        else if (Array.isArray(spec)) {\n            key.set(spec[0], spec[1] ?? 1);\n        }\n        else if (spec instanceof Map) {\n            for (const [property, value] of spec) {\n                key.set(property, value);\n            }\n        }\n        else if ((0, utils_1.isObject)(spec)) {\n            for (const [property, value] of Object.entries(spec)) {\n                key.set(property, value);\n            }\n        }\n    }\n    return { ...options, key };\n}\n/** @internal */\nclass IndexesOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(_server, session) {\n        const coll = this.collection;\n        const options = this.options;\n        return (0, common_functions_1.indexInformation)(coll.s.db, coll.collectionName, {\n            full: true,\n            ...options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.IndexesOperation = IndexesOperation;\n/** @internal */\nclass CreateIndexesOperation extends command_1.CommandOperation {\n    constructor(parent, collectionName, indexes, options) {\n        super(parent, options);\n        this.options = options ?? {};\n        this.collectionName = collectionName;\n        this.indexes = indexes.map(userIndex => {\n            // Ensure the key is a Map to preserve index key ordering\n            const key = userIndex.key instanceof Map ? userIndex.key : new Map(Object.entries(userIndex.key));\n            const name = userIndex.name != null ? userIndex.name : Array.from(key).flat().join('_');\n            const validIndexOptions = Object.fromEntries(Object.entries({ ...userIndex }).filter(([optionName]) => VALID_INDEX_OPTIONS.has(optionName)));\n            return {\n                ...validIndexOptions,\n                name,\n                key\n            };\n        });\n    }\n    async execute(server, session) {\n        const options = this.options;\n        const indexes = this.indexes;\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cmd = { createIndexes: this.collectionName, indexes };\n        if (options.commitQuorum != null) {\n            if (serverWireVersion < 9) {\n                throw new error_1.MongoCompatibilityError('Option `commitQuorum` for `createIndexes` not supported on servers < 4.4');\n            }\n            cmd.commitQuorum = options.commitQuorum;\n        }\n        // collation is set on each index, it should not be defined at the root\n        this.options.collation = undefined;\n        await super.executeCommand(server, session, cmd);\n        const indexNames = indexes.map(index => index.name || '');\n        return indexNames;\n    }\n}\nexports.CreateIndexesOperation = CreateIndexesOperation;\n/** @internal */\nclass CreateIndexOperation extends CreateIndexesOperation {\n    constructor(parent, collectionName, indexSpec, options) {\n        super(parent, collectionName, [makeIndexSpec(indexSpec, options)], options);\n    }\n    async execute(server, session) {\n        const indexNames = await super.execute(server, session);\n        return indexNames[0];\n    }\n}\nexports.CreateIndexOperation = CreateIndexOperation;\n/** @internal */\nclass EnsureIndexOperation extends CreateIndexOperation {\n    constructor(db, collectionName, indexSpec, options) {\n        super(db, collectionName, indexSpec, options);\n        this.readPreference = read_preference_1.ReadPreference.primary;\n        this.db = db;\n        this.collectionName = collectionName;\n    }\n    async execute(server, session) {\n        const indexName = this.indexes[0].name;\n        const indexes = await this.db\n            .collection(this.collectionName)\n            .listIndexes({ session })\n            .toArray()\n            .catch(error => {\n            if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)\n                return [];\n            throw error;\n        });\n        if (indexName && indexes.some(index => index.name === indexName))\n            return indexName;\n        return super.execute(server, session);\n    }\n}\nexports.EnsureIndexOperation = EnsureIndexOperation;\n/** @internal */\nclass DropIndexOperation extends command_1.CommandOperation {\n    constructor(collection, indexName, options) {\n        super(collection, options);\n        this.options = options ?? {};\n        this.collection = collection;\n        this.indexName = indexName;\n    }\n    async execute(server, session) {\n        const cmd = { dropIndexes: this.collection.collectionName, index: this.indexName };\n        return super.executeCommand(server, session, cmd);\n    }\n}\nexports.DropIndexOperation = DropIndexOperation;\n/** @internal */\nclass ListIndexesOperation extends command_1.CommandOperation {\n    constructor(collection, options) {\n        super(collection, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.collectionNamespace = collection.s.namespace;\n    }\n    async execute(server, session) {\n        const serverWireVersion = (0, utils_1.maxWireVersion)(server);\n        const cursor = this.options.batchSize ? { batchSize: this.options.batchSize } : {};\n        const command = { listIndexes: this.collectionNamespace.collection, cursor };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (serverWireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.ListIndexesOperation = ListIndexesOperation;\n/** @internal */\nclass IndexExistsOperation extends operation_1.AbstractOperation {\n    constructor(collection, indexes, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n        this.indexes = indexes;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const indexes = this.indexes;\n        const info = await (0, common_functions_1.indexInformation)(coll.s.db, coll.collectionName, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n        // Let's check for the index names\n        if (!Array.isArray(indexes))\n            return info[indexes] != null;\n        // All keys found return true\n        return indexes.every(indexName => info[indexName] != null);\n    }\n}\nexports.IndexExistsOperation = IndexExistsOperation;\n/** @internal */\nclass IndexInformationOperation extends operation_1.AbstractOperation {\n    constructor(db, name, options) {\n        super(options);\n        this.options = options ?? {};\n        this.db = db;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const db = this.db;\n        const name = this.name;\n        return (0, common_functions_1.indexInformation)(db, name, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.IndexInformationOperation = IndexInformationOperation;\n(0, operation_1.defineAspects)(ListIndexesOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n(0, operation_1.defineAspects)(CreateIndexesOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(CreateIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(EnsureIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(DropIndexOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=indexes.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/indexes.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/insert.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/insert.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.InsertManyOperation = exports.InsertOneOperation = exports.InsertOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst write_concern_1 = __webpack_require__(/*! ../write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst bulk_write_1 = __webpack_require__(/*! ./bulk_write */ \"./node_modules/mongodb/lib/operations/bulk_write.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst common_functions_1 = __webpack_require__(/*! ./common_functions */ \"./node_modules/mongodb/lib/operations/common_functions.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass InsertOperation extends command_1.CommandOperation {\n    constructor(ns, documents, options) {\n        super(undefined, options);\n        this.options = { ...options, checkKeys: options.checkKeys ?? false };\n        this.ns = ns;\n        this.documents = documents;\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            insert: this.ns.collection,\n            documents: this.documents,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.InsertOperation = InsertOperation;\nclass InsertOneOperation extends InsertOperation {\n    constructor(collection, doc, options) {\n        super(collection.s.namespace, (0, common_functions_1.prepareDocs)(collection, [doc], options), options);\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors) {\n            // This should be a WriteError but we can't change it now because of error hierarchy\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        }\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            insertedId: this.documents[0]._id\n        };\n    }\n}\nexports.InsertOneOperation = InsertOneOperation;\n/** @internal */\nclass InsertManyOperation extends operation_1.AbstractOperation {\n    constructor(collection, docs, options) {\n        super(options);\n        if (!Array.isArray(docs)) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"docs\" must be an array of documents');\n        }\n        this.options = options;\n        this.collection = collection;\n        this.docs = docs;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const options = { ...this.options, ...this.bsonOptions, readPreference: this.readPreference };\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        const bulkWriteOperation = new bulk_write_1.BulkWriteOperation(coll, (0, common_functions_1.prepareDocs)(coll, this.docs, options).map(document => ({ insertOne: { document } })), options);\n        try {\n            const res = await bulkWriteOperation.execute(server, session);\n            return {\n                acknowledged: writeConcern?.w !== 0,\n                insertedCount: res.insertedCount,\n                insertedIds: res.insertedIds\n            };\n        }\n        catch (err) {\n            if (err && err.message === 'Operation must be an object with an operation key') {\n                throw new error_1.MongoInvalidArgumentError('Collection.insertMany() cannot be called with an array that has null/undefined values');\n            }\n            throw err;\n        }\n    }\n}\nexports.InsertManyOperation = InsertManyOperation;\n(0, operation_1.defineAspects)(InsertOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertOneOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION]);\n(0, operation_1.defineAspects)(InsertManyOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=insert.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/insert.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/is_capped.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/is_capped.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.IsCappedOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass IsCappedOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return !!collection.options?.capped;\n    }\n}\nexports.IsCappedOperation = IsCappedOperation;\n//# sourceMappingURL=is_capped.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/is_capped.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/kill_cursors.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/kill_cursors.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.KillCursorsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\nclass KillCursorsOperation extends operation_1.AbstractOperation {\n    constructor(cursorId, ns, server, options) {\n        super(options);\n        this.ns = ns;\n        this.cursorId = cursorId;\n        this.server = server;\n    }\n    async execute(server, session) {\n        if (server !== this.server) {\n            throw new error_1.MongoRuntimeError('Killcursor must run on the same server operation began on');\n        }\n        const killCursors = this.ns.collection;\n        if (killCursors == null) {\n            // Cursors should have adopted the namespace returned by MongoDB\n            // which should always defined a collection name (even a pseudo one, ex. db.aggregate())\n            throw new error_1.MongoRuntimeError('A collection name must be determined before killCursors');\n        }\n        const killCursorsCommand = {\n            killCursors,\n            cursors: [this.cursorId]\n        };\n        try {\n            await server.commandAsync(this.ns, killCursorsCommand, { session });\n        }\n        catch {\n            // The driver should never emit errors from killCursors, this is spec-ed behavior\n        }\n    }\n}\nexports.KillCursorsOperation = KillCursorsOperation;\n(0, operation_1.defineAspects)(KillCursorsOperation, [operation_1.Aspect.MUST_SELECT_SAME_SERVER]);\n//# sourceMappingURL=kill_cursors.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/kill_cursors.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_collections.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_collections.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListCollectionsOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListCollectionsOperation extends command_1.CommandOperation {\n    constructor(db, filter, options) {\n        super(db, options);\n        this.options = { ...options };\n        delete this.options.writeConcern;\n        this.db = db;\n        this.filter = filter;\n        this.nameOnly = !!this.options.nameOnly;\n        this.authorizedCollections = !!this.options.authorizedCollections;\n        if (typeof this.options.batchSize === 'number') {\n            this.batchSize = this.options.batchSize;\n        }\n    }\n    async execute(server, session) {\n        return super.executeCommand(server, session, this.generateCommand((0, utils_1.maxWireVersion)(server)));\n    }\n    /* This is here for the purpose of unit testing the final command that gets sent. */\n    generateCommand(wireVersion) {\n        const command = {\n            listCollections: 1,\n            filter: this.filter,\n            cursor: this.batchSize ? { batchSize: this.batchSize } : {},\n            nameOnly: this.nameOnly,\n            authorizedCollections: this.authorizedCollections\n        };\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (wireVersion >= 9 && this.options.comment !== undefined) {\n            command.comment = this.options.comment;\n        }\n        return command;\n    }\n}\nexports.ListCollectionsOperation = ListCollectionsOperation;\n(0, operation_1.defineAspects)(ListCollectionsOperation, [\n    operation_1.Aspect.READ_OPERATION,\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.CURSOR_CREATING\n]);\n//# sourceMappingURL=list_collections.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/list_collections.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/list_databases.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/list_databases.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListDatabasesOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass ListDatabasesOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options ?? {};\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        const cmd = { listDatabases: 1 };\n        if (typeof this.options.nameOnly === 'boolean') {\n            cmd.nameOnly = this.options.nameOnly;\n        }\n        if (this.options.filter) {\n            cmd.filter = this.options.filter;\n        }\n        if (typeof this.options.authorizedDatabases === 'boolean') {\n            cmd.authorizedDatabases = this.options.authorizedDatabases;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if ((0, utils_1.maxWireVersion)(server) >= 9 && this.options.comment !== undefined) {\n            cmd.comment = this.options.comment;\n        }\n        return super.executeCommand(server, session, cmd);\n    }\n}\nexports.ListDatabasesOperation = ListDatabasesOperation;\n(0, operation_1.defineAspects)(ListDatabasesOperation, [operation_1.Aspect.READ_OPERATION, operation_1.Aspect.RETRYABLE]);\n//# sourceMappingURL=list_databases.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/list_databases.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/operation.js":
/*!**********************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/operation.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defineAspects = exports.AbstractOperation = exports.Aspect = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nexports.Aspect = {\n    READ_OPERATION: Symbol('READ_OPERATION'),\n    WRITE_OPERATION: Symbol('WRITE_OPERATION'),\n    RETRYABLE: Symbol('RETRYABLE'),\n    EXPLAINABLE: Symbol('EXPLAINABLE'),\n    SKIP_COLLATION: Symbol('SKIP_COLLATION'),\n    CURSOR_CREATING: Symbol('CURSOR_CREATING'),\n    MUST_SELECT_SAME_SERVER: Symbol('MUST_SELECT_SAME_SERVER')\n};\n/** @internal */\nconst kSession = Symbol('session');\n/**\n * This class acts as a parent class for any operation and is responsible for setting this.options,\n * as well as setting and getting a session.\n * Additionally, this class implements `hasAspect`, which determines whether an operation has\n * a specific aspect.\n * @internal\n */\nclass AbstractOperation {\n    constructor(options = {}) {\n        this.readPreference = this.hasAspect(exports.Aspect.WRITE_OPERATION)\n            ? read_preference_1.ReadPreference.primary\n            : read_preference_1.ReadPreference.fromOptions(options) ?? read_preference_1.ReadPreference.primary;\n        // Pull the BSON serialize options from the already-resolved options\n        this.bsonOptions = (0, bson_1.resolveBSONOptions)(options);\n        this[kSession] = options.session != null ? options.session : undefined;\n        this.options = options;\n        this.bypassPinningCheck = !!options.bypassPinningCheck;\n        this.trySecondaryWrite = false;\n    }\n    hasAspect(aspect) {\n        const ctor = this.constructor;\n        if (ctor.aspects == null) {\n            return false;\n        }\n        return ctor.aspects.has(aspect);\n    }\n    get session() {\n        return this[kSession];\n    }\n    clearSession() {\n        this[kSession] = undefined;\n    }\n    get canRetryRead() {\n        return true;\n    }\n    get canRetryWrite() {\n        return true;\n    }\n}\nexports.AbstractOperation = AbstractOperation;\nfunction defineAspects(operation, aspects) {\n    if (!Array.isArray(aspects) && !(aspects instanceof Set)) {\n        aspects = [aspects];\n    }\n    aspects = new Set(aspects);\n    Object.defineProperty(operation, 'aspects', {\n        value: aspects,\n        writable: false\n    });\n    return aspects;\n}\nexports.defineAspects = defineAspects;\n//# sourceMappingURL=operation.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/options_operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/options_operation.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OptionsOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass OptionsOperation extends operation_1.AbstractOperation {\n    constructor(collection, options) {\n        super(options);\n        this.options = options;\n        this.collection = collection;\n    }\n    async execute(server, session) {\n        const coll = this.collection;\n        const [collection] = await coll.s.db\n            .listCollections({ name: coll.collectionName }, { ...this.options, nameOnly: false, readPreference: this.readPreference, session })\n            .toArray();\n        if (collection == null || collection.options == null) {\n            throw new error_1.MongoAPIError(`collection ${coll.namespace} not found`);\n        }\n        return collection.options;\n    }\n}\nexports.OptionsOperation = OptionsOperation;\n//# sourceMappingURL=options_operation.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/options_operation.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/profiling_level.js":
/*!****************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/profiling_level.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ProfilingLevelOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        const doc = await super.executeCommand(server, session, { profile: -1 });\n        if (doc.ok === 1) {\n            const was = doc.was;\n            if (was === 0)\n                return 'off';\n            if (was === 1)\n                return 'slow_only';\n            if (was === 2)\n                return 'all';\n            throw new error_1.MongoUnexpectedServerResponseError(`Illegal profiling level value ${was}`);\n        }\n        else {\n            throw new error_1.MongoUnexpectedServerResponseError('Error with profile command');\n        }\n    }\n}\nexports.ProfilingLevelOperation = ProfilingLevelOperation;\n//# sourceMappingURL=profiling_level.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/remove_user.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/remove_user.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RemoveUserOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RemoveUserOperation extends command_1.CommandOperation {\n    constructor(db, username, options) {\n        super(db, options);\n        this.options = options;\n        this.username = username;\n    }\n    async execute(server, session) {\n        await super.executeCommand(server, session, { dropUser: this.username });\n        return true;\n    }\n}\nexports.RemoveUserOperation = RemoveUserOperation;\n(0, operation_1.defineAspects)(RemoveUserOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=remove_user.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/remove_user.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/rename.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/rename.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RenameOperation = void 0;\nconst collection_1 = __webpack_require__(/*! ../collection */ \"./node_modules/mongodb/lib/collection.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RenameOperation extends command_1.CommandOperation {\n    constructor(collection, newName, options) {\n        super(collection, options);\n        this.collection = collection;\n        this.newName = newName;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        // Build the command\n        const renameCollection = this.collection.namespace;\n        const toCollection = this.collection.s.namespace.withCollection(this.newName).toString();\n        const dropTarget = typeof this.options.dropTarget === 'boolean' ? this.options.dropTarget : false;\n        const command = {\n            renameCollection: renameCollection,\n            to: toCollection,\n            dropTarget: dropTarget\n        };\n        await super.executeCommand(server, session, command);\n        return new collection_1.Collection(this.collection.s.db, this.newName, this.collection.s.options);\n    }\n}\nexports.RenameOperation = RenameOperation;\n(0, operation_1.defineAspects)(RenameOperation, [operation_1.Aspect.WRITE_OPERATION]);\n//# sourceMappingURL=rename.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/rename.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/run_command.js":
/*!************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/run_command.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RunAdminCommandOperation = exports.RunCommandOperation = void 0;\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass RunCommandOperation extends operation_1.AbstractOperation {\n    constructor(parent, command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = parent.s.namespace.withCollection('$cmd');\n    }\n    async execute(server, session) {\n        this.server = server;\n        return server.commandAsync(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.RunCommandOperation = RunCommandOperation;\nclass RunAdminCommandOperation extends operation_1.AbstractOperation {\n    constructor(command, options) {\n        super(options);\n        this.command = command;\n        this.options = options;\n        this.ns = new utils_1.MongoDBNamespace('admin', '$cmd');\n    }\n    async execute(server, session) {\n        this.server = server;\n        return server.commandAsync(this.ns, this.command, {\n            ...this.options,\n            readPreference: this.readPreference,\n            session\n        });\n    }\n}\nexports.RunAdminCommandOperation = RunAdminCommandOperation;\n//# sourceMappingURL=run_command.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/run_command.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/create.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/create.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.CreateSearchIndexesOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass CreateSearchIndexesOperation extends operation_1.AbstractOperation {\n    constructor(collection, descriptions) {\n        super();\n        this.collection = collection;\n        this.descriptions = descriptions;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            createSearchIndexes: namespace.collection,\n            indexes: this.descriptions\n        };\n        const res = await server.commandAsync(namespace, command, { session });\n        const indexesCreated = res?.indexesCreated ?? [];\n        return indexesCreated.map(({ name }) => name);\n    }\n}\nexports.CreateSearchIndexesOperation = CreateSearchIndexesOperation;\n//# sourceMappingURL=create.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/search_indexes/create.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/drop.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/drop.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DropSearchIndexOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../../error */ \"./node_modules/mongodb/lib/error.js\");\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DropSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name) {\n        super();\n        this.collection = collection;\n        this.name = name;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            dropSearchIndex: namespace.collection\n        };\n        if (typeof this.name === 'string') {\n            command.name = this.name;\n        }\n        try {\n            await server.commandAsync(namespace, command, { session });\n        }\n        catch (error) {\n            const isNamespaceNotFoundError = error instanceof error_1.MongoServerError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound;\n            if (!isNamespaceNotFoundError) {\n                throw error;\n            }\n        }\n    }\n}\nexports.DropSearchIndexOperation = DropSearchIndexOperation;\n//# sourceMappingURL=drop.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/search_indexes/drop.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/search_indexes/update.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/search_indexes/update.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UpdateSearchIndexOperation = void 0;\nconst operation_1 = __webpack_require__(/*! ../operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass UpdateSearchIndexOperation extends operation_1.AbstractOperation {\n    constructor(collection, name, definition) {\n        super();\n        this.collection = collection;\n        this.name = name;\n        this.definition = definition;\n    }\n    async execute(server, session) {\n        const namespace = this.collection.fullNamespace;\n        const command = {\n            updateSearchIndex: namespace.collection,\n            name: this.name,\n            definition: this.definition\n        };\n        await server.commandAsync(namespace, command, { session });\n        return;\n    }\n}\nexports.UpdateSearchIndexOperation = UpdateSearchIndexOperation;\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/search_indexes/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/set_profiling_level.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/set_profiling_level.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SetProfilingLevelOperation = exports.ProfilingLevel = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst levelValues = new Set(['off', 'slow_only', 'all']);\n/** @public */\nexports.ProfilingLevel = Object.freeze({\n    off: 'off',\n    slowOnly: 'slow_only',\n    all: 'all'\n});\n/** @internal */\nclass SetProfilingLevelOperation extends command_1.CommandOperation {\n    constructor(db, level, options) {\n        super(db, options);\n        this.options = options;\n        switch (level) {\n            case exports.ProfilingLevel.off:\n                this.profile = 0;\n                break;\n            case exports.ProfilingLevel.slowOnly:\n                this.profile = 1;\n                break;\n            case exports.ProfilingLevel.all:\n                this.profile = 2;\n                break;\n            default:\n                this.profile = 0;\n                break;\n        }\n        this.level = level;\n    }\n    async execute(server, session) {\n        const level = this.level;\n        if (!levelValues.has(level)) {\n            throw new error_1.MongoInvalidArgumentError(`Profiling level must be one of \"${(0, utils_1.enumToString)(exports.ProfilingLevel)}\"`);\n        }\n        // TODO(NODE-3483): Determine error to put here\n        await super.executeCommand(server, session, { profile: this.profile });\n        return level;\n    }\n}\nexports.SetProfilingLevelOperation = SetProfilingLevelOperation;\n//# sourceMappingURL=set_profiling_level.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/set_profiling_level.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/stats.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/stats.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DbStatsOperation = void 0;\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/** @internal */\nclass DbStatsOperation extends command_1.CommandOperation {\n    constructor(db, options) {\n        super(db, options);\n        this.options = options;\n    }\n    async execute(server, session) {\n        const command = { dbStats: true };\n        if (this.options.scale != null) {\n            command.scale = this.options.scale;\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.DbStatsOperation = DbStatsOperation;\n(0, operation_1.defineAspects)(DbStatsOperation, [operation_1.Aspect.READ_OPERATION]);\n//# sourceMappingURL=stats.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/stats.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/update.js":
/*!*******************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/update.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.makeUpdateStatement = exports.ReplaceOneOperation = exports.UpdateManyOperation = exports.UpdateOneOperation = exports.UpdateOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\nconst operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/mongodb/lib/operations/operation.js\");\n/**\n * @internal\n * UpdateOperation is used in bulk write, while UpdateOneOperation and UpdateManyOperation are only used in the collections API\n */\nclass UpdateOperation extends command_1.CommandOperation {\n    constructor(ns, statements, options) {\n        super(undefined, options);\n        this.options = options;\n        this.ns = ns;\n        this.statements = statements;\n    }\n    get canRetryWrite() {\n        if (super.canRetryWrite === false) {\n            return false;\n        }\n        return this.statements.every(op => op.multi == null || op.multi === false);\n    }\n    async execute(server, session) {\n        const options = this.options ?? {};\n        const ordered = typeof options.ordered === 'boolean' ? options.ordered : true;\n        const command = {\n            update: this.ns.collection,\n            updates: this.statements,\n            ordered\n        };\n        if (typeof options.bypassDocumentValidation === 'boolean') {\n            command.bypassDocumentValidation = options.bypassDocumentValidation;\n        }\n        if (options.let) {\n            command.let = options.let;\n        }\n        // we check for undefined specifically here to allow falsy values\n        // eslint-disable-next-line no-restricted-syntax\n        if (options.comment !== undefined) {\n            command.comment = options.comment;\n        }\n        const unacknowledgedWrite = this.writeConcern && this.writeConcern.w === 0;\n        if (unacknowledgedWrite) {\n            if (this.statements.find((o) => o.hint)) {\n                // TODO(NODE-3541): fix error for hint with unacknowledged writes\n                throw new error_1.MongoCompatibilityError(`hint is not supported with unacknowledged writes`);\n            }\n        }\n        return super.executeCommand(server, session, command);\n    }\n}\nexports.UpdateOperation = UpdateOperation;\n/** @internal */\nclass UpdateOneOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: false })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateOneOperation = UpdateOneOperation;\n/** @internal */\nclass UpdateManyOperation extends UpdateOperation {\n    constructor(collection, filter, update, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, update, { ...options, multi: true })], options);\n        if (!(0, utils_1.hasAtomicOperators)(update)) {\n            throw new error_1.MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.UpdateManyOperation = UpdateManyOperation;\n/** @internal */\nclass ReplaceOneOperation extends UpdateOperation {\n    constructor(collection, filter, replacement, options) {\n        super(collection.s.namespace, [makeUpdateStatement(filter, replacement, { ...options, multi: false })], options);\n        if ((0, utils_1.hasAtomicOperators)(replacement)) {\n            throw new error_1.MongoInvalidArgumentError('Replacement document must not contain atomic operators');\n        }\n    }\n    async execute(server, session) {\n        const res = await super.execute(server, session);\n        if (this.explain != null)\n            return res;\n        if (res.code)\n            throw new error_1.MongoServerError(res);\n        if (res.writeErrors)\n            throw new error_1.MongoServerError(res.writeErrors[0]);\n        return {\n            acknowledged: this.writeConcern?.w !== 0,\n            modifiedCount: res.nModified ?? res.n,\n            upsertedId: Array.isArray(res.upserted) && res.upserted.length > 0 ? res.upserted[0]._id : null,\n            upsertedCount: Array.isArray(res.upserted) && res.upserted.length ? res.upserted.length : 0,\n            matchedCount: Array.isArray(res.upserted) && res.upserted.length > 0 ? 0 : res.n\n        };\n    }\n}\nexports.ReplaceOneOperation = ReplaceOneOperation;\nfunction makeUpdateStatement(filter, update, options) {\n    if (filter == null || typeof filter !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Selector must be a valid JavaScript object');\n    }\n    if (update == null || typeof update !== 'object') {\n        throw new error_1.MongoInvalidArgumentError('Document must be a valid JavaScript object');\n    }\n    const op = { q: filter, u: update };\n    if (typeof options.upsert === 'boolean') {\n        op.upsert = options.upsert;\n    }\n    if (options.multi) {\n        op.multi = options.multi;\n    }\n    if (options.hint) {\n        op.hint = options.hint;\n    }\n    if (options.arrayFilters) {\n        op.arrayFilters = options.arrayFilters;\n    }\n    if (options.collation) {\n        op.collation = options.collation;\n    }\n    return op;\n}\nexports.makeUpdateStatement = makeUpdateStatement;\n(0, operation_1.defineAspects)(UpdateOperation, [operation_1.Aspect.RETRYABLE, operation_1.Aspect.WRITE_OPERATION, operation_1.Aspect.SKIP_COLLATION]);\n(0, operation_1.defineAspects)(UpdateOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(UpdateManyOperation, [\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.EXPLAINABLE,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n(0, operation_1.defineAspects)(ReplaceOneOperation, [\n    operation_1.Aspect.RETRYABLE,\n    operation_1.Aspect.WRITE_OPERATION,\n    operation_1.Aspect.SKIP_COLLATION\n]);\n//# sourceMappingURL=update.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/update.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/operations/validate_collection.js":
/*!********************************************************************!*\
  !*** ./node_modules/mongodb/lib/operations/validate_collection.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ValidateCollectionOperation = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst command_1 = __webpack_require__(/*! ./command */ \"./node_modules/mongodb/lib/operations/command.js\");\n/** @internal */\nclass ValidateCollectionOperation extends command_1.CommandOperation {\n    constructor(admin, collectionName, options) {\n        // Decorate command with extra options\n        const command = { validate: collectionName };\n        const keys = Object.keys(options);\n        for (let i = 0; i < keys.length; i++) {\n            if (Object.prototype.hasOwnProperty.call(options, keys[i]) && keys[i] !== 'session') {\n                command[keys[i]] = options[keys[i]];\n            }\n        }\n        super(admin.s.db, options);\n        this.options = options;\n        this.command = command;\n        this.collectionName = collectionName;\n    }\n    async execute(server, session) {\n        const collectionName = this.collectionName;\n        const doc = await super.executeCommand(server, session, this.command);\n        if (doc.result != null && typeof doc.result !== 'string')\n            throw new error_1.MongoUnexpectedServerResponseError('Error with validation data');\n        if (doc.result != null && doc.result.match(/exception|corrupt/) != null)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        if (doc.valid != null && !doc.valid)\n            throw new error_1.MongoUnexpectedServerResponseError(`Invalid collection ${collectionName}`);\n        return doc;\n    }\n}\nexports.ValidateCollectionOperation = ValidateCollectionOperation;\n//# sourceMappingURL=validate_collection.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/operations/validate_collection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_concern.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/read_concern.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadConcern = exports.ReadConcernLevel = void 0;\n/** @public */\nexports.ReadConcernLevel = Object.freeze({\n    local: 'local',\n    majority: 'majority',\n    linearizable: 'linearizable',\n    available: 'available',\n    snapshot: 'snapshot'\n});\n/**\n * The MongoDB ReadConcern, which allows for control of the consistency and isolation properties\n * of the data read from replica sets and replica set shards.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/read-concern/index.html\n */\nclass ReadConcern {\n    /** Constructs a ReadConcern from the read concern level.*/\n    constructor(level) {\n        /**\n         * A spec test exists that allows level to be any string.\n         * \"invalid readConcern with out stage\"\n         * @see ./test/spec/crud/v2/aggregate-out-readConcern.json\n         * @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#unknown-levels-and-additional-options-for-string-based-readconcerns\n         */\n        this.level = exports.ReadConcernLevel[level] ?? level;\n    }\n    /**\n     * Construct a ReadConcern given an options object.\n     *\n     * @param options - The options object from which to extract the write concern.\n     */\n    static fromOptions(options) {\n        if (options == null) {\n            return;\n        }\n        if (options.readConcern) {\n            const { readConcern } = options;\n            if (readConcern instanceof ReadConcern) {\n                return readConcern;\n            }\n            else if (typeof readConcern === 'string') {\n                return new ReadConcern(readConcern);\n            }\n            else if ('level' in readConcern && readConcern.level) {\n                return new ReadConcern(readConcern.level);\n            }\n        }\n        if (options.level) {\n            return new ReadConcern(options.level);\n        }\n        return;\n    }\n    static get MAJORITY() {\n        return exports.ReadConcernLevel.majority;\n    }\n    static get AVAILABLE() {\n        return exports.ReadConcernLevel.available;\n    }\n    static get LINEARIZABLE() {\n        return exports.ReadConcernLevel.linearizable;\n    }\n    static get SNAPSHOT() {\n        return exports.ReadConcernLevel.snapshot;\n    }\n    toJSON() {\n        return { level: this.level };\n    }\n}\nexports.ReadConcern = ReadConcern;\n//# sourceMappingURL=read_concern.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/read_concern.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/read_preference.js":
/*!*****************************************************!*\
  !*** ./node_modules/mongodb/lib/read_preference.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadPreference = exports.ReadPreferenceMode = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @public */\nexports.ReadPreferenceMode = Object.freeze({\n    primary: 'primary',\n    primaryPreferred: 'primaryPreferred',\n    secondary: 'secondary',\n    secondaryPreferred: 'secondaryPreferred',\n    nearest: 'nearest'\n});\n/**\n * The **ReadPreference** class is a class that represents a MongoDB ReadPreference and is\n * used to construct connections.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/core/read-preference/\n */\nclass ReadPreference {\n    /**\n     * @param mode - A string describing the read preference mode (primary|primaryPreferred|secondary|secondaryPreferred|nearest)\n     * @param tags - A tag set used to target reads to members with the specified tag(s). tagSet is not available if using read preference mode primary.\n     * @param options - Additional read preference options\n     */\n    constructor(mode, tags, options) {\n        if (!ReadPreference.isValid(mode)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference mode ${JSON.stringify(mode)}`);\n        }\n        if (options == null && typeof tags === 'object' && !Array.isArray(tags)) {\n            options = tags;\n            tags = undefined;\n        }\n        else if (tags && !Array.isArray(tags)) {\n            throw new error_1.MongoInvalidArgumentError('ReadPreference tags must be an array');\n        }\n        this.mode = mode;\n        this.tags = tags;\n        this.hedge = options?.hedge;\n        this.maxStalenessSeconds = undefined;\n        this.minWireVersion = undefined;\n        options = options ?? {};\n        if (options.maxStalenessSeconds != null) {\n            if (options.maxStalenessSeconds <= 0) {\n                throw new error_1.MongoInvalidArgumentError('maxStalenessSeconds must be a positive integer');\n            }\n            this.maxStalenessSeconds = options.maxStalenessSeconds;\n            // NOTE: The minimum required wire version is 5 for this read preference. If the existing\n            //       topology has a lower value then a MongoError will be thrown during server selection.\n            this.minWireVersion = 5;\n        }\n        if (this.mode === ReadPreference.PRIMARY) {\n            if (this.tags && Array.isArray(this.tags) && this.tags.length > 0) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with tags');\n            }\n            if (this.maxStalenessSeconds) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with maxStalenessSeconds');\n            }\n            if (this.hedge) {\n                throw new error_1.MongoInvalidArgumentError('Primary read preference cannot be combined with hedge');\n            }\n        }\n    }\n    // Support the deprecated `preference` property introduced in the porcelain layer\n    get preference() {\n        return this.mode;\n    }\n    static fromString(mode) {\n        return new ReadPreference(mode);\n    }\n    /**\n     * Construct a ReadPreference given an options object.\n     *\n     * @param options - The options object from which to extract the read preference.\n     */\n    static fromOptions(options) {\n        if (!options)\n            return;\n        const readPreference = options.readPreference ?? options.session?.transaction.options.readPreference;\n        const readPreferenceTags = options.readPreferenceTags;\n        if (readPreference == null) {\n            return;\n        }\n        if (typeof readPreference === 'string') {\n            return new ReadPreference(readPreference, readPreferenceTags, {\n                maxStalenessSeconds: options.maxStalenessSeconds,\n                hedge: options.hedge\n            });\n        }\n        else if (!(readPreference instanceof ReadPreference) && typeof readPreference === 'object') {\n            const mode = readPreference.mode || readPreference.preference;\n            if (mode && typeof mode === 'string') {\n                return new ReadPreference(mode, readPreference.tags ?? readPreferenceTags, {\n                    maxStalenessSeconds: readPreference.maxStalenessSeconds,\n                    hedge: options.hedge\n                });\n            }\n        }\n        if (readPreferenceTags) {\n            readPreference.tags = readPreferenceTags;\n        }\n        return readPreference;\n    }\n    /**\n     * Replaces options.readPreference with a ReadPreference instance\n     */\n    static translate(options) {\n        if (options.readPreference == null)\n            return options;\n        const r = options.readPreference;\n        if (typeof r === 'string') {\n            options.readPreference = new ReadPreference(r);\n        }\n        else if (r && !(r instanceof ReadPreference) && typeof r === 'object') {\n            const mode = r.mode || r.preference;\n            if (mode && typeof mode === 'string') {\n                options.readPreference = new ReadPreference(mode, r.tags, {\n                    maxStalenessSeconds: r.maxStalenessSeconds\n                });\n            }\n        }\n        else if (!(r instanceof ReadPreference)) {\n            throw new error_1.MongoInvalidArgumentError(`Invalid read preference: ${r}`);\n        }\n        return options;\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    static isValid(mode) {\n        const VALID_MODES = new Set([\n            ReadPreference.PRIMARY,\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST,\n            null\n        ]);\n        return VALID_MODES.has(mode);\n    }\n    /**\n     * Validate if a mode is legal\n     *\n     * @param mode - The string representing the read preference mode.\n     */\n    isValid(mode) {\n        return ReadPreference.isValid(typeof mode === 'string' ? mode : this.mode);\n    }\n    /**\n     * Indicates that this readPreference needs the \"SecondaryOk\" bit when sent over the wire\n     * @see https://www.mongodb.com/docs/manual/reference/mongodb-wire-protocol/#op-query\n     */\n    secondaryOk() {\n        const NEEDS_SECONDARYOK = new Set([\n            ReadPreference.PRIMARY_PREFERRED,\n            ReadPreference.SECONDARY,\n            ReadPreference.SECONDARY_PREFERRED,\n            ReadPreference.NEAREST\n        ]);\n        return NEEDS_SECONDARYOK.has(this.mode);\n    }\n    /**\n     * Check if the two ReadPreferences are equivalent\n     *\n     * @param readPreference - The read preference with which to check equality\n     */\n    equals(readPreference) {\n        return readPreference.mode === this.mode;\n    }\n    /** Return JSON representation */\n    toJSON() {\n        const readPreference = { mode: this.mode };\n        if (Array.isArray(this.tags))\n            readPreference.tags = this.tags;\n        if (this.maxStalenessSeconds)\n            readPreference.maxStalenessSeconds = this.maxStalenessSeconds;\n        if (this.hedge)\n            readPreference.hedge = this.hedge;\n        return readPreference;\n    }\n}\nReadPreference.PRIMARY = exports.ReadPreferenceMode.primary;\nReadPreference.PRIMARY_PREFERRED = exports.ReadPreferenceMode.primaryPreferred;\nReadPreference.SECONDARY = exports.ReadPreferenceMode.secondary;\nReadPreference.SECONDARY_PREFERRED = exports.ReadPreferenceMode.secondaryPreferred;\nReadPreference.NEAREST = exports.ReadPreferenceMode.nearest;\nReadPreference.primary = new ReadPreference(exports.ReadPreferenceMode.primary);\nReadPreference.primaryPreferred = new ReadPreference(exports.ReadPreferenceMode.primaryPreferred);\nReadPreference.secondary = new ReadPreference(exports.ReadPreferenceMode.secondary);\nReadPreference.secondaryPreferred = new ReadPreference(exports.ReadPreferenceMode.secondaryPreferred);\nReadPreference.nearest = new ReadPreference(exports.ReadPreferenceMode.nearest);\nexports.ReadPreference = ReadPreference;\n//# sourceMappingURL=read_preference.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/read_preference.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/common.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/common.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports._advanceClusterTime = exports.drainTimerQueue = exports.ServerType = exports.TopologyType = exports.STATE_CONNECTED = exports.STATE_CONNECTING = exports.STATE_CLOSED = exports.STATE_CLOSING = void 0;\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n// shared state names\nexports.STATE_CLOSING = 'closing';\nexports.STATE_CLOSED = 'closed';\nexports.STATE_CONNECTING = 'connecting';\nexports.STATE_CONNECTED = 'connected';\n/**\n * An enumeration of topology types we know about\n * @public\n */\nexports.TopologyType = Object.freeze({\n    Single: 'Single',\n    ReplicaSetNoPrimary: 'ReplicaSetNoPrimary',\n    ReplicaSetWithPrimary: 'ReplicaSetWithPrimary',\n    Sharded: 'Sharded',\n    Unknown: 'Unknown',\n    LoadBalanced: 'LoadBalanced'\n});\n/**\n * An enumeration of server types we know about\n * @public\n */\nexports.ServerType = Object.freeze({\n    Standalone: 'Standalone',\n    Mongos: 'Mongos',\n    PossiblePrimary: 'PossiblePrimary',\n    RSPrimary: 'RSPrimary',\n    RSSecondary: 'RSSecondary',\n    RSArbiter: 'RSArbiter',\n    RSOther: 'RSOther',\n    RSGhost: 'RSGhost',\n    Unknown: 'Unknown',\n    LoadBalancer: 'LoadBalancer'\n});\n/** @internal */\nfunction drainTimerQueue(queue) {\n    queue.forEach(timers_1.clearTimeout);\n    queue.clear();\n}\nexports.drainTimerQueue = drainTimerQueue;\n/** Shared function to determine clusterTime for a given topology or session */\nfunction _advanceClusterTime(entity, $clusterTime) {\n    if (entity.clusterTime == null) {\n        entity.clusterTime = $clusterTime;\n    }\n    else {\n        if ($clusterTime.clusterTime.greaterThan(entity.clusterTime.clusterTime)) {\n            entity.clusterTime = $clusterTime;\n        }\n    }\n}\nexports._advanceClusterTime = _advanceClusterTime;\n//# sourceMappingURL=common.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/common.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/events.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/events.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerHeartbeatFailedEvent = exports.ServerHeartbeatSucceededEvent = exports.ServerHeartbeatStartedEvent = exports.TopologyClosedEvent = exports.TopologyOpeningEvent = exports.TopologyDescriptionChangedEvent = exports.ServerClosedEvent = exports.ServerOpeningEvent = exports.ServerDescriptionChangedEvent = void 0;\n/**\n * Emitted when server description changes, but does NOT include changes to the RTT.\n * @public\n * @category Event\n */\nclass ServerDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, address, previousDescription, newDescription) {\n        this.topologyId = topologyId;\n        this.address = address;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.ServerDescriptionChangedEvent = ServerDescriptionChangedEvent;\n/**\n * Emitted when server is initialized.\n * @public\n * @category Event\n */\nclass ServerOpeningEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerOpeningEvent = ServerOpeningEvent;\n/**\n * Emitted when server is closed.\n * @public\n * @category Event\n */\nclass ServerClosedEvent {\n    /** @internal */\n    constructor(topologyId, address) {\n        this.topologyId = topologyId;\n        this.address = address;\n    }\n}\nexports.ServerClosedEvent = ServerClosedEvent;\n/**\n * Emitted when topology description changes.\n * @public\n * @category Event\n */\nclass TopologyDescriptionChangedEvent {\n    /** @internal */\n    constructor(topologyId, previousDescription, newDescription) {\n        this.topologyId = topologyId;\n        this.previousDescription = previousDescription;\n        this.newDescription = newDescription;\n    }\n}\nexports.TopologyDescriptionChangedEvent = TopologyDescriptionChangedEvent;\n/**\n * Emitted when topology is initialized.\n * @public\n * @category Event\n */\nclass TopologyOpeningEvent {\n    /** @internal */\n    constructor(topologyId) {\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyOpeningEvent = TopologyOpeningEvent;\n/**\n * Emitted when topology is closed.\n * @public\n * @category Event\n */\nclass TopologyClosedEvent {\n    /** @internal */\n    constructor(topologyId) {\n        this.topologyId = topologyId;\n    }\n}\nexports.TopologyClosedEvent = TopologyClosedEvent;\n/**\n * Emitted when the server monitors hello command is started - immediately before\n * the hello command is serialized into raw BSON and written to the socket.\n *\n * @public\n * @category Event\n */\nclass ServerHeartbeatStartedEvent {\n    /** @internal */\n    constructor(connectionId, awaited) {\n        this.connectionId = connectionId;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatStartedEvent = ServerHeartbeatStartedEvent;\n/**\n * Emitted when the server monitors hello succeeds.\n * @public\n * @category Event\n */\nclass ServerHeartbeatSucceededEvent {\n    /** @internal */\n    constructor(connectionId, duration, reply, awaited) {\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.reply = reply ?? {};\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatSucceededEvent = ServerHeartbeatSucceededEvent;\n/**\n * Emitted when the server monitors hello fails, either with an ok: 0 or a socket exception.\n * @public\n * @category Event\n */\nclass ServerHeartbeatFailedEvent {\n    /** @internal */\n    constructor(connectionId, duration, failure, awaited) {\n        this.connectionId = connectionId;\n        this.duration = duration;\n        this.failure = failure;\n        this.awaited = awaited;\n    }\n}\nexports.ServerHeartbeatFailedEvent = ServerHeartbeatFailedEvent;\n//# sourceMappingURL=events.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/events.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/monitor.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/monitor.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MonitorInterval = exports.RTTPinger = exports.Monitor = exports.ServerMonitoringMode = void 0;\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst connect_1 = __webpack_require__(/*! ../cmap/connect */ \"./node_modules/mongodb/lib/cmap/connect.js\");\nconst connection_1 = __webpack_require__(/*! ../cmap/connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst client_metadata_1 = __webpack_require__(/*! ../cmap/handshake/client_metadata */ \"./node_modules/mongodb/lib/cmap/handshake/client_metadata.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\n/** @internal */\nconst kServer = Symbol('server');\n/** @internal */\nconst kMonitorId = Symbol('monitorId');\n/** @internal */\nconst kConnection = Symbol('connection');\n/** @internal */\nconst kCancellationToken = Symbol('cancellationToken');\n/** @internal */\nconst kRoundTripTime = Symbol('roundTripTime');\nconst STATE_IDLE = 'idle';\nconst STATE_MONITORING = 'monitoring';\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, STATE_IDLE, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, STATE_MONITORING],\n    [STATE_IDLE]: [STATE_IDLE, STATE_MONITORING, common_1.STATE_CLOSING],\n    [STATE_MONITORING]: [STATE_MONITORING, STATE_IDLE, common_1.STATE_CLOSING]\n});\nconst INVALID_REQUEST_CHECK_STATES = new Set([common_1.STATE_CLOSING, common_1.STATE_CLOSED, STATE_MONITORING]);\nfunction isInCloseState(monitor) {\n    return monitor.s.state === common_1.STATE_CLOSED || monitor.s.state === common_1.STATE_CLOSING;\n}\n/** @public */\nexports.ServerMonitoringMode = Object.freeze({\n    auto: 'auto',\n    poll: 'poll',\n    stream: 'stream'\n});\n/** @internal */\nclass Monitor extends mongo_types_1.TypedEventEmitter {\n    get connection() {\n        return this[kConnection];\n    }\n    constructor(server, options) {\n        super();\n        this[kServer] = server;\n        this[kConnection] = undefined;\n        this[kCancellationToken] = new mongo_types_1.CancellationToken();\n        this[kCancellationToken].setMaxListeners(Infinity);\n        this[kMonitorId] = undefined;\n        this.s = {\n            state: common_1.STATE_CLOSED\n        };\n        this.address = server.description.address;\n        this.options = Object.freeze({\n            connectTimeoutMS: options.connectTimeoutMS ?? 10000,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS ?? 10000,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS ?? 500,\n            serverMonitoringMode: options.serverMonitoringMode\n        });\n        this.isRunningInFaasEnv = (0, client_metadata_1.getFAASEnv)() != null;\n        const cancellationToken = this[kCancellationToken];\n        // TODO: refactor this to pull it directly from the pool, requires new ConnectionPool integration\n        const connectOptions = Object.assign({\n            id: '<monitor>',\n            generation: server.pool.generation,\n            connectionType: connection_1.Connection,\n            cancellationToken,\n            hostAddress: server.description.hostAddress\n        }, options, \n        // force BSON serialization options\n        {\n            raw: false,\n            useBigInt64: false,\n            promoteLongs: true,\n            promoteValues: true,\n            promoteBuffers: true\n        });\n        // ensure no authentication is used for monitoring\n        delete connectOptions.credentials;\n        if (connectOptions.autoEncrypter) {\n            delete connectOptions.autoEncrypter;\n        }\n        this.connectOptions = Object.freeze(connectOptions);\n    }\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        // start\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS,\n            immediate: true\n        });\n    }\n    requestCheck() {\n        if (INVALID_REQUEST_CHECK_STATES.has(this.s.state)) {\n            return;\n        }\n        this[kMonitorId]?.wake();\n    }\n    reset() {\n        const topologyVersion = this[kServer].description.topologyVersion;\n        if (isInCloseState(this) || topologyVersion == null) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // restart monitor\n        stateTransition(this, STATE_IDLE);\n        // restart monitoring\n        const heartbeatFrequencyMS = this.options.heartbeatFrequencyMS;\n        const minHeartbeatFrequencyMS = this.options.minHeartbeatFrequencyMS;\n        this[kMonitorId] = new MonitorInterval(monitorServer(this), {\n            heartbeatFrequencyMS: heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: minHeartbeatFrequencyMS\n        });\n    }\n    close() {\n        if (isInCloseState(this)) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        resetMonitorState(this);\n        // close monitor\n        this.emit('close');\n        stateTransition(this, common_1.STATE_CLOSED);\n    }\n}\nexports.Monitor = Monitor;\nfunction resetMonitorState(monitor) {\n    monitor[kMonitorId]?.stop();\n    monitor[kMonitorId] = undefined;\n    monitor.rttPinger?.close();\n    monitor.rttPinger = undefined;\n    monitor[kCancellationToken].emit('cancel');\n    monitor[kConnection]?.destroy({ force: true });\n    monitor[kConnection] = undefined;\n}\nfunction useStreamingProtocol(monitor, topologyVersion) {\n    // If we have no topology version we always poll no matter\n    // what the user provided, since the server does not support\n    // the streaming protocol.\n    if (topologyVersion == null)\n        return false;\n    const serverMonitoringMode = monitor.options.serverMonitoringMode;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.poll)\n        return false;\n    if (serverMonitoringMode === exports.ServerMonitoringMode.stream)\n        return true;\n    // If we are in auto mode, we need to figure out if we're in a FaaS\n    // environment or not and choose the appropriate mode.\n    if (monitor.isRunningInFaasEnv)\n        return false;\n    return true;\n}\nfunction checkServer(monitor, callback) {\n    let start = (0, utils_1.now)();\n    const topologyVersion = monitor[kServer].description.topologyVersion;\n    const isAwaitable = useStreamingProtocol(monitor, topologyVersion);\n    monitor.emit(server_1.Server.SERVER_HEARTBEAT_STARTED, new events_1.ServerHeartbeatStartedEvent(monitor.address, isAwaitable));\n    function failureHandler(err, awaited) {\n        monitor[kConnection]?.destroy({ force: true });\n        monitor[kConnection] = undefined;\n        monitor.emit(server_1.Server.SERVER_HEARTBEAT_FAILED, new events_1.ServerHeartbeatFailedEvent(monitor.address, (0, utils_1.calculateDurationInMs)(start), err, awaited));\n        const error = !(err instanceof error_1.MongoError)\n            ? new error_1.MongoError(error_1.MongoError.buildErrorMessage(err), { cause: err })\n            : err;\n        error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n        if (error instanceof error_1.MongoNetworkTimeoutError) {\n            error.addErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n        }\n        monitor.emit('resetServer', error);\n        callback(err);\n    }\n    const connection = monitor[kConnection];\n    if (connection && !connection.closed) {\n        const { serverApi, helloOk } = connection;\n        const connectTimeoutMS = monitor.options.connectTimeoutMS;\n        const maxAwaitTimeMS = monitor.options.heartbeatFrequencyMS;\n        const cmd = {\n            [serverApi?.version || helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND]: 1,\n            ...(isAwaitable && topologyVersion\n                ? { maxAwaitTimeMS, topologyVersion: makeTopologyVersion(topologyVersion) }\n                : {})\n        };\n        const options = isAwaitable\n            ? {\n                socketTimeoutMS: connectTimeoutMS ? connectTimeoutMS + maxAwaitTimeMS : 0,\n                exhaustAllowed: true\n            }\n            : { socketTimeoutMS: connectTimeoutMS };\n        if (isAwaitable && monitor.rttPinger == null) {\n            monitor.rttPinger = new RTTPinger(monitor[kCancellationToken], Object.assign({ heartbeatFrequencyMS: monitor.options.heartbeatFrequencyMS }, monitor.connectOptions));\n        }\n        connection.command((0, utils_1.ns)('admin.$cmd'), cmd, options, (err, hello) => {\n            if (err) {\n                return failureHandler(err, isAwaitable);\n            }\n            if (!('isWritablePrimary' in hello)) {\n                // Provide hello-style response document.\n                hello.isWritablePrimary = hello[constants_1.LEGACY_HELLO_COMMAND];\n            }\n            const duration = isAwaitable && monitor.rttPinger\n                ? monitor.rttPinger.roundTripTime\n                : (0, utils_1.calculateDurationInMs)(start);\n            monitor.emit(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, new events_1.ServerHeartbeatSucceededEvent(monitor.address, duration, hello, isAwaitable));\n            // If we are using the streaming protocol then we immediately issue another 'started'\n            // event, otherwise the \"check\" is complete and return to the main monitor loop.\n            if (isAwaitable) {\n                monitor.emit(server_1.Server.SERVER_HEARTBEAT_STARTED, new events_1.ServerHeartbeatStartedEvent(monitor.address, true));\n                start = (0, utils_1.now)();\n            }\n            else {\n                monitor.rttPinger?.close();\n                monitor.rttPinger = undefined;\n                callback(undefined, hello);\n            }\n        });\n        return;\n    }\n    // connecting does an implicit `hello`\n    (0, connect_1.connect)(monitor.connectOptions, (err, conn) => {\n        if (err) {\n            monitor[kConnection] = undefined;\n            failureHandler(err, false);\n            return;\n        }\n        if (conn) {\n            // Tell the connection that we are using the streaming protocol so that the\n            // connection's message stream will only read the last hello on the buffer.\n            conn.isMonitoringConnection = true;\n            if (isInCloseState(monitor)) {\n                conn.destroy({ force: true });\n                return;\n            }\n            monitor[kConnection] = conn;\n            monitor.emit(server_1.Server.SERVER_HEARTBEAT_SUCCEEDED, new events_1.ServerHeartbeatSucceededEvent(monitor.address, (0, utils_1.calculateDurationInMs)(start), conn.hello, useStreamingProtocol(monitor, conn.hello?.topologyVersion)));\n            callback(undefined, conn.hello);\n        }\n    });\n}\nfunction monitorServer(monitor) {\n    return (callback) => {\n        if (monitor.s.state === STATE_MONITORING) {\n            process.nextTick(callback);\n            return;\n        }\n        stateTransition(monitor, STATE_MONITORING);\n        function done() {\n            if (!isInCloseState(monitor)) {\n                stateTransition(monitor, STATE_IDLE);\n            }\n            callback();\n        }\n        checkServer(monitor, (err, hello) => {\n            if (err) {\n                // otherwise an error occurred on initial discovery, also bail\n                if (monitor[kServer].description.type === common_1.ServerType.Unknown) {\n                    return done();\n                }\n            }\n            // if the check indicates streaming is supported, immediately reschedule monitoring\n            if (useStreamingProtocol(monitor, hello?.topologyVersion)) {\n                (0, timers_1.setTimeout)(() => {\n                    if (!isInCloseState(monitor)) {\n                        monitor[kMonitorId]?.wake();\n                    }\n                }, 0);\n            }\n            done();\n        });\n    };\n}\nfunction makeTopologyVersion(tv) {\n    return {\n        processId: tv.processId,\n        // tests mock counter as just number, but in a real situation counter should always be a Long\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        counter: bson_1.Long.isLong(tv.counter) ? tv.counter : bson_1.Long.fromNumber(tv.counter)\n    };\n}\n/** @internal */\nclass RTTPinger {\n    constructor(cancellationToken, options) {\n        this.connection = undefined;\n        this[kCancellationToken] = cancellationToken;\n        this[kRoundTripTime] = 0;\n        this.closed = false;\n        const heartbeatFrequencyMS = options.heartbeatFrequencyMS;\n        this[kMonitorId] = (0, timers_1.setTimeout)(() => measureRoundTripTime(this, options), heartbeatFrequencyMS);\n    }\n    get roundTripTime() {\n        return this[kRoundTripTime];\n    }\n    close() {\n        this.closed = true;\n        (0, timers_1.clearTimeout)(this[kMonitorId]);\n        this.connection?.destroy({ force: true });\n        this.connection = undefined;\n    }\n}\nexports.RTTPinger = RTTPinger;\nfunction measureRoundTripTime(rttPinger, options) {\n    const start = (0, utils_1.now)();\n    options.cancellationToken = rttPinger[kCancellationToken];\n    const heartbeatFrequencyMS = options.heartbeatFrequencyMS;\n    if (rttPinger.closed) {\n        return;\n    }\n    function measureAndReschedule(conn) {\n        if (rttPinger.closed) {\n            conn?.destroy({ force: true });\n            return;\n        }\n        if (rttPinger.connection == null) {\n            rttPinger.connection = conn;\n        }\n        rttPinger[kRoundTripTime] = (0, utils_1.calculateDurationInMs)(start);\n        rttPinger[kMonitorId] = (0, timers_1.setTimeout)(() => measureRoundTripTime(rttPinger, options), heartbeatFrequencyMS);\n    }\n    const connection = rttPinger.connection;\n    if (connection == null) {\n        (0, connect_1.connect)(options, (err, conn) => {\n            if (err) {\n                rttPinger.connection = undefined;\n                rttPinger[kRoundTripTime] = 0;\n                return;\n            }\n            measureAndReschedule(conn);\n        });\n        return;\n    }\n    const commandName = connection.serverApi?.version || connection.helloOk ? 'hello' : constants_1.LEGACY_HELLO_COMMAND;\n    connection.commandAsync((0, utils_1.ns)('admin.$cmd'), { [commandName]: 1 }, undefined).then(() => measureAndReschedule(), () => {\n        rttPinger.connection?.destroy({ force: true });\n        rttPinger.connection = undefined;\n        rttPinger[kRoundTripTime] = 0;\n        return;\n    });\n}\n/**\n * @internal\n */\nclass MonitorInterval {\n    constructor(fn, options = {}) {\n        this.isExpeditedCallToFnScheduled = false;\n        this.stopped = false;\n        this.isExecutionInProgress = false;\n        this.hasExecutedOnce = false;\n        this._executeAndReschedule = () => {\n            if (this.stopped)\n                return;\n            if (this.timerId) {\n                (0, timers_1.clearTimeout)(this.timerId);\n            }\n            this.isExpeditedCallToFnScheduled = false;\n            this.isExecutionInProgress = true;\n            this.fn(() => {\n                this.lastExecutionEnded = (0, utils_1.now)();\n                this.isExecutionInProgress = false;\n                this._reschedule(this.heartbeatFrequencyMS);\n            });\n        };\n        this.fn = fn;\n        this.lastExecutionEnded = -Infinity;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 1000;\n        this.minHeartbeatFrequencyMS = options.minHeartbeatFrequencyMS ?? 500;\n        if (options.immediate) {\n            this._executeAndReschedule();\n        }\n        else {\n            this._reschedule(undefined);\n        }\n    }\n    wake() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        // TODO(NODE-4674): Add error handling and logging to the monitor\n        if (timeSinceLastCall < 0) {\n            return this._executeAndReschedule();\n        }\n        if (this.isExecutionInProgress) {\n            return;\n        }\n        // debounce multiple calls to wake within the `minInterval`\n        if (this.isExpeditedCallToFnScheduled) {\n            return;\n        }\n        // reschedule a call as soon as possible, ensuring the call never happens\n        // faster than the `minInterval`\n        if (timeSinceLastCall < this.minHeartbeatFrequencyMS) {\n            this.isExpeditedCallToFnScheduled = true;\n            this._reschedule(this.minHeartbeatFrequencyMS - timeSinceLastCall);\n            return;\n        }\n        this._executeAndReschedule();\n    }\n    stop() {\n        this.stopped = true;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n            this.timerId = undefined;\n        }\n        this.lastExecutionEnded = -Infinity;\n        this.isExpeditedCallToFnScheduled = false;\n    }\n    toString() {\n        return JSON.stringify(this);\n    }\n    toJSON() {\n        const currentTime = (0, utils_1.now)();\n        const timeSinceLastCall = currentTime - this.lastExecutionEnded;\n        return {\n            timerId: this.timerId != null ? 'set' : 'cleared',\n            lastCallTime: this.lastExecutionEnded,\n            isExpeditedCheckScheduled: this.isExpeditedCallToFnScheduled,\n            stopped: this.stopped,\n            heartbeatFrequencyMS: this.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: this.minHeartbeatFrequencyMS,\n            currentTime,\n            timeSinceLastCall\n        };\n    }\n    _reschedule(ms) {\n        if (this.stopped)\n            return;\n        if (this.timerId) {\n            (0, timers_1.clearTimeout)(this.timerId);\n        }\n        this.timerId = (0, timers_1.setTimeout)(this._executeAndReschedule, ms || this.heartbeatFrequencyMS);\n    }\n}\nexports.MonitorInterval = MonitorInterval;\n//# sourceMappingURL=monitor.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/monitor.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server.js":
/*!*************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Server = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst connection_1 = __webpack_require__(/*! ../cmap/connection */ \"./node_modules/mongodb/lib/cmap/connection.js\");\nconst connection_pool_1 = __webpack_require__(/*! ../cmap/connection_pool */ \"./node_modules/mongodb/lib/cmap/connection_pool.js\");\nconst errors_1 = __webpack_require__(/*! ../cmap/errors */ \"./node_modules/mongodb/lib/cmap/errors.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst transactions_1 = __webpack_require__(/*! ../transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst monitor_1 = __webpack_require__(/*! ./monitor */ \"./node_modules/mongodb/lib/sdam/monitor.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nclass Server extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a server\n     */\n    constructor(topology, description, options) {\n        super();\n        this.commandAsync = (0, util_1.promisify)((ns, cmd, options, \n        // callback type defines Document result because result is never nullish when it succeeds, otherwise promise rejects\n        callback) => this.command(ns, cmd, options, callback));\n        this.serverApi = options.serverApi;\n        const poolOptions = { hostAddress: description.hostAddress, ...options };\n        this.topology = topology;\n        this.pool = new connection_pool_1.ConnectionPool(this, poolOptions);\n        this.s = {\n            description,\n            options,\n            state: common_1.STATE_CLOSED,\n            operationCount: 0\n        };\n        for (const event of [...constants_1.CMAP_EVENTS, ...constants_1.APM_EVENTS]) {\n            this.pool.on(event, (e) => this.emit(event, e));\n        }\n        this.pool.on(connection_1.Connection.CLUSTER_TIME_RECEIVED, (clusterTime) => {\n            this.clusterTime = clusterTime;\n        });\n        if (this.loadBalanced) {\n            this.monitor = null;\n            // monitoring is disabled in load balancing mode\n            return;\n        }\n        // create the monitor\n        this.monitor = new monitor_1.Monitor(this, this.s.options);\n        for (const event of constants_1.HEARTBEAT_EVENTS) {\n            this.monitor.on(event, (e) => this.emit(event, e));\n        }\n        this.monitor.on('resetServer', (error) => markServerUnknown(this, error));\n        this.monitor.on(Server.SERVER_HEARTBEAT_SUCCEEDED, (event) => {\n            this.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(this.description.hostAddress, event.reply, {\n                roundTripTime: calculateRoundTripTime(this.description.roundTripTime, event.duration)\n            }));\n            if (this.s.state === common_1.STATE_CONNECTING) {\n                stateTransition(this, common_1.STATE_CONNECTED);\n                this.emit(Server.CONNECT, this);\n            }\n        });\n    }\n    get clusterTime() {\n        return this.topology.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.topology.clusterTime = clusterTime;\n    }\n    get description() {\n        return this.s.description;\n    }\n    get name() {\n        return this.s.description.address;\n    }\n    get autoEncrypter() {\n        if (this.s.options && this.s.options.autoEncrypter) {\n            return this.s.options.autoEncrypter;\n        }\n        return;\n    }\n    get loadBalanced() {\n        return this.topology.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /**\n     * Initiate server connect\n     */\n    connect() {\n        if (this.s.state !== common_1.STATE_CLOSED) {\n            return;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // If in load balancer mode we automatically set the server to\n        // a load balancer. It never transitions out of this state and\n        // has no monitor.\n        if (!this.loadBalanced) {\n            this.monitor?.connect();\n        }\n        else {\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Server.CONNECT, this);\n        }\n    }\n    /** Destroy the server connection */\n    destroy(options, callback) {\n        if (typeof options === 'function') {\n            callback = options;\n            options = { force: false };\n        }\n        options = Object.assign({}, { force: false }, options);\n        if (this.s.state === common_1.STATE_CLOSED) {\n            if (typeof callback === 'function') {\n                callback();\n            }\n            return;\n        }\n        stateTransition(this, common_1.STATE_CLOSING);\n        if (!this.loadBalanced) {\n            this.monitor?.close();\n        }\n        this.pool.close(options, err => {\n            stateTransition(this, common_1.STATE_CLOSED);\n            this.emit('closed');\n            if (typeof callback === 'function') {\n                callback(err);\n            }\n        });\n    }\n    /**\n     * Immediately schedule monitoring of this server. If there already an attempt being made\n     * this will be a no-op.\n     */\n    requestCheck() {\n        if (!this.loadBalanced) {\n            this.monitor?.requestCheck();\n        }\n    }\n    /**\n     * Execute a command\n     * @internal\n     */\n    command(ns, cmd, options, callback) {\n        if (callback == null) {\n            throw new error_1.MongoInvalidArgumentError('Callback must be provided');\n        }\n        if (ns.db == null || typeof ns === 'string') {\n            throw new error_1.MongoInvalidArgumentError('Namespace must not be a string');\n        }\n        if (this.s.state === common_1.STATE_CLOSING || this.s.state === common_1.STATE_CLOSED) {\n            callback(new error_1.MongoServerClosedError());\n            return;\n        }\n        // Clone the options\n        const finalOptions = Object.assign({}, options, { wireProtocolCommand: false });\n        // There are cases where we need to flag the read preference not to get sent in\n        // the command, such as pre-5.0 servers attempting to perform an aggregate write\n        // with a non-primary read preference. In this case the effective read preference\n        // (primary) is not the same as the provided and must be removed completely.\n        if (finalOptions.omitReadPreference) {\n            delete finalOptions.readPreference;\n        }\n        const session = finalOptions.session;\n        const conn = session?.pinnedConnection;\n        // NOTE: This is a hack! We can't retrieve the connections used for executing an operation\n        //       (and prevent them from being checked back in) at the point of operation execution.\n        //       This should be considered as part of the work for NODE-2882\n        // NOTE:\n        //       When incrementing operation count, it's important that we increment it before we\n        //       attempt to check out a connection from the pool.  This ensures that operations that\n        //       are waiting for a connection are included in the operation count.  Load balanced\n        //       mode will only ever have a single server, so the operation count doesn't matter.\n        //       Incrementing the operation count above the logic to handle load balanced mode would\n        //       require special logic to decrement it again, or would double increment (the load\n        //       balanced code makes a recursive call).  Instead, we increment the count after this\n        //       check.\n        if (this.loadBalanced && session && conn == null && isPinnableCommand(cmd, session)) {\n            this.pool.checkOut((err, checkedOut) => {\n                if (err || checkedOut == null) {\n                    if (callback)\n                        return callback(err);\n                    return;\n                }\n                session.pin(checkedOut);\n                this.command(ns, cmd, finalOptions, callback);\n            });\n            return;\n        }\n        this.incrementOperationCount();\n        this.pool.withConnection(conn, (err, conn, cb) => {\n            if (err || !conn) {\n                this.decrementOperationCount();\n                if (!err) {\n                    return cb(new error_1.MongoRuntimeError('Failed to create connection without error'));\n                }\n                if (!(err instanceof errors_1.PoolClearedError)) {\n                    this.handleError(err);\n                }\n                return cb(err);\n            }\n            conn.command(ns, cmd, finalOptions, makeOperationHandler(this, conn, cmd, finalOptions, (error, response) => {\n                this.decrementOperationCount();\n                cb(error, response);\n            }));\n        }, callback);\n    }\n    /**\n     * Handle SDAM error\n     * @internal\n     */\n    handleError(error, connection) {\n        if (!(error instanceof error_1.MongoError)) {\n            return;\n        }\n        const isStaleError = error.connectionGeneration && error.connectionGeneration < this.pool.generation;\n        if (isStaleError) {\n            return;\n        }\n        const isNetworkNonTimeoutError = error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError);\n        const isNetworkTimeoutBeforeHandshakeError = (0, error_1.isNetworkErrorBeforeHandshake)(error);\n        const isAuthHandshakeError = error.hasErrorLabel(error_1.MongoErrorLabel.HandshakeError);\n        if (isNetworkNonTimeoutError || isNetworkTimeoutBeforeHandshakeError || isAuthHandshakeError) {\n            // In load balanced mode we never mark the server as unknown and always\n            // clear for the specific service id.\n            if (!this.loadBalanced) {\n                error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                markServerUnknown(this, error);\n            }\n            else if (connection) {\n                this.pool.clear({ serviceId: connection.serviceId });\n            }\n        }\n        else {\n            if ((0, error_1.isSDAMUnrecoverableError)(error)) {\n                if (shouldHandleStateChangeError(this, error)) {\n                    const shouldClearPool = (0, utils_1.maxWireVersion)(this) <= 7 || (0, error_1.isNodeShuttingDownError)(error);\n                    if (this.loadBalanced && connection && shouldClearPool) {\n                        this.pool.clear({ serviceId: connection.serviceId });\n                    }\n                    if (!this.loadBalanced) {\n                        if (shouldClearPool) {\n                            error.addErrorLabel(error_1.MongoErrorLabel.ResetPool);\n                        }\n                        markServerUnknown(this, error);\n                        process.nextTick(() => this.requestCheck());\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Decrement the operation count, returning the new count.\n     */\n    decrementOperationCount() {\n        return (this.s.operationCount -= 1);\n    }\n    /**\n     * Increment the operation count, returning the new count.\n     */\n    incrementOperationCount() {\n        return (this.s.operationCount += 1);\n    }\n}\n/** @event */\nServer.SERVER_HEARTBEAT_STARTED = constants_1.SERVER_HEARTBEAT_STARTED;\n/** @event */\nServer.SERVER_HEARTBEAT_SUCCEEDED = constants_1.SERVER_HEARTBEAT_SUCCEEDED;\n/** @event */\nServer.SERVER_HEARTBEAT_FAILED = constants_1.SERVER_HEARTBEAT_FAILED;\n/** @event */\nServer.CONNECT = constants_1.CONNECT;\n/** @event */\nServer.DESCRIPTION_RECEIVED = constants_1.DESCRIPTION_RECEIVED;\n/** @event */\nServer.CLOSED = constants_1.CLOSED;\n/** @event */\nServer.ENDED = constants_1.ENDED;\nexports.Server = Server;\nfunction calculateRoundTripTime(oldRtt, duration) {\n    if (oldRtt === -1) {\n        return duration;\n    }\n    const alpha = 0.2;\n    return alpha * duration + (1 - alpha) * oldRtt;\n}\nfunction markServerUnknown(server, error) {\n    // Load balancer servers can never be marked unknown.\n    if (server.loadBalanced) {\n        return;\n    }\n    if (error instanceof error_1.MongoNetworkError && !(error instanceof error_1.MongoNetworkTimeoutError)) {\n        server.monitor?.reset();\n    }\n    server.emit(Server.DESCRIPTION_RECEIVED, new server_description_1.ServerDescription(server.description.hostAddress, undefined, { error }));\n}\nfunction isPinnableCommand(cmd, session) {\n    if (session) {\n        return (session.inTransaction() ||\n            'aggregate' in cmd ||\n            'find' in cmd ||\n            'getMore' in cmd ||\n            'listCollections' in cmd ||\n            'listIndexes' in cmd);\n    }\n    return false;\n}\nfunction connectionIsStale(pool, connection) {\n    if (connection.serviceId) {\n        return (connection.generation !== pool.serviceGenerations.get(connection.serviceId.toHexString()));\n    }\n    return connection.generation !== pool.generation;\n}\nfunction shouldHandleStateChangeError(server, err) {\n    const etv = err.topologyVersion;\n    const stv = server.description.topologyVersion;\n    return (0, server_description_1.compareTopologyVersion)(stv, etv) < 0;\n}\nfunction inActiveTransaction(session, cmd) {\n    return session && session.inTransaction() && !(0, transactions_1.isTransactionCommand)(cmd);\n}\n/** this checks the retryWrites option passed down from the client options, it\n * does not check if the server supports retryable writes */\nfunction isRetryableWritesEnabled(topology) {\n    return topology.s.options.retryWrites !== false;\n}\nfunction makeOperationHandler(server, connection, cmd, options, callback) {\n    const session = options?.session;\n    return function handleOperationResult(error, result) {\n        // We should not swallow an error if it is present.\n        if (error == null && result != null) {\n            return callback(undefined, result);\n        }\n        if (options != null && 'noResponse' in options && options.noResponse === true) {\n            return callback(undefined, null);\n        }\n        if (!error) {\n            return callback(new error_1.MongoUnexpectedServerResponseError('Empty response with no error'));\n        }\n        if (!(error instanceof error_1.MongoError)) {\n            // Node.js or some other error we have not special handling for\n            return callback(error);\n        }\n        if (connectionIsStale(server.pool, connection)) {\n            return callback(error);\n        }\n        if (error instanceof error_1.MongoNetworkError) {\n            if (session && !session.hasEnded && session.serverSession) {\n                session.serverSession.isDirty = true;\n            }\n            // inActiveTransaction check handles commit and abort.\n            if (inActiveTransaction(session, cmd) &&\n                !error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.TransientTransactionError);\n            }\n            if ((isRetryableWritesEnabled(server.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, utils_1.supportsRetryableWrites)(server) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        else {\n            if ((isRetryableWritesEnabled(server.topology) || (0, transactions_1.isTransactionCommand)(cmd)) &&\n                (0, error_1.needsRetryableWriteLabel)(error, (0, utils_1.maxWireVersion)(server)) &&\n                !inActiveTransaction(session, cmd)) {\n                error.addErrorLabel(error_1.MongoErrorLabel.RetryableWriteError);\n            }\n        }\n        if (session &&\n            session.isPinned &&\n            error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n            session.unpin({ force: true });\n        }\n        server.handleError(error, connection);\n        return callback(error);\n    };\n}\n//# sourceMappingURL=server.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/server.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_description.js":
/*!*************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_description.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.compareTopologyVersion = exports.parseServerType = exports.ServerDescription = void 0;\nconst bson_1 = __webpack_require__(/*! ../bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst WRITABLE_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.LoadBalancer\n]);\nconst DATA_BEARING_SERVER_TYPES = new Set([\n    common_1.ServerType.RSPrimary,\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.Mongos,\n    common_1.ServerType.Standalone,\n    common_1.ServerType.LoadBalancer\n]);\n/**\n * The client's view of a single server, based on the most recent hello outcome.\n *\n * Internal type, not meant to be directly instantiated\n * @public\n */\nclass ServerDescription {\n    /**\n     * Create a ServerDescription\n     * @internal\n     *\n     * @param address - The address of the server\n     * @param hello - An optional hello response for this server\n     */\n    constructor(address, hello, options = {}) {\n        if (address == null || address === '') {\n            throw new error_1.MongoRuntimeError('ServerDescription must be provided with a non-empty address');\n        }\n        this.address =\n            typeof address === 'string'\n                ? utils_1.HostAddress.fromString(address).toString() // Use HostAddress to normalize\n                : address.toString();\n        this.type = parseServerType(hello, options);\n        this.hosts = hello?.hosts?.map((host) => host.toLowerCase()) ?? [];\n        this.passives = hello?.passives?.map((host) => host.toLowerCase()) ?? [];\n        this.arbiters = hello?.arbiters?.map((host) => host.toLowerCase()) ?? [];\n        this.tags = hello?.tags ?? {};\n        this.minWireVersion = hello?.minWireVersion ?? 0;\n        this.maxWireVersion = hello?.maxWireVersion ?? 0;\n        this.roundTripTime = options?.roundTripTime ?? -1;\n        this.lastUpdateTime = (0, utils_1.now)();\n        this.lastWriteDate = hello?.lastWrite?.lastWriteDate ?? 0;\n        this.error = options.error ?? null;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        this.topologyVersion = this.error?.topologyVersion ?? hello?.topologyVersion ?? null;\n        this.setName = hello?.setName ?? null;\n        this.setVersion = hello?.setVersion ?? null;\n        this.electionId = hello?.electionId ?? null;\n        this.logicalSessionTimeoutMinutes = hello?.logicalSessionTimeoutMinutes ?? null;\n        this.primary = hello?.primary ?? null;\n        this.me = hello?.me?.toLowerCase() ?? null;\n        this.$clusterTime = hello?.$clusterTime ?? null;\n    }\n    get hostAddress() {\n        return utils_1.HostAddress.fromString(this.address);\n    }\n    get allHosts() {\n        return this.hosts.concat(this.arbiters).concat(this.passives);\n    }\n    /** Is this server available for reads*/\n    get isReadable() {\n        return this.type === common_1.ServerType.RSSecondary || this.isWritable;\n    }\n    /** Is this server data bearing */\n    get isDataBearing() {\n        return DATA_BEARING_SERVER_TYPES.has(this.type);\n    }\n    /** Is this server available for writes */\n    get isWritable() {\n        return WRITABLE_SERVER_TYPES.has(this.type);\n    }\n    get host() {\n        const chopLength = `:${this.port}`.length;\n        return this.address.slice(0, -chopLength);\n    }\n    get port() {\n        const port = this.address.split(':').pop();\n        return port ? Number.parseInt(port, 10) : 27017;\n    }\n    /**\n     * Determines if another `ServerDescription` is equal to this one per the rules defined\n     * in the {@link https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#serverdescription|SDAM spec}\n     */\n    equals(other) {\n        // Despite using the comparator that would determine a nullish topologyVersion as greater than\n        // for equality we should only always perform direct equality comparison\n        const topologyVersionsEqual = this.topologyVersion === other?.topologyVersion ||\n            compareTopologyVersion(this.topologyVersion, other?.topologyVersion) === 0;\n        const electionIdsEqual = this.electionId != null && other?.electionId != null\n            ? (0, utils_1.compareObjectId)(this.electionId, other.electionId) === 0\n            : this.electionId === other?.electionId;\n        return (other != null &&\n            (0, utils_1.errorStrictEqual)(this.error, other.error) &&\n            this.type === other.type &&\n            this.minWireVersion === other.minWireVersion &&\n            (0, utils_1.arrayStrictEqual)(this.hosts, other.hosts) &&\n            tagsStrictEqual(this.tags, other.tags) &&\n            this.setName === other.setName &&\n            this.setVersion === other.setVersion &&\n            electionIdsEqual &&\n            this.primary === other.primary &&\n            this.logicalSessionTimeoutMinutes === other.logicalSessionTimeoutMinutes &&\n            topologyVersionsEqual);\n    }\n}\nexports.ServerDescription = ServerDescription;\n// Parses a `hello` message and determines the server type\nfunction parseServerType(hello, options) {\n    if (options?.loadBalanced) {\n        return common_1.ServerType.LoadBalancer;\n    }\n    if (!hello || !hello.ok) {\n        return common_1.ServerType.Unknown;\n    }\n    if (hello.isreplicaset) {\n        return common_1.ServerType.RSGhost;\n    }\n    if (hello.msg && hello.msg === 'isdbgrid') {\n        return common_1.ServerType.Mongos;\n    }\n    if (hello.setName) {\n        if (hello.hidden) {\n            return common_1.ServerType.RSOther;\n        }\n        else if (hello.isWritablePrimary) {\n            return common_1.ServerType.RSPrimary;\n        }\n        else if (hello.secondary) {\n            return common_1.ServerType.RSSecondary;\n        }\n        else if (hello.arbiterOnly) {\n            return common_1.ServerType.RSArbiter;\n        }\n        else {\n            return common_1.ServerType.RSOther;\n        }\n    }\n    return common_1.ServerType.Standalone;\n}\nexports.parseServerType = parseServerType;\nfunction tagsStrictEqual(tags, tags2) {\n    const tagsKeys = Object.keys(tags);\n    const tags2Keys = Object.keys(tags2);\n    return (tagsKeys.length === tags2Keys.length &&\n        tagsKeys.every((key) => tags2[key] === tags[key]));\n}\n/**\n * Compares two topology versions.\n *\n * 1. If the response topologyVersion is unset or the ServerDescription's\n *    topologyVersion is null, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is not equal to the\n *    ServerDescription's, the client MUST assume the response is more recent.\n * 1. If the response's topologyVersion.processId is equal to the\n *    ServerDescription's, the client MUST use the counter field to determine\n *    which topologyVersion is more recent.\n *\n * ```ts\n * currentTv <   newTv === -1\n * currentTv === newTv === 0\n * currentTv >   newTv === 1\n * ```\n */\nfunction compareTopologyVersion(currentTv, newTv) {\n    if (currentTv == null || newTv == null) {\n        return -1;\n    }\n    if (!currentTv.processId.equals(newTv.processId)) {\n        return -1;\n    }\n    // TODO(NODE-2674): Preserve int64 sent from MongoDB\n    const currentCounter = bson_1.Long.isLong(currentTv.counter)\n        ? currentTv.counter\n        : bson_1.Long.fromNumber(currentTv.counter);\n    const newCounter = bson_1.Long.isLong(newTv.counter) ? newTv.counter : bson_1.Long.fromNumber(newTv.counter);\n    return currentCounter.compare(newCounter);\n}\nexports.compareTopologyVersion = compareTopologyVersion;\n//# sourceMappingURL=server_description.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/server_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/server_selection.js":
/*!***********************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/server_selection.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.readPreferenceServerSelector = exports.secondaryWritableServerSelector = exports.sameServerSelector = exports.writableServerSelector = exports.MIN_SECONDARY_WRITE_WIRE_VERSION = void 0;\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\n// max staleness constants\nconst IDLE_WRITE_PERIOD = 10000;\nconst SMALLEST_MAX_STALENESS_SECONDS = 90;\n//  Minimum version to try writes on secondaries.\nexports.MIN_SECONDARY_WRITE_WIRE_VERSION = 13;\n/**\n * Returns a server selector that selects for writable servers\n */\nfunction writableServerSelector() {\n    return (topologyDescription, servers) => latencyWindowReducer(topologyDescription, servers.filter((s) => s.isWritable));\n}\nexports.writableServerSelector = writableServerSelector;\n/**\n * The purpose of this selector is to select the same server, only\n * if it is in a state that it can have commands sent to it.\n */\nfunction sameServerSelector(description) {\n    return (topologyDescription, servers) => {\n        if (!description)\n            return [];\n        // Filter the servers to match the provided description only if\n        // the type is not unknown.\n        return servers.filter(sd => {\n            return sd.address === description.address && sd.type !== common_1.ServerType.Unknown;\n        });\n    };\n}\nexports.sameServerSelector = sameServerSelector;\n/**\n * Returns a server selector that uses a read preference to select a\n * server potentially for a write on a secondary.\n */\nfunction secondaryWritableServerSelector(wireVersion, readPreference) {\n    // If server version < 5.0, read preference always primary.\n    // If server version >= 5.0...\n    // - If read preference is supplied, use that.\n    // - If no read preference is supplied, use primary.\n    if (!readPreference ||\n        !wireVersion ||\n        (wireVersion && wireVersion < exports.MIN_SECONDARY_WRITE_WIRE_VERSION)) {\n        return readPreferenceServerSelector(read_preference_1.ReadPreference.primary);\n    }\n    return readPreferenceServerSelector(readPreference);\n}\nexports.secondaryWritableServerSelector = secondaryWritableServerSelector;\n/**\n * Reduces the passed in array of servers by the rules of the \"Max Staleness\" specification\n * found here: https://github.com/mongodb/specifications/blob/master/source/max-staleness/max-staleness.rst\n *\n * @param readPreference - The read preference providing max staleness guidance\n * @param topologyDescription - The topology description\n * @param servers - The list of server descriptions to be reduced\n * @returns The list of servers that satisfy the requirements of max staleness\n */\nfunction maxStalenessReducer(readPreference, topologyDescription, servers) {\n    if (readPreference.maxStalenessSeconds == null || readPreference.maxStalenessSeconds < 0) {\n        return servers;\n    }\n    const maxStaleness = readPreference.maxStalenessSeconds;\n    const maxStalenessVariance = (topologyDescription.heartbeatFrequencyMS + IDLE_WRITE_PERIOD) / 1000;\n    if (maxStaleness < maxStalenessVariance) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${maxStalenessVariance} seconds`);\n    }\n    if (maxStaleness < SMALLEST_MAX_STALENESS_SECONDS) {\n        throw new error_1.MongoInvalidArgumentError(`Option \"maxStalenessSeconds\" must be at least ${SMALLEST_MAX_STALENESS_SECONDS} seconds`);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetWithPrimary) {\n        const primary = Array.from(topologyDescription.servers.values()).filter(primaryFilter)[0];\n        return servers.reduce((result, server) => {\n            const stalenessMS = server.lastUpdateTime -\n                server.lastWriteDate -\n                (primary.lastUpdateTime - primary.lastWriteDate) +\n                topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    if (topologyDescription.type === common_1.TopologyType.ReplicaSetNoPrimary) {\n        if (servers.length === 0) {\n            return servers;\n        }\n        const sMax = servers.reduce((max, s) => s.lastWriteDate > max.lastWriteDate ? s : max);\n        return servers.reduce((result, server) => {\n            const stalenessMS = sMax.lastWriteDate - server.lastWriteDate + topologyDescription.heartbeatFrequencyMS;\n            const staleness = stalenessMS / 1000;\n            const maxStalenessSeconds = readPreference.maxStalenessSeconds ?? 0;\n            if (staleness <= maxStalenessSeconds) {\n                result.push(server);\n            }\n            return result;\n        }, []);\n    }\n    return servers;\n}\n/**\n * Determines whether a server's tags match a given set of tags\n *\n * @param tagSet - The requested tag set to match\n * @param serverTags - The server's tags\n */\nfunction tagSetMatch(tagSet, serverTags) {\n    const keys = Object.keys(tagSet);\n    const serverTagKeys = Object.keys(serverTags);\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (serverTagKeys.indexOf(key) === -1 || serverTags[key] !== tagSet[key]) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Reduces a set of server descriptions based on tags requested by the read preference\n *\n * @param readPreference - The read preference providing the requested tags\n * @param servers - The list of server descriptions to reduce\n * @returns The list of servers matching the requested tags\n */\nfunction tagSetReducer(readPreference, servers) {\n    if (readPreference.tags == null ||\n        (Array.isArray(readPreference.tags) && readPreference.tags.length === 0)) {\n        return servers;\n    }\n    for (let i = 0; i < readPreference.tags.length; ++i) {\n        const tagSet = readPreference.tags[i];\n        const serversMatchingTagset = servers.reduce((matched, server) => {\n            if (tagSetMatch(tagSet, server.tags))\n                matched.push(server);\n            return matched;\n        }, []);\n        if (serversMatchingTagset.length) {\n            return serversMatchingTagset;\n        }\n    }\n    return [];\n}\n/**\n * Reduces a list of servers to ensure they fall within an acceptable latency window. This is\n * further specified in the \"Server Selection\" specification, found here:\n * https://github.com/mongodb/specifications/blob/master/source/server-selection/server-selection.rst\n *\n * @param topologyDescription - The topology description\n * @param servers - The list of servers to reduce\n * @returns The servers which fall within an acceptable latency window\n */\nfunction latencyWindowReducer(topologyDescription, servers) {\n    const low = servers.reduce((min, server) => min === -1 ? server.roundTripTime : Math.min(server.roundTripTime, min), -1);\n    const high = low + topologyDescription.localThresholdMS;\n    return servers.reduce((result, server) => {\n        if (server.roundTripTime <= high && server.roundTripTime >= low)\n            result.push(server);\n        return result;\n    }, []);\n}\n// filters\nfunction primaryFilter(server) {\n    return server.type === common_1.ServerType.RSPrimary;\n}\nfunction secondaryFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary;\n}\nfunction nearestFilter(server) {\n    return server.type === common_1.ServerType.RSSecondary || server.type === common_1.ServerType.RSPrimary;\n}\nfunction knownFilter(server) {\n    return server.type !== common_1.ServerType.Unknown;\n}\nfunction loadBalancerFilter(server) {\n    return server.type === common_1.ServerType.LoadBalancer;\n}\n/**\n * Returns a function which selects servers based on a provided read preference\n *\n * @param readPreference - The read preference to select with\n */\nfunction readPreferenceServerSelector(readPreference) {\n    if (!readPreference.isValid()) {\n        throw new error_1.MongoInvalidArgumentError('Invalid read preference specified');\n    }\n    return (topologyDescription, servers) => {\n        const commonWireVersion = topologyDescription.commonWireVersion;\n        if (commonWireVersion &&\n            readPreference.minWireVersion &&\n            readPreference.minWireVersion > commonWireVersion) {\n            throw new error_1.MongoCompatibilityError(`Minimum wire version '${readPreference.minWireVersion}' required, but found '${commonWireVersion}'`);\n        }\n        if (topologyDescription.type === common_1.TopologyType.LoadBalanced) {\n            return servers.filter(loadBalancerFilter);\n        }\n        if (topologyDescription.type === common_1.TopologyType.Unknown) {\n            return [];\n        }\n        if (topologyDescription.type === common_1.TopologyType.Single ||\n            topologyDescription.type === common_1.TopologyType.Sharded) {\n            return latencyWindowReducer(topologyDescription, servers.filter(knownFilter));\n        }\n        const mode = readPreference.mode;\n        if (mode === read_preference_1.ReadPreference.PRIMARY) {\n            return servers.filter(primaryFilter);\n        }\n        if (mode === read_preference_1.ReadPreference.PRIMARY_PREFERRED) {\n            const result = servers.filter(primaryFilter);\n            if (result.length) {\n                return result;\n            }\n        }\n        const filter = mode === read_preference_1.ReadPreference.NEAREST ? nearestFilter : secondaryFilter;\n        const selectedServers = latencyWindowReducer(topologyDescription, tagSetReducer(readPreference, maxStalenessReducer(readPreference, topologyDescription, servers.filter(filter))));\n        if (mode === read_preference_1.ReadPreference.SECONDARY_PREFERRED && selectedServers.length === 0) {\n            return servers.filter(primaryFilter);\n        }\n        return selectedServers;\n    };\n}\nexports.readPreferenceServerSelector = readPreferenceServerSelector;\n//# sourceMappingURL=server_selection.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/server_selection.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/srv_polling.js":
/*!******************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/srv_polling.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SrvPoller = exports.SrvPollingEvent = void 0;\nconst dns = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'dns'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\n/**\n * @internal\n * @category Event\n */\nclass SrvPollingEvent {\n    constructor(srvRecords) {\n        this.srvRecords = srvRecords;\n    }\n    hostnames() {\n        return new Set(this.srvRecords.map(r => utils_1.HostAddress.fromSrvRecord(r).toString()));\n    }\n}\nexports.SrvPollingEvent = SrvPollingEvent;\n/** @internal */\nclass SrvPoller extends mongo_types_1.TypedEventEmitter {\n    constructor(options) {\n        super();\n        if (!options || !options.srvHost) {\n            throw new error_1.MongoRuntimeError('Options for SrvPoller must exist and include srvHost');\n        }\n        this.srvHost = options.srvHost;\n        this.srvMaxHosts = options.srvMaxHosts ?? 0;\n        this.srvServiceName = options.srvServiceName ?? 'mongodb';\n        this.rescanSrvIntervalMS = 60000;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 10000;\n        this.haMode = false;\n        this.generation = 0;\n        this._timeout = undefined;\n    }\n    get srvAddress() {\n        return `_${this.srvServiceName}._tcp.${this.srvHost}`;\n    }\n    get intervalMS() {\n        return this.haMode ? this.heartbeatFrequencyMS : this.rescanSrvIntervalMS;\n    }\n    start() {\n        if (!this._timeout) {\n            this.schedule();\n        }\n    }\n    stop() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n            this.generation += 1;\n            this._timeout = undefined;\n        }\n    }\n    // TODO(NODE-4994): implement new logging logic for SrvPoller failures\n    schedule() {\n        if (this._timeout) {\n            (0, timers_1.clearTimeout)(this._timeout);\n        }\n        this._timeout = (0, timers_1.setTimeout)(() => {\n            this._poll().catch(() => null);\n        }, this.intervalMS);\n    }\n    success(srvRecords) {\n        this.haMode = false;\n        this.schedule();\n        this.emit(SrvPoller.SRV_RECORD_DISCOVERY, new SrvPollingEvent(srvRecords));\n    }\n    failure() {\n        this.haMode = true;\n        this.schedule();\n    }\n    async _poll() {\n        const generation = this.generation;\n        let srvRecords;\n        try {\n            srvRecords = await dns.promises.resolveSrv(this.srvAddress);\n        }\n        catch (dnsError) {\n            this.failure();\n            return;\n        }\n        if (generation !== this.generation) {\n            return;\n        }\n        const finalAddresses = [];\n        for (const record of srvRecords) {\n            if ((0, utils_1.matchesParentDomain)(record.name, this.srvHost)) {\n                finalAddresses.push(record);\n            }\n        }\n        if (!finalAddresses.length) {\n            this.failure();\n            return;\n        }\n        this.success(finalAddresses);\n    }\n}\n/** @event */\nSrvPoller.SRV_RECORD_DISCOVERY = 'srvRecordDiscovery';\nexports.SrvPoller = SrvPoller;\n//# sourceMappingURL=srv_polling.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/srv_polling.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ServerCapabilities = exports.Topology = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst connection_string_1 = __webpack_require__(/*! ../connection_string */ \"./node_modules/mongodb/lib/connection_string.js\");\nconst constants_1 = __webpack_require__(/*! ../constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ../mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst read_preference_1 = __webpack_require__(/*! ../read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst events_1 = __webpack_require__(/*! ./events */ \"./node_modules/mongodb/lib/sdam/events.js\");\nconst server_1 = __webpack_require__(/*! ./server */ \"./node_modules/mongodb/lib/sdam/server.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\nconst server_selection_1 = __webpack_require__(/*! ./server_selection */ \"./node_modules/mongodb/lib/sdam/server_selection.js\");\nconst srv_polling_1 = __webpack_require__(/*! ./srv_polling */ \"./node_modules/mongodb/lib/sdam/srv_polling.js\");\nconst topology_description_1 = __webpack_require__(/*! ./topology_description */ \"./node_modules/mongodb/lib/sdam/topology_description.js\");\n// Global state\nlet globalTopologyCounter = 0;\nconst stateTransition = (0, utils_1.makeStateMachine)({\n    [common_1.STATE_CLOSED]: [common_1.STATE_CLOSED, common_1.STATE_CONNECTING],\n    [common_1.STATE_CONNECTING]: [common_1.STATE_CONNECTING, common_1.STATE_CLOSING, common_1.STATE_CONNECTED, common_1.STATE_CLOSED],\n    [common_1.STATE_CONNECTED]: [common_1.STATE_CONNECTED, common_1.STATE_CLOSING, common_1.STATE_CLOSED],\n    [common_1.STATE_CLOSING]: [common_1.STATE_CLOSING, common_1.STATE_CLOSED]\n});\n/** @internal */\nconst kCancelled = Symbol('cancelled');\n/** @internal */\nconst kWaitQueue = Symbol('waitQueue');\n/**\n * A container of server instances representing a connection to a MongoDB topology.\n * @internal\n */\nclass Topology extends mongo_types_1.TypedEventEmitter {\n    /**\n     * @param seedlist - a list of HostAddress instances to connect to\n     */\n    constructor(client, seeds, options) {\n        super();\n        this.client = client;\n        this.selectServerAsync = (0, util_1.promisify)((selector, options, callback) => this.selectServer(selector, options, callback));\n        // Options should only be undefined in tests, MongoClient will always have defined options\n        options = options ?? {\n            hosts: [utils_1.HostAddress.fromString('localhost:27017')],\n            ...Object.fromEntries(connection_string_1.DEFAULT_OPTIONS.entries()),\n            ...Object.fromEntries(connection_string_1.FEATURE_FLAGS.entries())\n        };\n        if (typeof seeds === 'string') {\n            seeds = [utils_1.HostAddress.fromString(seeds)];\n        }\n        else if (!Array.isArray(seeds)) {\n            seeds = [seeds];\n        }\n        const seedlist = [];\n        for (const seed of seeds) {\n            if (typeof seed === 'string') {\n                seedlist.push(utils_1.HostAddress.fromString(seed));\n            }\n            else if (seed instanceof utils_1.HostAddress) {\n                seedlist.push(seed);\n            }\n            else {\n                // FIXME(NODE-3483): May need to be a MongoParseError\n                throw new error_1.MongoRuntimeError(`Topology cannot be constructed from ${JSON.stringify(seed)}`);\n            }\n        }\n        const topologyType = topologyTypeFromOptions(options);\n        const topologyId = globalTopologyCounter++;\n        const selectedHosts = options.srvMaxHosts == null ||\n            options.srvMaxHosts === 0 ||\n            options.srvMaxHosts >= seedlist.length\n            ? seedlist\n            : (0, utils_1.shuffle)(seedlist, options.srvMaxHosts);\n        const serverDescriptions = new Map();\n        for (const hostAddress of selectedHosts) {\n            serverDescriptions.set(hostAddress.toString(), new server_description_1.ServerDescription(hostAddress));\n        }\n        this[kWaitQueue] = new utils_1.List();\n        this.s = {\n            // the id of this topology\n            id: topologyId,\n            // passed in options\n            options,\n            // initial seedlist of servers to connect to\n            seedlist,\n            // initial state\n            state: common_1.STATE_CLOSED,\n            // the topology description\n            description: new topology_description_1.TopologyDescription(topologyType, serverDescriptions, options.replicaSet, undefined, undefined, undefined, options),\n            serverSelectionTimeoutMS: options.serverSelectionTimeoutMS,\n            heartbeatFrequencyMS: options.heartbeatFrequencyMS,\n            minHeartbeatFrequencyMS: options.minHeartbeatFrequencyMS,\n            // a map of server instances to normalized addresses\n            servers: new Map(),\n            credentials: options?.credentials,\n            clusterTime: undefined,\n            // timer management\n            connectionTimers: new Set(),\n            detectShardedTopology: ev => this.detectShardedTopology(ev),\n            detectSrvRecords: ev => this.detectSrvRecords(ev)\n        };\n        if (options.srvHost && !options.loadBalanced) {\n            this.s.srvPoller =\n                options.srvPoller ??\n                    new srv_polling_1.SrvPoller({\n                        heartbeatFrequencyMS: this.s.heartbeatFrequencyMS,\n                        srvHost: options.srvHost,\n                        srvMaxHosts: options.srvMaxHosts,\n                        srvServiceName: options.srvServiceName\n                    });\n            this.on(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n        }\n    }\n    detectShardedTopology(event) {\n        const previousType = event.previousDescription.type;\n        const newType = event.newDescription.type;\n        const transitionToSharded = previousType !== common_1.TopologyType.Sharded && newType === common_1.TopologyType.Sharded;\n        const srvListeners = this.s.srvPoller?.listeners(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY);\n        const listeningToSrvPolling = !!srvListeners?.includes(this.s.detectSrvRecords);\n        if (transitionToSharded && !listeningToSrvPolling) {\n            this.s.srvPoller?.on(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n            this.s.srvPoller?.start();\n        }\n    }\n    detectSrvRecords(ev) {\n        const previousTopologyDescription = this.s.description;\n        this.s.description = this.s.description.updateFromSrvPollingEvent(ev, this.s.options.srvMaxHosts);\n        if (this.s.description === previousTopologyDescription) {\n            // Nothing changed, so return\n            return;\n        }\n        updateServers(this);\n        this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n    }\n    /**\n     * @returns A `TopologyDescription` for this topology\n     */\n    get description() {\n        return this.s.description;\n    }\n    get loadBalanced() {\n        return this.s.options.loadBalanced;\n    }\n    get capabilities() {\n        return new ServerCapabilities(this.lastHello());\n    }\n    connect(options, callback) {\n        if (typeof options === 'function')\n            (callback = options), (options = {});\n        options = options ?? {};\n        if (this.s.state === common_1.STATE_CONNECTED) {\n            if (typeof callback === 'function') {\n                callback();\n            }\n            return;\n        }\n        stateTransition(this, common_1.STATE_CONNECTING);\n        // emit SDAM monitoring events\n        this.emit(Topology.TOPOLOGY_OPENING, new events_1.TopologyOpeningEvent(this.s.id));\n        // emit an event for the topology change\n        this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, new topology_description_1.TopologyDescription(common_1.TopologyType.Unknown), // initial is always Unknown\n        this.s.description));\n        // connect all known servers, then attempt server selection to connect\n        const serverDescriptions = Array.from(this.s.description.servers.values());\n        this.s.servers = new Map(serverDescriptions.map(serverDescription => [\n            serverDescription.address,\n            createAndConnectServer(this, serverDescription)\n        ]));\n        // In load balancer mode we need to fake a server description getting\n        // emitted from the monitor, since the monitor doesn't exist.\n        if (this.s.options.loadBalanced) {\n            for (const description of serverDescriptions) {\n                const newDescription = new server_description_1.ServerDescription(description.hostAddress, undefined, {\n                    loadBalanced: this.s.options.loadBalanced\n                });\n                this.serverUpdateHandler(newDescription);\n            }\n        }\n        const exitWithError = (error) => callback ? callback(error) : this.emit(Topology.ERROR, error);\n        const readPreference = options.readPreference ?? read_preference_1.ReadPreference.primary;\n        this.selectServer((0, server_selection_1.readPreferenceServerSelector)(readPreference), options, (err, server) => {\n            if (err) {\n                return this.close({ force: false }, () => exitWithError(err));\n            }\n            // TODO: NODE-2471\n            const skipPingOnConnect = this.s.options[Symbol.for('@@mdb.skipPingOnConnect')] === true;\n            if (!skipPingOnConnect && server && this.s.credentials) {\n                server.command((0, utils_1.ns)('admin.$cmd'), { ping: 1 }, {}, err => {\n                    if (err) {\n                        return exitWithError(err);\n                    }\n                    stateTransition(this, common_1.STATE_CONNECTED);\n                    this.emit(Topology.OPEN, this);\n                    this.emit(Topology.CONNECT, this);\n                    callback?.(undefined, this);\n                });\n                return;\n            }\n            stateTransition(this, common_1.STATE_CONNECTED);\n            this.emit(Topology.OPEN, this);\n            this.emit(Topology.CONNECT, this);\n            callback?.(undefined, this);\n        });\n    }\n    close(options, callback) {\n        options = options ?? { force: false };\n        if (this.s.state === common_1.STATE_CLOSED || this.s.state === common_1.STATE_CLOSING) {\n            return callback?.();\n        }\n        const destroyedServers = Array.from(this.s.servers.values(), server => {\n            return (0, util_1.promisify)(destroyServer)(server, this, { force: !!options?.force });\n        });\n        Promise.all(destroyedServers)\n            .then(() => {\n            this.s.servers.clear();\n            stateTransition(this, common_1.STATE_CLOSING);\n            drainWaitQueue(this[kWaitQueue], new error_1.MongoTopologyClosedError());\n            (0, common_1.drainTimerQueue)(this.s.connectionTimers);\n            if (this.s.srvPoller) {\n                this.s.srvPoller.stop();\n                this.s.srvPoller.removeListener(srv_polling_1.SrvPoller.SRV_RECORD_DISCOVERY, this.s.detectSrvRecords);\n            }\n            this.removeListener(Topology.TOPOLOGY_DESCRIPTION_CHANGED, this.s.detectShardedTopology);\n            stateTransition(this, common_1.STATE_CLOSED);\n            // emit an event for close\n            this.emit(Topology.TOPOLOGY_CLOSED, new events_1.TopologyClosedEvent(this.s.id));\n        })\n            .finally(() => callback?.());\n    }\n    /**\n     * Selects a server according to the selection predicate provided\n     *\n     * @param selector - An optional selector to select servers by, defaults to a random selection within a latency window\n     * @param options - Optional settings related to server selection\n     * @param callback - The callback used to indicate success or failure\n     * @returns An instance of a `Server` meeting the criteria of the predicate provided\n     */\n    selectServer(selector, options, callback) {\n        let serverSelector;\n        if (typeof selector !== 'function') {\n            if (typeof selector === 'string') {\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.fromString(selector));\n            }\n            else {\n                let readPreference;\n                if (selector instanceof read_preference_1.ReadPreference) {\n                    readPreference = selector;\n                }\n                else {\n                    read_preference_1.ReadPreference.translate(options);\n                    readPreference = options.readPreference || read_preference_1.ReadPreference.primary;\n                }\n                serverSelector = (0, server_selection_1.readPreferenceServerSelector)(readPreference);\n            }\n        }\n        else {\n            serverSelector = selector;\n        }\n        options = Object.assign({}, { serverSelectionTimeoutMS: this.s.serverSelectionTimeoutMS }, options);\n        const isSharded = this.description.type === common_1.TopologyType.Sharded;\n        const session = options.session;\n        const transaction = session && session.transaction;\n        if (isSharded && transaction && transaction.server) {\n            callback(undefined, transaction.server);\n            return;\n        }\n        const waitQueueMember = {\n            serverSelector,\n            transaction,\n            callback,\n            timeoutController: new utils_1.TimeoutController(options.serverSelectionTimeoutMS)\n        };\n        waitQueueMember.timeoutController.signal.addEventListener('abort', () => {\n            waitQueueMember[kCancelled] = true;\n            waitQueueMember.timeoutController.clear();\n            const timeoutError = new error_1.MongoServerSelectionError(`Server selection timed out after ${options.serverSelectionTimeoutMS} ms`, this.description);\n            waitQueueMember.callback(timeoutError);\n        });\n        this[kWaitQueue].push(waitQueueMember);\n        processWaitQueue(this);\n    }\n    /**\n     * Update the internal TopologyDescription with a ServerDescription\n     *\n     * @param serverDescription - The server to update in the internal list of server descriptions\n     */\n    serverUpdateHandler(serverDescription) {\n        if (!this.s.description.hasServer(serverDescription.address)) {\n            return;\n        }\n        // ignore this server update if its from an outdated topologyVersion\n        if (isStaleServerDescription(this.s.description, serverDescription)) {\n            return;\n        }\n        // these will be used for monitoring events later\n        const previousTopologyDescription = this.s.description;\n        const previousServerDescription = this.s.description.servers.get(serverDescription.address);\n        if (!previousServerDescription) {\n            return;\n        }\n        // Driver Sessions Spec: \"Whenever a driver receives a cluster time from\n        // a server it MUST compare it to the current highest seen cluster time\n        // for the deployment. If the new cluster time is higher than the\n        // highest seen cluster time it MUST become the new highest seen cluster\n        // time. Two cluster times are compared using only the BsonTimestamp\n        // value of the clusterTime embedded field.\"\n        const clusterTime = serverDescription.$clusterTime;\n        if (clusterTime) {\n            (0, common_1._advanceClusterTime)(this, clusterTime);\n        }\n        // If we already know all the information contained in this updated description, then\n        // we don't need to emit SDAM events, but still need to update the description, in order\n        // to keep client-tracked attributes like last update time and round trip time up to date\n        const equalDescriptions = previousServerDescription && previousServerDescription.equals(serverDescription);\n        // first update the TopologyDescription\n        this.s.description = this.s.description.update(serverDescription);\n        if (this.s.description.compatibilityError) {\n            this.emit(Topology.ERROR, new error_1.MongoCompatibilityError(this.s.description.compatibilityError));\n            return;\n        }\n        // emit monitoring events for this change\n        if (!equalDescriptions) {\n            const newDescription = this.s.description.servers.get(serverDescription.address);\n            if (newDescription) {\n                this.emit(Topology.SERVER_DESCRIPTION_CHANGED, new events_1.ServerDescriptionChangedEvent(this.s.id, serverDescription.address, previousServerDescription, newDescription));\n            }\n        }\n        // update server list from updated descriptions\n        updateServers(this, serverDescription);\n        // attempt to resolve any outstanding server selection attempts\n        if (this[kWaitQueue].length > 0) {\n            processWaitQueue(this);\n        }\n        if (!equalDescriptions) {\n            this.emit(Topology.TOPOLOGY_DESCRIPTION_CHANGED, new events_1.TopologyDescriptionChangedEvent(this.s.id, previousTopologyDescription, this.s.description));\n        }\n    }\n    auth(credentials, callback) {\n        if (typeof credentials === 'function')\n            (callback = credentials), (credentials = undefined);\n        if (typeof callback === 'function')\n            callback(undefined, true);\n    }\n    get clientMetadata() {\n        return this.s.options.metadata;\n    }\n    isConnected() {\n        return this.s.state === common_1.STATE_CONNECTED;\n    }\n    isDestroyed() {\n        return this.s.state === common_1.STATE_CLOSED;\n    }\n    // NOTE: There are many places in code where we explicitly check the last hello\n    //       to do feature support detection. This should be done any other way, but for\n    //       now we will just return the first hello seen, which should suffice.\n    lastHello() {\n        const serverDescriptions = Array.from(this.description.servers.values());\n        if (serverDescriptions.length === 0)\n            return {};\n        const sd = serverDescriptions.filter((sd) => sd.type !== common_1.ServerType.Unknown)[0];\n        const result = sd || { maxWireVersion: this.description.commonWireVersion };\n        return result;\n    }\n    get commonWireVersion() {\n        return this.description.commonWireVersion;\n    }\n    get logicalSessionTimeoutMinutes() {\n        return this.description.logicalSessionTimeoutMinutes;\n    }\n    get clusterTime() {\n        return this.s.clusterTime;\n    }\n    set clusterTime(clusterTime) {\n        this.s.clusterTime = clusterTime;\n    }\n}\n/** @event */\nTopology.SERVER_OPENING = constants_1.SERVER_OPENING;\n/** @event */\nTopology.SERVER_CLOSED = constants_1.SERVER_CLOSED;\n/** @event */\nTopology.SERVER_DESCRIPTION_CHANGED = constants_1.SERVER_DESCRIPTION_CHANGED;\n/** @event */\nTopology.TOPOLOGY_OPENING = constants_1.TOPOLOGY_OPENING;\n/** @event */\nTopology.TOPOLOGY_CLOSED = constants_1.TOPOLOGY_CLOSED;\n/** @event */\nTopology.TOPOLOGY_DESCRIPTION_CHANGED = constants_1.TOPOLOGY_DESCRIPTION_CHANGED;\n/** @event */\nTopology.ERROR = constants_1.ERROR;\n/** @event */\nTopology.OPEN = constants_1.OPEN;\n/** @event */\nTopology.CONNECT = constants_1.CONNECT;\n/** @event */\nTopology.CLOSE = constants_1.CLOSE;\n/** @event */\nTopology.TIMEOUT = constants_1.TIMEOUT;\nexports.Topology = Topology;\n/** Destroys a server, and removes all event listeners from the instance */\nfunction destroyServer(server, topology, options, callback) {\n    options = options ?? { force: false };\n    for (const event of constants_1.LOCAL_SERVER_EVENTS) {\n        server.removeAllListeners(event);\n    }\n    server.destroy(options, () => {\n        topology.emit(Topology.SERVER_CLOSED, new events_1.ServerClosedEvent(topology.s.id, server.description.address));\n        for (const event of constants_1.SERVER_RELAY_EVENTS) {\n            server.removeAllListeners(event);\n        }\n        if (typeof callback === 'function') {\n            callback();\n        }\n    });\n}\n/** Predicts the TopologyType from options */\nfunction topologyTypeFromOptions(options) {\n    if (options?.directConnection) {\n        return common_1.TopologyType.Single;\n    }\n    if (options?.replicaSet) {\n        return common_1.TopologyType.ReplicaSetNoPrimary;\n    }\n    if (options?.loadBalanced) {\n        return common_1.TopologyType.LoadBalanced;\n    }\n    return common_1.TopologyType.Unknown;\n}\n/**\n * Creates new server instances and attempts to connect them\n *\n * @param topology - The topology that this server belongs to\n * @param serverDescription - The description for the server to initialize and connect to\n */\nfunction createAndConnectServer(topology, serverDescription) {\n    topology.emit(Topology.SERVER_OPENING, new events_1.ServerOpeningEvent(topology.s.id, serverDescription.address));\n    const server = new server_1.Server(topology, serverDescription, topology.s.options);\n    for (const event of constants_1.SERVER_RELAY_EVENTS) {\n        server.on(event, (e) => topology.emit(event, e));\n    }\n    server.on(server_1.Server.DESCRIPTION_RECEIVED, description => topology.serverUpdateHandler(description));\n    server.connect();\n    return server;\n}\n/**\n * @param topology - Topology to update.\n * @param incomingServerDescription - New server description.\n */\nfunction updateServers(topology, incomingServerDescription) {\n    // update the internal server's description\n    if (incomingServerDescription && topology.s.servers.has(incomingServerDescription.address)) {\n        const server = topology.s.servers.get(incomingServerDescription.address);\n        if (server) {\n            server.s.description = incomingServerDescription;\n            if (incomingServerDescription.error instanceof error_1.MongoError &&\n                incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.ResetPool)) {\n                const interruptInUseConnections = incomingServerDescription.error.hasErrorLabel(error_1.MongoErrorLabel.InterruptInUseConnections);\n                server.pool.clear({ interruptInUseConnections });\n            }\n            else if (incomingServerDescription.error == null) {\n                const newTopologyType = topology.s.description.type;\n                const shouldMarkPoolReady = incomingServerDescription.isDataBearing ||\n                    (incomingServerDescription.type !== common_1.ServerType.Unknown &&\n                        newTopologyType === common_1.TopologyType.Single);\n                if (shouldMarkPoolReady) {\n                    server.pool.ready();\n                }\n            }\n        }\n    }\n    // add new servers for all descriptions we currently don't know about locally\n    for (const serverDescription of topology.description.servers.values()) {\n        if (!topology.s.servers.has(serverDescription.address)) {\n            const server = createAndConnectServer(topology, serverDescription);\n            topology.s.servers.set(serverDescription.address, server);\n        }\n    }\n    // for all servers no longer known, remove their descriptions and destroy their instances\n    for (const entry of topology.s.servers) {\n        const serverAddress = entry[0];\n        if (topology.description.hasServer(serverAddress)) {\n            continue;\n        }\n        if (!topology.s.servers.has(serverAddress)) {\n            continue;\n        }\n        const server = topology.s.servers.get(serverAddress);\n        topology.s.servers.delete(serverAddress);\n        // prepare server for garbage collection\n        if (server) {\n            destroyServer(server, topology);\n        }\n    }\n}\nfunction drainWaitQueue(queue, err) {\n    while (queue.length) {\n        const waitQueueMember = queue.shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        waitQueueMember.timeoutController.clear();\n        if (!waitQueueMember[kCancelled]) {\n            waitQueueMember.callback(err);\n        }\n    }\n}\nfunction processWaitQueue(topology) {\n    if (topology.s.state === common_1.STATE_CLOSED) {\n        drainWaitQueue(topology[kWaitQueue], new error_1.MongoTopologyClosedError());\n        return;\n    }\n    const isSharded = topology.description.type === common_1.TopologyType.Sharded;\n    const serverDescriptions = Array.from(topology.description.servers.values());\n    const membersToProcess = topology[kWaitQueue].length;\n    for (let i = 0; i < membersToProcess; ++i) {\n        const waitQueueMember = topology[kWaitQueue].shift();\n        if (!waitQueueMember) {\n            continue;\n        }\n        if (waitQueueMember[kCancelled]) {\n            continue;\n        }\n        let selectedDescriptions;\n        try {\n            const serverSelector = waitQueueMember.serverSelector;\n            selectedDescriptions = serverSelector\n                ? serverSelector(topology.description, serverDescriptions)\n                : serverDescriptions;\n        }\n        catch (e) {\n            waitQueueMember.timeoutController.clear();\n            waitQueueMember.callback(e);\n            continue;\n        }\n        let selectedServer;\n        if (selectedDescriptions.length === 0) {\n            topology[kWaitQueue].push(waitQueueMember);\n            continue;\n        }\n        else if (selectedDescriptions.length === 1) {\n            selectedServer = topology.s.servers.get(selectedDescriptions[0].address);\n        }\n        else {\n            const descriptions = (0, utils_1.shuffle)(selectedDescriptions, 2);\n            const server1 = topology.s.servers.get(descriptions[0].address);\n            const server2 = topology.s.servers.get(descriptions[1].address);\n            selectedServer =\n                server1 && server2 && server1.s.operationCount < server2.s.operationCount\n                    ? server1\n                    : server2;\n        }\n        if (!selectedServer) {\n            waitQueueMember.callback(new error_1.MongoServerSelectionError('server selection returned a server description but the server was not found in the topology', topology.description));\n            return;\n        }\n        const transaction = waitQueueMember.transaction;\n        if (isSharded && transaction && transaction.isActive && selectedServer) {\n            transaction.pinServer(selectedServer);\n        }\n        waitQueueMember.timeoutController.clear();\n        waitQueueMember.callback(undefined, selectedServer);\n    }\n    if (topology[kWaitQueue].length > 0) {\n        // ensure all server monitors attempt monitoring soon\n        for (const [, server] of topology.s.servers) {\n            process.nextTick(function scheduleServerCheck() {\n                return server.requestCheck();\n            });\n        }\n    }\n}\nfunction isStaleServerDescription(topologyDescription, incomingServerDescription) {\n    const currentServerDescription = topologyDescription.servers.get(incomingServerDescription.address);\n    const currentTopologyVersion = currentServerDescription?.topologyVersion;\n    return ((0, server_description_1.compareTopologyVersion)(currentTopologyVersion, incomingServerDescription.topologyVersion) > 0);\n}\n/** @public */\nclass ServerCapabilities {\n    constructor(hello) {\n        this.minWireVersion = hello.minWireVersion || 0;\n        this.maxWireVersion = hello.maxWireVersion || 0;\n    }\n    get hasAggregationCursor() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasWriteCommands() {\n        return this.maxWireVersion >= 2;\n    }\n    get hasTextSearch() {\n        return this.minWireVersion >= 0;\n    }\n    get hasAuthCommands() {\n        return this.maxWireVersion >= 1;\n    }\n    get hasListCollectionsCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get hasListIndexesCommand() {\n        return this.maxWireVersion >= 3;\n    }\n    get supportsSnapshotReads() {\n        return this.maxWireVersion >= 13;\n    }\n    get commandsTakeWriteConcern() {\n        return this.maxWireVersion >= 5;\n    }\n    get commandsTakeCollation() {\n        return this.maxWireVersion >= 5;\n    }\n}\nexports.ServerCapabilities = ServerCapabilities;\n//# sourceMappingURL=topology.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/topology.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sdam/topology_description.js":
/*!***************************************************************!*\
  !*** ./node_modules/mongodb/lib/sdam/topology_description.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TopologyDescription = void 0;\nconst WIRE_CONSTANTS = __webpack_require__(/*! ../cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst error_1 = __webpack_require__(/*! ../error */ \"./node_modules/mongodb/lib/error.js\");\nconst utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst common_1 = __webpack_require__(/*! ./common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst server_description_1 = __webpack_require__(/*! ./server_description */ \"./node_modules/mongodb/lib/sdam/server_description.js\");\n// constants related to compatibility checks\nconst MIN_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_SERVER_VERSION;\nconst MAX_SUPPORTED_SERVER_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_SERVER_VERSION;\nconst MIN_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MIN_SUPPORTED_WIRE_VERSION;\nconst MAX_SUPPORTED_WIRE_VERSION = WIRE_CONSTANTS.MAX_SUPPORTED_WIRE_VERSION;\nconst MONGOS_OR_UNKNOWN = new Set([common_1.ServerType.Mongos, common_1.ServerType.Unknown]);\nconst MONGOS_OR_STANDALONE = new Set([common_1.ServerType.Mongos, common_1.ServerType.Standalone]);\nconst NON_PRIMARY_RS_MEMBERS = new Set([\n    common_1.ServerType.RSSecondary,\n    common_1.ServerType.RSArbiter,\n    common_1.ServerType.RSOther\n]);\n/**\n * Representation of a deployment of servers\n * @public\n */\nclass TopologyDescription {\n    /**\n     * Create a TopologyDescription\n     */\n    constructor(topologyType, serverDescriptions = null, setName = null, maxSetVersion = null, maxElectionId = null, commonWireVersion = null, options = null) {\n        options = options ?? {};\n        this.type = topologyType ?? common_1.TopologyType.Unknown;\n        this.servers = serverDescriptions ?? new Map();\n        this.stale = false;\n        this.compatible = true;\n        this.heartbeatFrequencyMS = options.heartbeatFrequencyMS ?? 0;\n        this.localThresholdMS = options.localThresholdMS ?? 15;\n        this.setName = setName ?? null;\n        this.maxElectionId = maxElectionId ?? null;\n        this.maxSetVersion = maxSetVersion ?? null;\n        this.commonWireVersion = commonWireVersion ?? 0;\n        // determine server compatibility\n        for (const serverDescription of this.servers.values()) {\n            // Load balancer mode is always compatible.\n            if (serverDescription.type === common_1.ServerType.Unknown ||\n                serverDescription.type === common_1.ServerType.LoadBalancer) {\n                continue;\n            }\n            if (serverDescription.minWireVersion > MAX_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} requires wire version ${serverDescription.minWireVersion}, but this version of the driver only supports up to ${MAX_SUPPORTED_WIRE_VERSION} (MongoDB ${MAX_SUPPORTED_SERVER_VERSION})`;\n            }\n            if (serverDescription.maxWireVersion < MIN_SUPPORTED_WIRE_VERSION) {\n                this.compatible = false;\n                this.compatibilityError = `Server at ${serverDescription.address} reports wire version ${serverDescription.maxWireVersion}, but this version of the driver requires at least ${MIN_SUPPORTED_WIRE_VERSION} (MongoDB ${MIN_SUPPORTED_SERVER_VERSION}).`;\n                break;\n            }\n        }\n        // Whenever a client updates the TopologyDescription from a hello response, it MUST set\n        // TopologyDescription.logicalSessionTimeoutMinutes to the smallest logicalSessionTimeoutMinutes\n        // value among ServerDescriptions of all data-bearing server types. If any have a null\n        // logicalSessionTimeoutMinutes, then TopologyDescription.logicalSessionTimeoutMinutes MUST be\n        // set to null.\n        this.logicalSessionTimeoutMinutes = null;\n        for (const [, server] of this.servers) {\n            if (server.isReadable) {\n                if (server.logicalSessionTimeoutMinutes == null) {\n                    // If any of the servers have a null logicalSessionsTimeout, then the whole topology does\n                    this.logicalSessionTimeoutMinutes = null;\n                    break;\n                }\n                if (this.logicalSessionTimeoutMinutes == null) {\n                    // First server with a non null logicalSessionsTimeout\n                    this.logicalSessionTimeoutMinutes = server.logicalSessionTimeoutMinutes;\n                    continue;\n                }\n                // Always select the smaller of the:\n                // current server logicalSessionsTimeout and the topologies logicalSessionsTimeout\n                this.logicalSessionTimeoutMinutes = Math.min(this.logicalSessionTimeoutMinutes, server.logicalSessionTimeoutMinutes);\n            }\n        }\n    }\n    /**\n     * Returns a new TopologyDescription based on the SrvPollingEvent\n     * @internal\n     */\n    updateFromSrvPollingEvent(ev, srvMaxHosts = 0) {\n        /** The SRV addresses defines the set of addresses we should be using */\n        const incomingHostnames = ev.hostnames();\n        const currentHostnames = new Set(this.servers.keys());\n        const hostnamesToAdd = new Set(incomingHostnames);\n        const hostnamesToRemove = new Set();\n        for (const hostname of currentHostnames) {\n            // filter hostnamesToAdd (made from incomingHostnames) down to what is *not* present in currentHostnames\n            hostnamesToAdd.delete(hostname);\n            if (!incomingHostnames.has(hostname)) {\n                // If the SRV Records no longer include this hostname\n                // we have to stop using it\n                hostnamesToRemove.add(hostname);\n            }\n        }\n        if (hostnamesToAdd.size === 0 && hostnamesToRemove.size === 0) {\n            // No new hosts to add and none to remove\n            return this;\n        }\n        const serverDescriptions = new Map(this.servers);\n        for (const removedHost of hostnamesToRemove) {\n            serverDescriptions.delete(removedHost);\n        }\n        if (hostnamesToAdd.size > 0) {\n            if (srvMaxHosts === 0) {\n                // Add all!\n                for (const hostToAdd of hostnamesToAdd) {\n                    serverDescriptions.set(hostToAdd, new server_description_1.ServerDescription(hostToAdd));\n                }\n            }\n            else if (serverDescriptions.size < srvMaxHosts) {\n                // Add only the amount needed to get us back to srvMaxHosts\n                const selectedHosts = (0, utils_1.shuffle)(hostnamesToAdd, srvMaxHosts - serverDescriptions.size);\n                for (const selectedHostToAdd of selectedHosts) {\n                    serverDescriptions.set(selectedHostToAdd, new server_description_1.ServerDescription(selectedHostToAdd));\n                }\n            }\n        }\n        return new TopologyDescription(this.type, serverDescriptions, this.setName, this.maxSetVersion, this.maxElectionId, this.commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    /**\n     * Returns a copy of this description updated with a given ServerDescription\n     * @internal\n     */\n    update(serverDescription) {\n        const address = serverDescription.address;\n        // potentially mutated values\n        let { type: topologyType, setName, maxSetVersion, maxElectionId, commonWireVersion } = this;\n        const serverType = serverDescription.type;\n        const serverDescriptions = new Map(this.servers);\n        // update common wire version\n        if (serverDescription.maxWireVersion !== 0) {\n            if (commonWireVersion == null) {\n                commonWireVersion = serverDescription.maxWireVersion;\n            }\n            else {\n                commonWireVersion = Math.min(commonWireVersion, serverDescription.maxWireVersion);\n            }\n        }\n        if (typeof serverDescription.setName === 'string' &&\n            typeof setName === 'string' &&\n            serverDescription.setName !== setName) {\n            if (topologyType === common_1.TopologyType.Single) {\n                // \"Single\" Topology with setName mismatch is direct connection usage, mark unknown do not remove\n                serverDescription = new server_description_1.ServerDescription(address);\n            }\n            else {\n                serverDescriptions.delete(address);\n            }\n        }\n        // update the actual server description\n        serverDescriptions.set(address, serverDescription);\n        if (topologyType === common_1.TopologyType.Single) {\n            // once we are defined as single, that never changes\n            return new TopologyDescription(common_1.TopologyType.Single, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n        }\n        if (topologyType === common_1.TopologyType.Unknown) {\n            if (serverType === common_1.ServerType.Standalone && this.servers.size !== 1) {\n                serverDescriptions.delete(address);\n            }\n            else {\n                topologyType = topologyTypeForServerType(serverType);\n            }\n        }\n        if (topologyType === common_1.TopologyType.Sharded) {\n            if (!MONGOS_OR_UNKNOWN.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetNoPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n            }\n            if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                const result = updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName);\n                topologyType = result[0];\n                setName = result[1];\n            }\n        }\n        if (topologyType === common_1.TopologyType.ReplicaSetWithPrimary) {\n            if (MONGOS_OR_STANDALONE.has(serverType)) {\n                serverDescriptions.delete(address);\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n            else if (serverType === common_1.ServerType.RSPrimary) {\n                const result = updateRsFromPrimary(serverDescriptions, serverDescription, setName, maxSetVersion, maxElectionId);\n                topologyType = result[0];\n                setName = result[1];\n                maxSetVersion = result[2];\n                maxElectionId = result[3];\n            }\n            else if (NON_PRIMARY_RS_MEMBERS.has(serverType)) {\n                topologyType = updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName);\n            }\n            else {\n                topologyType = checkHasPrimary(serverDescriptions);\n            }\n        }\n        return new TopologyDescription(topologyType, serverDescriptions, setName, maxSetVersion, maxElectionId, commonWireVersion, { heartbeatFrequencyMS: this.heartbeatFrequencyMS, localThresholdMS: this.localThresholdMS });\n    }\n    get error() {\n        const descriptionsWithError = Array.from(this.servers.values()).filter((sd) => sd.error);\n        if (descriptionsWithError.length > 0) {\n            return descriptionsWithError[0].error;\n        }\n        return null;\n    }\n    /**\n     * Determines if the topology description has any known servers\n     */\n    get hasKnownServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.type !== common_1.ServerType.Unknown);\n    }\n    /**\n     * Determines if this topology description has a data-bearing server available.\n     */\n    get hasDataBearingServers() {\n        return Array.from(this.servers.values()).some((sd) => sd.isDataBearing);\n    }\n    /**\n     * Determines if the topology has a definition for the provided address\n     * @internal\n     */\n    hasServer(address) {\n        return this.servers.has(address);\n    }\n}\nexports.TopologyDescription = TopologyDescription;\nfunction topologyTypeForServerType(serverType) {\n    switch (serverType) {\n        case common_1.ServerType.Standalone:\n            return common_1.TopologyType.Single;\n        case common_1.ServerType.Mongos:\n            return common_1.TopologyType.Sharded;\n        case common_1.ServerType.RSPrimary:\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        case common_1.ServerType.RSOther:\n        case common_1.ServerType.RSSecondary:\n            return common_1.TopologyType.ReplicaSetNoPrimary;\n        default:\n            return common_1.TopologyType.Unknown;\n    }\n}\nfunction updateRsFromPrimary(serverDescriptions, serverDescription, setName = null, maxSetVersion = null, maxElectionId = null) {\n    setName = setName || serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n    }\n    if (serverDescription.maxWireVersion >= 17) {\n        const electionIdComparison = (0, utils_1.compareObjectId)(maxElectionId, serverDescription.electionId);\n        const maxElectionIdIsEqual = electionIdComparison === 0;\n        const maxElectionIdIsLess = electionIdComparison === -1;\n        const maxSetVersionIsLessOrEqual = (maxSetVersion ?? -1) <= (serverDescription.setVersion ?? -1);\n        if (maxElectionIdIsLess || (maxElectionIdIsEqual && maxSetVersionIsLessOrEqual)) {\n            // The reported electionId was greater\n            // or the electionId was equal and reported setVersion was greater\n            // Always update both values, they are a tuple\n            maxElectionId = serverDescription.electionId;\n            maxSetVersion = serverDescription.setVersion;\n        }\n        else {\n            // Stale primary\n            // replace serverDescription with a default ServerDescription of type \"Unknown\"\n            serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n            return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n        }\n    }\n    else {\n        const electionId = serverDescription.electionId ? serverDescription.electionId : null;\n        if (serverDescription.setVersion && electionId) {\n            if (maxSetVersion && maxElectionId) {\n                if (maxSetVersion > serverDescription.setVersion ||\n                    (0, utils_1.compareObjectId)(maxElectionId, electionId) > 0) {\n                    // this primary is stale, we must remove it\n                    serverDescriptions.set(serverDescription.address, new server_description_1.ServerDescription(serverDescription.address));\n                    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n                }\n            }\n            maxElectionId = serverDescription.electionId;\n        }\n        if (serverDescription.setVersion != null &&\n            (maxSetVersion == null || serverDescription.setVersion > maxSetVersion)) {\n            maxSetVersion = serverDescription.setVersion;\n        }\n    }\n    // We've heard from the primary. Is it the same primary as before?\n    for (const [address, server] of serverDescriptions) {\n        if (server.type === common_1.ServerType.RSPrimary && server.address !== serverDescription.address) {\n            // Reset old primary's type to Unknown.\n            serverDescriptions.set(address, new server_description_1.ServerDescription(server.address));\n            // There can only be one primary\n            break;\n        }\n    }\n    // Discover new hosts from this primary's response.\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    // Remove hosts not in the response.\n    const currentAddresses = Array.from(serverDescriptions.keys());\n    const responseAddresses = serverDescription.allHosts;\n    currentAddresses\n        .filter((addr) => responseAddresses.indexOf(addr) === -1)\n        .forEach((address) => {\n        serverDescriptions.delete(address);\n    });\n    return [checkHasPrimary(serverDescriptions), setName, maxSetVersion, maxElectionId];\n}\nfunction updateRsWithPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    if (setName == null) {\n        // TODO(NODE-3483): should be an appropriate runtime error\n        throw new error_1.MongoRuntimeError('Argument \"setName\" is required if connected to a replica set');\n    }\n    if (setName !== serverDescription.setName ||\n        (serverDescription.me && serverDescription.address !== serverDescription.me)) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return checkHasPrimary(serverDescriptions);\n}\nfunction updateRsNoPrimaryFromMember(serverDescriptions, serverDescription, setName = null) {\n    const topologyType = common_1.TopologyType.ReplicaSetNoPrimary;\n    setName = setName ?? serverDescription.setName;\n    if (setName !== serverDescription.setName) {\n        serverDescriptions.delete(serverDescription.address);\n        return [topologyType, setName];\n    }\n    serverDescription.allHosts.forEach((address) => {\n        if (!serverDescriptions.has(address)) {\n            serverDescriptions.set(address, new server_description_1.ServerDescription(address));\n        }\n    });\n    if (serverDescription.me && serverDescription.address !== serverDescription.me) {\n        serverDescriptions.delete(serverDescription.address);\n    }\n    return [topologyType, setName];\n}\nfunction checkHasPrimary(serverDescriptions) {\n    for (const serverDescription of serverDescriptions.values()) {\n        if (serverDescription.type === common_1.ServerType.RSPrimary) {\n            return common_1.TopologyType.ReplicaSetWithPrimary;\n        }\n    }\n    return common_1.TopologyType.ReplicaSetNoPrimary;\n}\n//# sourceMappingURL=topology_description.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sdam/topology_description.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sessions.js":
/*!**********************************************!*\
  !*** ./node_modules/mongodb/lib/sessions.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar _a;\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.updateSessionFromResponse = exports.applySession = exports.ServerSessionPool = exports.ServerSession = exports.maybeClearPinnedConnection = exports.ClientSession = void 0;\nconst util_1 = __webpack_require__(/*! util */ \"../../node_modules/util/util.js\");\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst metrics_1 = __webpack_require__(/*! ./cmap/metrics */ \"./node_modules/mongodb/lib/cmap/metrics.js\");\nconst shared_1 = __webpack_require__(/*! ./cmap/wire_protocol/shared */ \"./node_modules/mongodb/lib/cmap/wire_protocol/shared.js\");\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst mongo_types_1 = __webpack_require__(/*! ./mongo_types */ \"./node_modules/mongodb/lib/mongo_types.js\");\nconst execute_operation_1 = __webpack_require__(/*! ./operations/execute_operation */ \"./node_modules/mongodb/lib/operations/execute_operation.js\");\nconst run_command_1 = __webpack_require__(/*! ./operations/run_command */ \"./node_modules/mongodb/lib/operations/run_command.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst transactions_1 = __webpack_require__(/*! ./transactions */ \"./node_modules/mongodb/lib/transactions.js\");\nconst utils_1 = __webpack_require__(/*! ./utils */ \"./node_modules/mongodb/lib/utils.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nconst minWireVersionForShardedTransactions = 8;\n/** @internal */\nconst kServerSession = Symbol('serverSession');\n/** @internal */\nconst kSnapshotTime = Symbol('snapshotTime');\n/** @internal */\nconst kSnapshotEnabled = Symbol('snapshotEnabled');\n/** @internal */\nconst kPinnedConnection = Symbol('pinnedConnection');\n/** @internal Accumulates total number of increments to add to txnNumber when applying session to command */\nconst kTxnNumberIncrement = Symbol('txnNumberIncrement');\n/**\n * A class representing a client session on the server\n *\n * NOTE: not meant to be instantiated directly.\n * @public\n */\nclass ClientSession extends mongo_types_1.TypedEventEmitter {\n    /**\n     * Create a client session.\n     * @internal\n     * @param client - The current client\n     * @param sessionPool - The server session pool (Internal Class)\n     * @param options - Optional settings\n     * @param clientOptions - Optional settings provided when creating a MongoClient\n     */\n    constructor(client, sessionPool, options, clientOptions) {\n        super();\n        /** @internal */\n        this[_a] = false;\n        if (client == null) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a MongoClient');\n        }\n        if (sessionPool == null || !(sessionPool instanceof ServerSessionPool)) {\n            // TODO(NODE-3483)\n            throw new error_1.MongoRuntimeError('ClientSession requires a ServerSessionPool');\n        }\n        options = options ?? {};\n        if (options.snapshot === true) {\n            this[kSnapshotEnabled] = true;\n            if (options.causalConsistency === true) {\n                throw new error_1.MongoInvalidArgumentError('Properties \"causalConsistency\" and \"snapshot\" are mutually exclusive');\n            }\n        }\n        this.client = client;\n        this.sessionPool = sessionPool;\n        this.hasEnded = false;\n        this.clientOptions = clientOptions;\n        this.explicit = !!options.explicit;\n        this[kServerSession] = this.explicit ? this.sessionPool.acquire() : null;\n        this[kTxnNumberIncrement] = 0;\n        const defaultCausalConsistencyValue = this.explicit && options.snapshot !== true;\n        this.supports = {\n            // if we can enable causal consistency, do so by default\n            causalConsistency: options.causalConsistency ?? defaultCausalConsistencyValue\n        };\n        this.clusterTime = options.initialClusterTime;\n        this.operationTime = undefined;\n        this.owner = options.owner;\n        this.defaultTransactionOptions = Object.assign({}, options.defaultTransactionOptions);\n        this.transaction = new transactions_1.Transaction();\n    }\n    /** The server id associated with this session */\n    get id() {\n        return this[kServerSession]?.id;\n    }\n    get serverSession() {\n        let serverSession = this[kServerSession];\n        if (serverSession == null) {\n            if (this.explicit) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an explicit session');\n            }\n            if (this.hasEnded) {\n                throw new error_1.MongoRuntimeError('Unexpected null serverSession for an ended implicit session');\n            }\n            serverSession = this.sessionPool.acquire();\n            this[kServerSession] = serverSession;\n        }\n        return serverSession;\n    }\n    /** Whether or not this session is configured for snapshot reads */\n    get snapshotEnabled() {\n        return this[kSnapshotEnabled];\n    }\n    get loadBalanced() {\n        return this.client.topology?.description.type === common_1.TopologyType.LoadBalanced;\n    }\n    /** @internal */\n    get pinnedConnection() {\n        return this[kPinnedConnection];\n    }\n    /** @internal */\n    pin(conn) {\n        if (this[kPinnedConnection]) {\n            throw TypeError('Cannot pin multiple connections to the same session');\n        }\n        this[kPinnedConnection] = conn;\n        conn.emit(constants_1.PINNED, this.inTransaction() ? metrics_1.ConnectionPoolMetrics.TXN : metrics_1.ConnectionPoolMetrics.CURSOR);\n    }\n    /** @internal */\n    unpin(options) {\n        if (this.loadBalanced) {\n            return maybeClearPinnedConnection(this, options);\n        }\n        this.transaction.unpinServer();\n    }\n    get isPinned() {\n        return this.loadBalanced ? !!this[kPinnedConnection] : this.transaction.isPinned;\n    }\n    /**\n     * Ends this session on the server\n     *\n     * @param options - Optional settings. Currently reserved for future use\n     */\n    async endSession(options) {\n        try {\n            if (this.inTransaction()) {\n                await this.abortTransaction();\n            }\n            if (!this.hasEnded) {\n                const serverSession = this[kServerSession];\n                if (serverSession != null) {\n                    // release the server session back to the pool\n                    this.sessionPool.release(serverSession);\n                    // Make sure a new serverSession never makes it onto this ClientSession\n                    Object.defineProperty(this, kServerSession, {\n                        value: ServerSession.clone(serverSession),\n                        writable: false\n                    });\n                }\n                // mark the session as ended, and emit a signal\n                this.hasEnded = true;\n                this.emit('ended', this);\n            }\n        }\n        catch {\n            // spec indicates that we should ignore all errors for `endSessions`\n        }\n        finally {\n            maybeClearPinnedConnection(this, { force: true, ...options });\n        }\n    }\n    /**\n     * Advances the operationTime for a ClientSession.\n     *\n     * @param operationTime - the `BSON.Timestamp` of the operation type it is desired to advance to\n     */\n    advanceOperationTime(operationTime) {\n        if (this.operationTime == null) {\n            this.operationTime = operationTime;\n            return;\n        }\n        if (operationTime.greaterThan(this.operationTime)) {\n            this.operationTime = operationTime;\n        }\n    }\n    /**\n     * Advances the clusterTime for a ClientSession to the provided clusterTime of another ClientSession\n     *\n     * @param clusterTime - the $clusterTime returned by the server from another session in the form of a document containing the `BSON.Timestamp` clusterTime and signature\n     */\n    advanceClusterTime(clusterTime) {\n        if (!clusterTime || typeof clusterTime !== 'object') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must be an object');\n        }\n        if (!clusterTime.clusterTime || clusterTime.clusterTime._bsontype !== 'Timestamp') {\n            throw new error_1.MongoInvalidArgumentError('input cluster time \"clusterTime\" property must be a valid BSON Timestamp');\n        }\n        if (!clusterTime.signature ||\n            clusterTime.signature.hash?._bsontype !== 'Binary' ||\n            (typeof clusterTime.signature.keyId !== 'bigint' &&\n                typeof clusterTime.signature.keyId !== 'number' &&\n                clusterTime.signature.keyId?._bsontype !== 'Long') // apparently we decode the key to number?\n        ) {\n            throw new error_1.MongoInvalidArgumentError('input cluster time must have a valid \"signature\" property with BSON Binary hash and BSON Long keyId');\n        }\n        (0, common_1._advanceClusterTime)(this, clusterTime);\n    }\n    /**\n     * Used to determine if this session equals another\n     *\n     * @param session - The session to compare to\n     */\n    equals(session) {\n        if (!(session instanceof ClientSession)) {\n            return false;\n        }\n        if (this.id == null || session.id == null) {\n            return false;\n        }\n        return utils_1.ByteUtils.equals(this.id.id.buffer, session.id.id.buffer);\n    }\n    /**\n     * Increment the transaction number on the internal ServerSession\n     *\n     * @privateRemarks\n     * This helper increments a value stored on the client session that will be\n     * added to the serverSession's txnNumber upon applying it to a command.\n     * This is because the serverSession is lazily acquired after a connection is obtained\n     */\n    incrementTransactionNumber() {\n        this[kTxnNumberIncrement] += 1;\n    }\n    /** @returns whether this session is currently in a transaction or not */\n    inTransaction() {\n        return this.transaction.isActive;\n    }\n    /**\n     * Starts a new transaction with the given options.\n     *\n     * @param options - Options for the transaction\n     */\n    startTransaction(options) {\n        if (this[kSnapshotEnabled]) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported in snapshot sessions');\n        }\n        if (this.inTransaction()) {\n            throw new error_1.MongoTransactionError('Transaction already in progress');\n        }\n        if (this.isPinned && this.transaction.isCommitted) {\n            this.unpin();\n        }\n        const topologyMaxWireVersion = (0, utils_1.maxWireVersion)(this.client.topology);\n        if ((0, shared_1.isSharded)(this.client.topology) &&\n            topologyMaxWireVersion != null &&\n            topologyMaxWireVersion < minWireVersionForShardedTransactions) {\n            throw new error_1.MongoCompatibilityError('Transactions are not supported on sharded clusters in MongoDB < 4.2.');\n        }\n        // increment txnNumber\n        this.incrementTransactionNumber();\n        // create transaction state\n        this.transaction = new transactions_1.Transaction({\n            readConcern: options?.readConcern ??\n                this.defaultTransactionOptions.readConcern ??\n                this.clientOptions?.readConcern,\n            writeConcern: options?.writeConcern ??\n                this.defaultTransactionOptions.writeConcern ??\n                this.clientOptions?.writeConcern,\n            readPreference: options?.readPreference ??\n                this.defaultTransactionOptions.readPreference ??\n                this.clientOptions?.readPreference,\n            maxCommitTimeMS: options?.maxCommitTimeMS ?? this.defaultTransactionOptions.maxCommitTimeMS\n        });\n        this.transaction.transition(transactions_1.TxnState.STARTING_TRANSACTION);\n    }\n    /**\n     * Commits the currently active transaction in this session.\n     */\n    async commitTransaction() {\n        return endTransactionAsync(this, 'commitTransaction');\n    }\n    /**\n     * Aborts the currently active transaction in this session.\n     */\n    async abortTransaction() {\n        return endTransactionAsync(this, 'abortTransaction');\n    }\n    /**\n     * This is here to ensure that ClientSession is never serialized to BSON.\n     */\n    toBSON() {\n        throw new error_1.MongoRuntimeError('ClientSession cannot be serialized to BSON.');\n    }\n    /**\n     * Starts a transaction and runs a provided function, ensuring the commitTransaction is always attempted when all operations run in the function have completed.\n     *\n     * **IMPORTANT:** This method requires the user to return a Promise, and `await` all operations.\n     *\n     * @remarks\n     * This function:\n     * - If all operations successfully complete and the `commitTransaction` operation is successful, then this function will return the result of the provided function.\n     * - If the transaction is unable to complete or an error is thrown from within the provided function, then this function will throw an error.\n     *   - If the transaction is manually aborted within the provided function it will not throw.\n     * - May be called multiple times if the driver needs to attempt to retry the operations.\n     *\n     * Checkout a descriptive example here:\n     * @see https://www.mongodb.com/blog/post/quick-start-nodejs--mongodb--how-to-implement-transactions\n     *\n     * @param fn - callback to run within a transaction\n     * @param options - optional settings for the transaction\n     * @returns A raw command response or undefined\n     */\n    async withTransaction(fn, options) {\n        const startTime = (0, utils_1.now)();\n        return attemptTransaction(this, startTime, fn, options);\n    }\n}\nexports.ClientSession = ClientSession;\n_a = kSnapshotEnabled;\nconst MAX_WITH_TRANSACTION_TIMEOUT = 120000;\nconst NON_DETERMINISTIC_WRITE_CONCERN_ERRORS = new Set([\n    'CannotSatisfyWriteConcern',\n    'UnknownReplWriteConcern',\n    'UnsatisfiableWriteConcern'\n]);\nfunction hasNotTimedOut(startTime, max) {\n    return (0, utils_1.calculateDurationInMs)(startTime) < max;\n}\nfunction isUnknownTransactionCommitResult(err) {\n    const isNonDeterministicWriteConcernError = err instanceof error_1.MongoServerError &&\n        err.codeName &&\n        NON_DETERMINISTIC_WRITE_CONCERN_ERRORS.has(err.codeName);\n    return (isMaxTimeMSExpiredError(err) ||\n        (!isNonDeterministicWriteConcernError &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnsatisfiableWriteConcern &&\n            err.code !== error_1.MONGODB_ERROR_CODES.UnknownReplWriteConcern));\n}\nfunction maybeClearPinnedConnection(session, options) {\n    // unpin a connection if it has been pinned\n    const conn = session[kPinnedConnection];\n    const error = options?.error;\n    if (session.inTransaction() &&\n        error &&\n        error instanceof error_1.MongoError &&\n        error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n        return;\n    }\n    const topology = session.client.topology;\n    // NOTE: the spec talks about what to do on a network error only, but the tests seem to\n    //       to validate that we don't unpin on _all_ errors?\n    if (conn && topology != null) {\n        const servers = Array.from(topology.s.servers.values());\n        const loadBalancer = servers[0];\n        if (options?.error == null || options?.force) {\n            loadBalancer.pool.checkIn(conn);\n            conn.emit(constants_1.UNPINNED, session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION\n                ? metrics_1.ConnectionPoolMetrics.TXN\n                : metrics_1.ConnectionPoolMetrics.CURSOR);\n            if (options?.forceClear) {\n                loadBalancer.pool.clear({ serviceId: conn.serviceId });\n            }\n        }\n        session[kPinnedConnection] = undefined;\n    }\n}\nexports.maybeClearPinnedConnection = maybeClearPinnedConnection;\nfunction isMaxTimeMSExpiredError(err) {\n    if (err == null || !(err instanceof error_1.MongoServerError)) {\n        return false;\n    }\n    return (err.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired ||\n        (err.writeConcernError && err.writeConcernError.code === error_1.MONGODB_ERROR_CODES.MaxTimeMSExpired));\n}\nfunction attemptTransactionCommit(session, startTime, fn, result, options) {\n    return session.commitTransaction().then(() => result, (err) => {\n        if (err instanceof error_1.MongoError &&\n            hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT) &&\n            !isMaxTimeMSExpiredError(err)) {\n            if (err.hasErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult)) {\n                return attemptTransactionCommit(session, startTime, fn, result, options);\n            }\n            if (err.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                return attemptTransaction(session, startTime, fn, options);\n            }\n        }\n        throw err;\n    });\n}\nconst USER_EXPLICIT_TXN_END_STATES = new Set([\n    transactions_1.TxnState.NO_TRANSACTION,\n    transactions_1.TxnState.TRANSACTION_COMMITTED,\n    transactions_1.TxnState.TRANSACTION_ABORTED\n]);\nfunction userExplicitlyEndedTransaction(session) {\n    return USER_EXPLICIT_TXN_END_STATES.has(session.transaction.state);\n}\nfunction attemptTransaction(session, startTime, fn, options = {}) {\n    session.startTransaction(options);\n    let promise;\n    try {\n        promise = fn(session);\n    }\n    catch (err) {\n        promise = Promise.reject(err);\n    }\n    if (!(0, utils_1.isPromiseLike)(promise)) {\n        session.abortTransaction().catch(() => null);\n        return Promise.reject(new error_1.MongoInvalidArgumentError('Function provided to `withTransaction` must return a Promise'));\n    }\n    return promise.then(result => {\n        if (userExplicitlyEndedTransaction(session)) {\n            return result;\n        }\n        return attemptTransactionCommit(session, startTime, fn, result, options);\n    }, err => {\n        function maybeRetryOrThrow(err) {\n            if (err instanceof error_1.MongoError &&\n                err.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError) &&\n                hasNotTimedOut(startTime, MAX_WITH_TRANSACTION_TIMEOUT)) {\n                return attemptTransaction(session, startTime, fn, options);\n            }\n            if (isMaxTimeMSExpiredError(err)) {\n                err.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n            }\n            throw err;\n        }\n        if (session.inTransaction()) {\n            return session.abortTransaction().then(() => maybeRetryOrThrow(err));\n        }\n        return maybeRetryOrThrow(err);\n    });\n}\nconst endTransactionAsync = (0, util_1.promisify)(endTransaction);\nfunction endTransaction(session, commandName, callback) {\n    // handle any initial problematic cases\n    const txnState = session.transaction.state;\n    if (txnState === transactions_1.TxnState.NO_TRANSACTION) {\n        callback(new error_1.MongoTransactionError('No transaction started'));\n        return;\n    }\n    if (commandName === 'commitTransaction') {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY);\n            callback();\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            callback(new error_1.MongoTransactionError('Cannot call commitTransaction after calling abortTransaction'));\n            return;\n        }\n    }\n    else {\n        if (txnState === transactions_1.TxnState.STARTING_TRANSACTION) {\n            // the transaction was never started, we can safely exit here\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            callback();\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_ABORTED) {\n            callback(new error_1.MongoTransactionError('Cannot call abortTransaction twice'));\n            return;\n        }\n        if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED ||\n            txnState === transactions_1.TxnState.TRANSACTION_COMMITTED_EMPTY) {\n            callback(new error_1.MongoTransactionError('Cannot call abortTransaction after calling commitTransaction'));\n            return;\n        }\n    }\n    // construct and send the command\n    const command = { [commandName]: 1 };\n    // apply a writeConcern if specified\n    let writeConcern;\n    if (session.transaction.options.writeConcern) {\n        writeConcern = Object.assign({}, session.transaction.options.writeConcern);\n    }\n    else if (session.clientOptions && session.clientOptions.writeConcern) {\n        writeConcern = { w: session.clientOptions.writeConcern.w };\n    }\n    if (txnState === transactions_1.TxnState.TRANSACTION_COMMITTED) {\n        writeConcern = Object.assign({ wtimeoutMS: 10000 }, writeConcern, { w: 'majority' });\n    }\n    if (writeConcern) {\n        write_concern_1.WriteConcern.apply(command, writeConcern);\n    }\n    if (commandName === 'commitTransaction' && session.transaction.options.maxTimeMS) {\n        Object.assign(command, { maxTimeMS: session.transaction.options.maxTimeMS });\n    }\n    function commandHandler(error) {\n        if (commandName !== 'commitTransaction') {\n            session.transaction.transition(transactions_1.TxnState.TRANSACTION_ABORTED);\n            if (session.loadBalanced) {\n                maybeClearPinnedConnection(session, { force: false });\n            }\n            // The spec indicates that we should ignore all errors on `abortTransaction`\n            return callback();\n        }\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_COMMITTED);\n        if (error instanceof error_1.MongoError) {\n            if ((0, error_1.isRetryableWriteError)(error) ||\n                error instanceof error_1.MongoWriteConcernError ||\n                isMaxTimeMSExpiredError(error)) {\n                if (isUnknownTransactionCommitResult(error)) {\n                    error.addErrorLabel(error_1.MongoErrorLabel.UnknownTransactionCommitResult);\n                    // per txns spec, must unpin session in this case\n                    session.unpin({ error });\n                }\n            }\n            else if (error.hasErrorLabel(error_1.MongoErrorLabel.TransientTransactionError)) {\n                session.unpin({ error });\n            }\n        }\n        callback(error);\n    }\n    if (session.transaction.recoveryToken) {\n        command.recoveryToken = session.transaction.recoveryToken;\n    }\n    // send the command\n    (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n        session,\n        readPreference: read_preference_1.ReadPreference.primary,\n        bypassPinningCheck: true\n    }), error => {\n        if (command.abortTransaction) {\n            // always unpin on abort regardless of command outcome\n            session.unpin();\n        }\n        if (error instanceof error_1.MongoError && (0, error_1.isRetryableWriteError)(error)) {\n            // SPEC-1185: apply majority write concern when retrying commitTransaction\n            if (command.commitTransaction) {\n                // per txns spec, must unpin session in this case\n                session.unpin({ force: true });\n                command.writeConcern = Object.assign({ wtimeout: 10000 }, command.writeConcern, {\n                    w: 'majority'\n                });\n            }\n            return (0, execute_operation_1.executeOperation)(session.client, new run_command_1.RunAdminCommandOperation(command, {\n                session,\n                readPreference: read_preference_1.ReadPreference.primary,\n                bypassPinningCheck: true\n            }), commandHandler);\n        }\n        commandHandler(error);\n    });\n}\n/**\n * Reflects the existence of a session on the server. Can be reused by the session pool.\n * WARNING: not meant to be instantiated directly. For internal use only.\n * @public\n */\nclass ServerSession {\n    /** @internal */\n    constructor() {\n        this.id = { id: new bson_1.Binary((0, utils_1.uuidV4)(), bson_1.Binary.SUBTYPE_UUID) };\n        this.lastUse = (0, utils_1.now)();\n        this.txnNumber = 0;\n        this.isDirty = false;\n    }\n    /**\n     * Determines if the server session has timed out.\n     *\n     * @param sessionTimeoutMinutes - The server's \"logicalSessionTimeoutMinutes\"\n     */\n    hasTimedOut(sessionTimeoutMinutes) {\n        // Take the difference of the lastUse timestamp and now, which will result in a value in\n        // milliseconds, and then convert milliseconds to minutes to compare to `sessionTimeoutMinutes`\n        const idleTimeMinutes = Math.round((((0, utils_1.calculateDurationInMs)(this.lastUse) % 86400000) % 3600000) / 60000);\n        return idleTimeMinutes > sessionTimeoutMinutes - 1;\n    }\n    /**\n     * @internal\n     * Cloning meant to keep a readable reference to the server session data\n     * after ClientSession has ended\n     */\n    static clone(serverSession) {\n        const arrayBuffer = new ArrayBuffer(16);\n        const idBytes = Buffer.from(arrayBuffer);\n        idBytes.set(serverSession.id.id.buffer);\n        const id = new bson_1.Binary(idBytes, serverSession.id.id.sub_type);\n        // Manual prototype construction to avoid modifying the constructor of this class\n        return Object.setPrototypeOf({\n            id: { id },\n            lastUse: serverSession.lastUse,\n            txnNumber: serverSession.txnNumber,\n            isDirty: serverSession.isDirty\n        }, ServerSession.prototype);\n    }\n}\nexports.ServerSession = ServerSession;\n/**\n * Maintains a pool of Server Sessions.\n * For internal use only\n * @internal\n */\nclass ServerSessionPool {\n    constructor(client) {\n        if (client == null) {\n            throw new error_1.MongoRuntimeError('ServerSessionPool requires a MongoClient');\n        }\n        this.client = client;\n        this.sessions = new utils_1.List();\n    }\n    /**\n     * Acquire a Server Session from the pool.\n     * Iterates through each session in the pool, removing any stale sessions\n     * along the way. The first non-stale session found is removed from the\n     * pool and returned. If no non-stale session is found, a new ServerSession is created.\n     */\n    acquire() {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        let session = null;\n        // Try to obtain from session pool\n        while (this.sessions.length > 0) {\n            const potentialSession = this.sessions.shift();\n            if (potentialSession != null &&\n                (!!this.client.topology?.loadBalanced ||\n                    !potentialSession.hasTimedOut(sessionTimeoutMinutes))) {\n                session = potentialSession;\n                break;\n            }\n        }\n        // If nothing valid came from the pool make a new one\n        if (session == null) {\n            session = new ServerSession();\n        }\n        return session;\n    }\n    /**\n     * Release a session to the session pool\n     * Adds the session back to the session pool if the session has not timed out yet.\n     * This method also removes any stale sessions from the pool.\n     *\n     * @param session - The session to release to the pool\n     */\n    release(session) {\n        const sessionTimeoutMinutes = this.client.topology?.logicalSessionTimeoutMinutes ?? 10;\n        if (this.client.topology?.loadBalanced && !sessionTimeoutMinutes) {\n            this.sessions.unshift(session);\n        }\n        if (!sessionTimeoutMinutes) {\n            return;\n        }\n        this.sessions.prune(session => session.hasTimedOut(sessionTimeoutMinutes));\n        if (!session.hasTimedOut(sessionTimeoutMinutes)) {\n            if (session.isDirty) {\n                return;\n            }\n            // otherwise, readd this session to the session pool\n            this.sessions.unshift(session);\n        }\n    }\n}\nexports.ServerSessionPool = ServerSessionPool;\n/**\n * Optionally decorate a command with sessions specific keys\n *\n * @param session - the session tracking transaction state\n * @param command - the command to decorate\n * @param options - Optional settings passed to calling operation\n *\n * @internal\n */\nfunction applySession(session, command, options) {\n    if (session.hasEnded) {\n        return new error_1.MongoExpiredSessionError();\n    }\n    // May acquire serverSession here\n    const serverSession = session.serverSession;\n    if (serverSession == null) {\n        return new error_1.MongoRuntimeError('Unable to acquire server session');\n    }\n    if (options.writeConcern?.w === 0) {\n        if (session && session.explicit) {\n            // Error if user provided an explicit session to an unacknowledged write (SPEC-1019)\n            return new error_1.MongoAPIError('Cannot have explicit session with unacknowledged writes');\n        }\n        return;\n    }\n    // mark the last use of this session, and apply the `lsid`\n    serverSession.lastUse = (0, utils_1.now)();\n    command.lsid = serverSession.id;\n    const inTxnOrTxnCommand = session.inTransaction() || (0, transactions_1.isTransactionCommand)(command);\n    const isRetryableWrite = !!options.willRetryWrite;\n    if (isRetryableWrite || inTxnOrTxnCommand) {\n        serverSession.txnNumber += session[kTxnNumberIncrement];\n        session[kTxnNumberIncrement] = 0;\n        // TODO(NODE-2674): Preserve int64 sent from MongoDB\n        command.txnNumber = bson_1.Long.fromNumber(serverSession.txnNumber);\n    }\n    if (!inTxnOrTxnCommand) {\n        if (session.transaction.state !== transactions_1.TxnState.NO_TRANSACTION) {\n            session.transaction.transition(transactions_1.TxnState.NO_TRANSACTION);\n        }\n        if (session.supports.causalConsistency &&\n            session.operationTime &&\n            (0, utils_1.commandSupportsReadConcern)(command)) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n        else if (session[kSnapshotEnabled]) {\n            command.readConcern = command.readConcern || { level: read_concern_1.ReadConcernLevel.snapshot };\n            if (session[kSnapshotTime] != null) {\n                Object.assign(command.readConcern, { atClusterTime: session[kSnapshotTime] });\n            }\n        }\n        return;\n    }\n    // now attempt to apply transaction-specific sessions data\n    // `autocommit` must always be false to differentiate from retryable writes\n    command.autocommit = false;\n    if (session.transaction.state === transactions_1.TxnState.STARTING_TRANSACTION) {\n        session.transaction.transition(transactions_1.TxnState.TRANSACTION_IN_PROGRESS);\n        command.startTransaction = true;\n        const readConcern = session.transaction.options.readConcern || session?.clientOptions?.readConcern;\n        if (readConcern) {\n            command.readConcern = readConcern;\n        }\n        if (session.supports.causalConsistency && session.operationTime) {\n            command.readConcern = command.readConcern || {};\n            Object.assign(command.readConcern, { afterClusterTime: session.operationTime });\n        }\n    }\n    return;\n}\nexports.applySession = applySession;\nfunction updateSessionFromResponse(session, document) {\n    if (document.$clusterTime) {\n        (0, common_1._advanceClusterTime)(session, document.$clusterTime);\n    }\n    if (document.operationTime && session && session.supports.causalConsistency) {\n        session.advanceOperationTime(document.operationTime);\n    }\n    if (document.recoveryToken && session && session.inTransaction()) {\n        session.transaction._recoveryToken = document.recoveryToken;\n    }\n    if (session?.[kSnapshotEnabled] && session[kSnapshotTime] == null) {\n        // find and aggregate commands return atClusterTime on the cursor\n        // distinct includes it in the response body\n        const atClusterTime = document.cursor?.atClusterTime || document.atClusterTime;\n        if (atClusterTime) {\n            session[kSnapshotTime] = atClusterTime;\n        }\n    }\n}\nexports.updateSessionFromResponse = updateSessionFromResponse;\n//# sourceMappingURL=sessions.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sessions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/sort.js":
/*!******************************************!*\
  !*** ./node_modules/mongodb/lib/sort.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.formatSort = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\n/** @internal */\nfunction prepareDirection(direction = 1) {\n    const value = `${direction}`.toLowerCase();\n    if (isMeta(direction))\n        return direction;\n    switch (value) {\n        case 'ascending':\n        case 'asc':\n        case '1':\n            return 1;\n        case 'descending':\n        case 'desc':\n        case '-1':\n            return -1;\n        default:\n            throw new error_1.MongoInvalidArgumentError(`Invalid sort direction: ${JSON.stringify(direction)}`);\n    }\n}\n/** @internal */\nfunction isMeta(t) {\n    return typeof t === 'object' && t != null && '$meta' in t && typeof t.$meta === 'string';\n}\n/** @internal */\nfunction isPair(t) {\n    if (Array.isArray(t) && t.length === 2) {\n        try {\n            prepareDirection(t[1]);\n            return true;\n        }\n        catch (e) {\n            return false;\n        }\n    }\n    return false;\n}\nfunction isDeep(t) {\n    return Array.isArray(t) && Array.isArray(t[0]);\n}\nfunction isMap(t) {\n    return t instanceof Map && t.size > 0;\n}\n/** @internal */\nfunction pairToMap(v) {\n    return new Map([[`${v[0]}`, prepareDirection([v[1]])]]);\n}\n/** @internal */\nfunction deepToMap(t) {\n    const sortEntries = t.map(([k, v]) => [`${k}`, prepareDirection(v)]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction stringsToMap(t) {\n    const sortEntries = t.map(key => [`${key}`, 1]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction objectToMap(t) {\n    const sortEntries = Object.entries(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** @internal */\nfunction mapToMap(t) {\n    const sortEntries = Array.from(t).map(([k, v]) => [\n        `${k}`,\n        prepareDirection(v)\n    ]);\n    return new Map(sortEntries);\n}\n/** converts a Sort type into a type that is valid for the server (SortForCmd) */\nfunction formatSort(sort, direction) {\n    if (sort == null)\n        return undefined;\n    if (typeof sort === 'string')\n        return new Map([[sort, prepareDirection(direction)]]);\n    if (typeof sort !== 'object') {\n        throw new error_1.MongoInvalidArgumentError(`Invalid sort format: ${JSON.stringify(sort)} Sort must be a valid object`);\n    }\n    if (!Array.isArray(sort)) {\n        return isMap(sort) ? mapToMap(sort) : Object.keys(sort).length ? objectToMap(sort) : undefined;\n    }\n    if (!sort.length)\n        return undefined;\n    if (isDeep(sort))\n        return deepToMap(sort);\n    if (isPair(sort))\n        return pairToMap(sort);\n    return stringsToMap(sort);\n}\nexports.formatSort = formatSort;\n//# sourceMappingURL=sort.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/sort.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/transactions.js":
/*!**************************************************!*\
  !*** ./node_modules/mongodb/lib/transactions.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isTransactionCommand = exports.Transaction = exports.TxnState = void 0;\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\n/** @internal */\nexports.TxnState = Object.freeze({\n    NO_TRANSACTION: 'NO_TRANSACTION',\n    STARTING_TRANSACTION: 'STARTING_TRANSACTION',\n    TRANSACTION_IN_PROGRESS: 'TRANSACTION_IN_PROGRESS',\n    TRANSACTION_COMMITTED: 'TRANSACTION_COMMITTED',\n    TRANSACTION_COMMITTED_EMPTY: 'TRANSACTION_COMMITTED_EMPTY',\n    TRANSACTION_ABORTED: 'TRANSACTION_ABORTED'\n});\nconst stateMachine = {\n    [exports.TxnState.NO_TRANSACTION]: [exports.TxnState.NO_TRANSACTION, exports.TxnState.STARTING_TRANSACTION],\n    [exports.TxnState.STARTING_TRANSACTION]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_IN_PROGRESS]: [\n        exports.TxnState.TRANSACTION_IN_PROGRESS,\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_ABORTED\n    ],\n    [exports.TxnState.TRANSACTION_COMMITTED]: [\n        exports.TxnState.TRANSACTION_COMMITTED,\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.STARTING_TRANSACTION,\n        exports.TxnState.NO_TRANSACTION\n    ],\n    [exports.TxnState.TRANSACTION_ABORTED]: [exports.TxnState.STARTING_TRANSACTION, exports.TxnState.NO_TRANSACTION],\n    [exports.TxnState.TRANSACTION_COMMITTED_EMPTY]: [\n        exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n        exports.TxnState.NO_TRANSACTION\n    ]\n};\nconst ACTIVE_STATES = new Set([\n    exports.TxnState.STARTING_TRANSACTION,\n    exports.TxnState.TRANSACTION_IN_PROGRESS\n]);\nconst COMMITTED_STATES = new Set([\n    exports.TxnState.TRANSACTION_COMMITTED,\n    exports.TxnState.TRANSACTION_COMMITTED_EMPTY,\n    exports.TxnState.TRANSACTION_ABORTED\n]);\n/**\n * @public\n * A class maintaining state related to a server transaction. Internal Only\n */\nclass Transaction {\n    /** Create a transaction @internal */\n    constructor(options) {\n        options = options ?? {};\n        this.state = exports.TxnState.NO_TRANSACTION;\n        this.options = {};\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options);\n        if (writeConcern) {\n            if (writeConcern.w === 0) {\n                throw new error_1.MongoTransactionError('Transactions do not support unacknowledged write concern');\n            }\n            this.options.writeConcern = writeConcern;\n        }\n        if (options.readConcern) {\n            this.options.readConcern = read_concern_1.ReadConcern.fromOptions(options);\n        }\n        if (options.readPreference) {\n            this.options.readPreference = read_preference_1.ReadPreference.fromOptions(options);\n        }\n        if (options.maxCommitTimeMS) {\n            this.options.maxTimeMS = options.maxCommitTimeMS;\n        }\n        // TODO: This isn't technically necessary\n        this._pinnedServer = undefined;\n        this._recoveryToken = undefined;\n    }\n    /** @internal */\n    get server() {\n        return this._pinnedServer;\n    }\n    get recoveryToken() {\n        return this._recoveryToken;\n    }\n    get isPinned() {\n        return !!this.server;\n    }\n    /** @returns Whether the transaction has started */\n    get isStarting() {\n        return this.state === exports.TxnState.STARTING_TRANSACTION;\n    }\n    /**\n     * @returns Whether this session is presently in a transaction\n     */\n    get isActive() {\n        return ACTIVE_STATES.has(this.state);\n    }\n    get isCommitted() {\n        return COMMITTED_STATES.has(this.state);\n    }\n    /**\n     * Transition the transaction in the state machine\n     * @internal\n     * @param nextState - The new state to transition to\n     */\n    transition(nextState) {\n        const nextStates = stateMachine[this.state];\n        if (nextStates && nextStates.includes(nextState)) {\n            this.state = nextState;\n            if (this.state === exports.TxnState.NO_TRANSACTION ||\n                this.state === exports.TxnState.STARTING_TRANSACTION ||\n                this.state === exports.TxnState.TRANSACTION_ABORTED) {\n                this.unpinServer();\n            }\n            return;\n        }\n        throw new error_1.MongoRuntimeError(`Attempted illegal state transition from [${this.state}] to [${nextState}]`);\n    }\n    /** @internal */\n    pinServer(server) {\n        if (this.isActive) {\n            this._pinnedServer = server;\n        }\n    }\n    /** @internal */\n    unpinServer() {\n        this._pinnedServer = undefined;\n    }\n}\nexports.Transaction = Transaction;\nfunction isTransactionCommand(command) {\n    return !!(command.commitTransaction || command.abortTransaction);\n}\nexports.isTransactionCommand = isTransactionCommand;\n//# sourceMappingURL=transactions.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/transactions.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/utils.js":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/lib/utils.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DOCUMENT_DB_CHECK = exports.TimeoutController = exports.request = exports.matchesParentDomain = exports.parseUnsignedInteger = exports.parseInteger = exports.compareObjectId = exports.commandSupportsReadConcern = exports.shuffle = exports.supportsRetryableWrites = exports.enumToString = exports.emitWarningOnce = exports.emitWarning = exports.MONGODB_WARNING_CODE = exports.DEFAULT_PK_FACTORY = exports.HostAddress = exports.BufferPool = exports.List = exports.deepCopy = exports.isRecord = exports.setDifference = exports.isHello = exports.isSuperset = exports.resolveOptions = exports.hasAtomicOperators = exports.calculateDurationInMs = exports.now = exports.makeStateMachine = exports.errorStrictEqual = exports.arrayStrictEqual = exports.eachAsync = exports.maxWireVersion = exports.uuidV4 = exports.maybeCallback = exports.makeCounter = exports.MongoDBCollectionNamespace = exports.MongoDBNamespace = exports.ns = exports.getTopology = exports.decorateWithExplain = exports.decorateWithReadConcern = exports.decorateWithCollation = exports.isPromiseLike = exports.applyRetryableWrites = exports.filterOptions = exports.mergeOptions = exports.isObject = exports.normalizeHintField = exports.hostMatchesWildcards = exports.ByteUtils = void 0;\nexports.isHostMatch = exports.COSMOS_DB_MSG = exports.DOCUMENT_DB_MSG = exports.COSMOS_DB_CHECK = void 0;\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst http = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'http'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst timers_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'timers'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst url = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'url'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst url_1 = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'url'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst bson_1 = __webpack_require__(/*! ./bson */ \"./node_modules/mongodb/lib/bson.js\");\nconst constants_1 = __webpack_require__(/*! ./cmap/wire_protocol/constants */ \"./node_modules/mongodb/lib/cmap/wire_protocol/constants.js\");\nconst constants_2 = __webpack_require__(/*! ./constants */ \"./node_modules/mongodb/lib/constants.js\");\nconst error_1 = __webpack_require__(/*! ./error */ \"./node_modules/mongodb/lib/error.js\");\nconst read_concern_1 = __webpack_require__(/*! ./read_concern */ \"./node_modules/mongodb/lib/read_concern.js\");\nconst read_preference_1 = __webpack_require__(/*! ./read_preference */ \"./node_modules/mongodb/lib/read_preference.js\");\nconst common_1 = __webpack_require__(/*! ./sdam/common */ \"./node_modules/mongodb/lib/sdam/common.js\");\nconst write_concern_1 = __webpack_require__(/*! ./write_concern */ \"./node_modules/mongodb/lib/write_concern.js\");\nexports.ByteUtils = {\n    toLocalBufferType(buffer) {\n        return Buffer.isBuffer(buffer)\n            ? buffer\n            : Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    },\n    equals(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).equals(seqB);\n    },\n    compare(seqA, seqB) {\n        return exports.ByteUtils.toLocalBufferType(seqA).compare(seqB);\n    },\n    toBase64(uint8array) {\n        return exports.ByteUtils.toLocalBufferType(uint8array).toString('base64');\n    }\n};\n/**\n * Determines if a connection's address matches a user provided list\n * of domain wildcards.\n */\nfunction hostMatchesWildcards(host, wildcards) {\n    for (const wildcard of wildcards) {\n        if (host === wildcard ||\n            (wildcard.startsWith('*.') && host?.endsWith(wildcard.substring(2, wildcard.length))) ||\n            (wildcard.startsWith('*/') && host?.endsWith(wildcard.substring(2, wildcard.length)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.hostMatchesWildcards = hostMatchesWildcards;\n/**\n * Ensure Hint field is in a shape we expect:\n * - object of index names mapping to 1 or -1\n * - just an index name\n * @internal\n */\nfunction normalizeHintField(hint) {\n    let finalHint = undefined;\n    if (typeof hint === 'string') {\n        finalHint = hint;\n    }\n    else if (Array.isArray(hint)) {\n        finalHint = {};\n        hint.forEach(param => {\n            finalHint[param] = 1;\n        });\n    }\n    else if (hint != null && typeof hint === 'object') {\n        finalHint = {};\n        for (const name in hint) {\n            finalHint[name] = hint[name];\n        }\n    }\n    return finalHint;\n}\nexports.normalizeHintField = normalizeHintField;\nconst TO_STRING = (object) => Object.prototype.toString.call(object);\n/**\n * Checks if arg is an Object:\n * - **NOTE**: the check is based on the `[Symbol.toStringTag]() === 'Object'`\n * @internal\n */\nfunction isObject(arg) {\n    return '[object Object]' === TO_STRING(arg);\n}\nexports.isObject = isObject;\n/** @internal */\nfunction mergeOptions(target, source) {\n    return { ...target, ...source };\n}\nexports.mergeOptions = mergeOptions;\n/** @internal */\nfunction filterOptions(options, names) {\n    const filterOptions = {};\n    for (const name in options) {\n        if (names.includes(name)) {\n            filterOptions[name] = options[name];\n        }\n    }\n    // Filtered options\n    return filterOptions;\n}\nexports.filterOptions = filterOptions;\n/**\n * Applies retryWrites: true to a command if retryWrites is set on the command's database.\n * @internal\n *\n * @param target - The target command to which we will apply retryWrites.\n * @param db - The database from which we can inherit a retryWrites value.\n */\nfunction applyRetryableWrites(target, db) {\n    if (db && db.s.options?.retryWrites) {\n        target.retryWrites = true;\n    }\n    return target;\n}\nexports.applyRetryableWrites = applyRetryableWrites;\n/**\n * Applies a write concern to a command based on well defined inheritance rules, optionally\n * detecting support for the write concern in the first place.\n * @internal\n *\n * @param target - the target command we will be applying the write concern to\n * @param sources - sources where we can inherit default write concerns from\n * @param options - optional settings passed into a command for write concern overrides\n */\n/**\n * Checks if a given value is a Promise\n *\n * @typeParam T - The resolution type of the possible promise\n * @param value - An object that could be a promise\n * @returns true if the provided value is a Promise\n */\nfunction isPromiseLike(value) {\n    return !!value && typeof value.then === 'function';\n}\nexports.isPromiseLike = isPromiseLike;\n/**\n * Applies collation to a given command.\n * @internal\n *\n * @param command - the command on which to apply collation\n * @param target - target of command\n * @param options - options containing collation settings\n */\nfunction decorateWithCollation(command, target, options) {\n    const capabilities = getTopology(target).capabilities;\n    if (options.collation && typeof options.collation === 'object') {\n        if (capabilities && capabilities.commandsTakeCollation) {\n            command.collation = options.collation;\n        }\n        else {\n            throw new error_1.MongoCompatibilityError(`Current topology does not support collation`);\n        }\n    }\n}\nexports.decorateWithCollation = decorateWithCollation;\n/**\n * Applies a read concern to a given command.\n * @internal\n *\n * @param command - the command on which to apply the read concern\n * @param coll - the parent collection of the operation calling this method\n */\nfunction decorateWithReadConcern(command, coll, options) {\n    if (options && options.session && options.session.inTransaction()) {\n        return;\n    }\n    const readConcern = Object.assign({}, command.readConcern || {});\n    if (coll.s.readConcern) {\n        Object.assign(readConcern, coll.s.readConcern);\n    }\n    if (Object.keys(readConcern).length > 0) {\n        Object.assign(command, { readConcern: readConcern });\n    }\n}\nexports.decorateWithReadConcern = decorateWithReadConcern;\n/**\n * Applies an explain to a given command.\n * @internal\n *\n * @param command - the command on which to apply the explain\n * @param options - the options containing the explain verbosity\n */\nfunction decorateWithExplain(command, explain) {\n    if (command.explain) {\n        return command;\n    }\n    return { explain: command, verbosity: explain.verbosity };\n}\nexports.decorateWithExplain = decorateWithExplain;\n/**\n * A helper function to get the topology from a given provider. Throws\n * if the topology cannot be found.\n * @throws MongoNotConnectedError\n * @internal\n */\nfunction getTopology(provider) {\n    // MongoClient or ClientSession or AbstractCursor\n    if ('topology' in provider && provider.topology) {\n        return provider.topology;\n    }\n    else if ('client' in provider && provider.client.topology) {\n        return provider.client.topology;\n    }\n    throw new error_1.MongoNotConnectedError('MongoClient must be connected to perform this operation');\n}\nexports.getTopology = getTopology;\n/** @internal */\nfunction ns(ns) {\n    return MongoDBNamespace.fromString(ns);\n}\nexports.ns = ns;\n/** @public */\nclass MongoDBNamespace {\n    /**\n     * Create a namespace object\n     *\n     * @param db - database name\n     * @param collection - collection name\n     */\n    constructor(db, collection) {\n        this.db = db;\n        this.collection = collection;\n        this.collection = collection === '' ? undefined : collection;\n    }\n    toString() {\n        return this.collection ? `${this.db}.${this.collection}` : this.db;\n    }\n    withCollection(collection) {\n        return new MongoDBCollectionNamespace(this.db, collection);\n    }\n    static fromString(namespace) {\n        if (typeof namespace !== 'string' || namespace === '') {\n            // TODO(NODE-3483): Replace with MongoNamespaceError\n            throw new error_1.MongoRuntimeError(`Cannot parse namespace from \"${namespace}\"`);\n        }\n        const [db, ...collectionParts] = namespace.split('.');\n        const collection = collectionParts.join('.');\n        return new MongoDBNamespace(db, collection === '' ? undefined : collection);\n    }\n}\nexports.MongoDBNamespace = MongoDBNamespace;\n/**\n * @public\n *\n * A class representing a collection's namespace.  This class enforces (through Typescript) that\n * the `collection` portion of the namespace is defined and should only be\n * used in scenarios where this can be guaranteed.\n */\nclass MongoDBCollectionNamespace extends MongoDBNamespace {\n    constructor(db, collection) {\n        super(db, collection);\n        this.collection = collection;\n    }\n    static fromString(namespace) {\n        return super.fromString(namespace);\n    }\n}\nexports.MongoDBCollectionNamespace = MongoDBCollectionNamespace;\n/** @internal */\nfunction* makeCounter(seed = 0) {\n    let count = seed;\n    while (true) {\n        const newCount = count;\n        count += 1;\n        yield newCount;\n    }\n}\nexports.makeCounter = makeCounter;\nfunction maybeCallback(promiseFn, callback) {\n    const promise = promiseFn();\n    if (callback == null) {\n        return promise;\n    }\n    promise.then(result => callback(undefined, result), error => callback(error));\n    return;\n}\nexports.maybeCallback = maybeCallback;\n/**\n * Synchronously Generate a UUIDv4\n * @internal\n */\nfunction uuidV4() {\n    const result = crypto.randomBytes(16);\n    result[6] = (result[6] & 0x0f) | 0x40;\n    result[8] = (result[8] & 0x3f) | 0x80;\n    return result;\n}\nexports.uuidV4 = uuidV4;\n/**\n * A helper function for determining `maxWireVersion` between legacy and new topology instances\n * @internal\n */\nfunction maxWireVersion(topologyOrServer) {\n    if (topologyOrServer) {\n        if (topologyOrServer.loadBalanced) {\n            // Since we do not have a monitor, we assume the load balanced server is always\n            // pointed at the latest mongodb version. There is a risk that for on-prem\n            // deployments that don't upgrade immediately that this could alert to the\n            // application that a feature is available that is actually not.\n            return constants_1.MAX_SUPPORTED_WIRE_VERSION;\n        }\n        if (topologyOrServer.hello) {\n            return topologyOrServer.hello.maxWireVersion;\n        }\n        if ('lastHello' in topologyOrServer && typeof topologyOrServer.lastHello === 'function') {\n            const lastHello = topologyOrServer.lastHello();\n            if (lastHello) {\n                return lastHello.maxWireVersion;\n            }\n        }\n        if (topologyOrServer.description &&\n            'maxWireVersion' in topologyOrServer.description &&\n            topologyOrServer.description.maxWireVersion != null) {\n            return topologyOrServer.description.maxWireVersion;\n        }\n    }\n    return 0;\n}\nexports.maxWireVersion = maxWireVersion;\n/**\n * Applies the function `eachFn` to each item in `arr`, in parallel.\n * @internal\n *\n * @param arr - An array of items to asynchronously iterate over\n * @param eachFn - A function to call on each item of the array. The callback signature is `(item, callback)`, where the callback indicates iteration is complete.\n * @param callback - The callback called after every item has been iterated\n */\nfunction eachAsync(arr, eachFn, callback) {\n    arr = arr || [];\n    let idx = 0;\n    let awaiting = 0;\n    for (idx = 0; idx < arr.length; ++idx) {\n        awaiting++;\n        eachFn(arr[idx], eachCallback);\n    }\n    if (awaiting === 0) {\n        callback();\n        return;\n    }\n    function eachCallback(err) {\n        awaiting--;\n        if (err) {\n            callback(err);\n            return;\n        }\n        if (idx === arr.length && awaiting <= 0) {\n            callback();\n        }\n    }\n}\nexports.eachAsync = eachAsync;\n/** @internal */\nfunction arrayStrictEqual(arr, arr2) {\n    if (!Array.isArray(arr) || !Array.isArray(arr2)) {\n        return false;\n    }\n    return arr.length === arr2.length && arr.every((elt, idx) => elt === arr2[idx]);\n}\nexports.arrayStrictEqual = arrayStrictEqual;\n/** @internal */\nfunction errorStrictEqual(lhs, rhs) {\n    if (lhs === rhs) {\n        return true;\n    }\n    if (!lhs || !rhs) {\n        return lhs === rhs;\n    }\n    if ((lhs == null && rhs != null) || (lhs != null && rhs == null)) {\n        return false;\n    }\n    if (lhs.constructor.name !== rhs.constructor.name) {\n        return false;\n    }\n    if (lhs.message !== rhs.message) {\n        return false;\n    }\n    return true;\n}\nexports.errorStrictEqual = errorStrictEqual;\n/** @internal */\nfunction makeStateMachine(stateTable) {\n    return function stateTransition(target, newState) {\n        const legalStates = stateTable[target.s.state];\n        if (legalStates && legalStates.indexOf(newState) < 0) {\n            throw new error_1.MongoRuntimeError(`illegal state transition from [${target.s.state}] => [${newState}], allowed: [${legalStates}]`);\n        }\n        target.emit('stateChanged', target.s.state, newState);\n        target.s.state = newState;\n    };\n}\nexports.makeStateMachine = makeStateMachine;\n/** @internal */\nfunction now() {\n    const hrtime = process.hrtime();\n    return Math.floor(hrtime[0] * 1000 + hrtime[1] / 1000000);\n}\nexports.now = now;\n/** @internal */\nfunction calculateDurationInMs(started) {\n    if (typeof started !== 'number') {\n        throw new error_1.MongoInvalidArgumentError('Numeric value required to calculate duration');\n    }\n    const elapsed = now() - started;\n    return elapsed < 0 ? 0 : elapsed;\n}\nexports.calculateDurationInMs = calculateDurationInMs;\n/** @internal */\nfunction hasAtomicOperators(doc) {\n    if (Array.isArray(doc)) {\n        for (const document of doc) {\n            if (hasAtomicOperators(document)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    const keys = Object.keys(doc);\n    return keys.length > 0 && keys[0][0] === '$';\n}\nexports.hasAtomicOperators = hasAtomicOperators;\n/**\n * Merge inherited properties from parent into options, prioritizing values from options,\n * then values from parent.\n * @internal\n */\nfunction resolveOptions(parent, options) {\n    const result = Object.assign({}, options, (0, bson_1.resolveBSONOptions)(options, parent));\n    // Users cannot pass a readConcern/writeConcern to operations in a transaction\n    const session = options?.session;\n    if (!session?.inTransaction()) {\n        const readConcern = read_concern_1.ReadConcern.fromOptions(options) ?? parent?.readConcern;\n        if (readConcern) {\n            result.readConcern = readConcern;\n        }\n        const writeConcern = write_concern_1.WriteConcern.fromOptions(options) ?? parent?.writeConcern;\n        if (writeConcern) {\n            result.writeConcern = writeConcern;\n        }\n    }\n    const readPreference = read_preference_1.ReadPreference.fromOptions(options) ?? parent?.readPreference;\n    if (readPreference) {\n        result.readPreference = readPreference;\n    }\n    return result;\n}\nexports.resolveOptions = resolveOptions;\nfunction isSuperset(set, subset) {\n    set = Array.isArray(set) ? new Set(set) : set;\n    subset = Array.isArray(subset) ? new Set(subset) : subset;\n    for (const elem of subset) {\n        if (!set.has(elem)) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.isSuperset = isSuperset;\n/**\n * Checks if the document is a Hello request\n * @internal\n */\nfunction isHello(doc) {\n    return doc[constants_2.LEGACY_HELLO_COMMAND] || doc.hello ? true : false;\n}\nexports.isHello = isHello;\n/** Returns the items that are uniquely in setA */\nfunction setDifference(setA, setB) {\n    const difference = new Set(setA);\n    for (const elem of setB) {\n        difference.delete(elem);\n    }\n    return difference;\n}\nexports.setDifference = setDifference;\nconst HAS_OWN = (object, prop) => Object.prototype.hasOwnProperty.call(object, prop);\nfunction isRecord(value, requiredKeys = undefined) {\n    if (!isObject(value)) {\n        return false;\n    }\n    const ctor = value.constructor;\n    if (ctor && ctor.prototype) {\n        if (!isObject(ctor.prototype)) {\n            return false;\n        }\n        // Check to see if some method exists from the Object exists\n        if (!HAS_OWN(ctor.prototype, 'isPrototypeOf')) {\n            return false;\n        }\n    }\n    if (requiredKeys) {\n        const keys = Object.keys(value);\n        return isSuperset(keys, requiredKeys);\n    }\n    return true;\n}\nexports.isRecord = isRecord;\n/**\n * Make a deep copy of an object\n *\n * NOTE: This is not meant to be the perfect implementation of a deep copy,\n * but instead something that is good enough for the purposes of\n * command monitoring.\n */\nfunction deepCopy(value) {\n    if (value == null) {\n        return value;\n    }\n    else if (Array.isArray(value)) {\n        return value.map(item => deepCopy(item));\n    }\n    else if (isRecord(value)) {\n        const res = {};\n        for (const key in value) {\n            res[key] = deepCopy(value[key]);\n        }\n        return res;\n    }\n    const ctor = value.constructor;\n    if (ctor) {\n        switch (ctor.name.toLowerCase()) {\n            case 'date':\n                return new ctor(Number(value));\n            case 'map':\n                return new Map(value);\n            case 'set':\n                return new Set(value);\n            case 'buffer':\n                return Buffer.from(value);\n        }\n    }\n    return value;\n}\nexports.deepCopy = deepCopy;\n/**\n * A sequential list of items in a circularly linked list\n * @remarks\n * The head node is special, it is always defined and has a value of null.\n * It is never \"included\" in the list, in that, it is not returned by pop/shift or yielded by the iterator.\n * The circular linkage and always defined head node are to reduce checks for null next/prev references to zero.\n * New nodes are declared as object literals with keys always in the same order: next, prev, value.\n * @internal\n */\nclass List {\n    get length() {\n        return this.count;\n    }\n    get [Symbol.toStringTag]() {\n        return 'List';\n    }\n    constructor() {\n        this.count = 0;\n        // this is carefully crafted:\n        // declaring a complete and consistently key ordered\n        // object is beneficial to the runtime optimizations\n        this.head = {\n            next: null,\n            prev: null,\n            value: null\n        };\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    toArray() {\n        return Array.from(this);\n    }\n    toString() {\n        return `head <=> ${this.toArray().join(' <=> ')} <=> head`;\n    }\n    *[Symbol.iterator]() {\n        for (const node of this.nodes()) {\n            yield node.value;\n        }\n    }\n    *nodes() {\n        let ptr = this.head.next;\n        while (ptr !== this.head) {\n            // Save next before yielding so that we make removing within iteration safe\n            const { next } = ptr;\n            yield ptr;\n            ptr = next;\n        }\n    }\n    /** Insert at end of list */\n    push(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head,\n            prev: this.head.prev,\n            value\n        };\n        this.head.prev.next = newNode;\n        this.head.prev = newNode;\n    }\n    /** Inserts every item inside an iterable instead of the iterable itself */\n    pushMany(iterable) {\n        for (const value of iterable) {\n            this.push(value);\n        }\n    }\n    /** Insert at front of list */\n    unshift(value) {\n        this.count += 1;\n        const newNode = {\n            next: this.head.next,\n            prev: this.head,\n            value\n        };\n        this.head.next.prev = newNode;\n        this.head.next = newNode;\n    }\n    remove(node) {\n        if (node === this.head || this.length === 0) {\n            return null;\n        }\n        this.count -= 1;\n        const prevNode = node.prev;\n        const nextNode = node.next;\n        prevNode.next = nextNode;\n        nextNode.prev = prevNode;\n        return node.value;\n    }\n    /** Removes the first node at the front of the list */\n    shift() {\n        return this.remove(this.head.next);\n    }\n    /** Removes the last node at the end of the list */\n    pop() {\n        return this.remove(this.head.prev);\n    }\n    /** Iterates through the list and removes nodes where filter returns true */\n    prune(filter) {\n        for (const node of this.nodes()) {\n            if (filter(node.value)) {\n                this.remove(node);\n            }\n        }\n    }\n    clear() {\n        this.count = 0;\n        this.head.next = this.head;\n        this.head.prev = this.head;\n    }\n    /** Returns the first item in the list, does not remove */\n    first() {\n        // If the list is empty, value will be the head's null\n        return this.head.next.value;\n    }\n    /** Returns the last item in the list, does not remove */\n    last() {\n        // If the list is empty, value will be the head's null\n        return this.head.prev.value;\n    }\n}\nexports.List = List;\n/**\n * A pool of Buffers which allow you to read them as if they were one\n * @internal\n */\nclass BufferPool {\n    constructor() {\n        this.buffers = new List();\n        this.totalByteLength = 0;\n    }\n    get length() {\n        return this.totalByteLength;\n    }\n    /** Adds a buffer to the internal buffer pool list */\n    append(buffer) {\n        this.buffers.push(buffer);\n        this.totalByteLength += buffer.length;\n    }\n    /**\n     * If BufferPool contains 4 bytes or more construct an int32 from the leading bytes,\n     * otherwise return null. Size can be negative, caller should error check.\n     */\n    getInt32() {\n        if (this.totalByteLength < 4) {\n            return null;\n        }\n        const firstBuffer = this.buffers.first();\n        if (firstBuffer != null && firstBuffer.byteLength >= 4) {\n            return firstBuffer.readInt32LE(0);\n        }\n        // Unlikely case: an int32 is split across buffers.\n        // Use read and put the returned buffer back on top\n        const top4Bytes = this.read(4);\n        const value = top4Bytes.readInt32LE(0);\n        // Put it back.\n        this.totalByteLength += 4;\n        this.buffers.unshift(top4Bytes);\n        return value;\n    }\n    /** Reads the requested number of bytes, optionally consuming them */\n    read(size) {\n        if (typeof size !== 'number' || size < 0) {\n            throw new error_1.MongoInvalidArgumentError('Argument \"size\" must be a non-negative number');\n        }\n        // oversized request returns empty buffer\n        if (size > this.totalByteLength) {\n            return Buffer.alloc(0);\n        }\n        // We know we have enough, we just don't know how it is spread across chunks\n        // TODO(NODE-4732): alloc API should change based on raw option\n        const result = Buffer.allocUnsafe(size);\n        for (let bytesRead = 0; bytesRead < size;) {\n            const buffer = this.buffers.shift();\n            if (buffer == null) {\n                break;\n            }\n            const bytesRemaining = size - bytesRead;\n            const bytesReadable = Math.min(bytesRemaining, buffer.byteLength);\n            const bytes = buffer.subarray(0, bytesReadable);\n            result.set(bytes, bytesRead);\n            bytesRead += bytesReadable;\n            this.totalByteLength -= bytesReadable;\n            if (bytesReadable < buffer.byteLength) {\n                this.buffers.unshift(buffer.subarray(bytesReadable));\n            }\n        }\n        return result;\n    }\n}\nexports.BufferPool = BufferPool;\n/** @public */\nclass HostAddress {\n    constructor(hostString) {\n        this.host = undefined;\n        this.port = undefined;\n        this.socketPath = undefined;\n        this.isIPv6 = false;\n        const escapedHost = hostString.split(' ').join('%20'); // escape spaces, for socket path hosts\n        if (escapedHost.endsWith('.sock')) {\n            // heuristically determine if we're working with a domain socket\n            this.socketPath = decodeURIComponent(escapedHost);\n            return;\n        }\n        const urlString = `iLoveJS://${escapedHost}`;\n        let url;\n        try {\n            url = new url_1.URL(urlString);\n        }\n        catch (urlError) {\n            const runtimeError = new error_1.MongoRuntimeError(`Unable to parse ${escapedHost} with URL`);\n            runtimeError.cause = urlError;\n            throw runtimeError;\n        }\n        const hostname = url.hostname;\n        const port = url.port;\n        let normalized = decodeURIComponent(hostname).toLowerCase();\n        if (normalized.startsWith('[') && normalized.endsWith(']')) {\n            this.isIPv6 = true;\n            normalized = normalized.substring(1, hostname.length - 1);\n        }\n        this.host = normalized.toLowerCase();\n        if (typeof port === 'number') {\n            this.port = port;\n        }\n        else if (typeof port === 'string' && port !== '') {\n            this.port = Number.parseInt(port, 10);\n        }\n        else {\n            this.port = 27017;\n        }\n        if (this.port === 0) {\n            throw new error_1.MongoParseError('Invalid port (zero) with hostname');\n        }\n        Object.freeze(this);\n    }\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        return this.inspect();\n    }\n    inspect() {\n        return `new HostAddress('${this.toString()}')`;\n    }\n    toString() {\n        if (typeof this.host === 'string') {\n            if (this.isIPv6) {\n                return `[${this.host}]:${this.port}`;\n            }\n            return `${this.host}:${this.port}`;\n        }\n        return `${this.socketPath}`;\n    }\n    static fromString(s) {\n        return new HostAddress(s);\n    }\n    static fromHostPort(host, port) {\n        if (host.includes(':')) {\n            host = `[${host}]`; // IPv6 address\n        }\n        return HostAddress.fromString(`${host}:${port}`);\n    }\n    static fromSrvRecord({ name, port }) {\n        return HostAddress.fromHostPort(name, port);\n    }\n    toHostPort() {\n        if (this.socketPath) {\n            return { host: this.socketPath, port: 0 };\n        }\n        const host = this.host ?? '';\n        const port = this.port ?? 0;\n        return { host, port };\n    }\n}\nexports.HostAddress = HostAddress;\nexports.DEFAULT_PK_FACTORY = {\n    // We prefer not to rely on ObjectId having a createPk method\n    createPk() {\n        return new bson_1.ObjectId();\n    }\n};\n/**\n * When the driver used emitWarning the code will be equal to this.\n * @public\n *\n * @example\n * ```ts\n * process.on('warning', (warning) => {\n *  if (warning.code === MONGODB_WARNING_CODE) console.error('Ah an important warning! :)')\n * })\n * ```\n */\nexports.MONGODB_WARNING_CODE = 'MONGODB DRIVER';\n/** @internal */\nfunction emitWarning(message) {\n    return process.emitWarning(message, { code: exports.MONGODB_WARNING_CODE });\n}\nexports.emitWarning = emitWarning;\nconst emittedWarnings = new Set();\n/**\n * Will emit a warning once for the duration of the application.\n * Uses the message to identify if it has already been emitted\n * so using string interpolation can cause multiple emits\n * @internal\n */\nfunction emitWarningOnce(message) {\n    if (!emittedWarnings.has(message)) {\n        emittedWarnings.add(message);\n        return emitWarning(message);\n    }\n}\nexports.emitWarningOnce = emitWarningOnce;\n/**\n * Takes a JS object and joins the values into a string separated by ', '\n */\nfunction enumToString(en) {\n    return Object.values(en).join(', ');\n}\nexports.enumToString = enumToString;\n/**\n * Determine if a server supports retryable writes.\n *\n * @internal\n */\nfunction supportsRetryableWrites(server) {\n    if (!server) {\n        return false;\n    }\n    if (server.loadBalanced) {\n        // Loadbalanced topologies will always support retry writes\n        return true;\n    }\n    if (server.description.logicalSessionTimeoutMinutes != null) {\n        // that supports sessions\n        if (server.description.type !== common_1.ServerType.Standalone) {\n            // and that is not a standalone\n            return true;\n        }\n    }\n    return false;\n}\nexports.supportsRetryableWrites = supportsRetryableWrites;\n/**\n * FisherYates Shuffle\n *\n * Reference: https://bost.ocks.org/mike/shuffle/\n * @param sequence - items to be shuffled\n * @param limit - Defaults to `0`. If nonzero shuffle will slice the randomized array e.g, `.slice(0, limit)` otherwise will return the entire randomized array.\n */\nfunction shuffle(sequence, limit = 0) {\n    const items = Array.from(sequence); // shallow copy in order to never shuffle the input\n    if (limit > items.length) {\n        throw new error_1.MongoRuntimeError('Limit must be less than the number of items');\n    }\n    let remainingItemsToShuffle = items.length;\n    const lowerBound = limit % items.length === 0 ? 1 : items.length - limit;\n    while (remainingItemsToShuffle > lowerBound) {\n        // Pick a remaining element\n        const randomIndex = Math.floor(Math.random() * remainingItemsToShuffle);\n        remainingItemsToShuffle -= 1;\n        // And swap it with the current element\n        const swapHold = items[remainingItemsToShuffle];\n        items[remainingItemsToShuffle] = items[randomIndex];\n        items[randomIndex] = swapHold;\n    }\n    return limit % items.length === 0 ? items : items.slice(lowerBound);\n}\nexports.shuffle = shuffle;\n// TODO(NODE-4936): read concern eligibility for commands should be codified in command construction\n// @see https://github.com/mongodb/specifications/blob/master/source/read-write-concern/read-write-concern.rst#read-concern\nfunction commandSupportsReadConcern(command) {\n    if (command.aggregate || command.count || command.distinct || command.find || command.geoNear) {\n        return true;\n    }\n    return false;\n}\nexports.commandSupportsReadConcern = commandSupportsReadConcern;\n/**\n * Compare objectIds. `null` is always less\n * - `+1 = oid1 is greater than oid2`\n * - `-1 = oid1 is less than oid2`\n * - `+0 = oid1 is equal oid2`\n */\nfunction compareObjectId(oid1, oid2) {\n    if (oid1 == null && oid2 == null) {\n        return 0;\n    }\n    if (oid1 == null) {\n        return -1;\n    }\n    if (oid2 == null) {\n        return 1;\n    }\n    return exports.ByteUtils.compare(oid1.id, oid2.id);\n}\nexports.compareObjectId = compareObjectId;\nfunction parseInteger(value) {\n    if (typeof value === 'number')\n        return Math.trunc(value);\n    const parsedValue = Number.parseInt(String(value), 10);\n    return Number.isNaN(parsedValue) ? null : parsedValue;\n}\nexports.parseInteger = parseInteger;\nfunction parseUnsignedInteger(value) {\n    const parsedInt = parseInteger(value);\n    return parsedInt != null && parsedInt >= 0 ? parsedInt : null;\n}\nexports.parseUnsignedInteger = parseUnsignedInteger;\n/**\n * Determines whether a provided address matches the provided parent domain.\n *\n * If a DNS server were to become compromised SRV records would still need to\n * advertise addresses that are under the same domain as the srvHost.\n *\n * @param address - The address to check against a domain\n * @param srvHost - The domain to check the provided address against\n * @returns Whether the provided address matches the parent domain\n */\nfunction matchesParentDomain(address, srvHost) {\n    // Remove trailing dot if exists on either the resolved address or the srv hostname\n    const normalizedAddress = address.endsWith('.') ? address.slice(0, address.length - 1) : address;\n    const normalizedSrvHost = srvHost.endsWith('.') ? srvHost.slice(0, srvHost.length - 1) : srvHost;\n    const allCharacterBeforeFirstDot = /^.*?\\./;\n    // Remove all characters before first dot\n    // Add leading dot back to string so\n    //   an srvHostDomain = '.trusted.site'\n    //   will not satisfy an addressDomain that endsWith '.fake-trusted.site'\n    const addressDomain = `.${normalizedAddress.replace(allCharacterBeforeFirstDot, '')}`;\n    const srvHostDomain = `.${normalizedSrvHost.replace(allCharacterBeforeFirstDot, '')}`;\n    return addressDomain.endsWith(srvHostDomain);\n}\nexports.matchesParentDomain = matchesParentDomain;\nasync function request(uri, options = {}) {\n    return new Promise((resolve, reject) => {\n        const requestOptions = {\n            method: 'GET',\n            timeout: 10000,\n            json: true,\n            ...url.parse(uri),\n            ...options\n        };\n        const req = http.request(requestOptions, res => {\n            res.setEncoding('utf8');\n            let data = '';\n            res.on('data', d => {\n                data += d;\n            });\n            res.once('end', () => {\n                if (options.json === false) {\n                    resolve(data);\n                    return;\n                }\n                try {\n                    const parsed = JSON.parse(data);\n                    resolve(parsed);\n                }\n                catch {\n                    // TODO(NODE-3483)\n                    reject(new error_1.MongoRuntimeError(`Invalid JSON response: \"${data}\"`));\n                }\n            });\n        });\n        req.once('timeout', () => req.destroy(new error_1.MongoNetworkTimeoutError(`Network request to ${uri} timed out after ${options.timeout} ms`)));\n        req.once('error', error => reject(error));\n        req.end();\n    });\n}\nexports.request = request;\n/**\n * A custom AbortController that aborts after a specified timeout.\n *\n * If `timeout` is undefined or \\<=0, the abort controller never aborts.\n *\n * This class provides two benefits over the built-in AbortSignal.timeout() method.\n * - This class provides a mechanism for cancelling the timeout\n * - This class supports infinite timeouts by interpreting a timeout of 0 as infinite.  This is\n *    consistent with existing timeout options in the Node driver (serverSelectionTimeoutMS, for example).\n * @internal\n */\nclass TimeoutController extends AbortController {\n    constructor(timeout = 0, timeoutId = timeout > 0 ? (0, timers_1.setTimeout)(() => this.abort(), timeout) : null) {\n        super();\n        this.timeoutId = timeoutId;\n    }\n    clear() {\n        if (this.timeoutId != null) {\n            (0, timers_1.clearTimeout)(this.timeoutId);\n        }\n        this.timeoutId = null;\n    }\n}\nexports.TimeoutController = TimeoutController;\n/** @internal */\nexports.DOCUMENT_DB_CHECK = /(\\.docdb\\.amazonaws\\.com$)|(\\.docdb-elastic\\.amazonaws\\.com$)/;\n/** @internal */\nexports.COSMOS_DB_CHECK = /\\.cosmos\\.azure\\.com$/;\n/** @internal */\nexports.DOCUMENT_DB_MSG = 'You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb';\n/** @internal */\nexports.COSMOS_DB_MSG = 'You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb';\n/** @internal */\nfunction isHostMatch(match, host) {\n    return host && match.test(host.toLowerCase()) ? true : false;\n}\nexports.isHostMatch = isHostMatch;\n//# sourceMappingURL=utils.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/utils.js?");

/***/ }),

/***/ "./node_modules/mongodb/lib/write_concern.js":
/*!***************************************************!*\
  !*** ./node_modules/mongodb/lib/write_concern.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WriteConcern = exports.WRITE_CONCERN_KEYS = void 0;\nexports.WRITE_CONCERN_KEYS = ['w', 'wtimeout', 'j', 'journal', 'fsync'];\n/**\n * A MongoDB WriteConcern, which describes the level of acknowledgement\n * requested from MongoDB for write operations.\n * @public\n *\n * @see https://www.mongodb.com/docs/manual/reference/write-concern/\n */\nclass WriteConcern {\n    /**\n     * Constructs a WriteConcern from the write concern properties.\n     * @param w - request acknowledgment that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.\n     * @param wtimeoutMS - specify a time limit to prevent write operations from blocking indefinitely\n     * @param journal - request acknowledgment that the write operation has been written to the on-disk journal\n     * @param fsync - equivalent to the j option. Is deprecated and will be removed in the next major version.\n     */\n    constructor(w, wtimeoutMS, journal, fsync) {\n        if (w != null) {\n            if (!Number.isNaN(Number(w))) {\n                this.w = Number(w);\n            }\n            else {\n                this.w = w;\n            }\n        }\n        if (wtimeoutMS != null) {\n            this.wtimeoutMS = this.wtimeout = wtimeoutMS;\n        }\n        if (journal != null) {\n            this.journal = this.j = journal;\n        }\n        if (fsync != null) {\n            this.journal = this.j = fsync ? true : false;\n        }\n    }\n    /**\n     * Apply a write concern to a command document. Will modify and return the command.\n     */\n    static apply(command, writeConcern) {\n        const wc = {};\n        // The write concern document sent to the server has w/wtimeout/j fields.\n        if (writeConcern.w != null)\n            wc.w = writeConcern.w;\n        if (writeConcern.wtimeoutMS != null)\n            wc.wtimeout = writeConcern.wtimeoutMS;\n        if (writeConcern.journal != null)\n            wc.j = writeConcern.j;\n        command.writeConcern = wc;\n        return command;\n    }\n    /** Construct a WriteConcern given an options object. */\n    static fromOptions(options, inherit) {\n        if (options == null)\n            return undefined;\n        inherit = inherit ?? {};\n        let opts;\n        if (typeof options === 'string' || typeof options === 'number') {\n            opts = { w: options };\n        }\n        else if (options instanceof WriteConcern) {\n            opts = options;\n        }\n        else {\n            opts = options.writeConcern;\n        }\n        const parentOpts = inherit instanceof WriteConcern ? inherit : inherit.writeConcern;\n        const { w = undefined, wtimeout = undefined, j = undefined, fsync = undefined, journal = undefined, wtimeoutMS = undefined } = {\n            ...parentOpts,\n            ...opts\n        };\n        if (w != null ||\n            wtimeout != null ||\n            wtimeoutMS != null ||\n            j != null ||\n            journal != null ||\n            fsync != null) {\n            return new WriteConcern(w, wtimeout ?? wtimeoutMS, j ?? journal, fsync);\n        }\n        return undefined;\n    }\n}\nexports.WriteConcern = WriteConcern;\n//# sourceMappingURL=write_concern.js.map\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/lib/write_concern.js?");

/***/ }),

/***/ "./node_modules/punycode/punycode.es6.js":
/*!***********************************************!*\
  !*** ./node_modules/punycode/punycode.es6.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   toASCII: () => (/* binding */ toASCII),\n/* harmony export */   toUnicode: () => (/* binding */ toUnicode),\n/* harmony export */   ucs2decode: () => (/* binding */ ucs2decode),\n/* harmony export */   ucs2encode: () => (/* binding */ ucs2encode)\n/* harmony export */ });\n\n\n/** Highest positive signed 32-bit float value */\nconst maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1\n\n/** Bootstring parameters */\nconst base = 36;\nconst tMin = 1;\nconst tMax = 26;\nconst skew = 38;\nconst damp = 700;\nconst initialBias = 72;\nconst initialN = 128; // 0x80\nconst delimiter = '-'; // '\\x2D'\n\n/** Regular expressions */\nconst regexPunycode = /^xn--/;\nconst regexNonASCII = /[^\\0-\\x7F]/; // Note: U+007F DEL is excluded too.\nconst regexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g; // RFC 3490 separators\n\n/** Error messages */\nconst errors = {\n\t'overflow': 'Overflow: input needs wider integers to process',\n\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t'invalid-input': 'Invalid input'\n};\n\n/** Convenience shortcuts */\nconst baseMinusTMin = base - tMin;\nconst floor = Math.floor;\nconst stringFromCharCode = String.fromCharCode;\n\n/*--------------------------------------------------------------------------*/\n\n/**\n * A generic error utility function.\n * @private\n * @param {String} type The error type.\n * @returns {Error} Throws a `RangeError` with the applicable error message.\n */\nfunction error(type) {\n\tthrow new RangeError(errors[type]);\n}\n\n/**\n * A generic `Array#map` utility function.\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} callback The function that gets called for every array\n * item.\n * @returns {Array} A new array of values returned by the callback function.\n */\nfunction map(array, callback) {\n\tconst result = [];\n\tlet length = array.length;\n\twhile (length--) {\n\t\tresult[length] = callback(array[length]);\n\t}\n\treturn result;\n}\n\n/**\n * A simple `Array#map`-like wrapper to work with domain name strings or email\n * addresses.\n * @private\n * @param {String} domain The domain name or email address.\n * @param {Function} callback The function that gets called for every\n * character.\n * @returns {String} A new string of characters returned by the callback\n * function.\n */\nfunction mapDomain(domain, callback) {\n\tconst parts = domain.split('@');\n\tlet result = '';\n\tif (parts.length > 1) {\n\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t// the local part (i.e. everything up to `@`) intact.\n\t\tresult = parts[0] + '@';\n\t\tdomain = parts[1];\n\t}\n\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\tdomain = domain.replace(regexSeparators, '\\x2E');\n\tconst labels = domain.split('.');\n\tconst encoded = map(labels, callback).join('.');\n\treturn result + encoded;\n}\n\n/**\n * Creates an array containing the numeric code points of each Unicode\n * character in the string. While JavaScript uses UCS-2 internally,\n * this function will convert a pair of surrogate halves (each of which\n * UCS-2 exposes as separate characters) into a single code point,\n * matching UTF-16.\n * @see `punycode.ucs2.encode`\n * @see <https://mathiasbynens.be/notes/javascript-encoding>\n * @memberOf punycode.ucs2\n * @name decode\n * @param {String} string The Unicode input string (UCS-2).\n * @returns {Array} The new array of code points.\n */\nfunction ucs2decode(string) {\n\tconst output = [];\n\tlet counter = 0;\n\tconst length = string.length;\n\twhile (counter < length) {\n\t\tconst value = string.charCodeAt(counter++);\n\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t// It's a high surrogate, and there is a next character.\n\t\t\tconst extra = string.charCodeAt(counter++);\n\t\t\tif ((extra & 0xFC00) == 0xDC00) { // Low surrogate.\n\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t} else {\n\t\t\t\t// It's an unmatched surrogate; only append this code unit, in case the\n\t\t\t\t// next code unit is the high surrogate of a surrogate pair.\n\t\t\t\toutput.push(value);\n\t\t\t\tcounter--;\n\t\t\t}\n\t\t} else {\n\t\t\toutput.push(value);\n\t\t}\n\t}\n\treturn output;\n}\n\n/**\n * Creates a string based on an array of numeric code points.\n * @see `punycode.ucs2.decode`\n * @memberOf punycode.ucs2\n * @name encode\n * @param {Array} codePoints The array of numeric code points.\n * @returns {String} The new Unicode string (UCS-2).\n */\nconst ucs2encode = codePoints => String.fromCodePoint(...codePoints);\n\n/**\n * Converts a basic code point into a digit/integer.\n * @see `digitToBasic()`\n * @private\n * @param {Number} codePoint The basic numeric code point value.\n * @returns {Number} The numeric value of a basic code point (for use in\n * representing integers) in the range `0` to `base - 1`, or `base` if\n * the code point does not represent a value.\n */\nconst basicToDigit = function(codePoint) {\n\tif (codePoint >= 0x30 && codePoint < 0x3A) {\n\t\treturn 26 + (codePoint - 0x30);\n\t}\n\tif (codePoint >= 0x41 && codePoint < 0x5B) {\n\t\treturn codePoint - 0x41;\n\t}\n\tif (codePoint >= 0x61 && codePoint < 0x7B) {\n\t\treturn codePoint - 0x61;\n\t}\n\treturn base;\n};\n\n/**\n * Converts a digit/integer into a basic code point.\n * @see `basicToDigit()`\n * @private\n * @param {Number} digit The numeric value of a basic code point.\n * @returns {Number} The basic code point whose value (when used for\n * representing integers) is `digit`, which needs to be in the range\n * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n * used; else, the lowercase form is used. The behavior is undefined\n * if `flag` is non-zero and `digit` has no uppercase form.\n */\nconst digitToBasic = function(digit, flag) {\n\t//  0..25 map to ASCII a..z or A..Z\n\t// 26..35 map to ASCII 0..9\n\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n};\n\n/**\n * Bias adaptation function as per section 3.4 of RFC 3492.\n * https://tools.ietf.org/html/rfc3492#section-3.4\n * @private\n */\nconst adapt = function(delta, numPoints, firstTime) {\n\tlet k = 0;\n\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\tdelta += floor(delta / numPoints);\n\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\tdelta = floor(delta / baseMinusTMin);\n\t}\n\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n};\n\n/**\n * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n * symbols.\n * @memberOf punycode\n * @param {String} input The Punycode string of ASCII-only symbols.\n * @returns {String} The resulting string of Unicode symbols.\n */\nconst decode = function(input) {\n\t// Don't use UCS-2.\n\tconst output = [];\n\tconst inputLength = input.length;\n\tlet i = 0;\n\tlet n = initialN;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points: let `basic` be the number of input code\n\t// points before the last delimiter, or `0` if there is none, then copy\n\t// the first basic code points to the output.\n\n\tlet basic = input.lastIndexOf(delimiter);\n\tif (basic < 0) {\n\t\tbasic = 0;\n\t}\n\n\tfor (let j = 0; j < basic; ++j) {\n\t\t// if it's not a basic code point\n\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\terror('not-basic');\n\t\t}\n\t\toutput.push(input.charCodeAt(j));\n\t}\n\n\t// Main decoding loop: start just after the last delimiter if any basic code\n\t// points were copied; start at the beginning otherwise.\n\n\tfor (let index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t// `index` is the index of the next character to be consumed.\n\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t// which gets added to `i`. The overflow checking is easier\n\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t// value at the end to obtain `delta`.\n\t\tconst oldi = i;\n\t\tfor (let w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\tif (index >= inputLength) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\n\t\t\tconst digit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\tif (digit >= base) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\t\t\tif (digit > floor((maxInt - i) / w)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\ti += digit * w;\n\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\tif (digit < t) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tconst baseMinusT = base - t;\n\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tw *= baseMinusT;\n\n\t\t}\n\n\t\tconst out = output.length + 1;\n\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t// incrementing `n` each time, so we'll fix that now:\n\t\tif (floor(i / out) > maxInt - n) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tn += floor(i / out);\n\t\ti %= out;\n\n\t\t// Insert `n` at position `i` of the output.\n\t\toutput.splice(i++, 0, n);\n\n\t}\n\n\treturn String.fromCodePoint(...output);\n};\n\n/**\n * Converts a string of Unicode symbols (e.g. a domain name label) to a\n * Punycode string of ASCII-only symbols.\n * @memberOf punycode\n * @param {String} input The string of Unicode symbols.\n * @returns {String} The resulting Punycode string of ASCII-only symbols.\n */\nconst encode = function(input) {\n\tconst output = [];\n\n\t// Convert the input in UCS-2 to an array of Unicode code points.\n\tinput = ucs2decode(input);\n\n\t// Cache the length.\n\tconst inputLength = input.length;\n\n\t// Initialize the state.\n\tlet n = initialN;\n\tlet delta = 0;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points.\n\tfor (const currentValue of input) {\n\t\tif (currentValue < 0x80) {\n\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t}\n\t}\n\n\tconst basicLength = output.length;\n\tlet handledCPCount = basicLength;\n\n\t// `handledCPCount` is the number of code points that have been handled;\n\t// `basicLength` is the number of basic code points.\n\n\t// Finish the basic string with a delimiter unless it's empty.\n\tif (basicLength) {\n\t\toutput.push(delimiter);\n\t}\n\n\t// Main encoding loop:\n\twhile (handledCPCount < inputLength) {\n\n\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t// larger one:\n\t\tlet m = maxInt;\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\tm = currentValue;\n\t\t\t}\n\t\t}\n\n\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t// but guard against overflow.\n\t\tconst handledCPCountPlusOne = handledCPCount + 1;\n\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\tn = m;\n\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\t\t\tif (currentValue === n) {\n\t\t\t\t// Represent delta as a generalized variable-length integer.\n\t\t\t\tlet q = delta;\n\t\t\t\tfor (let k = base; /* no condition */; k += base) {\n\t\t\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tconst qMinusT = q - t;\n\t\t\t\t\tconst baseMinusT = base - t;\n\t\t\t\t\toutput.push(\n\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t);\n\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t}\n\n\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount === basicLength);\n\t\t\t\tdelta = 0;\n\t\t\t\t++handledCPCount;\n\t\t\t}\n\t\t}\n\n\t\t++delta;\n\t\t++n;\n\n\t}\n\treturn output.join('');\n};\n\n/**\n * Converts a Punycode string representing a domain name or an email address\n * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n * it doesn't matter if you call it on a string that has already been\n * converted to Unicode.\n * @memberOf punycode\n * @param {String} input The Punycoded domain name or email address to\n * convert to Unicode.\n * @returns {String} The Unicode representation of the given Punycode\n * string.\n */\nconst toUnicode = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexPunycode.test(string)\n\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t: string;\n\t});\n};\n\n/**\n * Converts a Unicode string representing a domain name or an email address to\n * Punycode. Only the non-ASCII parts of the domain name will be converted,\n * i.e. it doesn't matter if you call it with a domain that's already in\n * ASCII.\n * @memberOf punycode\n * @param {String} input The domain name or email address to convert, as a\n * Unicode string.\n * @returns {String} The Punycode representation of the given domain name or\n * email address.\n */\nconst toASCII = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexNonASCII.test(string)\n\t\t\t? 'xn--' + encode(string)\n\t\t\t: string;\n\t});\n};\n\n/*--------------------------------------------------------------------------*/\n\n/** Define the public API */\nconst punycode = {\n\t/**\n\t * A string representing the current Punycode.js version number.\n\t * @memberOf punycode\n\t * @type String\n\t */\n\t'version': '2.3.1',\n\t/**\n\t * An object of methods to convert from JavaScript's internal character\n\t * representation (UCS-2) to Unicode code points, and back.\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode\n\t * @type Object\n\t */\n\t'ucs2': {\n\t\t'decode': ucs2decode,\n\t\t'encode': ucs2encode\n\t},\n\t'decode': decode,\n\t'encode': encode,\n\t'toASCII': toASCII,\n\t'toUnicode': toUnicode\n};\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (punycode);\n\n\n//# sourceURL=webpack://oracle2/./node_modules/punycode/punycode.es6.js?");

/***/ }),

/***/ "./node_modules/sparse-bitfield/index.js":
/*!***********************************************!*\
  !*** ./node_modules/sparse-bitfield/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var pager = __webpack_require__(/*! memory-pager */ \"./node_modules/memory-pager/index.js\")\n\nmodule.exports = Bitfield\n\nfunction Bitfield (opts) {\n  if (!(this instanceof Bitfield)) return new Bitfield(opts)\n  if (!opts) opts = {}\n  if (Buffer.isBuffer(opts)) opts = {buffer: opts}\n\n  this.pageOffset = opts.pageOffset || 0\n  this.pageSize = opts.pageSize || 1024\n  this.pages = opts.pages || pager(this.pageSize)\n\n  this.byteLength = this.pages.length * this.pageSize\n  this.length = 8 * this.byteLength\n\n  if (!powerOfTwo(this.pageSize)) throw new Error('The page size should be a power of two')\n\n  this._trackUpdates = !!opts.trackUpdates\n  this._pageMask = this.pageSize - 1\n\n  if (opts.buffer) {\n    for (var i = 0; i < opts.buffer.length; i += this.pageSize) {\n      this.pages.set(i / this.pageSize, opts.buffer.slice(i, i + this.pageSize))\n    }\n    this.byteLength = opts.buffer.length\n    this.length = 8 * this.byteLength\n  }\n}\n\nBitfield.prototype.get = function (i) {\n  var o = i & 7\n  var j = (i - o) / 8\n\n  return !!(this.getByte(j) & (128 >> o))\n}\n\nBitfield.prototype.getByte = function (i) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, true)\n\n  return page ? page.buffer[o + this.pageOffset] : 0\n}\n\nBitfield.prototype.set = function (i, v) {\n  var o = i & 7\n  var j = (i - o) / 8\n  var b = this.getByte(j)\n\n  return this.setByte(j, v ? b | (128 >> o) : b & (255 ^ (128 >> o)))\n}\n\nBitfield.prototype.toBuffer = function () {\n  var all = alloc(this.pages.length * this.pageSize)\n\n  for (var i = 0; i < this.pages.length; i++) {\n    var next = this.pages.get(i, true)\n    var allOffset = i * this.pageSize\n    if (next) next.buffer.copy(all, allOffset, this.pageOffset, this.pageOffset + this.pageSize)\n  }\n\n  return all\n}\n\nBitfield.prototype.setByte = function (i, b) {\n  var o = i & this._pageMask\n  var j = (i - o) / this.pageSize\n  var page = this.pages.get(j, false)\n\n  o += this.pageOffset\n\n  if (page.buffer[o] === b) return false\n  page.buffer[o] = b\n\n  if (i >= this.byteLength) {\n    this.byteLength = i + 1\n    this.length = this.byteLength * 8\n  }\n\n  if (this._trackUpdates) this.pages.updated(page)\n\n  return true\n}\n\nfunction alloc (n) {\n  if (Buffer.alloc) return Buffer.alloc(n)\n  var b = new Buffer(n)\n  b.fill(0)\n  return b\n}\n\nfunction powerOfTwo (x) {\n  return !(x & (x - 1))\n}\n\n\n//# sourceURL=webpack://oracle2/./node_modules/sparse-bitfield/index.js?");

/***/ }),

/***/ "./node_modules/tr46/index.js":
/*!************************************!*\
  !*** ./node_modules/tr46/index.js ***!
  \************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst punycode = __webpack_require__(/*! punycode/ */ \"./node_modules/punycode/punycode.es6.js\");\nconst regexes = __webpack_require__(/*! ./lib/regexes.js */ \"./node_modules/tr46/lib/regexes.js\");\nconst mappingTable = __webpack_require__(/*! ./lib/mappingTable.json */ \"./node_modules/tr46/lib/mappingTable.json\");\nconst { STATUS_MAPPING } = __webpack_require__(/*! ./lib/statusMapping.js */ \"./node_modules/tr46/lib/statusMapping.js\");\n\nfunction containsNonASCII(str) {\n  return /[^\\x00-\\x7F]/u.test(str);\n}\n\nfunction findStatus(val, { useSTD3ASCIIRules }) {\n  let start = 0;\n  let end = mappingTable.length - 1;\n\n  while (start <= end) {\n    const mid = Math.floor((start + end) / 2);\n\n    const target = mappingTable[mid];\n    const min = Array.isArray(target[0]) ? target[0][0] : target[0];\n    const max = Array.isArray(target[0]) ? target[0][1] : target[0];\n\n    if (min <= val && max >= val) {\n      if (useSTD3ASCIIRules &&\n          (target[1] === STATUS_MAPPING.disallowed_STD3_valid || target[1] === STATUS_MAPPING.disallowed_STD3_mapped)) {\n        return [STATUS_MAPPING.disallowed, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_valid) {\n        return [STATUS_MAPPING.valid, ...target.slice(2)];\n      } else if (target[1] === STATUS_MAPPING.disallowed_STD3_mapped) {\n        return [STATUS_MAPPING.mapped, ...target.slice(2)];\n      }\n\n      return target.slice(1);\n    } else if (min > val) {\n      end = mid - 1;\n    } else {\n      start = mid + 1;\n    }\n  }\n\n  return null;\n}\n\nfunction mapChars(domainName, { useSTD3ASCIIRules, processingOption }) {\n  let hasError = false;\n  let processed = \"\";\n\n  for (const ch of domainName) {\n    const [status, mapping] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n\n    switch (status) {\n      case STATUS_MAPPING.disallowed:\n        hasError = true;\n        processed += ch;\n        break;\n      case STATUS_MAPPING.ignored:\n        break;\n      case STATUS_MAPPING.mapped:\n        processed += mapping;\n        break;\n      case STATUS_MAPPING.deviation:\n        if (processingOption === \"transitional\") {\n          processed += mapping;\n        } else {\n          processed += ch;\n        }\n        break;\n      case STATUS_MAPPING.valid:\n        processed += ch;\n        break;\n    }\n  }\n\n  return {\n    string: processed,\n    error: hasError\n  };\n}\n\nfunction validateLabel(label, { checkHyphens, checkBidi, checkJoiners, processingOption, useSTD3ASCIIRules }) {\n  if (label.normalize(\"NFC\") !== label) {\n    return false;\n  }\n\n  const codePoints = Array.from(label);\n\n  if (checkHyphens) {\n    if ((codePoints[2] === \"-\" && codePoints[3] === \"-\") ||\n        (label.startsWith(\"-\") || label.endsWith(\"-\"))) {\n      return false;\n    }\n  }\n\n  if (label.includes(\".\") ||\n      (codePoints.length > 0 && regexes.combiningMarks.test(codePoints[0]))) {\n    return false;\n  }\n\n  for (const ch of codePoints) {\n    const [status] = findStatus(ch.codePointAt(0), { useSTD3ASCIIRules });\n    if ((processingOption === \"transitional\" && status !== STATUS_MAPPING.valid) ||\n        (processingOption === \"nontransitional\" &&\n         status !== STATUS_MAPPING.valid && status !== STATUS_MAPPING.deviation)) {\n      return false;\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5892#appendix-A\n  if (checkJoiners) {\n    let last = 0;\n    for (const [i, ch] of codePoints.entries()) {\n      if (ch === \"\\u200C\" || ch === \"\\u200D\") {\n        if (i > 0) {\n          if (regexes.combiningClassVirama.test(codePoints[i - 1])) {\n            continue;\n          }\n          if (ch === \"\\u200C\") {\n            // TODO: make this more efficient\n            const next = codePoints.indexOf(\"\\u200C\", i + 1);\n            const test = next < 0 ? codePoints.slice(last) : codePoints.slice(last, next);\n            if (regexes.validZWNJ.test(test.join(\"\"))) {\n              last = i + 1;\n              continue;\n            }\n          }\n        }\n        return false;\n      }\n    }\n  }\n\n  // https://tools.ietf.org/html/rfc5893#section-2\n  // For the codePoints length check, see discussion in https://github.com/jsdom/whatwg-url/pull/250 and the second item\n  // in https://github.com/whatwg/url/issues/744.\n  if (checkBidi && codePoints.length > 0) {\n    let rtl;\n\n    // 1\n    if (regexes.bidiS1LTR.test(codePoints[0])) {\n      rtl = false;\n    } else if (regexes.bidiS1RTL.test(codePoints[0])) {\n      rtl = true;\n    } else {\n      return false;\n    }\n\n    if (rtl) {\n      // 2-4\n      if (!regexes.bidiS2.test(label) ||\n          !regexes.bidiS3.test(label) ||\n          (regexes.bidiS4EN.test(label) && regexes.bidiS4AN.test(label))) {\n        return false;\n      }\n    } else if (!regexes.bidiS5.test(label) ||\n               !regexes.bidiS6.test(label)) { // 5-6\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction isBidiDomain(labels) {\n  const domain = labels.map(label => {\n    if (label.startsWith(\"xn--\")) {\n      try {\n        return punycode.decode(label.substring(4));\n      } catch (err) {\n        return \"\";\n      }\n    }\n    return label;\n  }).join(\".\");\n  return regexes.bidiDomain.test(domain);\n}\n\nfunction processing(domainName, options) {\n  const { processingOption } = options;\n\n  // 1. Map.\n  let { string, error } = mapChars(domainName, options);\n\n  // 2. Normalize.\n  string = string.normalize(\"NFC\");\n\n  // 3. Break.\n  const labels = string.split(\".\");\n  const isBidi = isBidiDomain(labels);\n\n  // 4. Convert/Validate.\n  for (const [i, origLabel] of labels.entries()) {\n    let label = origLabel;\n    let curProcessing = processingOption;\n    if (label.startsWith(\"xn--\")) {\n      try {\n        label = punycode.decode(label.substring(4));\n        labels[i] = label;\n      } catch (err) {\n        error = true;\n        continue;\n      }\n      curProcessing = \"nontransitional\";\n    }\n\n    // No need to validate if we already know there is an error.\n    if (error) {\n      continue;\n    }\n    const validation = validateLabel(label, {\n      ...options,\n      processingOption: curProcessing,\n      checkBidi: options.checkBidi && isBidi\n    });\n    if (!validation) {\n      error = true;\n    }\n  }\n\n  return {\n    string: labels.join(\".\"),\n    error\n  };\n}\n\nfunction toASCII(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\",\n  verifyDNSLength = false\n} = {}) {\n  if (processingOption !== \"transitional\" && processingOption !== \"nontransitional\") {\n    throw new RangeError(\"processingOption must be either transitional or nontransitional\");\n  }\n\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n  let labels = result.string.split(\".\");\n  labels = labels.map(l => {\n    if (containsNonASCII(l)) {\n      try {\n        return `xn--${punycode.encode(l)}`;\n      } catch (e) {\n        result.error = true;\n      }\n    }\n    return l;\n  });\n\n  if (verifyDNSLength) {\n    const total = labels.join(\".\").length;\n    if (total > 253 || total === 0) {\n      result.error = true;\n    }\n\n    for (let i = 0; i < labels.length; ++i) {\n      if (labels[i].length > 63 || labels[i].length === 0) {\n        result.error = true;\n        break;\n      }\n    }\n  }\n\n  if (result.error) {\n    return null;\n  }\n  return labels.join(\".\");\n}\n\nfunction toUnicode(domainName, {\n  checkHyphens = false,\n  checkBidi = false,\n  checkJoiners = false,\n  useSTD3ASCIIRules = false,\n  processingOption = \"nontransitional\"\n} = {}) {\n  const result = processing(domainName, {\n    processingOption,\n    checkHyphens,\n    checkBidi,\n    checkJoiners,\n    useSTD3ASCIIRules\n  });\n\n  return {\n    domain: result.string,\n    error: result.error\n  };\n}\n\nmodule.exports = {\n  toASCII,\n  toUnicode\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/tr46/index.js?");

/***/ }),

/***/ "./node_modules/tr46/lib/regexes.js":
/*!******************************************!*\
  !*** ./node_modules/tr46/lib/regexes.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nconst combiningMarks = /[\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0903\\u093A-\\u093C\\u093E-\\u094F\\u0951-\\u0957\\u0962\\u0963\\u0981-\\u0983\\u09BC\\u09BE-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CD\\u09D7\\u09E2\\u09E3\\u09FE\\u0A01-\\u0A03\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81-\\u0A83\\u0ABC\\u0ABE-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01-\\u0B03\\u0B3C\\u0B3E-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B62\\u0B63\\u0B82\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD7\\u0C00-\\u0C04\\u0C3C\\u0C3E-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81-\\u0C83\\u0CBC\\u0CBE-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CE2\\u0CE3\\u0CF3\\u0D00-\\u0D03\\u0D3B\\u0D3C\\u0D3E-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4D\\u0D57\\u0D62\\u0D63\\u0D81-\\u0D83\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DF2\\u0DF3\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F3E\\u0F3F\\u0F71-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102B-\\u103E\\u1056-\\u1059\\u105E-\\u1060\\u1062-\\u1064\\u1067-\\u106D\\u1071-\\u1074\\u1082-\\u108D\\u108F\\u109A-\\u109D\\u135D-\\u135F\\u1712-\\u1715\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u192B\\u1930-\\u193B\\u1A17-\\u1A1B\\u1A55-\\u1A5E\\u1A60-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B04\\u1B34-\\u1B44\\u1B6B-\\u1B73\\u1B80-\\u1B82\\u1BA1-\\u1BAD\\u1BE6-\\u1BF3\\u1C24-\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE8\\u1CED\\u1CF4\\u1CF7-\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302F\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA823-\\uA827\\uA82C\\uA880\\uA881\\uA8B4-\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA953\\uA980-\\uA983\\uA9B3-\\uA9C0\\uA9E5\\uAA29-\\uAA36\\uAA43\\uAA4C\\uAA4D\\uAA7B-\\uAA7D\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEB-\\uAAEF\\uAAF5\\uAAF6\\uABE3-\\uABEA\\uABEC\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{11002}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11082}\\u{110B0}-\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{11134}\\u{11145}\\u{11146}\\u{11173}\\u{11180}-\\u{11182}\\u{111B3}-\\u{111C0}\\u{111C9}-\\u{111CC}\\u{111CE}\\u{111CF}\\u{1122C}-\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}-\\u{112EA}\\u{11300}-\\u{11303}\\u{1133B}\\u{1133C}\\u{1133E}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11357}\\u{11362}\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11435}-\\u{11446}\\u{1145E}\\u{114B0}-\\u{114C3}\\u{115AF}-\\u{115B5}\\u{115B8}-\\u{115C0}\\u{115DC}\\u{115DD}\\u{11630}-\\u{11640}\\u{116AB}-\\u{116B7}\\u{1171D}-\\u{1172B}\\u{1182C}-\\u{1183A}\\u{11930}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{1193E}\\u{11940}\\u{11942}\\u{11943}\\u{119D1}-\\u{119D7}\\u{119DA}-\\u{119E0}\\u{119E4}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A39}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A5B}\\u{11A8A}-\\u{11A99}\\u{11C2F}-\\u{11C36}\\u{11C38}-\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D8A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D97}\\u{11EF3}-\\u{11EF6}\\u{11F00}\\u{11F01}\\u{11F03}\\u{11F34}-\\u{11F3A}\\u{11F3E}-\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F51}-\\u{16F87}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D165}-\\u{1D169}\\u{1D16D}-\\u{1D172}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]/u;\nconst combiningClassVirama = /[\\u094D\\u09CD\\u0A4D\\u0ACD\\u0B4D\\u0BCD\\u0C4D\\u0CCD\\u0D3B\\u0D3C\\u0D4D\\u0DCA\\u0E3A\\u0EBA\\u0F84\\u1039\\u103A\\u1714\\u1734\\u17D2\\u1A60\\u1B44\\u1BAA\\u1BAB\\u1BF2\\u1BF3\\u2D7F\\uA806\\uA8C4\\uA953\\uA9C0\\uAAF6\\uABED\\u{10A3F}\\u{11046}\\u{1107F}\\u{110B9}\\u{11133}\\u{11134}\\u{111C0}\\u{11235}\\u{112EA}\\u{1134D}\\u{11442}\\u{114C2}\\u{115BF}\\u{1163F}\\u{116B6}\\u{1172B}\\u{11839}\\u{119E0}\\u{11A34}\\u{11A47}\\u{11A99}\\u{11C3F}\\u{11D44}\\u{11D45}\\u{11D97}]/u;\nconst validZWNJ = /[\\u0620\\u0626\\u0628\\u062A-\\u062E\\u0633-\\u063F\\u0641-\\u0647\\u0649\\u064A\\u066E\\u066F\\u0678-\\u0687\\u069A-\\u06BF\\u06C1\\u06C2\\u06CC\\u06CE\\u06D0\\u06D1\\u06FA-\\u06FC\\u06FF\\u0712-\\u0714\\u071A-\\u071D\\u071F-\\u0727\\u0729\\u072B\\u072D\\u072E\\u074E-\\u0758\\u075C-\\u076A\\u076D-\\u0770\\u0772\\u0775-\\u0777\\u077A-\\u077F\\u07CA-\\u07EA\\u0841-\\u0845\\u0848\\u084A-\\u0853\\u0855\\u0860\\u0862-\\u0865\\u0868\\u08A0-\\u08A9\\u08AF\\u08B0\\u08B3\\u08B4\\u08B6-\\u08B8\\u08BA-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA872\\u{10AC0}-\\u{10AC4}\\u{10ACD}\\u{10AD3}-\\u{10ADC}\\u{10ADE}-\\u{10AE0}\\u{10AEB}-\\u{10AEE}\\u{10B80}\\u{10B82}\\u{10B86}-\\u{10B88}\\u{10B8A}\\u{10B8B}\\u{10B8D}\\u{10B90}\\u{10BAD}\\u{10BAE}\\u{10D00}-\\u{10D21}\\u{10D23}\\u{10F30}-\\u{10F32}\\u{10F34}-\\u{10F44}\\u{10F51}-\\u{10F53}\\u{1E900}-\\u{1E943}][\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*\\u200C[\\xAD\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u061C\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u070F\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u08D3-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CBF\\u0CC6\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECD\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732-\\u1734\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ABE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DF9\\u1DFB-\\u1DFF\\u200B\\u200E\\u200F\\u202A-\\u202E\\u2060-\\u2064\\u206A-\\u206F\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\uFEFF\\uFFF9-\\uFFFB\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10F46}-\\u{10F50}\\u{11001}\\u{11038}-\\u{11046}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C3F}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{13430}-\\u{13438}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E130}-\\u{1E136}\\u{1E2EC}-\\u{1E2EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94B}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*[\\u0620\\u0622-\\u063F\\u0641-\\u064A\\u066E\\u066F\\u0671-\\u0673\\u0675-\\u06D3\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u0710\\u0712-\\u072F\\u074D-\\u077F\\u07CA-\\u07EA\\u0840-\\u0855\\u0860\\u0862-\\u0865\\u0867-\\u086A\\u08A0-\\u08AC\\u08AE-\\u08B4\\u08B6-\\u08BD\\u1807\\u1820-\\u1878\\u1887-\\u18A8\\u18AA\\uA840-\\uA871\\u{10AC0}-\\u{10AC5}\\u{10AC7}\\u{10AC9}\\u{10ACA}\\u{10ACE}-\\u{10AD6}\\u{10AD8}-\\u{10AE1}\\u{10AE4}\\u{10AEB}-\\u{10AEF}\\u{10B80}-\\u{10B91}\\u{10BA9}-\\u{10BAE}\\u{10D01}-\\u{10D23}\\u{10F30}-\\u{10F44}\\u{10F51}-\\u{10F54}\\u{1E900}-\\u{1E943}]/u;\nconst bidiDomain = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS1LTR = /[A-Za-z\\xAA\\xB5\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2071\\u207F\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u249C-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D800}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]/u;\nconst bidiS1RTL = /[\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0608\\u060B\\u060D\\u061B-\\u064A\\u066D-\\u066F\\u0671-\\u06D5\\u06E5\\u06E6\\u06EE\\u06EF\\u06FA-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u08A0-\\u08C9\\u200F\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}]/u;\nconst bidiS2 = /^[\\0-\\x08\\x0E-\\x1B!-@\\[-`\\{-\\x84\\x86-\\xA9\\xAB-\\xB4\\xB6-\\xB9\\xBB-\\xBF\\xD7\\xF7\\u02B9\\u02BA\\u02C2-\\u02CF\\u02D2-\\u02DF\\u02E5-\\u02ED\\u02EF-\\u036F\\u0374\\u0375\\u037E\\u0384\\u0385\\u0387\\u03F6\\u0483-\\u0489\\u058A\\u058D-\\u058F\\u0591-\\u05C7\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u070D\\u070F-\\u074A\\u074D-\\u07B1\\u07C0-\\u07FA\\u07FD-\\u082D\\u0830-\\u083E\\u0840-\\u085B\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u0898-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09F2\\u09F3\\u09FB\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AF1\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0BF3-\\u0BFA\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C78-\\u0C7E\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E3F\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39-\\u0F3D\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1390-\\u1399\\u1400\\u169B\\u169C\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DB\\u17DD\\u17F0-\\u17F9\\u1800-\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1940\\u1944\\u1945\\u19DE-\\u19FF\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u1FBD\\u1FBF-\\u1FC1\\u1FCD-\\u1FCF\\u1FDD-\\u1FDF\\u1FED-\\u1FEF\\u1FFD\\u1FFE\\u200B-\\u200D\\u200F-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2070\\u2074-\\u207E\\u2080-\\u208E\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100\\u2101\\u2103-\\u2106\\u2108\\u2109\\u2114\\u2116-\\u2118\\u211E-\\u2123\\u2125\\u2127\\u2129\\u212E\\u213A\\u213B\\u2140-\\u2144\\u214A-\\u214D\\u2150-\\u215F\\u2189-\\u218B\\u2190-\\u2335\\u237B-\\u2394\\u2396-\\u2426\\u2440-\\u244A\\u2460-\\u249B\\u24EA-\\u26AB\\u26AD-\\u27FF\\u2900-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2BFF\\u2CE5-\\u2CEA\\u2CEF-\\u2CF1\\u2CF9-\\u2CFF\\u2D7F\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u3004\\u3008-\\u3020\\u302A-\\u302D\\u3030\\u3036\\u3037\\u303D-\\u303F\\u3099-\\u309C\\u30A0\\u30FB\\u31C0-\\u31E3\\u321D\\u321E\\u3250-\\u325F\\u327C-\\u327E\\u32B1-\\u32BF\\u32CC-\\u32CF\\u3377-\\u337A\\u33DE\\u33DF\\u33FF\\u4DC0-\\u4DFF\\uA490-\\uA4C6\\uA60D-\\uA60F\\uA66F-\\uA67F\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA700-\\uA721\\uA788\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA828-\\uA82C\\uA838\\uA839\\uA874-\\uA877\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uAB6A\\uAB6B\\uABE5\\uABE8\\uABED\\uFB1D-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD8F\\uFD92-\\uFDC7\\uFDCF\\uFDF0-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFEFF\\uFF01-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10101}\\u{10140}-\\u{1018C}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101FD}\\u{102E0}-\\u{102FB}\\u{10376}-\\u{1037A}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{1091F}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A38}-\\u{10A3A}\\u{10A3F}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE6}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B39}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D27}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAB}-\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10EFD}-\\u{10F27}\\u{10F30}-\\u{10F59}\\u{10F70}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{11001}\\u{11038}-\\u{11046}\\u{11052}-\\u{11065}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{11660}-\\u{1166C}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{11FD5}-\\u{11FF1}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE2}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1BCA0}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D173}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D1E9}\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D300}-\\u{1D356}\\u{1D6DB}\\u{1D715}\\u{1D74F}\\u{1D789}\\u{1D7C3}\\u{1D7CE}-\\u{1D7FF}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E2FF}\\u{1E4EC}-\\u{1E4EF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8D6}\\u{1E900}-\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F10F}\\u{1F12F}\\u{1F16A}-\\u{1F16F}\\u{1F1AD}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS3 = /[0-9\\xB2\\xB3\\xB9\\u05BE\\u05C0\\u05C3\\u05C6\\u05D0-\\u05EA\\u05EF-\\u05F4\\u0600-\\u0605\\u0608\\u060B\\u060D\\u061B-\\u064A\\u0660-\\u0669\\u066B-\\u066F\\u0671-\\u06D5\\u06DD\\u06E5\\u06E6\\u06EE-\\u070D\\u070F\\u0710\\u0712-\\u072F\\u074D-\\u07A5\\u07B1\\u07C0-\\u07EA\\u07F4\\u07F5\\u07FA\\u07FE-\\u0815\\u081A\\u0824\\u0828\\u0830-\\u083E\\u0840-\\u0858\\u085E\\u0860-\\u086A\\u0870-\\u088E\\u0890\\u0891\\u08A0-\\u08C9\\u08E2\\u200F\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFB1D\\uFB1F-\\uFB28\\uFB2A-\\uFB36\\uFB38-\\uFB3C\\uFB3E\\uFB40\\uFB41\\uFB43\\uFB44\\uFB46-\\uFBC2\\uFBD3-\\uFD3D\\uFD50-\\uFD8F\\uFD92-\\uFDC7\\uFDF0-\\uFDFC\\uFE70-\\uFE74\\uFE76-\\uFEFC\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{10800}-\\u{10805}\\u{10808}\\u{1080A}-\\u{10835}\\u{10837}\\u{10838}\\u{1083C}\\u{1083F}-\\u{10855}\\u{10857}-\\u{1089E}\\u{108A7}-\\u{108AF}\\u{108E0}-\\u{108F2}\\u{108F4}\\u{108F5}\\u{108FB}-\\u{1091B}\\u{10920}-\\u{10939}\\u{1093F}\\u{10980}-\\u{109B7}\\u{109BC}-\\u{109CF}\\u{109D2}-\\u{10A00}\\u{10A10}-\\u{10A13}\\u{10A15}-\\u{10A17}\\u{10A19}-\\u{10A35}\\u{10A40}-\\u{10A48}\\u{10A50}-\\u{10A58}\\u{10A60}-\\u{10A9F}\\u{10AC0}-\\u{10AE4}\\u{10AEB}-\\u{10AF6}\\u{10B00}-\\u{10B35}\\u{10B40}-\\u{10B55}\\u{10B58}-\\u{10B72}\\u{10B78}-\\u{10B91}\\u{10B99}-\\u{10B9C}\\u{10BA9}-\\u{10BAF}\\u{10C00}-\\u{10C48}\\u{10C80}-\\u{10CB2}\\u{10CC0}-\\u{10CF2}\\u{10CFA}-\\u{10D23}\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}\\u{10E80}-\\u{10EA9}\\u{10EAD}\\u{10EB0}\\u{10EB1}\\u{10F00}-\\u{10F27}\\u{10F30}-\\u{10F45}\\u{10F51}-\\u{10F59}\\u{10F70}-\\u{10F81}\\u{10F86}-\\u{10F89}\\u{10FB0}-\\u{10FCB}\\u{10FE0}-\\u{10FF6}\\u{1D7CE}-\\u{1D7FF}\\u{1E800}-\\u{1E8C4}\\u{1E8C7}-\\u{1E8CF}\\u{1E900}-\\u{1E943}\\u{1E94B}\\u{1E950}-\\u{1E959}\\u{1E95E}\\u{1E95F}\\u{1EC71}-\\u{1ECB4}\\u{1ED01}-\\u{1ED3D}\\u{1EE00}-\\u{1EE03}\\u{1EE05}-\\u{1EE1F}\\u{1EE21}\\u{1EE22}\\u{1EE24}\\u{1EE27}\\u{1EE29}-\\u{1EE32}\\u{1EE34}-\\u{1EE37}\\u{1EE39}\\u{1EE3B}\\u{1EE42}\\u{1EE47}\\u{1EE49}\\u{1EE4B}\\u{1EE4D}-\\u{1EE4F}\\u{1EE51}\\u{1EE52}\\u{1EE54}\\u{1EE57}\\u{1EE59}\\u{1EE5B}\\u{1EE5D}\\u{1EE5F}\\u{1EE61}\\u{1EE62}\\u{1EE64}\\u{1EE67}-\\u{1EE6A}\\u{1EE6C}-\\u{1EE72}\\u{1EE74}-\\u{1EE77}\\u{1EE79}-\\u{1EE7C}\\u{1EE7E}\\u{1EE80}-\\u{1EE89}\\u{1EE8B}-\\u{1EE9B}\\u{1EEA1}-\\u{1EEA3}\\u{1EEA5}-\\u{1EEA9}\\u{1EEAB}-\\u{1EEBB}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\nconst bidiS4EN = /[0-9\\xB2\\xB3\\xB9\\u06F0-\\u06F9\\u2070\\u2074-\\u2079\\u2080-\\u2089\\u2488-\\u249B\\uFF10-\\uFF19\\u{102E1}-\\u{102FB}\\u{1D7CE}-\\u{1D7FF}\\u{1F100}-\\u{1F10A}\\u{1FBF0}-\\u{1FBF9}]/u;\nconst bidiS4AN = /[\\u0600-\\u0605\\u0660-\\u0669\\u066B\\u066C\\u06DD\\u0890\\u0891\\u08E2\\u{10D30}-\\u{10D39}\\u{10E60}-\\u{10E7E}]/u;\nconst bidiS5 = /^[\\0-\\x08\\x0E-\\x1B!-\\x84\\x86-\\u0377\\u037A-\\u037F\\u0384-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u052F\\u0531-\\u0556\\u0559-\\u058A\\u058D-\\u058F\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0606\\u0607\\u0609\\u060A\\u060C\\u060E-\\u061A\\u064B-\\u065F\\u066A\\u0670\\u06D6-\\u06DC\\u06DE-\\u06E4\\u06E7-\\u06ED\\u06F0-\\u06F9\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07F6-\\u07F9\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BC-\\u09C4\\u09C7\\u09C8\\u09CB-\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E3\\u09E6-\\u09FE\\u0A01-\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3C\\u0A3E-\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A76\\u0A81-\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABC-\\u0AC5\\u0AC7-\\u0AC9\\u0ACB-\\u0ACD\\u0AD0\\u0AE0-\\u0AE3\\u0AE6-\\u0AF1\\u0AF9-\\u0AFF\\u0B01-\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3C-\\u0B44\\u0B47\\u0B48\\u0B4B-\\u0B4D\\u0B55-\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B63\\u0B66-\\u0B77\\u0B82\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE-\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCD\\u0BD0\\u0BD7\\u0BE6-\\u0BFA\\u0C00-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3C-\\u0C44\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C58-\\u0C5A\\u0C5D\\u0C60-\\u0C63\\u0C66-\\u0C6F\\u0C77-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBC-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA-\\u0CCD\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0-\\u0CE3\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D00-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D44\\u0D46-\\u0D48\\u0D4A-\\u0D4F\\u0D54-\\u0D63\\u0D66-\\u0D7F\\u0D81-\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCA\\u0DCF-\\u0DD4\\u0DD6\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E3A\\u0E3F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0EC8-\\u0ECE\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F47\\u0F49-\\u0F6C\\u0F71-\\u0F97\\u0F99-\\u0FBC\\u0FBE-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u135D-\\u137C\\u1380-\\u1399\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1400-\\u167F\\u1681-\\u169C\\u16A0-\\u16F8\\u1700-\\u1715\\u171F-\\u1736\\u1740-\\u1753\\u1760-\\u176C\\u176E-\\u1770\\u1772\\u1773\\u1780-\\u17DD\\u17E0-\\u17E9\\u17F0-\\u17F9\\u1800-\\u1819\\u1820-\\u1878\\u1880-\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1920-\\u192B\\u1930-\\u193B\\u1940\\u1944-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u19DE-\\u1A1B\\u1A1E-\\u1A5E\\u1A60-\\u1A7C\\u1A7F-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1AB0-\\u1ACE\\u1B00-\\u1B4C\\u1B50-\\u1B7E\\u1B80-\\u1BF3\\u1BFC-\\u1C37\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD0-\\u1CFA\\u1D00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FC4\\u1FC6-\\u1FD3\\u1FD6-\\u1FDB\\u1FDD-\\u1FEF\\u1FF2-\\u1FF4\\u1FF6-\\u1FFE\\u200B-\\u200E\\u2010-\\u2027\\u202F-\\u205E\\u2060-\\u2064\\u206A-\\u2071\\u2074-\\u208E\\u2090-\\u209C\\u20A0-\\u20C0\\u20D0-\\u20F0\\u2100-\\u218B\\u2190-\\u2426\\u2440-\\u244A\\u2460-\\u2B73\\u2B76-\\u2B95\\u2B97-\\u2CF3\\u2CF9-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D7F-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u2DE0-\\u2E5D\\u2E80-\\u2E99\\u2E9B-\\u2EF3\\u2F00-\\u2FD5\\u2FF0-\\u2FFB\\u3001-\\u303F\\u3041-\\u3096\\u3099-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31E3\\u31F0-\\u321E\\u3220-\\uA48C\\uA490-\\uA4C6\\uA4D0-\\uA62B\\uA640-\\uA6F7\\uA700-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA82C\\uA830-\\uA839\\uA840-\\uA877\\uA880-\\uA8C5\\uA8CE-\\uA8D9\\uA8E0-\\uA953\\uA95F-\\uA97C\\uA980-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9FE\\uAA00-\\uAA36\\uAA40-\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAAC2\\uAADB-\\uAAF6\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB6B\\uAB70-\\uABED\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFB1E\\uFB29\\uFD3E-\\uFD4F\\uFDCF\\uFDFD-\\uFE19\\uFE20-\\uFE52\\uFE54-\\uFE66\\uFE68-\\uFE6B\\uFEFF\\uFF01-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\uFFE0-\\uFFE6\\uFFE8-\\uFFEE\\uFFF9-\\uFFFD\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}-\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1018E}\\u{10190}-\\u{1019C}\\u{101A0}\\u{101D0}-\\u{101FD}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E0}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{1037A}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{1091F}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10B39}-\\u{10B3F}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11000}-\\u{1104D}\\u{11052}-\\u{11075}\\u{1107F}-\\u{110C2}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11100}-\\u{11134}\\u{11136}-\\u{11147}\\u{11150}-\\u{11176}\\u{11180}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{11241}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112EA}\\u{112F0}-\\u{112F9}\\u{11300}-\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133B}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11400}-\\u{1145B}\\u{1145D}-\\u{11461}\\u{11480}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B5}\\u{115B8}-\\u{115DD}\\u{11600}-\\u{11644}\\u{11650}-\\u{11659}\\u{11660}-\\u{1166C}\\u{11680}-\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{1171D}-\\u{1172B}\\u{11730}-\\u{11746}\\u{11800}-\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193B}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D7}\\u{119DA}-\\u{119E4}\\u{11A00}-\\u{11A47}\\u{11A50}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C36}\\u{11C38}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11C92}-\\u{11CA7}\\u{11CA9}-\\u{11CB6}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D47}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D90}\\u{11D91}\\u{11D93}-\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF8}\\u{11F00}-\\u{11F10}\\u{11F12}-\\u{11F3A}\\u{11F3E}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FF1}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{13455}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF0}-\\u{16AF5}\\u{16B00}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F4F}-\\u{16F87}\\u{16F8F}-\\u{16F9F}\\u{16FE0}-\\u{16FE4}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}-\\u{1BCA3}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D1EA}\\u{1D200}-\\u{1D245}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D300}-\\u{1D356}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D7CB}\\u{1D7CE}-\\u{1DA8B}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E030}-\\u{1E06D}\\u{1E08F}\\u{1E100}-\\u{1E12C}\\u{1E130}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AE}\\u{1E2C0}-\\u{1E2F9}\\u{1E2FF}\\u{1E4D0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{1EEF0}\\u{1EEF1}\\u{1F000}-\\u{1F02B}\\u{1F030}-\\u{1F093}\\u{1F0A0}-\\u{1F0AE}\\u{1F0B1}-\\u{1F0BF}\\u{1F0C1}-\\u{1F0CF}\\u{1F0D1}-\\u{1F0F5}\\u{1F100}-\\u{1F1AD}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1F260}-\\u{1F265}\\u{1F300}-\\u{1F6D7}\\u{1F6DC}-\\u{1F6EC}\\u{1F6F0}-\\u{1F6FC}\\u{1F700}-\\u{1F776}\\u{1F77B}-\\u{1F7D9}\\u{1F7E0}-\\u{1F7EB}\\u{1F7F0}\\u{1F800}-\\u{1F80B}\\u{1F810}-\\u{1F847}\\u{1F850}-\\u{1F859}\\u{1F860}-\\u{1F887}\\u{1F890}-\\u{1F8AD}\\u{1F8B0}\\u{1F8B1}\\u{1F900}-\\u{1FA53}\\u{1FA60}-\\u{1FA6D}\\u{1FA70}-\\u{1FA7C}\\u{1FA80}-\\u{1FA88}\\u{1FA90}-\\u{1FABD}\\u{1FABF}-\\u{1FAC5}\\u{1FACE}-\\u{1FADB}\\u{1FAE0}-\\u{1FAE8}\\u{1FAF0}-\\u{1FAF8}\\u{1FB00}-\\u{1FB92}\\u{1FB94}-\\u{1FBCA}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{E0001}\\u{E0020}-\\u{E007F}\\u{E0100}-\\u{E01EF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}]*$/u;\nconst bidiS6 = /[0-9A-Za-z\\xAA\\xB2\\xB3\\xB5\\xB9\\xBA\\xC0-\\xD6\\xD8-\\xF6\\xF8-\\u02B8\\u02BB-\\u02C1\\u02D0\\u02D1\\u02E0-\\u02E4\\u02EE\\u0370-\\u0373\\u0376\\u0377\\u037A-\\u037D\\u037F\\u0386\\u0388-\\u038A\\u038C\\u038E-\\u03A1\\u03A3-\\u03F5\\u03F7-\\u0482\\u048A-\\u052F\\u0531-\\u0556\\u0559-\\u0589\\u06F0-\\u06F9\\u0903-\\u0939\\u093B\\u093D-\\u0940\\u0949-\\u094C\\u094E-\\u0950\\u0958-\\u0961\\u0964-\\u0980\\u0982\\u0983\\u0985-\\u098C\\u098F\\u0990\\u0993-\\u09A8\\u09AA-\\u09B0\\u09B2\\u09B6-\\u09B9\\u09BD-\\u09C0\\u09C7\\u09C8\\u09CB\\u09CC\\u09CE\\u09D7\\u09DC\\u09DD\\u09DF-\\u09E1\\u09E6-\\u09F1\\u09F4-\\u09FA\\u09FC\\u09FD\\u0A03\\u0A05-\\u0A0A\\u0A0F\\u0A10\\u0A13-\\u0A28\\u0A2A-\\u0A30\\u0A32\\u0A33\\u0A35\\u0A36\\u0A38\\u0A39\\u0A3E-\\u0A40\\u0A59-\\u0A5C\\u0A5E\\u0A66-\\u0A6F\\u0A72-\\u0A74\\u0A76\\u0A83\\u0A85-\\u0A8D\\u0A8F-\\u0A91\\u0A93-\\u0AA8\\u0AAA-\\u0AB0\\u0AB2\\u0AB3\\u0AB5-\\u0AB9\\u0ABD-\\u0AC0\\u0AC9\\u0ACB\\u0ACC\\u0AD0\\u0AE0\\u0AE1\\u0AE6-\\u0AF0\\u0AF9\\u0B02\\u0B03\\u0B05-\\u0B0C\\u0B0F\\u0B10\\u0B13-\\u0B28\\u0B2A-\\u0B30\\u0B32\\u0B33\\u0B35-\\u0B39\\u0B3D\\u0B3E\\u0B40\\u0B47\\u0B48\\u0B4B\\u0B4C\\u0B57\\u0B5C\\u0B5D\\u0B5F-\\u0B61\\u0B66-\\u0B77\\u0B83\\u0B85-\\u0B8A\\u0B8E-\\u0B90\\u0B92-\\u0B95\\u0B99\\u0B9A\\u0B9C\\u0B9E\\u0B9F\\u0BA3\\u0BA4\\u0BA8-\\u0BAA\\u0BAE-\\u0BB9\\u0BBE\\u0BBF\\u0BC1\\u0BC2\\u0BC6-\\u0BC8\\u0BCA-\\u0BCC\\u0BD0\\u0BD7\\u0BE6-\\u0BF2\\u0C01-\\u0C03\\u0C05-\\u0C0C\\u0C0E-\\u0C10\\u0C12-\\u0C28\\u0C2A-\\u0C39\\u0C3D\\u0C41-\\u0C44\\u0C58-\\u0C5A\\u0C5D\\u0C60\\u0C61\\u0C66-\\u0C6F\\u0C77\\u0C7F\\u0C80\\u0C82-\\u0C8C\\u0C8E-\\u0C90\\u0C92-\\u0CA8\\u0CAA-\\u0CB3\\u0CB5-\\u0CB9\\u0CBD-\\u0CC4\\u0CC6-\\u0CC8\\u0CCA\\u0CCB\\u0CD5\\u0CD6\\u0CDD\\u0CDE\\u0CE0\\u0CE1\\u0CE6-\\u0CEF\\u0CF1-\\u0CF3\\u0D02-\\u0D0C\\u0D0E-\\u0D10\\u0D12-\\u0D3A\\u0D3D-\\u0D40\\u0D46-\\u0D48\\u0D4A-\\u0D4C\\u0D4E\\u0D4F\\u0D54-\\u0D61\\u0D66-\\u0D7F\\u0D82\\u0D83\\u0D85-\\u0D96\\u0D9A-\\u0DB1\\u0DB3-\\u0DBB\\u0DBD\\u0DC0-\\u0DC6\\u0DCF-\\u0DD1\\u0DD8-\\u0DDF\\u0DE6-\\u0DEF\\u0DF2-\\u0DF4\\u0E01-\\u0E30\\u0E32\\u0E33\\u0E40-\\u0E46\\u0E4F-\\u0E5B\\u0E81\\u0E82\\u0E84\\u0E86-\\u0E8A\\u0E8C-\\u0EA3\\u0EA5\\u0EA7-\\u0EB0\\u0EB2\\u0EB3\\u0EBD\\u0EC0-\\u0EC4\\u0EC6\\u0ED0-\\u0ED9\\u0EDC-\\u0EDF\\u0F00-\\u0F17\\u0F1A-\\u0F34\\u0F36\\u0F38\\u0F3E-\\u0F47\\u0F49-\\u0F6C\\u0F7F\\u0F85\\u0F88-\\u0F8C\\u0FBE-\\u0FC5\\u0FC7-\\u0FCC\\u0FCE-\\u0FDA\\u1000-\\u102C\\u1031\\u1038\\u103B\\u103C\\u103F-\\u1057\\u105A-\\u105D\\u1061-\\u1070\\u1075-\\u1081\\u1083\\u1084\\u1087-\\u108C\\u108E-\\u109C\\u109E-\\u10C5\\u10C7\\u10CD\\u10D0-\\u1248\\u124A-\\u124D\\u1250-\\u1256\\u1258\\u125A-\\u125D\\u1260-\\u1288\\u128A-\\u128D\\u1290-\\u12B0\\u12B2-\\u12B5\\u12B8-\\u12BE\\u12C0\\u12C2-\\u12C5\\u12C8-\\u12D6\\u12D8-\\u1310\\u1312-\\u1315\\u1318-\\u135A\\u1360-\\u137C\\u1380-\\u138F\\u13A0-\\u13F5\\u13F8-\\u13FD\\u1401-\\u167F\\u1681-\\u169A\\u16A0-\\u16F8\\u1700-\\u1711\\u1715\\u171F-\\u1731\\u1734-\\u1736\\u1740-\\u1751\\u1760-\\u176C\\u176E-\\u1770\\u1780-\\u17B3\\u17B6\\u17BE-\\u17C5\\u17C7\\u17C8\\u17D4-\\u17DA\\u17DC\\u17E0-\\u17E9\\u1810-\\u1819\\u1820-\\u1878\\u1880-\\u1884\\u1887-\\u18A8\\u18AA\\u18B0-\\u18F5\\u1900-\\u191E\\u1923-\\u1926\\u1929-\\u192B\\u1930\\u1931\\u1933-\\u1938\\u1946-\\u196D\\u1970-\\u1974\\u1980-\\u19AB\\u19B0-\\u19C9\\u19D0-\\u19DA\\u1A00-\\u1A16\\u1A19\\u1A1A\\u1A1E-\\u1A55\\u1A57\\u1A61\\u1A63\\u1A64\\u1A6D-\\u1A72\\u1A80-\\u1A89\\u1A90-\\u1A99\\u1AA0-\\u1AAD\\u1B04-\\u1B33\\u1B35\\u1B3B\\u1B3D-\\u1B41\\u1B43-\\u1B4C\\u1B50-\\u1B6A\\u1B74-\\u1B7E\\u1B82-\\u1BA1\\u1BA6\\u1BA7\\u1BAA\\u1BAE-\\u1BE5\\u1BE7\\u1BEA-\\u1BEC\\u1BEE\\u1BF2\\u1BF3\\u1BFC-\\u1C2B\\u1C34\\u1C35\\u1C3B-\\u1C49\\u1C4D-\\u1C88\\u1C90-\\u1CBA\\u1CBD-\\u1CC7\\u1CD3\\u1CE1\\u1CE9-\\u1CEC\\u1CEE-\\u1CF3\\u1CF5-\\u1CF7\\u1CFA\\u1D00-\\u1DBF\\u1E00-\\u1F15\\u1F18-\\u1F1D\\u1F20-\\u1F45\\u1F48-\\u1F4D\\u1F50-\\u1F57\\u1F59\\u1F5B\\u1F5D\\u1F5F-\\u1F7D\\u1F80-\\u1FB4\\u1FB6-\\u1FBC\\u1FBE\\u1FC2-\\u1FC4\\u1FC6-\\u1FCC\\u1FD0-\\u1FD3\\u1FD6-\\u1FDB\\u1FE0-\\u1FEC\\u1FF2-\\u1FF4\\u1FF6-\\u1FFC\\u200E\\u2070\\u2071\\u2074-\\u2079\\u207F-\\u2089\\u2090-\\u209C\\u2102\\u2107\\u210A-\\u2113\\u2115\\u2119-\\u211D\\u2124\\u2126\\u2128\\u212A-\\u212D\\u212F-\\u2139\\u213C-\\u213F\\u2145-\\u2149\\u214E\\u214F\\u2160-\\u2188\\u2336-\\u237A\\u2395\\u2488-\\u24E9\\u26AC\\u2800-\\u28FF\\u2C00-\\u2CE4\\u2CEB-\\u2CEE\\u2CF2\\u2CF3\\u2D00-\\u2D25\\u2D27\\u2D2D\\u2D30-\\u2D67\\u2D6F\\u2D70\\u2D80-\\u2D96\\u2DA0-\\u2DA6\\u2DA8-\\u2DAE\\u2DB0-\\u2DB6\\u2DB8-\\u2DBE\\u2DC0-\\u2DC6\\u2DC8-\\u2DCE\\u2DD0-\\u2DD6\\u2DD8-\\u2DDE\\u3005-\\u3007\\u3021-\\u3029\\u302E\\u302F\\u3031-\\u3035\\u3038-\\u303C\\u3041-\\u3096\\u309D-\\u309F\\u30A1-\\u30FA\\u30FC-\\u30FF\\u3105-\\u312F\\u3131-\\u318E\\u3190-\\u31BF\\u31F0-\\u321C\\u3220-\\u324F\\u3260-\\u327B\\u327F-\\u32B0\\u32C0-\\u32CB\\u32D0-\\u3376\\u337B-\\u33DD\\u33E0-\\u33FE\\u3400-\\u4DBF\\u4E00-\\uA48C\\uA4D0-\\uA60C\\uA610-\\uA62B\\uA640-\\uA66E\\uA680-\\uA69D\\uA6A0-\\uA6EF\\uA6F2-\\uA6F7\\uA722-\\uA787\\uA789-\\uA7CA\\uA7D0\\uA7D1\\uA7D3\\uA7D5-\\uA7D9\\uA7F2-\\uA801\\uA803-\\uA805\\uA807-\\uA80A\\uA80C-\\uA824\\uA827\\uA830-\\uA837\\uA840-\\uA873\\uA880-\\uA8C3\\uA8CE-\\uA8D9\\uA8F2-\\uA8FE\\uA900-\\uA925\\uA92E-\\uA946\\uA952\\uA953\\uA95F-\\uA97C\\uA983-\\uA9B2\\uA9B4\\uA9B5\\uA9BA\\uA9BB\\uA9BE-\\uA9CD\\uA9CF-\\uA9D9\\uA9DE-\\uA9E4\\uA9E6-\\uA9FE\\uAA00-\\uAA28\\uAA2F\\uAA30\\uAA33\\uAA34\\uAA40-\\uAA42\\uAA44-\\uAA4B\\uAA4D\\uAA50-\\uAA59\\uAA5C-\\uAA7B\\uAA7D-\\uAAAF\\uAAB1\\uAAB5\\uAAB6\\uAAB9-\\uAABD\\uAAC0\\uAAC2\\uAADB-\\uAAEB\\uAAEE-\\uAAF5\\uAB01-\\uAB06\\uAB09-\\uAB0E\\uAB11-\\uAB16\\uAB20-\\uAB26\\uAB28-\\uAB2E\\uAB30-\\uAB69\\uAB70-\\uABE4\\uABE6\\uABE7\\uABE9-\\uABEC\\uABF0-\\uABF9\\uAC00-\\uD7A3\\uD7B0-\\uD7C6\\uD7CB-\\uD7FB\\uD800-\\uFA6D\\uFA70-\\uFAD9\\uFB00-\\uFB06\\uFB13-\\uFB17\\uFF10-\\uFF19\\uFF21-\\uFF3A\\uFF41-\\uFF5A\\uFF66-\\uFFBE\\uFFC2-\\uFFC7\\uFFCA-\\uFFCF\\uFFD2-\\uFFD7\\uFFDA-\\uFFDC\\u{10000}-\\u{1000B}\\u{1000D}-\\u{10026}\\u{10028}-\\u{1003A}\\u{1003C}\\u{1003D}\\u{1003F}-\\u{1004D}\\u{10050}-\\u{1005D}\\u{10080}-\\u{100FA}\\u{10100}\\u{10102}\\u{10107}-\\u{10133}\\u{10137}-\\u{1013F}\\u{1018D}\\u{1018E}\\u{101D0}-\\u{101FC}\\u{10280}-\\u{1029C}\\u{102A0}-\\u{102D0}\\u{102E1}-\\u{102FB}\\u{10300}-\\u{10323}\\u{1032D}-\\u{1034A}\\u{10350}-\\u{10375}\\u{10380}-\\u{1039D}\\u{1039F}-\\u{103C3}\\u{103C8}-\\u{103D5}\\u{10400}-\\u{1049D}\\u{104A0}-\\u{104A9}\\u{104B0}-\\u{104D3}\\u{104D8}-\\u{104FB}\\u{10500}-\\u{10527}\\u{10530}-\\u{10563}\\u{1056F}-\\u{1057A}\\u{1057C}-\\u{1058A}\\u{1058C}-\\u{10592}\\u{10594}\\u{10595}\\u{10597}-\\u{105A1}\\u{105A3}-\\u{105B1}\\u{105B3}-\\u{105B9}\\u{105BB}\\u{105BC}\\u{10600}-\\u{10736}\\u{10740}-\\u{10755}\\u{10760}-\\u{10767}\\u{10780}-\\u{10785}\\u{10787}-\\u{107B0}\\u{107B2}-\\u{107BA}\\u{11000}\\u{11002}-\\u{11037}\\u{11047}-\\u{1104D}\\u{11066}-\\u{1106F}\\u{11071}\\u{11072}\\u{11075}\\u{11082}-\\u{110B2}\\u{110B7}\\u{110B8}\\u{110BB}-\\u{110C1}\\u{110CD}\\u{110D0}-\\u{110E8}\\u{110F0}-\\u{110F9}\\u{11103}-\\u{11126}\\u{1112C}\\u{11136}-\\u{11147}\\u{11150}-\\u{11172}\\u{11174}-\\u{11176}\\u{11182}-\\u{111B5}\\u{111BF}-\\u{111C8}\\u{111CD}\\u{111CE}\\u{111D0}-\\u{111DF}\\u{111E1}-\\u{111F4}\\u{11200}-\\u{11211}\\u{11213}-\\u{1122E}\\u{11232}\\u{11233}\\u{11235}\\u{11238}-\\u{1123D}\\u{1123F}\\u{11240}\\u{11280}-\\u{11286}\\u{11288}\\u{1128A}-\\u{1128D}\\u{1128F}-\\u{1129D}\\u{1129F}-\\u{112A9}\\u{112B0}-\\u{112DE}\\u{112E0}-\\u{112E2}\\u{112F0}-\\u{112F9}\\u{11302}\\u{11303}\\u{11305}-\\u{1130C}\\u{1130F}\\u{11310}\\u{11313}-\\u{11328}\\u{1132A}-\\u{11330}\\u{11332}\\u{11333}\\u{11335}-\\u{11339}\\u{1133D}-\\u{1133F}\\u{11341}-\\u{11344}\\u{11347}\\u{11348}\\u{1134B}-\\u{1134D}\\u{11350}\\u{11357}\\u{1135D}-\\u{11363}\\u{11400}-\\u{11437}\\u{11440}\\u{11441}\\u{11445}\\u{11447}-\\u{1145B}\\u{1145D}\\u{1145F}-\\u{11461}\\u{11480}-\\u{114B2}\\u{114B9}\\u{114BB}-\\u{114BE}\\u{114C1}\\u{114C4}-\\u{114C7}\\u{114D0}-\\u{114D9}\\u{11580}-\\u{115B1}\\u{115B8}-\\u{115BB}\\u{115BE}\\u{115C1}-\\u{115DB}\\u{11600}-\\u{11632}\\u{1163B}\\u{1163C}\\u{1163E}\\u{11641}-\\u{11644}\\u{11650}-\\u{11659}\\u{11680}-\\u{116AA}\\u{116AC}\\u{116AE}\\u{116AF}\\u{116B6}\\u{116B8}\\u{116B9}\\u{116C0}-\\u{116C9}\\u{11700}-\\u{1171A}\\u{11720}\\u{11721}\\u{11726}\\u{11730}-\\u{11746}\\u{11800}-\\u{1182E}\\u{11838}\\u{1183B}\\u{118A0}-\\u{118F2}\\u{118FF}-\\u{11906}\\u{11909}\\u{1190C}-\\u{11913}\\u{11915}\\u{11916}\\u{11918}-\\u{11935}\\u{11937}\\u{11938}\\u{1193D}\\u{1193F}-\\u{11942}\\u{11944}-\\u{11946}\\u{11950}-\\u{11959}\\u{119A0}-\\u{119A7}\\u{119AA}-\\u{119D3}\\u{119DC}-\\u{119DF}\\u{119E1}-\\u{119E4}\\u{11A00}\\u{11A07}\\u{11A08}\\u{11A0B}-\\u{11A32}\\u{11A39}\\u{11A3A}\\u{11A3F}-\\u{11A46}\\u{11A50}\\u{11A57}\\u{11A58}\\u{11A5C}-\\u{11A89}\\u{11A97}\\u{11A9A}-\\u{11AA2}\\u{11AB0}-\\u{11AF8}\\u{11B00}-\\u{11B09}\\u{11C00}-\\u{11C08}\\u{11C0A}-\\u{11C2F}\\u{11C3E}-\\u{11C45}\\u{11C50}-\\u{11C6C}\\u{11C70}-\\u{11C8F}\\u{11CA9}\\u{11CB1}\\u{11CB4}\\u{11D00}-\\u{11D06}\\u{11D08}\\u{11D09}\\u{11D0B}-\\u{11D30}\\u{11D46}\\u{11D50}-\\u{11D59}\\u{11D60}-\\u{11D65}\\u{11D67}\\u{11D68}\\u{11D6A}-\\u{11D8E}\\u{11D93}\\u{11D94}\\u{11D96}\\u{11D98}\\u{11DA0}-\\u{11DA9}\\u{11EE0}-\\u{11EF2}\\u{11EF5}-\\u{11EF8}\\u{11F02}-\\u{11F10}\\u{11F12}-\\u{11F35}\\u{11F3E}\\u{11F3F}\\u{11F41}\\u{11F43}-\\u{11F59}\\u{11FB0}\\u{11FC0}-\\u{11FD4}\\u{11FFF}-\\u{12399}\\u{12400}-\\u{1246E}\\u{12470}-\\u{12474}\\u{12480}-\\u{12543}\\u{12F90}-\\u{12FF2}\\u{13000}-\\u{1343F}\\u{13441}-\\u{13446}\\u{14400}-\\u{14646}\\u{16800}-\\u{16A38}\\u{16A40}-\\u{16A5E}\\u{16A60}-\\u{16A69}\\u{16A6E}-\\u{16ABE}\\u{16AC0}-\\u{16AC9}\\u{16AD0}-\\u{16AED}\\u{16AF5}\\u{16B00}-\\u{16B2F}\\u{16B37}-\\u{16B45}\\u{16B50}-\\u{16B59}\\u{16B5B}-\\u{16B61}\\u{16B63}-\\u{16B77}\\u{16B7D}-\\u{16B8F}\\u{16E40}-\\u{16E9A}\\u{16F00}-\\u{16F4A}\\u{16F50}-\\u{16F87}\\u{16F93}-\\u{16F9F}\\u{16FE0}\\u{16FE1}\\u{16FE3}\\u{16FF0}\\u{16FF1}\\u{17000}-\\u{187F7}\\u{18800}-\\u{18CD5}\\u{18D00}-\\u{18D08}\\u{1AFF0}-\\u{1AFF3}\\u{1AFF5}-\\u{1AFFB}\\u{1AFFD}\\u{1AFFE}\\u{1B000}-\\u{1B122}\\u{1B132}\\u{1B150}-\\u{1B152}\\u{1B155}\\u{1B164}-\\u{1B167}\\u{1B170}-\\u{1B2FB}\\u{1BC00}-\\u{1BC6A}\\u{1BC70}-\\u{1BC7C}\\u{1BC80}-\\u{1BC88}\\u{1BC90}-\\u{1BC99}\\u{1BC9C}\\u{1BC9F}\\u{1CF50}-\\u{1CFC3}\\u{1D000}-\\u{1D0F5}\\u{1D100}-\\u{1D126}\\u{1D129}-\\u{1D166}\\u{1D16A}-\\u{1D172}\\u{1D183}\\u{1D184}\\u{1D18C}-\\u{1D1A9}\\u{1D1AE}-\\u{1D1E8}\\u{1D2C0}-\\u{1D2D3}\\u{1D2E0}-\\u{1D2F3}\\u{1D360}-\\u{1D378}\\u{1D400}-\\u{1D454}\\u{1D456}-\\u{1D49C}\\u{1D49E}\\u{1D49F}\\u{1D4A2}\\u{1D4A5}\\u{1D4A6}\\u{1D4A9}-\\u{1D4AC}\\u{1D4AE}-\\u{1D4B9}\\u{1D4BB}\\u{1D4BD}-\\u{1D4C3}\\u{1D4C5}-\\u{1D505}\\u{1D507}-\\u{1D50A}\\u{1D50D}-\\u{1D514}\\u{1D516}-\\u{1D51C}\\u{1D51E}-\\u{1D539}\\u{1D53B}-\\u{1D53E}\\u{1D540}-\\u{1D544}\\u{1D546}\\u{1D54A}-\\u{1D550}\\u{1D552}-\\u{1D6A5}\\u{1D6A8}-\\u{1D6DA}\\u{1D6DC}-\\u{1D714}\\u{1D716}-\\u{1D74E}\\u{1D750}-\\u{1D788}\\u{1D78A}-\\u{1D7C2}\\u{1D7C4}-\\u{1D7CB}\\u{1D7CE}-\\u{1D9FF}\\u{1DA37}-\\u{1DA3A}\\u{1DA6D}-\\u{1DA74}\\u{1DA76}-\\u{1DA83}\\u{1DA85}-\\u{1DA8B}\\u{1DF00}-\\u{1DF1E}\\u{1DF25}-\\u{1DF2A}\\u{1E030}-\\u{1E06D}\\u{1E100}-\\u{1E12C}\\u{1E137}-\\u{1E13D}\\u{1E140}-\\u{1E149}\\u{1E14E}\\u{1E14F}\\u{1E290}-\\u{1E2AD}\\u{1E2C0}-\\u{1E2EB}\\u{1E2F0}-\\u{1E2F9}\\u{1E4D0}-\\u{1E4EB}\\u{1E4F0}-\\u{1E4F9}\\u{1E7E0}-\\u{1E7E6}\\u{1E7E8}-\\u{1E7EB}\\u{1E7ED}\\u{1E7EE}\\u{1E7F0}-\\u{1E7FE}\\u{1F100}-\\u{1F10A}\\u{1F110}-\\u{1F12E}\\u{1F130}-\\u{1F169}\\u{1F170}-\\u{1F1AC}\\u{1F1E6}-\\u{1F202}\\u{1F210}-\\u{1F23B}\\u{1F240}-\\u{1F248}\\u{1F250}\\u{1F251}\\u{1FBF0}-\\u{1FBF9}\\u{20000}-\\u{2A6DF}\\u{2A700}-\\u{2B739}\\u{2B740}-\\u{2B81D}\\u{2B820}-\\u{2CEA1}\\u{2CEB0}-\\u{2EBE0}\\u{2F800}-\\u{2FA1D}\\u{30000}-\\u{3134A}\\u{31350}-\\u{323AF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}][\\u0300-\\u036F\\u0483-\\u0489\\u0591-\\u05BD\\u05BF\\u05C1\\u05C2\\u05C4\\u05C5\\u05C7\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06DC\\u06DF-\\u06E4\\u06E7\\u06E8\\u06EA-\\u06ED\\u0711\\u0730-\\u074A\\u07A6-\\u07B0\\u07EB-\\u07F3\\u07FD\\u0816-\\u0819\\u081B-\\u0823\\u0825-\\u0827\\u0829-\\u082D\\u0859-\\u085B\\u0898-\\u089F\\u08CA-\\u08E1\\u08E3-\\u0902\\u093A\\u093C\\u0941-\\u0948\\u094D\\u0951-\\u0957\\u0962\\u0963\\u0981\\u09BC\\u09C1-\\u09C4\\u09CD\\u09E2\\u09E3\\u09FE\\u0A01\\u0A02\\u0A3C\\u0A41\\u0A42\\u0A47\\u0A48\\u0A4B-\\u0A4D\\u0A51\\u0A70\\u0A71\\u0A75\\u0A81\\u0A82\\u0ABC\\u0AC1-\\u0AC5\\u0AC7\\u0AC8\\u0ACD\\u0AE2\\u0AE3\\u0AFA-\\u0AFF\\u0B01\\u0B3C\\u0B3F\\u0B41-\\u0B44\\u0B4D\\u0B55\\u0B56\\u0B62\\u0B63\\u0B82\\u0BC0\\u0BCD\\u0C00\\u0C04\\u0C3C\\u0C3E-\\u0C40\\u0C46-\\u0C48\\u0C4A-\\u0C4D\\u0C55\\u0C56\\u0C62\\u0C63\\u0C81\\u0CBC\\u0CCC\\u0CCD\\u0CE2\\u0CE3\\u0D00\\u0D01\\u0D3B\\u0D3C\\u0D41-\\u0D44\\u0D4D\\u0D62\\u0D63\\u0D81\\u0DCA\\u0DD2-\\u0DD4\\u0DD6\\u0E31\\u0E34-\\u0E3A\\u0E47-\\u0E4E\\u0EB1\\u0EB4-\\u0EBC\\u0EC8-\\u0ECE\\u0F18\\u0F19\\u0F35\\u0F37\\u0F39\\u0F71-\\u0F7E\\u0F80-\\u0F84\\u0F86\\u0F87\\u0F8D-\\u0F97\\u0F99-\\u0FBC\\u0FC6\\u102D-\\u1030\\u1032-\\u1037\\u1039\\u103A\\u103D\\u103E\\u1058\\u1059\\u105E-\\u1060\\u1071-\\u1074\\u1082\\u1085\\u1086\\u108D\\u109D\\u135D-\\u135F\\u1712-\\u1714\\u1732\\u1733\\u1752\\u1753\\u1772\\u1773\\u17B4\\u17B5\\u17B7-\\u17BD\\u17C6\\u17C9-\\u17D3\\u17DD\\u180B-\\u180D\\u180F\\u1885\\u1886\\u18A9\\u1920-\\u1922\\u1927\\u1928\\u1932\\u1939-\\u193B\\u1A17\\u1A18\\u1A1B\\u1A56\\u1A58-\\u1A5E\\u1A60\\u1A62\\u1A65-\\u1A6C\\u1A73-\\u1A7C\\u1A7F\\u1AB0-\\u1ACE\\u1B00-\\u1B03\\u1B34\\u1B36-\\u1B3A\\u1B3C\\u1B42\\u1B6B-\\u1B73\\u1B80\\u1B81\\u1BA2-\\u1BA5\\u1BA8\\u1BA9\\u1BAB-\\u1BAD\\u1BE6\\u1BE8\\u1BE9\\u1BED\\u1BEF-\\u1BF1\\u1C2C-\\u1C33\\u1C36\\u1C37\\u1CD0-\\u1CD2\\u1CD4-\\u1CE0\\u1CE2-\\u1CE8\\u1CED\\u1CF4\\u1CF8\\u1CF9\\u1DC0-\\u1DFF\\u20D0-\\u20F0\\u2CEF-\\u2CF1\\u2D7F\\u2DE0-\\u2DFF\\u302A-\\u302D\\u3099\\u309A\\uA66F-\\uA672\\uA674-\\uA67D\\uA69E\\uA69F\\uA6F0\\uA6F1\\uA802\\uA806\\uA80B\\uA825\\uA826\\uA82C\\uA8C4\\uA8C5\\uA8E0-\\uA8F1\\uA8FF\\uA926-\\uA92D\\uA947-\\uA951\\uA980-\\uA982\\uA9B3\\uA9B6-\\uA9B9\\uA9BC\\uA9BD\\uA9E5\\uAA29-\\uAA2E\\uAA31\\uAA32\\uAA35\\uAA36\\uAA43\\uAA4C\\uAA7C\\uAAB0\\uAAB2-\\uAAB4\\uAAB7\\uAAB8\\uAABE\\uAABF\\uAAC1\\uAAEC\\uAAED\\uAAF6\\uABE5\\uABE8\\uABED\\uFB1E\\uFE00-\\uFE0F\\uFE20-\\uFE2F\\u{101FD}\\u{102E0}\\u{10376}-\\u{1037A}\\u{10A01}-\\u{10A03}\\u{10A05}\\u{10A06}\\u{10A0C}-\\u{10A0F}\\u{10A38}-\\u{10A3A}\\u{10A3F}\\u{10AE5}\\u{10AE6}\\u{10D24}-\\u{10D27}\\u{10EAB}\\u{10EAC}\\u{10EFD}-\\u{10EFF}\\u{10F46}-\\u{10F50}\\u{10F82}-\\u{10F85}\\u{11001}\\u{11038}-\\u{11046}\\u{11070}\\u{11073}\\u{11074}\\u{1107F}-\\u{11081}\\u{110B3}-\\u{110B6}\\u{110B9}\\u{110BA}\\u{110C2}\\u{11100}-\\u{11102}\\u{11127}-\\u{1112B}\\u{1112D}-\\u{11134}\\u{11173}\\u{11180}\\u{11181}\\u{111B6}-\\u{111BE}\\u{111C9}-\\u{111CC}\\u{111CF}\\u{1122F}-\\u{11231}\\u{11234}\\u{11236}\\u{11237}\\u{1123E}\\u{11241}\\u{112DF}\\u{112E3}-\\u{112EA}\\u{11300}\\u{11301}\\u{1133B}\\u{1133C}\\u{11340}\\u{11366}-\\u{1136C}\\u{11370}-\\u{11374}\\u{11438}-\\u{1143F}\\u{11442}-\\u{11444}\\u{11446}\\u{1145E}\\u{114B3}-\\u{114B8}\\u{114BA}\\u{114BF}\\u{114C0}\\u{114C2}\\u{114C3}\\u{115B2}-\\u{115B5}\\u{115BC}\\u{115BD}\\u{115BF}\\u{115C0}\\u{115DC}\\u{115DD}\\u{11633}-\\u{1163A}\\u{1163D}\\u{1163F}\\u{11640}\\u{116AB}\\u{116AD}\\u{116B0}-\\u{116B5}\\u{116B7}\\u{1171D}-\\u{1171F}\\u{11722}-\\u{11725}\\u{11727}-\\u{1172B}\\u{1182F}-\\u{11837}\\u{11839}\\u{1183A}\\u{1193B}\\u{1193C}\\u{1193E}\\u{11943}\\u{119D4}-\\u{119D7}\\u{119DA}\\u{119DB}\\u{119E0}\\u{11A01}-\\u{11A06}\\u{11A09}\\u{11A0A}\\u{11A33}-\\u{11A38}\\u{11A3B}-\\u{11A3E}\\u{11A47}\\u{11A51}-\\u{11A56}\\u{11A59}-\\u{11A5B}\\u{11A8A}-\\u{11A96}\\u{11A98}\\u{11A99}\\u{11C30}-\\u{11C36}\\u{11C38}-\\u{11C3D}\\u{11C92}-\\u{11CA7}\\u{11CAA}-\\u{11CB0}\\u{11CB2}\\u{11CB3}\\u{11CB5}\\u{11CB6}\\u{11D31}-\\u{11D36}\\u{11D3A}\\u{11D3C}\\u{11D3D}\\u{11D3F}-\\u{11D45}\\u{11D47}\\u{11D90}\\u{11D91}\\u{11D95}\\u{11D97}\\u{11EF3}\\u{11EF4}\\u{11F00}\\u{11F01}\\u{11F36}-\\u{11F3A}\\u{11F40}\\u{11F42}\\u{13440}\\u{13447}-\\u{13455}\\u{16AF0}-\\u{16AF4}\\u{16B30}-\\u{16B36}\\u{16F4F}\\u{16F8F}-\\u{16F92}\\u{16FE4}\\u{1BC9D}\\u{1BC9E}\\u{1CF00}-\\u{1CF2D}\\u{1CF30}-\\u{1CF46}\\u{1D167}-\\u{1D169}\\u{1D17B}-\\u{1D182}\\u{1D185}-\\u{1D18B}\\u{1D1AA}-\\u{1D1AD}\\u{1D242}-\\u{1D244}\\u{1DA00}-\\u{1DA36}\\u{1DA3B}-\\u{1DA6C}\\u{1DA75}\\u{1DA84}\\u{1DA9B}-\\u{1DA9F}\\u{1DAA1}-\\u{1DAAF}\\u{1E000}-\\u{1E006}\\u{1E008}-\\u{1E018}\\u{1E01B}-\\u{1E021}\\u{1E023}\\u{1E024}\\u{1E026}-\\u{1E02A}\\u{1E08F}\\u{1E130}-\\u{1E136}\\u{1E2AE}\\u{1E2EC}-\\u{1E2EF}\\u{1E4EC}-\\u{1E4EF}\\u{1E8D0}-\\u{1E8D6}\\u{1E944}-\\u{1E94A}\\u{E0100}-\\u{E01EF}]*$/u;\n\nmodule.exports = {\n  combiningMarks,\n  combiningClassVirama,\n  validZWNJ,\n  bidiDomain,\n  bidiS1LTR,\n  bidiS1RTL,\n  bidiS2,\n  bidiS3,\n  bidiS4EN,\n  bidiS4AN,\n  bidiS5,\n  bidiS6\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/tr46/lib/regexes.js?");

/***/ }),

/***/ "./node_modules/tr46/lib/statusMapping.js":
/*!************************************************!*\
  !*** ./node_modules/tr46/lib/statusMapping.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports.STATUS_MAPPING = {\n  mapped: 1,\n  valid: 2,\n  disallowed: 3,\n  disallowed_STD3_valid: 4,\n  disallowed_STD3_mapped: 5,\n  deviation: 6,\n  ignored: 7\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/tr46/lib/statusMapping.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/native.js":
/*!******************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/native.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst randomUUID = typeof crypto !== 'undefined' && crypto.randomUUID && crypto.randomUUID.bind(crypto);\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  randomUUID\n});\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/native.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/regex.js":
/*!*****************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/regex.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (/^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i);\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/regex.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/rng.js":
/*!***************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/rng.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ rng)\n/* harmony export */ });\n// Unique ID creation requires a high quality random # generator. In the browser we therefore\n// require the crypto API and do not support built-in fallback to lower quality random number\n// generators (like Math.random()).\nlet getRandomValues;\nconst rnds8 = new Uint8Array(16);\nfunction rng() {\n  // lazy load so that environments that need to polyfill have a chance to do so\n  if (!getRandomValues) {\n    // getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\n    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto);\n\n    if (!getRandomValues) {\n      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');\n    }\n  }\n\n  return getRandomValues(rnds8);\n}\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/rng.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/stringify.js":
/*!*********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/stringify.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   unsafeStringify: () => (/* binding */ unsafeStringify)\n/* harmony export */ });\n/* harmony import */ var _validate_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./validate.js */ \"./node_modules/uuid/dist/esm-browser/validate.js\");\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\n\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).slice(1));\n}\n\nfunction unsafeStringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  return byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]];\n}\n\nfunction stringify(arr, offset = 0) {\n  const uuid = unsafeStringify(arr, offset); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0,_validate_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (stringify);\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/stringify.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/v4.js":
/*!**************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/v4.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _native_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./native.js */ \"./node_modules/uuid/dist/esm-browser/native.js\");\n/* harmony import */ var _rng_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./rng.js */ \"./node_modules/uuid/dist/esm-browser/rng.js\");\n/* harmony import */ var _stringify_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./stringify.js */ \"./node_modules/uuid/dist/esm-browser/stringify.js\");\n\n\n\n\nfunction v4(options, buf, offset) {\n  if (_native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID && !buf && !options) {\n    return _native_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].randomUUID();\n  }\n\n  options = options || {};\n  const rnds = options.random || (options.rng || _rng_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0,_stringify_js__WEBPACK_IMPORTED_MODULE_2__.unsafeStringify)(rnds);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (v4);\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/v4.js?");

/***/ }),

/***/ "./node_modules/uuid/dist/esm-browser/validate.js":
/*!********************************************************!*\
  !*** ./node_modules/uuid/dist/esm-browser/validate.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _regex_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./regex.js */ \"./node_modules/uuid/dist/esm-browser/regex.js\");\n\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].test(uuid);\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (validate);\n\n//# sourceURL=webpack://oracle2/./node_modules/uuid/dist/esm-browser/validate.js?");

/***/ }),

/***/ "./node_modules/webidl-conversions/lib/index.js":
/*!******************************************************!*\
  !*** ./node_modules/webidl-conversions/lib/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nfunction makeException(ErrorType, message, options) {\n  if (options.globals) {\n    ErrorType = options.globals[ErrorType.name];\n  }\n  return new ErrorType(`${options.context ? options.context : \"Value\"} ${message}.`);\n}\n\nfunction toNumber(value, options) {\n  if (typeof value === \"bigint\") {\n    throw makeException(TypeError, \"is a BigInt which cannot be converted to a number\", options);\n  }\n  if (!options.globals) {\n    return Number(value);\n  }\n  return options.globals.Number(value);\n}\n\n// Round x to the nearest integer, choosing the even integer if it lies halfway between two.\nfunction evenRound(x) {\n  // There are four cases for numbers with fractional part being .5:\n  //\n  // case |     x     | floor(x) | round(x) | expected | x <> 0 | x % 1 | x & 1 |   example\n  //   1  |  2n + 0.5 |  2n      |  2n + 1  |  2n      |   >    |  0.5  |   0   |  0.5 ->  0\n  //   2  |  2n + 1.5 |  2n + 1  |  2n + 2  |  2n + 2  |   >    |  0.5  |   1   |  1.5 ->  2\n  //   3  | -2n - 0.5 | -2n - 1  | -2n      | -2n      |   <    | -0.5  |   0   | -0.5 ->  0\n  //   4  | -2n - 1.5 | -2n - 2  | -2n - 1  | -2n - 2  |   <    | -0.5  |   1   | -1.5 -> -2\n  // (where n is a non-negative integer)\n  //\n  // Branch here for cases 1 and 4\n  if ((x > 0 && (x % 1) === +0.5 && (x & 1) === 0) ||\n        (x < 0 && (x % 1) === -0.5 && (x & 1) === 1)) {\n    return censorNegativeZero(Math.floor(x));\n  }\n\n  return censorNegativeZero(Math.round(x));\n}\n\nfunction integerPart(n) {\n  return censorNegativeZero(Math.trunc(n));\n}\n\nfunction sign(x) {\n  return x < 0 ? -1 : 1;\n}\n\nfunction modulo(x, y) {\n  // https://tc39.github.io/ecma262/#eqn-modulo\n  // Note that http://stackoverflow.com/a/4467559/3191 does NOT work for large modulos\n  const signMightNotMatch = x % y;\n  if (sign(y) !== sign(signMightNotMatch)) {\n    return signMightNotMatch + y;\n  }\n  return signMightNotMatch;\n}\n\nfunction censorNegativeZero(x) {\n  return x === 0 ? 0 : x;\n}\n\nfunction createIntegerConversion(bitLength, { unsigned }) {\n  let lowerBound, upperBound;\n  if (unsigned) {\n    lowerBound = 0;\n    upperBound = 2 ** bitLength - 1;\n  } else {\n    lowerBound = -(2 ** (bitLength - 1));\n    upperBound = 2 ** (bitLength - 1) - 1;\n  }\n\n  const twoToTheBitLength = 2 ** bitLength;\n  const twoToOneLessThanTheBitLength = 2 ** (bitLength - 1);\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n    x = integerPart(x);\n\n    // Math.pow(2, 64) is not accurately representable in JavaScript, so try to avoid these per-spec operations if\n    // possible. Hopefully it's an optimization for the non-64-bitLength cases too.\n    if (x >= lowerBound && x <= upperBound) {\n      return x;\n    }\n\n    // These will not work great for bitLength of 64, but oh well. See the README for more details.\n    x = modulo(x, twoToTheBitLength);\n    if (!unsigned && x >= twoToOneLessThanTheBitLength) {\n      return x - twoToTheBitLength;\n    }\n    return x;\n  };\n}\n\nfunction createLongLongConversion(bitLength, { unsigned }) {\n  const upperBound = Number.MAX_SAFE_INTEGER;\n  const lowerBound = unsigned ? 0 : Number.MIN_SAFE_INTEGER;\n  const asBigIntN = unsigned ? BigInt.asUintN : BigInt.asIntN;\n\n  return (value, options = {}) => {\n    let x = toNumber(value, options);\n    x = censorNegativeZero(x);\n\n    if (options.enforceRange) {\n      if (!Number.isFinite(x)) {\n        throw makeException(TypeError, \"is not a finite number\", options);\n      }\n\n      x = integerPart(x);\n\n      if (x < lowerBound || x > upperBound) {\n        throw makeException(\n          TypeError,\n          `is outside the accepted range of ${lowerBound} to ${upperBound}, inclusive`,\n          options\n        );\n      }\n\n      return x;\n    }\n\n    if (!Number.isNaN(x) && options.clamp) {\n      x = Math.min(Math.max(x, lowerBound), upperBound);\n      x = evenRound(x);\n      return x;\n    }\n\n    if (!Number.isFinite(x) || x === 0) {\n      return 0;\n    }\n\n    let xBigInt = BigInt(integerPart(x));\n    xBigInt = asBigIntN(bitLength, xBigInt);\n    return Number(xBigInt);\n  };\n}\n\nexports.any = value => {\n  return value;\n};\n\nexports.undefined = () => {\n  return undefined;\n};\n\nexports.boolean = value => {\n  return Boolean(value);\n};\n\nexports.byte = createIntegerConversion(8, { unsigned: false });\nexports.octet = createIntegerConversion(8, { unsigned: true });\n\nexports.short = createIntegerConversion(16, { unsigned: false });\nexports[\"unsigned short\"] = createIntegerConversion(16, { unsigned: true });\n\nexports.long = createIntegerConversion(32, { unsigned: false });\nexports[\"unsigned long\"] = createIntegerConversion(32, { unsigned: true });\n\nexports[\"long long\"] = createLongLongConversion(64, { unsigned: false });\nexports[\"unsigned long long\"] = createLongLongConversion(64, { unsigned: true });\n\nexports.double = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  return x;\n};\n\nexports[\"unrestricted double\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  return x;\n};\n\nexports.float = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (!Number.isFinite(x)) {\n    throw makeException(TypeError, \"is not a finite floating-point value\", options);\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  const y = Math.fround(x);\n\n  if (!Number.isFinite(y)) {\n    throw makeException(TypeError, \"is outside the range of a single-precision floating-point value\", options);\n  }\n\n  return y;\n};\n\nexports[\"unrestricted float\"] = (value, options = {}) => {\n  const x = toNumber(value, options);\n\n  if (isNaN(x)) {\n    return x;\n  }\n\n  if (Object.is(x, -0)) {\n    return x;\n  }\n\n  return Math.fround(x);\n};\n\nexports.DOMString = (value, options = {}) => {\n  if (options.treatNullAsEmptyString && value === null) {\n    return \"\";\n  }\n\n  if (typeof value === \"symbol\") {\n    throw makeException(TypeError, \"is a symbol, which cannot be converted to a string\", options);\n  }\n\n  const StringCtor = options.globals ? options.globals.String : String;\n  return StringCtor(value);\n};\n\nexports.ByteString = (value, options = {}) => {\n  const x = exports.DOMString(value, options);\n  let c;\n  for (let i = 0; (c = x.codePointAt(i)) !== undefined; ++i) {\n    if (c > 255) {\n      throw makeException(TypeError, \"is not a valid ByteString\", options);\n    }\n  }\n\n  return x;\n};\n\nexports.USVString = (value, options = {}) => {\n  const S = exports.DOMString(value, options);\n  const n = S.length;\n  const U = [];\n  for (let i = 0; i < n; ++i) {\n    const c = S.charCodeAt(i);\n    if (c < 0xD800 || c > 0xDFFF) {\n      U.push(String.fromCodePoint(c));\n    } else if (0xDC00 <= c && c <= 0xDFFF) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else if (i === n - 1) {\n      U.push(String.fromCodePoint(0xFFFD));\n    } else {\n      const d = S.charCodeAt(i + 1);\n      if (0xDC00 <= d && d <= 0xDFFF) {\n        const a = c & 0x3FF;\n        const b = d & 0x3FF;\n        U.push(String.fromCodePoint((2 << 15) + ((2 << 9) * a) + b));\n        ++i;\n      } else {\n        U.push(String.fromCodePoint(0xFFFD));\n      }\n    }\n  }\n\n  return U.join(\"\");\n};\n\nexports.object = (value, options = {}) => {\n  if (value === null || (typeof value !== \"object\" && typeof value !== \"function\")) {\n    throw makeException(TypeError, \"is not an object\", options);\n  }\n\n  return value;\n};\n\nconst abByteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nconst sabByteLengthGetter =\n    typeof SharedArrayBuffer === \"function\" ?\n      Object.getOwnPropertyDescriptor(SharedArrayBuffer.prototype, \"byteLength\").get :\n      null;\n\nfunction isNonSharedArrayBuffer(value) {\n  try {\n    // This will throw on SharedArrayBuffers, but not detached ArrayBuffers.\n    // (The spec says it should throw, but the spec conflicts with implementations: https://github.com/tc39/ecma262/issues/678)\n    abByteLengthGetter.call(value);\n\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isSharedArrayBuffer(value) {\n  try {\n    sabByteLengthGetter.call(value);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\nfunction isArrayBufferDetached(value) {\n  try {\n    // eslint-disable-next-line no-new\n    new Uint8Array(value);\n    return false;\n  } catch {\n    return true;\n  }\n}\n\nexports.ArrayBuffer = (value, options = {}) => {\n  if (!isNonSharedArrayBuffer(value)) {\n    if (options.allowShared && !isSharedArrayBuffer(value)) {\n      throw makeException(TypeError, \"is not an ArrayBuffer or SharedArrayBuffer\", options);\n    }\n    throw makeException(TypeError, \"is not an ArrayBuffer\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nconst dvByteLengthGetter =\n    Object.getOwnPropertyDescriptor(DataView.prototype, \"byteLength\").get;\nexports.DataView = (value, options = {}) => {\n  try {\n    dvByteLengthGetter.call(value);\n  } catch (e) {\n    throw makeException(TypeError, \"is not a DataView\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a SharedArrayBuffer, which is not allowed\", options);\n  }\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is backed by a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\n// Returns the unforgeable `TypedArray` constructor name or `undefined`,\n// if the `this` value isn't a valid `TypedArray` object.\n//\n// https://tc39.es/ecma262/#sec-get-%typedarray%.prototype-@@tostringtag\nconst typedArrayNameGetter = Object.getOwnPropertyDescriptor(\n  Object.getPrototypeOf(Uint8Array).prototype,\n  Symbol.toStringTag\n).get;\n[\n  Int8Array,\n  Int16Array,\n  Int32Array,\n  Uint8Array,\n  Uint16Array,\n  Uint32Array,\n  Uint8ClampedArray,\n  Float32Array,\n  Float64Array\n].forEach(func => {\n  const { name } = func;\n  const article = /^[AEIOU]/u.test(name) ? \"an\" : \"a\";\n  exports[name] = (value, options = {}) => {\n    if (!ArrayBuffer.isView(value) || typedArrayNameGetter.call(value) !== name) {\n      throw makeException(TypeError, `is not ${article} ${name} object`, options);\n    }\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n\n    return value;\n  };\n});\n\n// Common definitions\n\nexports.ArrayBufferView = (value, options = {}) => {\n  if (!ArrayBuffer.isView(value)) {\n    throw makeException(TypeError, \"is not a view on an ArrayBuffer or SharedArrayBuffer\", options);\n  }\n\n  if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n  }\n\n  if (isArrayBufferDetached(value.buffer)) {\n    throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n  }\n  return value;\n};\n\nexports.BufferSource = (value, options = {}) => {\n  if (ArrayBuffer.isView(value)) {\n    if (!options.allowShared && isSharedArrayBuffer(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a SharedArrayBuffer, which is not allowed\", options);\n    }\n\n    if (isArrayBufferDetached(value.buffer)) {\n      throw makeException(TypeError, \"is a view on a detached ArrayBuffer\", options);\n    }\n    return value;\n  }\n\n  if (!options.allowShared && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer or a view on one\", options);\n  }\n  if (options.allowShared && !isSharedArrayBuffer(value) && !isNonSharedArrayBuffer(value)) {\n    throw makeException(TypeError, \"is not an ArrayBuffer, SharedArrayBuffer, or a view on one\", options);\n  }\n  if (isArrayBufferDetached(value)) {\n    throw makeException(TypeError, \"is a detached ArrayBuffer\", options);\n  }\n\n  return value;\n};\n\nexports.DOMTimeStamp = exports[\"unsigned long long\"];\n\n\n//# sourceURL=webpack://oracle2/./node_modules/webidl-conversions/lib/index.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/index.js":
/*!******************************************!*\
  !*** ./node_modules/whatwg-url/index.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { URL, URLSearchParams } = __webpack_require__(/*! ./webidl2js-wrapper */ \"./node_modules/whatwg-url/webidl2js-wrapper.js\");\nconst urlStateMachine = __webpack_require__(/*! ./lib/url-state-machine */ \"./node_modules/whatwg-url/lib/url-state-machine.js\");\nconst percentEncoding = __webpack_require__(/*! ./lib/percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nconst sharedGlobalObject = { Array, Object, Promise, String, TypeError };\nURL.install(sharedGlobalObject, [\"Window\"]);\nURLSearchParams.install(sharedGlobalObject, [\"Window\"]);\n\nexports.URL = sharedGlobalObject.URL;\nexports.URLSearchParams = sharedGlobalObject.URLSearchParams;\n\nexports.parseURL = urlStateMachine.parseURL;\nexports.basicURLParse = urlStateMachine.basicURLParse;\nexports.serializeURL = urlStateMachine.serializeURL;\nexports.serializePath = urlStateMachine.serializePath;\nexports.serializeHost = urlStateMachine.serializeHost;\nexports.serializeInteger = urlStateMachine.serializeInteger;\nexports.serializeURLOrigin = urlStateMachine.serializeURLOrigin;\nexports.setTheUsername = urlStateMachine.setTheUsername;\nexports.setThePassword = urlStateMachine.setThePassword;\nexports.cannotHaveAUsernamePasswordPort = urlStateMachine.cannotHaveAUsernamePasswordPort;\nexports.hasAnOpaquePath = urlStateMachine.hasAnOpaquePath;\n\nexports.percentDecodeString = percentEncoding.percentDecodeString;\nexports.percentDecodeBytes = percentEncoding.percentDecodeBytes;\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/index.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/Function.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/Function.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (typeof value !== \"function\") {\n    throw new globalObject.TypeError(context + \" is not a function\");\n  }\n\n  function invokeTheCallbackFunction(...args) {\n    const thisArg = utils.tryWrapperForImpl(this);\n    let callResult;\n\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    callResult = Reflect.apply(value, thisArg, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  }\n\n  invokeTheCallbackFunction.construct = (...args) => {\n    for (let i = 0; i < args.length; i++) {\n      args[i] = utils.tryWrapperForImpl(args[i]);\n    }\n\n    let callResult = Reflect.construct(value, args);\n\n    callResult = conversions[\"any\"](callResult, { context: context, globals: globalObject });\n\n    return callResult;\n  };\n\n  invokeTheCallbackFunction[utils.wrapperSymbol] = value;\n  invokeTheCallbackFunction.objectReference = value;\n\n  return invokeTheCallbackFunction;\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/Function.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URL-impl.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URL-impl.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst usm = __webpack_require__(/*! ./url-state-machine */ \"./node_modules/whatwg-url/lib/url-state-machine.js\");\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/whatwg-url/lib/urlencoded.js\");\nconst URLSearchParams = __webpack_require__(/*! ./URLSearchParams */ \"./node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.implementation = class URLImpl {\n  // Unlike the spec, we duplicate some code between the constructor and canParse, because we want to give useful error\n  // messages in the constructor that distinguish between the different causes of failure.\n  constructor(globalObject, constructorArgs) {\n    const url = constructorArgs[0];\n    const base = constructorArgs[1];\n\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        throw new TypeError(`Invalid base URL: ${base}`);\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${url}`);\n    }\n\n    const query = parsedURL.query !== null ? parsedURL.query : \"\";\n\n    this._url = parsedURL;\n\n    // We cannot invoke the \"new URLSearchParams object\" algorithm without going through the constructor, which strips\n    // question mark by default. Therefore the doNotStripQMark hack is used.\n    this._query = URLSearchParams.createImpl(globalObject, [query], { doNotStripQMark: true });\n    this._query._url = this;\n  }\n\n  static canParse(url, base) {\n    let parsedBase = null;\n    if (base !== undefined) {\n      parsedBase = usm.basicURLParse(base);\n      if (parsedBase === null) {\n        return false;\n      }\n    }\n\n    const parsedURL = usm.basicURLParse(url, { baseURL: parsedBase });\n    if (parsedURL === null) {\n      return false;\n    }\n\n    return true;\n  }\n\n  get href() {\n    return usm.serializeURL(this._url);\n  }\n\n  set href(v) {\n    const parsedURL = usm.basicURLParse(v);\n    if (parsedURL === null) {\n      throw new TypeError(`Invalid URL: ${v}`);\n    }\n\n    this._url = parsedURL;\n\n    this._query._list.splice(0);\n    const { query } = parsedURL;\n    if (query !== null) {\n      this._query._list = urlencoded.parseUrlencodedString(query);\n    }\n  }\n\n  get origin() {\n    return usm.serializeURLOrigin(this._url);\n  }\n\n  get protocol() {\n    return `${this._url.scheme}:`;\n  }\n\n  set protocol(v) {\n    usm.basicURLParse(`${v}:`, { url: this._url, stateOverride: \"scheme start\" });\n  }\n\n  get username() {\n    return this._url.username;\n  }\n\n  set username(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setTheUsername(this._url, v);\n  }\n\n  get password() {\n    return this._url.password;\n  }\n\n  set password(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    usm.setThePassword(this._url, v);\n  }\n\n  get host() {\n    const url = this._url;\n\n    if (url.host === null) {\n      return \"\";\n    }\n\n    if (url.port === null) {\n      return usm.serializeHost(url.host);\n    }\n\n    return `${usm.serializeHost(url.host)}:${usm.serializeInteger(url.port)}`;\n  }\n\n  set host(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"host\" });\n  }\n\n  get hostname() {\n    if (this._url.host === null) {\n      return \"\";\n    }\n\n    return usm.serializeHost(this._url.host);\n  }\n\n  set hostname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"hostname\" });\n  }\n\n  get port() {\n    if (this._url.port === null) {\n      return \"\";\n    }\n\n    return usm.serializeInteger(this._url.port);\n  }\n\n  set port(v) {\n    if (usm.cannotHaveAUsernamePasswordPort(this._url)) {\n      return;\n    }\n\n    if (v === \"\") {\n      this._url.port = null;\n    } else {\n      usm.basicURLParse(v, { url: this._url, stateOverride: \"port\" });\n    }\n  }\n\n  get pathname() {\n    return usm.serializePath(this._url);\n  }\n\n  set pathname(v) {\n    if (usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    this._url.path = [];\n    usm.basicURLParse(v, { url: this._url, stateOverride: \"path start\" });\n  }\n\n  get search() {\n    if (this._url.query === null || this._url.query === \"\") {\n      return \"\";\n    }\n\n    return `?${this._url.query}`;\n  }\n\n  set search(v) {\n    const url = this._url;\n\n    if (v === \"\") {\n      url.query = null;\n      this._query._list = [];\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"?\" ? v.substring(1) : v;\n    url.query = \"\";\n    usm.basicURLParse(input, { url, stateOverride: \"query\" });\n    this._query._list = urlencoded.parseUrlencodedString(input);\n  }\n\n  get searchParams() {\n    return this._query;\n  }\n\n  get hash() {\n    if (this._url.fragment === null || this._url.fragment === \"\") {\n      return \"\";\n    }\n\n    return `#${this._url.fragment}`;\n  }\n\n  set hash(v) {\n    if (v === \"\") {\n      this._url.fragment = null;\n      this._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      return;\n    }\n\n    const input = v[0] === \"#\" ? v.substring(1) : v;\n    this._url.fragment = \"\";\n    usm.basicURLParse(input, { url: this._url, stateOverride: \"fragment\" });\n  }\n\n  toJSON() {\n    return this.href;\n  }\n\n  _potentiallyStripTrailingSpacesFromAnOpaquePath() {\n    if (!usm.hasAnOpaquePath(this._url)) {\n      return;\n    }\n\n    if (this._url.fragment !== null) {\n      return;\n    }\n\n    if (this._url.query !== null) {\n      return;\n    }\n\n    this._url.path = this._url.path.replace(/\\u0020+$/u, \"\");\n  }\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/URL-impl.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URL.js":
/*!********************************************!*\
  !*** ./node_modules/whatwg-url/lib/URL.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URL\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URL'.`);\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URL\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URL {\n    constructor(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to construct 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to construct 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to construct 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    toJSON() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toJSON' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol].toJSON();\n    }\n\n    get href() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get href' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    set href(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set href' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'href' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"href\"] = V;\n    }\n\n    toString() {\n      const esValue = this;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'toString' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"href\"];\n    }\n\n    get origin() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get origin' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"origin\"];\n    }\n\n    get protocol() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"protocol\"];\n    }\n\n    set protocol(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set protocol' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'protocol' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"protocol\"] = V;\n    }\n\n    get username() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get username' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"username\"];\n    }\n\n    set username(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set username' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'username' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"username\"] = V;\n    }\n\n    get password() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get password' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"password\"];\n    }\n\n    set password(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set password' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'password' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"password\"] = V;\n    }\n\n    get host() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get host' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"host\"];\n    }\n\n    set host(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set host' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'host' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"host\"] = V;\n    }\n\n    get hostname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hostname\"];\n    }\n\n    set hostname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hostname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hostname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hostname\"] = V;\n    }\n\n    get port() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get port' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"port\"];\n    }\n\n    set port(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set port' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'port' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"port\"] = V;\n    }\n\n    get pathname() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"pathname\"];\n    }\n\n    set pathname(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set pathname' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'pathname' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"pathname\"] = V;\n    }\n\n    get search() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get search' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"search\"];\n    }\n\n    set search(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set search' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'search' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"search\"] = V;\n    }\n\n    get searchParams() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get searchParams' called on an object that is not a valid instance of URL.\");\n      }\n\n      return utils.getSameObject(this, \"searchParams\", () => {\n        return utils.tryWrapperForImpl(esValue[implSymbol][\"searchParams\"]);\n      });\n    }\n\n    get hash() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      return esValue[implSymbol][\"hash\"];\n    }\n\n    set hash(V) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set hash' called on an object that is not a valid instance of URL.\");\n      }\n\n      V = conversions[\"USVString\"](V, {\n        context: \"Failed to set the 'hash' property on 'URL': The provided value\",\n        globals: globalObject\n      });\n\n      esValue[implSymbol][\"hash\"] = V;\n    }\n\n    static canParse(url) {\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'canParse' on 'URL': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'canParse' on 'URL': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'canParse' on 'URL': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return Impl.implementation.canParse(...args);\n    }\n  }\n  Object.defineProperties(URL.prototype, {\n    toJSON: { enumerable: true },\n    href: { enumerable: true },\n    toString: { enumerable: true },\n    origin: { enumerable: true },\n    protocol: { enumerable: true },\n    username: { enumerable: true },\n    password: { enumerable: true },\n    host: { enumerable: true },\n    hostname: { enumerable: true },\n    port: { enumerable: true },\n    pathname: { enumerable: true },\n    search: { enumerable: true },\n    searchParams: { enumerable: true },\n    hash: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URL\", configurable: true }\n  });\n  Object.defineProperties(URL, { canParse: { enumerable: true } });\n  ctorRegistry[interfaceName] = URL;\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URL\n  });\n\n  if (globalNames.includes(\"Window\")) {\n    Object.defineProperty(globalObject, \"webkitURL\", {\n      configurable: true,\n      writable: true,\n      value: URL\n    });\n  }\n};\n\nconst Impl = __webpack_require__(/*! ./URL-impl.js */ \"./node_modules/whatwg-url/lib/URL-impl.js\");\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/URL.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URLSearchParams-impl.js":
/*!*************************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URLSearchParams-impl.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst urlencoded = __webpack_require__(/*! ./urlencoded */ \"./node_modules/whatwg-url/lib/urlencoded.js\");\n\nexports.implementation = class URLSearchParamsImpl {\n  constructor(globalObject, constructorArgs, { doNotStripQMark = false }) {\n    let init = constructorArgs[0];\n    this._list = [];\n    this._url = null;\n\n    if (!doNotStripQMark && typeof init === \"string\" && init[0] === \"?\") {\n      init = init.slice(1);\n    }\n\n    if (Array.isArray(init)) {\n      for (const pair of init) {\n        if (pair.length !== 2) {\n          throw new TypeError(\"Failed to construct 'URLSearchParams': parameter 1 sequence's element does not \" +\n                              \"contain exactly two elements.\");\n        }\n        this._list.push([pair[0], pair[1]]);\n      }\n    } else if (typeof init === \"object\" && Object.getPrototypeOf(init) === null) {\n      for (const name of Object.keys(init)) {\n        const value = init[name];\n        this._list.push([name, value]);\n      }\n    } else {\n      this._list = urlencoded.parseUrlencodedString(init);\n    }\n  }\n\n  _updateSteps() {\n    if (this._url !== null) {\n      let serializedQuery = urlencoded.serializeUrlencoded(this._list);\n      if (serializedQuery === \"\") {\n        serializedQuery = null;\n      }\n\n      this._url._url.query = serializedQuery;\n\n      if (serializedQuery === null) {\n        this._url._potentiallyStripTrailingSpacesFromAnOpaquePath();\n      }\n    }\n  }\n\n  get size() {\n    return this._list.length;\n  }\n\n  append(name, value) {\n    this._list.push([name, value]);\n    this._updateSteps();\n  }\n\n  delete(name, value) {\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name && (value === undefined || this._list[i][1] === value)) {\n        this._list.splice(i, 1);\n      } else {\n        i++;\n      }\n    }\n    this._updateSteps();\n  }\n\n  get(name) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        return tuple[1];\n      }\n    }\n    return null;\n  }\n\n  getAll(name) {\n    const output = [];\n    for (const tuple of this._list) {\n      if (tuple[0] === name) {\n        output.push(tuple[1]);\n      }\n    }\n    return output;\n  }\n\n  has(name, value) {\n    for (const tuple of this._list) {\n      if (tuple[0] === name && (value === undefined || tuple[1] === value)) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  set(name, value) {\n    let found = false;\n    let i = 0;\n    while (i < this._list.length) {\n      if (this._list[i][0] === name) {\n        if (found) {\n          this._list.splice(i, 1);\n        } else {\n          found = true;\n          this._list[i][1] = value;\n          i++;\n        }\n      } else {\n        i++;\n      }\n    }\n    if (!found) {\n      this._list.push([name, value]);\n    }\n    this._updateSteps();\n  }\n\n  sort() {\n    this._list.sort((a, b) => {\n      if (a[0] < b[0]) {\n        return -1;\n      }\n      if (a[0] > b[0]) {\n        return 1;\n      }\n      return 0;\n    });\n\n    this._updateSteps();\n  }\n\n  [Symbol.iterator]() {\n    return this._list[Symbol.iterator]();\n  }\n\n  toString() {\n    return urlencoded.serializeUrlencoded(this._list);\n  }\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/URLSearchParams-impl.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/URLSearchParams.js":
/*!********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/URLSearchParams.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst conversions = __webpack_require__(/*! webidl-conversions */ \"./node_modules/webidl-conversions/lib/index.js\");\nconst utils = __webpack_require__(/*! ./utils.js */ \"./node_modules/whatwg-url/lib/utils.js\");\n\nconst Function = __webpack_require__(/*! ./Function.js */ \"./node_modules/whatwg-url/lib/Function.js\");\nconst newObjectInRealm = utils.newObjectInRealm;\nconst implSymbol = utils.implSymbol;\nconst ctorRegistrySymbol = utils.ctorRegistrySymbol;\n\nconst interfaceName = \"URLSearchParams\";\n\nexports.is = value => {\n  return utils.isObject(value) && utils.hasOwn(value, implSymbol) && value[implSymbol] instanceof Impl.implementation;\n};\nexports.isImpl = value => {\n  return utils.isObject(value) && value instanceof Impl.implementation;\n};\nexports.convert = (globalObject, value, { context = \"The provided value\" } = {}) => {\n  if (exports.is(value)) {\n    return utils.implForWrapper(value);\n  }\n  throw new globalObject.TypeError(`${context} is not of type 'URLSearchParams'.`);\n};\n\nexports.createDefaultIterator = (globalObject, target, kind) => {\n  const ctorRegistry = globalObject[ctorRegistrySymbol];\n  const iteratorPrototype = ctorRegistry[\"URLSearchParams Iterator\"];\n  const iterator = Object.create(iteratorPrototype);\n  Object.defineProperty(iterator, utils.iterInternalSymbol, {\n    value: { target, kind, index: 0 },\n    configurable: true\n  });\n  return iterator;\n};\n\nfunction makeWrapper(globalObject, newTarget) {\n  let proto;\n  if (newTarget !== undefined) {\n    proto = newTarget.prototype;\n  }\n\n  if (!utils.isObject(proto)) {\n    proto = globalObject[ctorRegistrySymbol][\"URLSearchParams\"].prototype;\n  }\n\n  return Object.create(proto);\n}\n\nexports.create = (globalObject, constructorArgs, privateData) => {\n  const wrapper = makeWrapper(globalObject);\n  return exports.setup(wrapper, globalObject, constructorArgs, privateData);\n};\n\nexports.createImpl = (globalObject, constructorArgs, privateData) => {\n  const wrapper = exports.create(globalObject, constructorArgs, privateData);\n  return utils.implForWrapper(wrapper);\n};\n\nexports._internalSetup = (wrapper, globalObject) => {};\n\nexports.setup = (wrapper, globalObject, constructorArgs = [], privateData = {}) => {\n  privateData.wrapper = wrapper;\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: new Impl.implementation(globalObject, constructorArgs, privateData),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper;\n};\n\nexports[\"new\"] = (globalObject, newTarget) => {\n  const wrapper = makeWrapper(globalObject, newTarget);\n\n  exports._internalSetup(wrapper, globalObject);\n  Object.defineProperty(wrapper, implSymbol, {\n    value: Object.create(Impl.implementation.prototype),\n    configurable: true\n  });\n\n  wrapper[implSymbol][utils.wrapperSymbol] = wrapper;\n  if (Impl.init) {\n    Impl.init(wrapper[implSymbol]);\n  }\n  return wrapper[implSymbol];\n};\n\nconst exposed = new Set([\"Window\", \"Worker\"]);\n\nexports.install = (globalObject, globalNames) => {\n  if (!globalNames.some(globalName => exposed.has(globalName))) {\n    return;\n  }\n\n  const ctorRegistry = utils.initCtorRegistry(globalObject);\n  class URLSearchParams {\n    constructor() {\n      const args = [];\n      {\n        let curArg = arguments[0];\n        if (curArg !== undefined) {\n          if (utils.isObject(curArg)) {\n            if (curArg[Symbol.iterator] !== undefined) {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" sequence\" + \" is not an iterable object.\"\n                );\n              } else {\n                const V = [];\n                const tmp = curArg;\n                for (let nextItem of tmp) {\n                  if (!utils.isObject(nextItem)) {\n                    throw new globalObject.TypeError(\n                      \"Failed to construct 'URLSearchParams': parameter 1\" +\n                        \" sequence\" +\n                        \"'s element\" +\n                        \" is not an iterable object.\"\n                    );\n                  } else {\n                    const V = [];\n                    const tmp = nextItem;\n                    for (let nextItem of tmp) {\n                      nextItem = conversions[\"USVString\"](nextItem, {\n                        context:\n                          \"Failed to construct 'URLSearchParams': parameter 1\" +\n                          \" sequence\" +\n                          \"'s element\" +\n                          \"'s element\",\n                        globals: globalObject\n                      });\n\n                      V.push(nextItem);\n                    }\n                    nextItem = V;\n                  }\n\n                  V.push(nextItem);\n                }\n                curArg = V;\n              }\n            } else {\n              if (!utils.isObject(curArg)) {\n                throw new globalObject.TypeError(\n                  \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \" is not an object.\"\n                );\n              } else {\n                const result = Object.create(null);\n                for (const key of Reflect.ownKeys(curArg)) {\n                  const desc = Object.getOwnPropertyDescriptor(curArg, key);\n                  if (desc && desc.enumerable) {\n                    let typedKey = key;\n\n                    typedKey = conversions[\"USVString\"](typedKey, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s key\",\n                      globals: globalObject\n                    });\n\n                    let typedValue = curArg[key];\n\n                    typedValue = conversions[\"USVString\"](typedValue, {\n                      context: \"Failed to construct 'URLSearchParams': parameter 1\" + \" record\" + \"'s value\",\n                      globals: globalObject\n                    });\n\n                    result[typedKey] = typedValue;\n                  }\n                }\n                curArg = result;\n              }\n            }\n          } else {\n            curArg = conversions[\"USVString\"](curArg, {\n              context: \"Failed to construct 'URLSearchParams': parameter 1\",\n              globals: globalObject\n            });\n          }\n        } else {\n          curArg = \"\";\n        }\n        args.push(curArg);\n      }\n      return exports.setup(Object.create(new.target.prototype), globalObject, args);\n    }\n\n    append(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'append' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'append' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'append' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].append(...args));\n    }\n\n    delete(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'delete' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'delete' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'delete' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].delete(...args));\n    }\n\n    get(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'get' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'get' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'get' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return esValue[implSymbol].get(...args);\n    }\n\n    getAll(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'getAll' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'getAll' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'getAll' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].getAll(...args));\n    }\n\n    has(name) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'has' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'has' on 'URLSearchParams': 1 argument required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'has' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        if (curArg !== undefined) {\n          curArg = conversions[\"USVString\"](curArg, {\n            context: \"Failed to execute 'has' on 'URLSearchParams': parameter 2\",\n            globals: globalObject\n          });\n        }\n        args.push(curArg);\n      }\n      return esValue[implSymbol].has(...args);\n    }\n\n    set(name, value) {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'set' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      if (arguments.length < 2) {\n        throw new globalObject.TypeError(\n          `Failed to execute 'set' on 'URLSearchParams': 2 arguments required, but only ${arguments.length} present.`\n        );\n      }\n      const args = [];\n      {\n        let curArg = arguments[0];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 1\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      {\n        let curArg = arguments[1];\n        curArg = conversions[\"USVString\"](curArg, {\n          context: \"Failed to execute 'set' on 'URLSearchParams': parameter 2\",\n          globals: globalObject\n        });\n        args.push(curArg);\n      }\n      return utils.tryWrapperForImpl(esValue[implSymbol].set(...args));\n    }\n\n    sort() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\"'sort' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n\n      return utils.tryWrapperForImpl(esValue[implSymbol].sort());\n    }\n\n    toString() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'toString' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol].toString();\n    }\n\n    keys() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\"'keys' called on an object that is not a valid instance of URLSearchParams.\");\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key\");\n    }\n\n    values() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'values' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"value\");\n    }\n\n    entries() {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'entries' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      return exports.createDefaultIterator(globalObject, this, \"key+value\");\n    }\n\n    forEach(callback) {\n      if (!exports.is(this)) {\n        throw new globalObject.TypeError(\n          \"'forEach' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n      if (arguments.length < 1) {\n        throw new globalObject.TypeError(\n          \"Failed to execute 'forEach' on 'iterable': 1 argument required, but only 0 present.\"\n        );\n      }\n      callback = Function.convert(globalObject, callback, {\n        context: \"Failed to execute 'forEach' on 'iterable': The callback provided as parameter 1\"\n      });\n      const thisArg = arguments[1];\n      let pairs = Array.from(this[implSymbol]);\n      let i = 0;\n      while (i < pairs.length) {\n        const [key, value] = pairs[i].map(utils.tryWrapperForImpl);\n        callback.call(thisArg, value, key, this);\n        pairs = Array.from(this[implSymbol]);\n        i++;\n      }\n    }\n\n    get size() {\n      const esValue = this !== null && this !== undefined ? this : globalObject;\n\n      if (!exports.is(esValue)) {\n        throw new globalObject.TypeError(\n          \"'get size' called on an object that is not a valid instance of URLSearchParams.\"\n        );\n      }\n\n      return esValue[implSymbol][\"size\"];\n    }\n  }\n  Object.defineProperties(URLSearchParams.prototype, {\n    append: { enumerable: true },\n    delete: { enumerable: true },\n    get: { enumerable: true },\n    getAll: { enumerable: true },\n    has: { enumerable: true },\n    set: { enumerable: true },\n    sort: { enumerable: true },\n    toString: { enumerable: true },\n    keys: { enumerable: true },\n    values: { enumerable: true },\n    entries: { enumerable: true },\n    forEach: { enumerable: true },\n    size: { enumerable: true },\n    [Symbol.toStringTag]: { value: \"URLSearchParams\", configurable: true },\n    [Symbol.iterator]: { value: URLSearchParams.prototype.entries, configurable: true, writable: true }\n  });\n  ctorRegistry[interfaceName] = URLSearchParams;\n\n  ctorRegistry[\"URLSearchParams Iterator\"] = Object.create(ctorRegistry[\"%IteratorPrototype%\"], {\n    [Symbol.toStringTag]: {\n      configurable: true,\n      value: \"URLSearchParams Iterator\"\n    }\n  });\n  utils.define(ctorRegistry[\"URLSearchParams Iterator\"], {\n    next() {\n      const internal = this && this[utils.iterInternalSymbol];\n      if (!internal) {\n        throw new globalObject.TypeError(\"next() called on a value that is not a URLSearchParams iterator object\");\n      }\n\n      const { target, kind, index } = internal;\n      const values = Array.from(target[implSymbol]);\n      const len = values.length;\n      if (index >= len) {\n        return newObjectInRealm(globalObject, { value: undefined, done: true });\n      }\n\n      const pair = values[index];\n      internal.index = index + 1;\n      return newObjectInRealm(globalObject, utils.iteratorResult(pair.map(utils.tryWrapperForImpl), kind));\n    }\n  });\n\n  Object.defineProperty(globalObject, interfaceName, {\n    configurable: true,\n    writable: true,\n    value: URLSearchParams\n  });\n};\n\nconst Impl = __webpack_require__(/*! ./URLSearchParams-impl.js */ \"./node_modules/whatwg-url/lib/URLSearchParams-impl.js\");\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/URLSearchParams.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/encoding.js":
/*!*************************************************!*\
  !*** ./node_modules/whatwg-url/lib/encoding.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("\nconst utf8Encoder = new TextEncoder();\nconst utf8Decoder = new TextDecoder(\"utf-8\", { ignoreBOM: true });\n\nfunction utf8Encode(string) {\n  return utf8Encoder.encode(string);\n}\n\nfunction utf8DecodeWithoutBOM(bytes) {\n  return utf8Decoder.decode(bytes);\n}\n\nmodule.exports = {\n  utf8Encode,\n  utf8DecodeWithoutBOM\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/encoding.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/infra.js":
/*!**********************************************!*\
  !*** ./node_modules/whatwg-url/lib/infra.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// Note that we take code points as JS numbers, not JS strings.\n\nfunction isASCIIDigit(c) {\n  return c >= 0x30 && c <= 0x39;\n}\n\nfunction isASCIIAlpha(c) {\n  return (c >= 0x41 && c <= 0x5A) || (c >= 0x61 && c <= 0x7A);\n}\n\nfunction isASCIIAlphanumeric(c) {\n  return isASCIIAlpha(c) || isASCIIDigit(c);\n}\n\nfunction isASCIIHex(c) {\n  return isASCIIDigit(c) || (c >= 0x41 && c <= 0x46) || (c >= 0x61 && c <= 0x66);\n}\n\nmodule.exports = {\n  isASCIIDigit,\n  isASCIIAlpha,\n  isASCIIAlphanumeric,\n  isASCIIHex\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/infra.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/percent-encoding.js":
/*!*********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/percent-encoding.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { isASCIIHex } = __webpack_require__(/*! ./infra */ \"./node_modules/whatwg-url/lib/infra.js\");\nconst { utf8Encode } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#percent-encode\nfunction percentEncode(c) {\n  let hex = c.toString(16).toUpperCase();\n  if (hex.length === 1) {\n    hex = `0${hex}`;\n  }\n\n  return `%${hex}`;\n}\n\n// https://url.spec.whatwg.org/#percent-decode\nfunction percentDecodeBytes(input) {\n  const output = new Uint8Array(input.byteLength);\n  let outputIndex = 0;\n  for (let i = 0; i < input.byteLength; ++i) {\n    const byte = input[i];\n    if (byte !== 0x25) {\n      output[outputIndex++] = byte;\n    } else if (byte === 0x25 && (!isASCIIHex(input[i + 1]) || !isASCIIHex(input[i + 2]))) {\n      output[outputIndex++] = byte;\n    } else {\n      const bytePoint = parseInt(String.fromCodePoint(input[i + 1], input[i + 2]), 16);\n      output[outputIndex++] = bytePoint;\n      i += 2;\n    }\n  }\n\n  return output.slice(0, outputIndex);\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\nfunction percentDecodeString(input) {\n  const bytes = utf8Encode(input);\n  return percentDecodeBytes(bytes);\n}\n\n// https://url.spec.whatwg.org/#c0-control-percent-encode-set\nfunction isC0ControlPercentEncode(c) {\n  return c <= 0x1F || c > 0x7E;\n}\n\n// https://url.spec.whatwg.org/#fragment-percent-encode-set\nconst extraFragmentPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"<\"), p(\">\"), p(\"`\")]);\nfunction isFragmentPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraFragmentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#query-percent-encode-set\nconst extraQueryPercentEncodeSet = new Set([p(\" \"), p(\"\\\"\"), p(\"#\"), p(\"<\"), p(\">\")]);\nfunction isQueryPercentEncode(c) {\n  return isC0ControlPercentEncode(c) || extraQueryPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#special-query-percent-encode-set\nfunction isSpecialQueryPercentEncode(c) {\n  return isQueryPercentEncode(c) || c === p(\"'\");\n}\n\n// https://url.spec.whatwg.org/#path-percent-encode-set\nconst extraPathPercentEncodeSet = new Set([p(\"?\"), p(\"`\"), p(\"{\"), p(\"}\")]);\nfunction isPathPercentEncode(c) {\n  return isQueryPercentEncode(c) || extraPathPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#userinfo-percent-encode-set\nconst extraUserinfoPercentEncodeSet =\n  new Set([p(\"/\"), p(\":\"), p(\";\"), p(\"=\"), p(\"@\"), p(\"[\"), p(\"\\\\\"), p(\"]\"), p(\"^\"), p(\"|\")]);\nfunction isUserinfoPercentEncode(c) {\n  return isPathPercentEncode(c) || extraUserinfoPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#component-percent-encode-set\nconst extraComponentPercentEncodeSet = new Set([p(\"$\"), p(\"%\"), p(\"&\"), p(\"+\"), p(\",\")]);\nfunction isComponentPercentEncode(c) {\n  return isUserinfoPercentEncode(c) || extraComponentPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#application-x-www-form-urlencoded-percent-encode-set\nconst extraURLEncodedPercentEncodeSet = new Set([p(\"!\"), p(\"'\"), p(\"(\"), p(\")\"), p(\"~\")]);\nfunction isURLEncodedPercentEncode(c) {\n  return isComponentPercentEncode(c) || extraURLEncodedPercentEncodeSet.has(c);\n}\n\n// https://url.spec.whatwg.org/#code-point-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#utf-8-percent-encode\n// Assuming encoding is always utf-8 allows us to trim one of the logic branches. TODO: support encoding.\n// The \"-Internal\" variant here has code points as JS strings. The external version used by other files has code points\n// as JS numbers, like the rest of the codebase.\nfunction utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate) {\n  const bytes = utf8Encode(codePoint);\n  let output = \"\";\n  for (const byte of bytes) {\n    // Our percentEncodePredicate operates on bytes, not code points, so this is slightly different from the spec.\n    if (!percentEncodePredicate(byte)) {\n      output += String.fromCharCode(byte);\n    } else {\n      output += percentEncode(byte);\n    }\n  }\n\n  return output;\n}\n\nfunction utf8PercentEncodeCodePoint(codePoint, percentEncodePredicate) {\n  return utf8PercentEncodeCodePointInternal(String.fromCodePoint(codePoint), percentEncodePredicate);\n}\n\n// https://url.spec.whatwg.org/#string-percent-encode-after-encoding\n// https://url.spec.whatwg.org/#string-utf-8-percent-encode\nfunction utf8PercentEncodeString(input, percentEncodePredicate, spaceAsPlus = false) {\n  let output = \"\";\n  for (const codePoint of input) {\n    if (spaceAsPlus && codePoint === \" \") {\n      output += \"+\";\n    } else {\n      output += utf8PercentEncodeCodePointInternal(codePoint, percentEncodePredicate);\n    }\n  }\n  return output;\n}\n\nmodule.exports = {\n  isC0ControlPercentEncode,\n  isFragmentPercentEncode,\n  isQueryPercentEncode,\n  isSpecialQueryPercentEncode,\n  isPathPercentEncode,\n  isUserinfoPercentEncode,\n  isURLEncodedPercentEncode,\n  percentDecodeString,\n  percentDecodeBytes,\n  utf8PercentEncodeString,\n  utf8PercentEncodeCodePoint\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/percent-encoding.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/url-state-machine.js":
/*!**********************************************************!*\
  !*** ./node_modules/whatwg-url/lib/url-state-machine.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst tr46 = __webpack_require__(/*! tr46 */ \"./node_modules/tr46/index.js\");\n\nconst infra = __webpack_require__(/*! ./infra */ \"./node_modules/whatwg-url/lib/infra.js\");\nconst { utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeString, utf8PercentEncodeCodePoint, utf8PercentEncodeString, isC0ControlPercentEncode,\n  isFragmentPercentEncode, isQueryPercentEncode, isSpecialQueryPercentEncode, isPathPercentEncode,\n  isUserinfoPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\nconst specialSchemes = {\n  ftp: 21,\n  file: null,\n  http: 80,\n  https: 443,\n  ws: 80,\n  wss: 443\n};\n\nconst failure = Symbol(\"failure\");\n\nfunction countSymbols(str) {\n  return [...str].length;\n}\n\nfunction at(input, idx) {\n  const c = input[idx];\n  return isNaN(c) ? undefined : String.fromCodePoint(c);\n}\n\nfunction isSingleDot(buffer) {\n  return buffer === \".\" || buffer.toLowerCase() === \"%2e\";\n}\n\nfunction isDoubleDot(buffer) {\n  buffer = buffer.toLowerCase();\n  return buffer === \"..\" || buffer === \"%2e.\" || buffer === \".%2e\" || buffer === \"%2e%2e\";\n}\n\nfunction isWindowsDriveLetterCodePoints(cp1, cp2) {\n  return infra.isASCIIAlpha(cp1) && (cp2 === p(\":\") || cp2 === p(\"|\"));\n}\n\nfunction isWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && (string[1] === \":\" || string[1] === \"|\");\n}\n\nfunction isNormalizedWindowsDriveLetterString(string) {\n  return string.length === 2 && infra.isASCIIAlpha(string.codePointAt(0)) && string[1] === \":\";\n}\n\nfunction containsForbiddenHostCodePoint(string) {\n  return string.search(/\\u0000|\\u0009|\\u000A|\\u000D|\\u0020|#|\\/|:|<|>|\\?|@|\\[|\\\\|\\]|\\^|\\|/u) !== -1;\n}\n\nfunction containsForbiddenDomainCodePoint(string) {\n  return containsForbiddenHostCodePoint(string) || string.search(/[\\u0000-\\u001F]|%|\\u007F/u) !== -1;\n}\n\nfunction isSpecialScheme(scheme) {\n  return specialSchemes[scheme] !== undefined;\n}\n\nfunction isSpecial(url) {\n  return isSpecialScheme(url.scheme);\n}\n\nfunction isNotSpecial(url) {\n  return !isSpecialScheme(url.scheme);\n}\n\nfunction defaultPort(scheme) {\n  return specialSchemes[scheme];\n}\n\nfunction parseIPv4Number(input) {\n  if (input === \"\") {\n    return failure;\n  }\n\n  let R = 10;\n\n  if (input.length >= 2 && input.charAt(0) === \"0\" && input.charAt(1).toLowerCase() === \"x\") {\n    input = input.substring(2);\n    R = 16;\n  } else if (input.length >= 2 && input.charAt(0) === \"0\") {\n    input = input.substring(1);\n    R = 8;\n  }\n\n  if (input === \"\") {\n    return 0;\n  }\n\n  let regex = /[^0-7]/u;\n  if (R === 10) {\n    regex = /[^0-9]/u;\n  }\n  if (R === 16) {\n    regex = /[^0-9A-Fa-f]/u;\n  }\n\n  if (regex.test(input)) {\n    return failure;\n  }\n\n  return parseInt(input, R);\n}\n\nfunction parseIPv4(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length > 1) {\n      parts.pop();\n    }\n  }\n\n  if (parts.length > 4) {\n    return failure;\n  }\n\n  const numbers = [];\n  for (const part of parts) {\n    const n = parseIPv4Number(part);\n    if (n === failure) {\n      return failure;\n    }\n\n    numbers.push(n);\n  }\n\n  for (let i = 0; i < numbers.length - 1; ++i) {\n    if (numbers[i] > 255) {\n      return failure;\n    }\n  }\n  if (numbers[numbers.length - 1] >= 256 ** (5 - numbers.length)) {\n    return failure;\n  }\n\n  let ipv4 = numbers.pop();\n  let counter = 0;\n\n  for (const n of numbers) {\n    ipv4 += n * 256 ** (3 - counter);\n    ++counter;\n  }\n\n  return ipv4;\n}\n\nfunction serializeIPv4(address) {\n  let output = \"\";\n  let n = address;\n\n  for (let i = 1; i <= 4; ++i) {\n    output = String(n % 256) + output;\n    if (i !== 4) {\n      output = `.${output}`;\n    }\n    n = Math.floor(n / 256);\n  }\n\n  return output;\n}\n\nfunction parseIPv6(input) {\n  const address = [0, 0, 0, 0, 0, 0, 0, 0];\n  let pieceIndex = 0;\n  let compress = null;\n  let pointer = 0;\n\n  input = Array.from(input, c => c.codePointAt(0));\n\n  if (input[pointer] === p(\":\")) {\n    if (input[pointer + 1] !== p(\":\")) {\n      return failure;\n    }\n\n    pointer += 2;\n    ++pieceIndex;\n    compress = pieceIndex;\n  }\n\n  while (pointer < input.length) {\n    if (pieceIndex === 8) {\n      return failure;\n    }\n\n    if (input[pointer] === p(\":\")) {\n      if (compress !== null) {\n        return failure;\n      }\n      ++pointer;\n      ++pieceIndex;\n      compress = pieceIndex;\n      continue;\n    }\n\n    let value = 0;\n    let length = 0;\n\n    while (length < 4 && infra.isASCIIHex(input[pointer])) {\n      value = value * 0x10 + parseInt(at(input, pointer), 16);\n      ++pointer;\n      ++length;\n    }\n\n    if (input[pointer] === p(\".\")) {\n      if (length === 0) {\n        return failure;\n      }\n\n      pointer -= length;\n\n      if (pieceIndex > 6) {\n        return failure;\n      }\n\n      let numbersSeen = 0;\n\n      while (input[pointer] !== undefined) {\n        let ipv4Piece = null;\n\n        if (numbersSeen > 0) {\n          if (input[pointer] === p(\".\") && numbersSeen < 4) {\n            ++pointer;\n          } else {\n            return failure;\n          }\n        }\n\n        if (!infra.isASCIIDigit(input[pointer])) {\n          return failure;\n        }\n\n        while (infra.isASCIIDigit(input[pointer])) {\n          const number = parseInt(at(input, pointer));\n          if (ipv4Piece === null) {\n            ipv4Piece = number;\n          } else if (ipv4Piece === 0) {\n            return failure;\n          } else {\n            ipv4Piece = ipv4Piece * 10 + number;\n          }\n          if (ipv4Piece > 255) {\n            return failure;\n          }\n          ++pointer;\n        }\n\n        address[pieceIndex] = address[pieceIndex] * 0x100 + ipv4Piece;\n\n        ++numbersSeen;\n\n        if (numbersSeen === 2 || numbersSeen === 4) {\n          ++pieceIndex;\n        }\n      }\n\n      if (numbersSeen !== 4) {\n        return failure;\n      }\n\n      break;\n    } else if (input[pointer] === p(\":\")) {\n      ++pointer;\n      if (input[pointer] === undefined) {\n        return failure;\n      }\n    } else if (input[pointer] !== undefined) {\n      return failure;\n    }\n\n    address[pieceIndex] = value;\n    ++pieceIndex;\n  }\n\n  if (compress !== null) {\n    let swaps = pieceIndex - compress;\n    pieceIndex = 7;\n    while (pieceIndex !== 0 && swaps > 0) {\n      const temp = address[compress + swaps - 1];\n      address[compress + swaps - 1] = address[pieceIndex];\n      address[pieceIndex] = temp;\n      --pieceIndex;\n      --swaps;\n    }\n  } else if (compress === null && pieceIndex !== 8) {\n    return failure;\n  }\n\n  return address;\n}\n\nfunction serializeIPv6(address) {\n  let output = \"\";\n  const compress = findLongestZeroSequence(address);\n  let ignore0 = false;\n\n  for (let pieceIndex = 0; pieceIndex <= 7; ++pieceIndex) {\n    if (ignore0 && address[pieceIndex] === 0) {\n      continue;\n    } else if (ignore0) {\n      ignore0 = false;\n    }\n\n    if (compress === pieceIndex) {\n      const separator = pieceIndex === 0 ? \"::\" : \":\";\n      output += separator;\n      ignore0 = true;\n      continue;\n    }\n\n    output += address[pieceIndex].toString(16);\n\n    if (pieceIndex !== 7) {\n      output += \":\";\n    }\n  }\n\n  return output;\n}\n\nfunction parseHost(input, isNotSpecialArg = false) {\n  if (input[0] === \"[\") {\n    if (input[input.length - 1] !== \"]\") {\n      return failure;\n    }\n\n    return parseIPv6(input.substring(1, input.length - 1));\n  }\n\n  if (isNotSpecialArg) {\n    return parseOpaqueHost(input);\n  }\n\n  const domain = utf8DecodeWithoutBOM(percentDecodeString(input));\n  const asciiDomain = domainToASCII(domain);\n  if (asciiDomain === failure) {\n    return failure;\n  }\n\n  if (containsForbiddenDomainCodePoint(asciiDomain)) {\n    return failure;\n  }\n\n  if (endsInANumber(asciiDomain)) {\n    return parseIPv4(asciiDomain);\n  }\n\n  return asciiDomain;\n}\n\nfunction endsInANumber(input) {\n  const parts = input.split(\".\");\n  if (parts[parts.length - 1] === \"\") {\n    if (parts.length === 1) {\n      return false;\n    }\n    parts.pop();\n  }\n\n  const last = parts[parts.length - 1];\n  if (parseIPv4Number(last) !== failure) {\n    return true;\n  }\n\n  if (/^[0-9]+$/u.test(last)) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction parseOpaqueHost(input) {\n  if (containsForbiddenHostCodePoint(input)) {\n    return failure;\n  }\n\n  return utf8PercentEncodeString(input, isC0ControlPercentEncode);\n}\n\nfunction findLongestZeroSequence(arr) {\n  let maxIdx = null;\n  let maxLen = 1; // only find elements > 1\n  let currStart = null;\n  let currLen = 0;\n\n  for (let i = 0; i < arr.length; ++i) {\n    if (arr[i] !== 0) {\n      if (currLen > maxLen) {\n        maxIdx = currStart;\n        maxLen = currLen;\n      }\n\n      currStart = null;\n      currLen = 0;\n    } else {\n      if (currStart === null) {\n        currStart = i;\n      }\n      ++currLen;\n    }\n  }\n\n  // if trailing zeros\n  if (currLen > maxLen) {\n    return currStart;\n  }\n\n  return maxIdx;\n}\n\nfunction serializeHost(host) {\n  if (typeof host === \"number\") {\n    return serializeIPv4(host);\n  }\n\n  // IPv6 serializer\n  if (host instanceof Array) {\n    return `[${serializeIPv6(host)}]`;\n  }\n\n  return host;\n}\n\nfunction domainToASCII(domain, beStrict = false) {\n  const result = tr46.toASCII(domain, {\n    checkBidi: true,\n    checkHyphens: false,\n    checkJoiners: true,\n    useSTD3ASCIIRules: beStrict,\n    verifyDNSLength: beStrict\n  });\n  if (result === null || result === \"\") {\n    return failure;\n  }\n  return result;\n}\n\nfunction trimControlChars(url) {\n  return url.replace(/^[\\u0000-\\u001F\\u0020]+|[\\u0000-\\u001F\\u0020]+$/ug, \"\");\n}\n\nfunction trimTabAndNewline(url) {\n  return url.replace(/\\u0009|\\u000A|\\u000D/ug, \"\");\n}\n\nfunction shortenPath(url) {\n  const { path } = url;\n  if (path.length === 0) {\n    return;\n  }\n  if (url.scheme === \"file\" && path.length === 1 && isNormalizedWindowsDriveLetter(path[0])) {\n    return;\n  }\n\n  path.pop();\n}\n\nfunction includesCredentials(url) {\n  return url.username !== \"\" || url.password !== \"\";\n}\n\nfunction cannotHaveAUsernamePasswordPort(url) {\n  return url.host === null || url.host === \"\" || url.scheme === \"file\";\n}\n\nfunction hasAnOpaquePath(url) {\n  return typeof url.path === \"string\";\n}\n\nfunction isNormalizedWindowsDriveLetter(string) {\n  return /^[A-Za-z]:$/u.test(string);\n}\n\nfunction URLStateMachine(input, base, encodingOverride, url, stateOverride) {\n  this.pointer = 0;\n  this.input = input;\n  this.base = base || null;\n  this.encodingOverride = encodingOverride || \"utf-8\";\n  this.stateOverride = stateOverride;\n  this.url = url;\n  this.failure = false;\n  this.parseError = false;\n\n  if (!this.url) {\n    this.url = {\n      scheme: \"\",\n      username: \"\",\n      password: \"\",\n      host: null,\n      port: null,\n      path: [],\n      query: null,\n      fragment: null\n    };\n\n    const res = trimControlChars(this.input);\n    if (res !== this.input) {\n      this.parseError = true;\n    }\n    this.input = res;\n  }\n\n  const res = trimTabAndNewline(this.input);\n  if (res !== this.input) {\n    this.parseError = true;\n  }\n  this.input = res;\n\n  this.state = stateOverride || \"scheme start\";\n\n  this.buffer = \"\";\n  this.atFlag = false;\n  this.arrFlag = false;\n  this.passwordTokenSeenFlag = false;\n\n  this.input = Array.from(this.input, c => c.codePointAt(0));\n\n  for (; this.pointer <= this.input.length; ++this.pointer) {\n    const c = this.input[this.pointer];\n    const cStr = isNaN(c) ? undefined : String.fromCodePoint(c);\n\n    // exec state machine\n    const ret = this[`parse ${this.state}`](c, cStr);\n    if (!ret) {\n      break; // terminate algorithm\n    } else if (ret === failure) {\n      this.failure = true;\n      break;\n    }\n  }\n}\n\nURLStateMachine.prototype[\"parse scheme start\"] = function parseSchemeStart(c, cStr) {\n  if (infra.isASCIIAlpha(c)) {\n    this.buffer += cStr.toLowerCase();\n    this.state = \"scheme\";\n  } else if (!this.stateOverride) {\n    this.state = \"no scheme\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse scheme\"] = function parseScheme(c, cStr) {\n  if (infra.isASCIIAlphanumeric(c) || c === p(\"+\") || c === p(\"-\") || c === p(\".\")) {\n    this.buffer += cStr.toLowerCase();\n  } else if (c === p(\":\")) {\n    if (this.stateOverride) {\n      if (isSpecial(this.url) && !isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if (!isSpecial(this.url) && isSpecialScheme(this.buffer)) {\n        return false;\n      }\n\n      if ((includesCredentials(this.url) || this.url.port !== null) && this.buffer === \"file\") {\n        return false;\n      }\n\n      if (this.url.scheme === \"file\" && this.url.host === \"\") {\n        return false;\n      }\n    }\n    this.url.scheme = this.buffer;\n    if (this.stateOverride) {\n      if (this.url.port === defaultPort(this.url.scheme)) {\n        this.url.port = null;\n      }\n      return false;\n    }\n    this.buffer = \"\";\n    if (this.url.scheme === \"file\") {\n      if (this.input[this.pointer + 1] !== p(\"/\") || this.input[this.pointer + 2] !== p(\"/\")) {\n        this.parseError = true;\n      }\n      this.state = \"file\";\n    } else if (isSpecial(this.url) && this.base !== null && this.base.scheme === this.url.scheme) {\n      this.state = \"special relative or authority\";\n    } else if (isSpecial(this.url)) {\n      this.state = \"special authority slashes\";\n    } else if (this.input[this.pointer + 1] === p(\"/\")) {\n      this.state = \"path or authority\";\n      ++this.pointer;\n    } else {\n      this.url.path = \"\";\n      this.state = \"opaque path\";\n    }\n  } else if (!this.stateOverride) {\n    this.buffer = \"\";\n    this.state = \"no scheme\";\n    this.pointer = -1;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse no scheme\"] = function parseNoScheme(c) {\n  if (this.base === null || (hasAnOpaquePath(this.base) && c !== p(\"#\"))) {\n    return failure;\n  } else if (hasAnOpaquePath(this.base) && c === p(\"#\")) {\n    this.url.scheme = this.base.scheme;\n    this.url.path = this.base.path;\n    this.url.query = this.base.query;\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (this.base.scheme === \"file\") {\n    this.state = \"file\";\n    --this.pointer;\n  } else {\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special relative or authority\"] = function parseSpecialRelativeOrAuthority(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"relative\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path or authority\"] = function parsePathOrAuthority(c) {\n  if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative\"] = function parseRelative(c) {\n  this.url.scheme = this.base.scheme;\n  if (c === p(\"/\")) {\n    this.state = \"relative slash\";\n  } else if (isSpecial(this.url) && c === p(\"\\\\\")) {\n    this.parseError = true;\n    this.state = \"relative slash\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      this.url.path.pop();\n      this.state = \"path\";\n      --this.pointer;\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse relative slash\"] = function parseRelativeSlash(c) {\n  if (isSpecial(this.url) && (c === p(\"/\") || c === p(\"\\\\\"))) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"special authority ignore slashes\";\n  } else if (c === p(\"/\")) {\n    this.state = \"authority\";\n  } else {\n    this.url.username = this.base.username;\n    this.url.password = this.base.password;\n    this.url.host = this.base.host;\n    this.url.port = this.base.port;\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority slashes\"] = function parseSpecialAuthoritySlashes(c) {\n  if (c === p(\"/\") && this.input[this.pointer + 1] === p(\"/\")) {\n    this.state = \"special authority ignore slashes\";\n    ++this.pointer;\n  } else {\n    this.parseError = true;\n    this.state = \"special authority ignore slashes\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse special authority ignore slashes\"] = function parseSpecialAuthorityIgnoreSlashes(c) {\n  if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n    this.state = \"authority\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse authority\"] = function parseAuthority(c, cStr) {\n  if (c === p(\"@\")) {\n    this.parseError = true;\n    if (this.atFlag) {\n      this.buffer = `%40${this.buffer}`;\n    }\n    this.atFlag = true;\n\n    // careful, this is based on buffer and has its own pointer (this.pointer != pointer) and inner chars\n    const len = countSymbols(this.buffer);\n    for (let pointer = 0; pointer < len; ++pointer) {\n      const codePoint = this.buffer.codePointAt(pointer);\n\n      if (codePoint === p(\":\") && !this.passwordTokenSeenFlag) {\n        this.passwordTokenSeenFlag = true;\n        continue;\n      }\n      const encodedCodePoints = utf8PercentEncodeCodePoint(codePoint, isUserinfoPercentEncode);\n      if (this.passwordTokenSeenFlag) {\n        this.url.password += encodedCodePoints;\n      } else {\n        this.url.username += encodedCodePoints;\n      }\n    }\n    this.buffer = \"\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    if (this.atFlag && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n    this.pointer -= countSymbols(this.buffer) + 1;\n    this.buffer = \"\";\n    this.state = \"host\";\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse hostname\"] =\nURLStateMachine.prototype[\"parse host\"] = function parseHostName(c, cStr) {\n  if (this.stateOverride && this.url.scheme === \"file\") {\n    --this.pointer;\n    this.state = \"file host\";\n  } else if (c === p(\":\") && !this.arrFlag) {\n    if (this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    }\n\n    if (this.stateOverride === \"hostname\") {\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"port\";\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\"))) {\n    --this.pointer;\n    if (isSpecial(this.url) && this.buffer === \"\") {\n      this.parseError = true;\n      return failure;\n    } else if (this.stateOverride && this.buffer === \"\" &&\n               (includesCredentials(this.url) || this.url.port !== null)) {\n      this.parseError = true;\n      return false;\n    }\n\n    const host = parseHost(this.buffer, isNotSpecial(this.url));\n    if (host === failure) {\n      return failure;\n    }\n\n    this.url.host = host;\n    this.buffer = \"\";\n    this.state = \"path start\";\n    if (this.stateOverride) {\n      return false;\n    }\n  } else {\n    if (c === p(\"[\")) {\n      this.arrFlag = true;\n    } else if (c === p(\"]\")) {\n      this.arrFlag = false;\n    }\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse port\"] = function parsePort(c, cStr) {\n  if (infra.isASCIIDigit(c)) {\n    this.buffer += cStr;\n  } else if (isNaN(c) || c === p(\"/\") || c === p(\"?\") || c === p(\"#\") ||\n             (isSpecial(this.url) && c === p(\"\\\\\")) ||\n             this.stateOverride) {\n    if (this.buffer !== \"\") {\n      const port = parseInt(this.buffer);\n      if (port > 2 ** 16 - 1) {\n        this.parseError = true;\n        return failure;\n      }\n      this.url.port = port === defaultPort(this.url.scheme) ? null : port;\n      this.buffer = \"\";\n    }\n    if (this.stateOverride) {\n      return false;\n    }\n    this.state = \"path start\";\n    --this.pointer;\n  } else {\n    this.parseError = true;\n    return failure;\n  }\n\n  return true;\n};\n\nconst fileOtherwiseCodePoints = new Set([p(\"/\"), p(\"\\\\\"), p(\"?\"), p(\"#\")]);\n\nfunction startsWithWindowsDriveLetter(input, pointer) {\n  const length = input.length - pointer;\n  return length >= 2 &&\n    isWindowsDriveLetterCodePoints(input[pointer], input[pointer + 1]) &&\n    (length === 2 || fileOtherwiseCodePoints.has(input[pointer + 2]));\n}\n\nURLStateMachine.prototype[\"parse file\"] = function parseFile(c) {\n  this.url.scheme = \"file\";\n  this.url.host = \"\";\n\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file slash\";\n  } else if (this.base !== null && this.base.scheme === \"file\") {\n    this.url.host = this.base.host;\n    this.url.path = this.base.path.slice();\n    this.url.query = this.base.query;\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    } else if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    } else if (!isNaN(c)) {\n      this.url.query = null;\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer)) {\n        shortenPath(this.url);\n      } else {\n        this.parseError = true;\n        this.url.path = [];\n      }\n\n      this.state = \"path\";\n      --this.pointer;\n    }\n  } else {\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file slash\"] = function parseFileSlash(c) {\n  if (c === p(\"/\") || c === p(\"\\\\\")) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"file host\";\n  } else {\n    if (this.base !== null && this.base.scheme === \"file\") {\n      if (!startsWithWindowsDriveLetter(this.input, this.pointer) &&\n          isNormalizedWindowsDriveLetterString(this.base.path[0])) {\n        this.url.path.push(this.base.path[0]);\n      }\n      this.url.host = this.base.host;\n    }\n    this.state = \"path\";\n    --this.pointer;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse file host\"] = function parseFileHost(c, cStr) {\n  if (isNaN(c) || c === p(\"/\") || c === p(\"\\\\\") || c === p(\"?\") || c === p(\"#\")) {\n    --this.pointer;\n    if (!this.stateOverride && isWindowsDriveLetterString(this.buffer)) {\n      this.parseError = true;\n      this.state = \"path\";\n    } else if (this.buffer === \"\") {\n      this.url.host = \"\";\n      if (this.stateOverride) {\n        return false;\n      }\n      this.state = \"path start\";\n    } else {\n      let host = parseHost(this.buffer, isNotSpecial(this.url));\n      if (host === failure) {\n        return failure;\n      }\n      if (host === \"localhost\") {\n        host = \"\";\n      }\n      this.url.host = host;\n\n      if (this.stateOverride) {\n        return false;\n      }\n\n      this.buffer = \"\";\n      this.state = \"path start\";\n    }\n  } else {\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path start\"] = function parsePathStart(c) {\n  if (isSpecial(this.url)) {\n    if (c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n    this.state = \"path\";\n\n    if (c !== p(\"/\") && c !== p(\"\\\\\")) {\n      --this.pointer;\n    }\n  } else if (!this.stateOverride && c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (!this.stateOverride && c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else if (c !== undefined) {\n    this.state = \"path\";\n    if (c !== p(\"/\")) {\n      --this.pointer;\n    }\n  } else if (this.stateOverride && this.url.host === null) {\n    this.url.path.push(\"\");\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse path\"] = function parsePath(c) {\n  if (isNaN(c) || c === p(\"/\") || (isSpecial(this.url) && c === p(\"\\\\\")) ||\n      (!this.stateOverride && (c === p(\"?\") || c === p(\"#\")))) {\n    if (isSpecial(this.url) && c === p(\"\\\\\")) {\n      this.parseError = true;\n    }\n\n    if (isDoubleDot(this.buffer)) {\n      shortenPath(this.url);\n      if (c !== p(\"/\") && !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n        this.url.path.push(\"\");\n      }\n    } else if (isSingleDot(this.buffer) && c !== p(\"/\") &&\n               !(isSpecial(this.url) && c === p(\"\\\\\"))) {\n      this.url.path.push(\"\");\n    } else if (!isSingleDot(this.buffer)) {\n      if (this.url.scheme === \"file\" && this.url.path.length === 0 && isWindowsDriveLetterString(this.buffer)) {\n        this.buffer = `${this.buffer[0]}:`;\n      }\n      this.url.path.push(this.buffer);\n    }\n    this.buffer = \"\";\n    if (c === p(\"?\")) {\n      this.url.query = \"\";\n      this.state = \"query\";\n    }\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += utf8PercentEncodeCodePoint(c, isPathPercentEncode);\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse opaque path\"] = function parseOpaquePath(c) {\n  if (c === p(\"?\")) {\n    this.url.query = \"\";\n    this.state = \"query\";\n  } else if (c === p(\"#\")) {\n    this.url.fragment = \"\";\n    this.state = \"fragment\";\n  } else {\n    // TODO: Add: not a URL code point\n    if (!isNaN(c) && c !== p(\"%\")) {\n      this.parseError = true;\n    }\n\n    if (c === p(\"%\") &&\n        (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n         !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    if (!isNaN(c)) {\n      this.url.path += utf8PercentEncodeCodePoint(c, isC0ControlPercentEncode);\n    }\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse query\"] = function parseQuery(c, cStr) {\n  if (!isSpecial(this.url) || this.url.scheme === \"ws\" || this.url.scheme === \"wss\") {\n    this.encodingOverride = \"utf-8\";\n  }\n\n  if ((!this.stateOverride && c === p(\"#\")) || isNaN(c)) {\n    const queryPercentEncodePredicate = isSpecial(this.url) ? isSpecialQueryPercentEncode : isQueryPercentEncode;\n    this.url.query += utf8PercentEncodeString(this.buffer, queryPercentEncodePredicate);\n\n    this.buffer = \"\";\n\n    if (c === p(\"#\")) {\n      this.url.fragment = \"\";\n      this.state = \"fragment\";\n    }\n  } else if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.buffer += cStr;\n  }\n\n  return true;\n};\n\nURLStateMachine.prototype[\"parse fragment\"] = function parseFragment(c) {\n  if (!isNaN(c)) {\n    // TODO: If c is not a URL code point and not \"%\", parse error.\n    if (c === p(\"%\") &&\n      (!infra.isASCIIHex(this.input[this.pointer + 1]) ||\n        !infra.isASCIIHex(this.input[this.pointer + 2]))) {\n      this.parseError = true;\n    }\n\n    this.url.fragment += utf8PercentEncodeCodePoint(c, isFragmentPercentEncode);\n  }\n\n  return true;\n};\n\nfunction serializeURL(url, excludeFragment) {\n  let output = `${url.scheme}:`;\n  if (url.host !== null) {\n    output += \"//\";\n\n    if (url.username !== \"\" || url.password !== \"\") {\n      output += url.username;\n      if (url.password !== \"\") {\n        output += `:${url.password}`;\n      }\n      output += \"@\";\n    }\n\n    output += serializeHost(url.host);\n\n    if (url.port !== null) {\n      output += `:${url.port}`;\n    }\n  }\n\n  if (url.host === null && !hasAnOpaquePath(url) && url.path.length > 1 && url.path[0] === \"\") {\n    output += \"/.\";\n  }\n  output += serializePath(url);\n\n  if (url.query !== null) {\n    output += `?${url.query}`;\n  }\n\n  if (!excludeFragment && url.fragment !== null) {\n    output += `#${url.fragment}`;\n  }\n\n  return output;\n}\n\nfunction serializeOrigin(tuple) {\n  let result = `${tuple.scheme}://`;\n  result += serializeHost(tuple.host);\n\n  if (tuple.port !== null) {\n    result += `:${tuple.port}`;\n  }\n\n  return result;\n}\n\nfunction serializePath(url) {\n  if (hasAnOpaquePath(url)) {\n    return url.path;\n  }\n\n  let output = \"\";\n  for (const segment of url.path) {\n    output += `/${segment}`;\n  }\n  return output;\n}\n\nmodule.exports.serializeURL = serializeURL;\n\nmodule.exports.serializePath = serializePath;\n\nmodule.exports.serializeURLOrigin = function (url) {\n  // https://url.spec.whatwg.org/#concept-url-origin\n  switch (url.scheme) {\n    case \"blob\": {\n      const pathURL = module.exports.parseURL(serializePath(url));\n      if (pathURL === null) {\n        return \"null\";\n      }\n      if (pathURL.scheme !== \"http\" && pathURL.scheme !== \"https\") {\n        return \"null\";\n      }\n      return module.exports.serializeURLOrigin(pathURL);\n    }\n    case \"ftp\":\n    case \"http\":\n    case \"https\":\n    case \"ws\":\n    case \"wss\":\n      return serializeOrigin({\n        scheme: url.scheme,\n        host: url.host,\n        port: url.port\n      });\n    case \"file\":\n      // The spec says:\n      // > Unfortunate as it is, this is left as an exercise to the reader. When in doubt, return a new opaque origin.\n      // Browsers tested so far:\n      // - Chrome says \"file://\", but treats file: URLs as cross-origin for most (all?) purposes; see e.g.\n      //   https://bugs.chromium.org/p/chromium/issues/detail?id=37586\n      // - Firefox says \"null\", but treats file: URLs as same-origin sometimes based on directory stuff; see\n      //   https://developer.mozilla.org/en-US/docs/Archive/Misc_top_level/Same-origin_policy_for_file:_URIs\n      return \"null\";\n    default:\n      // serializing an opaque origin returns \"null\"\n      return \"null\";\n  }\n};\n\nmodule.exports.basicURLParse = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  const usm = new URLStateMachine(input, options.baseURL, options.encodingOverride, options.url, options.stateOverride);\n  if (usm.failure) {\n    return null;\n  }\n\n  return usm.url;\n};\n\nmodule.exports.setTheUsername = function (url, username) {\n  url.username = utf8PercentEncodeString(username, isUserinfoPercentEncode);\n};\n\nmodule.exports.setThePassword = function (url, password) {\n  url.password = utf8PercentEncodeString(password, isUserinfoPercentEncode);\n};\n\nmodule.exports.serializeHost = serializeHost;\n\nmodule.exports.cannotHaveAUsernamePasswordPort = cannotHaveAUsernamePasswordPort;\n\nmodule.exports.hasAnOpaquePath = hasAnOpaquePath;\n\nmodule.exports.serializeInteger = function (integer) {\n  return String(integer);\n};\n\nmodule.exports.parseURL = function (input, options) {\n  if (options === undefined) {\n    options = {};\n  }\n\n  // We don't handle blobs, so this just delegates:\n  return module.exports.basicURLParse(input, { baseURL: options.baseURL, encodingOverride: options.encodingOverride });\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/url-state-machine.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/urlencoded.js":
/*!***************************************************!*\
  !*** ./node_modules/whatwg-url/lib/urlencoded.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { utf8Encode, utf8DecodeWithoutBOM } = __webpack_require__(/*! ./encoding */ \"./node_modules/whatwg-url/lib/encoding.js\");\nconst { percentDecodeBytes, utf8PercentEncodeString, isURLEncodedPercentEncode } = __webpack_require__(/*! ./percent-encoding */ \"./node_modules/whatwg-url/lib/percent-encoding.js\");\n\nfunction p(char) {\n  return char.codePointAt(0);\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-parser\nfunction parseUrlencoded(input) {\n  const sequences = strictlySplitByteSequence(input, p(\"&\"));\n  const output = [];\n  for (const bytes of sequences) {\n    if (bytes.length === 0) {\n      continue;\n    }\n\n    let name, value;\n    const indexOfEqual = bytes.indexOf(p(\"=\"));\n\n    if (indexOfEqual >= 0) {\n      name = bytes.slice(0, indexOfEqual);\n      value = bytes.slice(indexOfEqual + 1);\n    } else {\n      name = bytes;\n      value = new Uint8Array(0);\n    }\n\n    name = replaceByteInByteSequence(name, 0x2B, 0x20);\n    value = replaceByteInByteSequence(value, 0x2B, 0x20);\n\n    const nameString = utf8DecodeWithoutBOM(percentDecodeBytes(name));\n    const valueString = utf8DecodeWithoutBOM(percentDecodeBytes(value));\n\n    output.push([nameString, valueString]);\n  }\n  return output;\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-string-parser\nfunction parseUrlencodedString(input) {\n  return parseUrlencoded(utf8Encode(input));\n}\n\n// https://url.spec.whatwg.org/#concept-urlencoded-serializer\nfunction serializeUrlencoded(tuples, encodingOverride = undefined) {\n  let encoding = \"utf-8\";\n  if (encodingOverride !== undefined) {\n    // TODO \"get the output encoding\", i.e. handle encoding labels vs. names.\n    encoding = encodingOverride;\n  }\n\n  let output = \"\";\n  for (const [i, tuple] of tuples.entries()) {\n    // TODO: handle encoding override\n\n    const name = utf8PercentEncodeString(tuple[0], isURLEncodedPercentEncode, true);\n\n    let value = tuple[1];\n    if (tuple.length > 2 && tuple[2] !== undefined) {\n      if (tuple[2] === \"hidden\" && name === \"_charset_\") {\n        value = encoding;\n      } else if (tuple[2] === \"file\") {\n        // value is a File object\n        value = value.name;\n      }\n    }\n\n    value = utf8PercentEncodeString(value, isURLEncodedPercentEncode, true);\n\n    if (i !== 0) {\n      output += \"&\";\n    }\n    output += `${name}=${value}`;\n  }\n  return output;\n}\n\nfunction strictlySplitByteSequence(buf, cp) {\n  const list = [];\n  let last = 0;\n  let i = buf.indexOf(cp);\n  while (i >= 0) {\n    list.push(buf.slice(last, i));\n    last = i + 1;\n    i = buf.indexOf(cp, last);\n  }\n  if (last !== buf.length) {\n    list.push(buf.slice(last));\n  }\n  return list;\n}\n\nfunction replaceByteInByteSequence(buf, from, to) {\n  let i = buf.indexOf(from);\n  while (i >= 0) {\n    buf[i] = to;\n    i = buf.indexOf(from, i + 1);\n  }\n  return buf;\n}\n\nmodule.exports = {\n  parseUrlencodedString,\n  serializeUrlencoded\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/urlencoded.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/lib/utils.js":
/*!**********************************************!*\
  !*** ./node_modules/whatwg-url/lib/utils.js ***!
  \**********************************************/
/***/ ((module, exports) => {

"use strict";
eval("\n\n// Returns \"Type(value) is Object\" in ES terminology.\nfunction isObject(value) {\n  return (typeof value === \"object\" && value !== null) || typeof value === \"function\";\n}\n\nconst hasOwn = Function.prototype.call.bind(Object.prototype.hasOwnProperty);\n\n// Like `Object.assign`, but using `[[GetOwnProperty]]` and `[[DefineOwnProperty]]`\n// instead of `[[Get]]` and `[[Set]]` and only allowing objects\nfunction define(target, source) {\n  for (const key of Reflect.ownKeys(source)) {\n    const descriptor = Reflect.getOwnPropertyDescriptor(source, key);\n    if (descriptor && !Reflect.defineProperty(target, key, descriptor)) {\n      throw new TypeError(`Cannot redefine property: ${String(key)}`);\n    }\n  }\n}\n\nfunction newObjectInRealm(globalObject, object) {\n  const ctorRegistry = initCtorRegistry(globalObject);\n  return Object.defineProperties(\n    Object.create(ctorRegistry[\"%Object.prototype%\"]),\n    Object.getOwnPropertyDescriptors(object)\n  );\n}\n\nconst wrapperSymbol = Symbol(\"wrapper\");\nconst implSymbol = Symbol(\"impl\");\nconst sameObjectCaches = Symbol(\"SameObject caches\");\nconst ctorRegistrySymbol = Symbol.for(\"[webidl2js] constructor registry\");\n\nconst AsyncIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf(async function* () {}).prototype);\n\nfunction initCtorRegistry(globalObject) {\n  if (hasOwn(globalObject, ctorRegistrySymbol)) {\n    return globalObject[ctorRegistrySymbol];\n  }\n\n  const ctorRegistry = Object.create(null);\n\n  // In addition to registering all the WebIDL2JS-generated types in the constructor registry,\n  // we also register a few intrinsics that we make use of in generated code, since they are not\n  // easy to grab from the globalObject variable.\n  ctorRegistry[\"%Object.prototype%\"] = globalObject.Object.prototype;\n  ctorRegistry[\"%IteratorPrototype%\"] = Object.getPrototypeOf(\n    Object.getPrototypeOf(new globalObject.Array()[Symbol.iterator]())\n  );\n\n  try {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = Object.getPrototypeOf(\n      Object.getPrototypeOf(\n        globalObject.eval(\"(async function* () {})\").prototype\n      )\n    );\n  } catch {\n    ctorRegistry[\"%AsyncIteratorPrototype%\"] = AsyncIteratorPrototype;\n  }\n\n  globalObject[ctorRegistrySymbol] = ctorRegistry;\n  return ctorRegistry;\n}\n\nfunction getSameObject(wrapper, prop, creator) {\n  if (!wrapper[sameObjectCaches]) {\n    wrapper[sameObjectCaches] = Object.create(null);\n  }\n\n  if (prop in wrapper[sameObjectCaches]) {\n    return wrapper[sameObjectCaches][prop];\n  }\n\n  wrapper[sameObjectCaches][prop] = creator();\n  return wrapper[sameObjectCaches][prop];\n}\n\nfunction wrapperForImpl(impl) {\n  return impl ? impl[wrapperSymbol] : null;\n}\n\nfunction implForWrapper(wrapper) {\n  return wrapper ? wrapper[implSymbol] : null;\n}\n\nfunction tryWrapperForImpl(impl) {\n  const wrapper = wrapperForImpl(impl);\n  return wrapper ? wrapper : impl;\n}\n\nfunction tryImplForWrapper(wrapper) {\n  const impl = implForWrapper(wrapper);\n  return impl ? impl : wrapper;\n}\n\nconst iterInternalSymbol = Symbol(\"internal\");\n\nfunction isArrayIndexPropName(P) {\n  if (typeof P !== \"string\") {\n    return false;\n  }\n  const i = P >>> 0;\n  if (i === 2 ** 32 - 1) {\n    return false;\n  }\n  const s = `${i}`;\n  if (P !== s) {\n    return false;\n  }\n  return true;\n}\n\nconst byteLengthGetter =\n    Object.getOwnPropertyDescriptor(ArrayBuffer.prototype, \"byteLength\").get;\nfunction isArrayBuffer(value) {\n  try {\n    byteLengthGetter.call(value);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\nfunction iteratorResult([key, value], kind) {\n  let result;\n  switch (kind) {\n    case \"key\":\n      result = key;\n      break;\n    case \"value\":\n      result = value;\n      break;\n    case \"key+value\":\n      result = [key, value];\n      break;\n  }\n  return { value: result, done: false };\n}\n\nconst supportsPropertyIndex = Symbol(\"supports property index\");\nconst supportedPropertyIndices = Symbol(\"supported property indices\");\nconst supportsPropertyName = Symbol(\"supports property name\");\nconst supportedPropertyNames = Symbol(\"supported property names\");\nconst indexedGet = Symbol(\"indexed property get\");\nconst indexedSetNew = Symbol(\"indexed property set new\");\nconst indexedSetExisting = Symbol(\"indexed property set existing\");\nconst namedGet = Symbol(\"named property get\");\nconst namedSetNew = Symbol(\"named property set new\");\nconst namedSetExisting = Symbol(\"named property set existing\");\nconst namedDelete = Symbol(\"named property delete\");\n\nconst asyncIteratorNext = Symbol(\"async iterator get the next iteration result\");\nconst asyncIteratorReturn = Symbol(\"async iterator return steps\");\nconst asyncIteratorInit = Symbol(\"async iterator initialization steps\");\nconst asyncIteratorEOI = Symbol(\"async iterator end of iteration\");\n\nmodule.exports = exports = {\n  isObject,\n  hasOwn,\n  define,\n  newObjectInRealm,\n  wrapperSymbol,\n  implSymbol,\n  getSameObject,\n  ctorRegistrySymbol,\n  initCtorRegistry,\n  wrapperForImpl,\n  implForWrapper,\n  tryWrapperForImpl,\n  tryImplForWrapper,\n  iterInternalSymbol,\n  isArrayBuffer,\n  isArrayIndexPropName,\n  supportsPropertyIndex,\n  supportedPropertyIndices,\n  supportsPropertyName,\n  supportedPropertyNames,\n  indexedGet,\n  indexedSetNew,\n  indexedSetExisting,\n  namedGet,\n  namedSetNew,\n  namedSetExisting,\n  namedDelete,\n  asyncIteratorNext,\n  asyncIteratorReturn,\n  asyncIteratorInit,\n  asyncIteratorEOI,\n  iteratorResult\n};\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/lib/utils.js?");

/***/ }),

/***/ "./node_modules/whatwg-url/webidl2js-wrapper.js":
/*!******************************************************!*\
  !*** ./node_modules/whatwg-url/webidl2js-wrapper.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst URL = __webpack_require__(/*! ./lib/URL */ \"./node_modules/whatwg-url/lib/URL.js\");\nconst URLSearchParams = __webpack_require__(/*! ./lib/URLSearchParams */ \"./node_modules/whatwg-url/lib/URLSearchParams.js\");\n\nexports.URL = URL;\nexports.URLSearchParams = URLSearchParams;\n\n\n//# sourceURL=webpack://oracle2/./node_modules/whatwg-url/webidl2js-wrapper.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var uuid__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! uuid */ \"./node_modules/uuid/dist/esm-browser/v4.js\");\n(__webpack_require__(/*! dotenv */ \"./node_modules/dotenv/lib/main.js\").config)()\n;\n\n// Initialize database\nconst { MongoClient } = __webpack_require__(/*! mongodb */ \"./node_modules/mongodb/lib/index.js\")\nconst uri = process.env.MONGO_URL\nconst client = new MongoClient(uri)\nconst db = client.db('Oracle')\nconst trials = db.collection('trials')\n\n// Initialize variables\nvar index = 0\nvar data = {}\nvar plog = '' // prediction log\nvar klog = '' // keypresses log\nvar correct = 0\nvar time = 0\nvar delay = 0\nvar uuid = (0,uuid__WEBPACK_IMPORTED_MODULE_0__[\"default\"])()\n\nasync function updateTrial(decision) {\n    console.log(\"here\")\n    const trial = await trials.findOne({ uuid: uuid })\n    console.log(trial)\n    if (trial) {\n        var data = [decision]\n        trials.updateOne({ uuid: uuid }, { data: data })\n    }\n    else { // Create trial if it does not exist \n        const trial = {\n            data: [],\n            uuid: uuid,\n            timestamp: Date.now(),\n        }\n        const result = await trials.insertOne(trial)\n    }\n}\n\n// Orignal Aaronson Oracle\ndocument.addEventListener('keydown', function(event) {\n    // Ignore all other keypresses\n    if (!(event.key == 'ArrowLeft' || event.key == 'ArrowRight')) return\n\n    // Initialize timer and track delays between presses\n    if (time == 0) {\n        time = Date.now()\n    } \n    else {\n        delay = Date.now() - time\n        time = Date.now()\n    }\n\n    // Make a prediction before the user makes their move\n    let prediction\n    let prev4 = klog.slice(index - 4, index)\n\n    if (index > 3 && prev4 in data) {\n        if (data[prev4].L > data[prev4].R) {\n            prediction = 'L'\n        }\n        else if (data[prev4].L < data[prev4].R) {\n            prediction = 'R'\n        }\n        else {\n            prediction = ['L', 'R'][Math.floor(Math.random() * 2)] // duplicate code\n        }\n    }\n    else {\n        prediction = ['L', 'R'][Math.floor(Math.random() * 2)]    // duplicate code\n    }\n    plog += prediction\n\n    // Log the user's decision\n    let keypress\n\n    if (event.key == 'ArrowLeft') {\n        index += 1\n        keypress = 'L'\n    }\n    else if (event.key == 'ArrowRight') {\n        index += 1\n        keypress = 'R'\n    }\n    klog += keypress \n\n    // Update predictions with most recent sequence\n    if (index > 3) {\n        if (prev4 in data) {\n            data[prev4][keypress] += 1\n        }\n        else {\n            data[prev4] = {L: 0, R: 0}\n            data[prev4][keypress] += 1\n        }\n    }\n\n    // Update trial in database\n    var decision = {\n        keypress: keypress,\n        delay: delay\n    }\n    updateTrial(decision)\n\n    // Calculate average for correct predictions\n    if (keypress == prediction) {\n        correct += 1\n    }\n    let average = (correct / index) * 100\n\n    // Add spaces between for readability\n    document.getElementById('predictions').textContent = plog.split('').join(' ')\n    document.getElementById('keypresses').textContent = klog.split('').join(' ')\n    document.getElementById('average').textContent = Math.floor(average) + \"%\"\n});\n\n\n//# sourceURL=webpack://oracle2/./src/index.js?");

/***/ }),

/***/ "../../node_modules/aws4/aws4.js":
/*!***************************************!*\
  !*** ../../node_modules/aws4/aws4.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var aws4 = exports,\n    url = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'url'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())),\n    querystring = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'querystring'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())),\n    crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())),\n    lru = __webpack_require__(/*! ./lru */ \"../../node_modules/aws4/lru.js\"),\n    credentialsCache = lru(1000)\n\n// http://docs.amazonwebservices.com/general/latest/gr/signature-version-4.html\n\nfunction hmac(key, string, encoding) {\n  return crypto.createHmac('sha256', key).update(string, 'utf8').digest(encoding)\n}\n\nfunction hash(string, encoding) {\n  return crypto.createHash('sha256').update(string, 'utf8').digest(encoding)\n}\n\n// This function assumes the string has already been percent encoded\nfunction encodeRfc3986(urlEncodedString) {\n  return urlEncodedString.replace(/[!'()*]/g, function(c) {\n    return '%' + c.charCodeAt(0).toString(16).toUpperCase()\n  })\n}\n\nfunction encodeRfc3986Full(str) {\n  return encodeRfc3986(encodeURIComponent(str))\n}\n\n// A bit of a combination of:\n// https://github.com/aws/aws-sdk-java-v2/blob/dc695de6ab49ad03934e1b02e7263abbd2354be0/core/auth/src/main/java/software/amazon/awssdk/auth/signer/internal/AbstractAws4Signer.java#L59\n// https://github.com/aws/aws-sdk-js/blob/18cb7e5b463b46239f9fdd4a65e2ff8c81831e8f/lib/signers/v4.js#L191-L199\n// https://github.com/mhart/aws4fetch/blob/b3aed16b6f17384cf36ea33bcba3c1e9f3bdfefd/src/main.js#L25-L34\nvar HEADERS_TO_IGNORE = {\n  'authorization': true,\n  'connection': true,\n  'x-amzn-trace-id': true,\n  'user-agent': true,\n  'expect': true,\n  'presigned-expires': true,\n  'range': true,\n}\n\n// request: { path | body, [host], [method], [headers], [service], [region] }\n// credentials: { accessKeyId, secretAccessKey, [sessionToken] }\nfunction RequestSigner(request, credentials) {\n\n  if (typeof request === 'string') request = url.parse(request)\n\n  var headers = request.headers = (request.headers || {}),\n      hostParts = (!this.service || !this.region) && this.matchHost(request.hostname || request.host || headers.Host || headers.host)\n\n  this.request = request\n  this.credentials = credentials || this.defaultCredentials()\n\n  this.service = request.service || hostParts[0] || ''\n  this.region = request.region || hostParts[1] || 'us-east-1'\n\n  // SES uses a different domain from the service name\n  if (this.service === 'email') this.service = 'ses'\n\n  if (!request.method && request.body)\n    request.method = 'POST'\n\n  if (!headers.Host && !headers.host) {\n    headers.Host = request.hostname || request.host || this.createHost()\n\n    // If a port is specified explicitly, use it as is\n    if (request.port)\n      headers.Host += ':' + request.port\n  }\n  if (!request.hostname && !request.host)\n    request.hostname = headers.Host || headers.host\n\n  this.isCodeCommitGit = this.service === 'codecommit' && request.method === 'GIT'\n\n  this.extraHeadersToIgnore = request.extraHeadersToIgnore || Object.create(null)\n  this.extraHeadersToInclude = request.extraHeadersToInclude || Object.create(null)\n}\n\nRequestSigner.prototype.matchHost = function(host) {\n  var match = (host || '').match(/([^\\.]+)\\.(?:([^\\.]*)\\.)?amazonaws\\.com(\\.cn)?$/)\n  var hostParts = (match || []).slice(1, 3)\n\n  // ES's hostParts are sometimes the other way round, if the value that is expected\n  // to be region equals es switch them back\n  // e.g. search-cluster-name-aaaa00aaaa0aaa0aaaaaaa0aaa.us-east-1.es.amazonaws.com\n  if (hostParts[1] === 'es' || hostParts[1] === 'aoss')\n    hostParts = hostParts.reverse()\n\n  if (hostParts[1] == 's3') {\n    hostParts[0] = 's3'\n    hostParts[1] = 'us-east-1'\n  } else {\n    for (var i = 0; i < 2; i++) {\n      if (/^s3-/.test(hostParts[i])) {\n        hostParts[1] = hostParts[i].slice(3)\n        hostParts[0] = 's3'\n        break\n      }\n    }\n  }\n\n  return hostParts\n}\n\n// http://docs.aws.amazon.com/general/latest/gr/rande.html\nRequestSigner.prototype.isSingleRegion = function() {\n  // Special case for S3 and SimpleDB in us-east-1\n  if (['s3', 'sdb'].indexOf(this.service) >= 0 && this.region === 'us-east-1') return true\n\n  return ['cloudfront', 'ls', 'route53', 'iam', 'importexport', 'sts']\n    .indexOf(this.service) >= 0\n}\n\nRequestSigner.prototype.createHost = function() {\n  var region = this.isSingleRegion() ? '' : '.' + this.region,\n      subdomain = this.service === 'ses' ? 'email' : this.service\n  return subdomain + region + '.amazonaws.com'\n}\n\nRequestSigner.prototype.prepareRequest = function() {\n  this.parsePath()\n\n  var request = this.request, headers = request.headers, query\n\n  if (request.signQuery) {\n\n    this.parsedPath.query = query = this.parsedPath.query || {}\n\n    if (this.credentials.sessionToken)\n      query['X-Amz-Security-Token'] = this.credentials.sessionToken\n\n    if (this.service === 's3' && !query['X-Amz-Expires'])\n      query['X-Amz-Expires'] = 86400\n\n    if (query['X-Amz-Date'])\n      this.datetime = query['X-Amz-Date']\n    else\n      query['X-Amz-Date'] = this.getDateTime()\n\n    query['X-Amz-Algorithm'] = 'AWS4-HMAC-SHA256'\n    query['X-Amz-Credential'] = this.credentials.accessKeyId + '/' + this.credentialString()\n    query['X-Amz-SignedHeaders'] = this.signedHeaders()\n\n  } else {\n\n    if (!request.doNotModifyHeaders && !this.isCodeCommitGit) {\n      if (request.body && !headers['Content-Type'] && !headers['content-type'])\n        headers['Content-Type'] = 'application/x-www-form-urlencoded; charset=utf-8'\n\n      if (request.body && !headers['Content-Length'] && !headers['content-length'])\n        headers['Content-Length'] = Buffer.byteLength(request.body)\n\n      if (this.credentials.sessionToken && !headers['X-Amz-Security-Token'] && !headers['x-amz-security-token'])\n        headers['X-Amz-Security-Token'] = this.credentials.sessionToken\n\n      if (this.service === 's3' && !headers['X-Amz-Content-Sha256'] && !headers['x-amz-content-sha256'])\n        headers['X-Amz-Content-Sha256'] = hash(this.request.body || '', 'hex')\n\n      if (headers['X-Amz-Date'] || headers['x-amz-date'])\n        this.datetime = headers['X-Amz-Date'] || headers['x-amz-date']\n      else\n        headers['X-Amz-Date'] = this.getDateTime()\n    }\n\n    delete headers.Authorization\n    delete headers.authorization\n  }\n}\n\nRequestSigner.prototype.sign = function() {\n  if (!this.parsedPath) this.prepareRequest()\n\n  if (this.request.signQuery) {\n    this.parsedPath.query['X-Amz-Signature'] = this.signature()\n  } else {\n    this.request.headers.Authorization = this.authHeader()\n  }\n\n  this.request.path = this.formatPath()\n\n  return this.request\n}\n\nRequestSigner.prototype.getDateTime = function() {\n  if (!this.datetime) {\n    var headers = this.request.headers,\n      date = new Date(headers.Date || headers.date || new Date)\n\n    this.datetime = date.toISOString().replace(/[:\\-]|\\.\\d{3}/g, '')\n\n    // Remove the trailing 'Z' on the timestamp string for CodeCommit git access\n    if (this.isCodeCommitGit) this.datetime = this.datetime.slice(0, -1)\n  }\n  return this.datetime\n}\n\nRequestSigner.prototype.getDate = function() {\n  return this.getDateTime().substr(0, 8)\n}\n\nRequestSigner.prototype.authHeader = function() {\n  return [\n    'AWS4-HMAC-SHA256 Credential=' + this.credentials.accessKeyId + '/' + this.credentialString(),\n    'SignedHeaders=' + this.signedHeaders(),\n    'Signature=' + this.signature(),\n  ].join(', ')\n}\n\nRequestSigner.prototype.signature = function() {\n  var date = this.getDate(),\n      cacheKey = [this.credentials.secretAccessKey, date, this.region, this.service].join(),\n      kDate, kRegion, kService, kCredentials = credentialsCache.get(cacheKey)\n  if (!kCredentials) {\n    kDate = hmac('AWS4' + this.credentials.secretAccessKey, date)\n    kRegion = hmac(kDate, this.region)\n    kService = hmac(kRegion, this.service)\n    kCredentials = hmac(kService, 'aws4_request')\n    credentialsCache.set(cacheKey, kCredentials)\n  }\n  return hmac(kCredentials, this.stringToSign(), 'hex')\n}\n\nRequestSigner.prototype.stringToSign = function() {\n  return [\n    'AWS4-HMAC-SHA256',\n    this.getDateTime(),\n    this.credentialString(),\n    hash(this.canonicalString(), 'hex'),\n  ].join('\\n')\n}\n\nRequestSigner.prototype.canonicalString = function() {\n  if (!this.parsedPath) this.prepareRequest()\n\n  var pathStr = this.parsedPath.path,\n      query = this.parsedPath.query,\n      headers = this.request.headers,\n      queryStr = '',\n      normalizePath = this.service !== 's3',\n      decodePath = this.service === 's3' || this.request.doNotEncodePath,\n      decodeSlashesInPath = this.service === 's3',\n      firstValOnly = this.service === 's3',\n      bodyHash\n\n  if (this.service === 's3' && this.request.signQuery) {\n    bodyHash = 'UNSIGNED-PAYLOAD'\n  } else if (this.isCodeCommitGit) {\n    bodyHash = ''\n  } else {\n    bodyHash = headers['X-Amz-Content-Sha256'] || headers['x-amz-content-sha256'] ||\n      hash(this.request.body || '', 'hex')\n  }\n\n  if (query) {\n    var reducedQuery = Object.keys(query).reduce(function(obj, key) {\n      if (!key) return obj\n      obj[encodeRfc3986Full(key)] = !Array.isArray(query[key]) ? query[key] :\n        (firstValOnly ? query[key][0] : query[key])\n      return obj\n    }, {})\n    var encodedQueryPieces = []\n    Object.keys(reducedQuery).sort().forEach(function(key) {\n      if (!Array.isArray(reducedQuery[key])) {\n        encodedQueryPieces.push(key + '=' + encodeRfc3986Full(reducedQuery[key]))\n      } else {\n        reducedQuery[key].map(encodeRfc3986Full).sort()\n          .forEach(function(val) { encodedQueryPieces.push(key + '=' + val) })\n      }\n    })\n    queryStr = encodedQueryPieces.join('&')\n  }\n  if (pathStr !== '/') {\n    if (normalizePath) pathStr = pathStr.replace(/\\/{2,}/g, '/')\n    pathStr = pathStr.split('/').reduce(function(path, piece) {\n      if (normalizePath && piece === '..') {\n        path.pop()\n      } else if (!normalizePath || piece !== '.') {\n        if (decodePath) piece = decodeURIComponent(piece.replace(/\\+/g, ' '))\n        path.push(encodeRfc3986Full(piece))\n      }\n      return path\n    }, []).join('/')\n    if (pathStr[0] !== '/') pathStr = '/' + pathStr\n    if (decodeSlashesInPath) pathStr = pathStr.replace(/%2F/g, '/')\n  }\n\n  return [\n    this.request.method || 'GET',\n    pathStr,\n    queryStr,\n    this.canonicalHeaders() + '\\n',\n    this.signedHeaders(),\n    bodyHash,\n  ].join('\\n')\n}\n\nRequestSigner.prototype.canonicalHeaders = function() {\n  var headers = this.request.headers\n  function trimAll(header) {\n    return header.toString().trim().replace(/\\s+/g, ' ')\n  }\n  return Object.keys(headers)\n    .filter(function(key) { return HEADERS_TO_IGNORE[key.toLowerCase()] == null })\n    .sort(function(a, b) { return a.toLowerCase() < b.toLowerCase() ? -1 : 1 })\n    .map(function(key) { return key.toLowerCase() + ':' + trimAll(headers[key]) })\n    .join('\\n')\n}\n\nRequestSigner.prototype.signedHeaders = function() {\n  var extraHeadersToInclude = this.extraHeadersToInclude,\n      extraHeadersToIgnore = this.extraHeadersToIgnore\n  return Object.keys(this.request.headers)\n    .map(function(key) { return key.toLowerCase() })\n    .filter(function(key) {\n      return extraHeadersToInclude[key] ||\n        (HEADERS_TO_IGNORE[key] == null && !extraHeadersToIgnore[key])\n    })\n    .sort()\n    .join(';')\n}\n\nRequestSigner.prototype.credentialString = function() {\n  return [\n    this.getDate(),\n    this.region,\n    this.service,\n    'aws4_request',\n  ].join('/')\n}\n\nRequestSigner.prototype.defaultCredentials = function() {\n  var env = process.env\n  return {\n    accessKeyId: env.AWS_ACCESS_KEY_ID || env.AWS_ACCESS_KEY,\n    secretAccessKey: env.AWS_SECRET_ACCESS_KEY || env.AWS_SECRET_KEY,\n    sessionToken: env.AWS_SESSION_TOKEN,\n  }\n}\n\nRequestSigner.prototype.parsePath = function() {\n  var path = this.request.path || '/'\n\n  // S3 doesn't always encode characters > 127 correctly and\n  // all services don't encode characters > 255 correctly\n  // So if there are non-reserved chars (and it's not already all % encoded), just encode them all\n  if (/[^0-9A-Za-z;,/?:@&=+$\\-_.!~*'()#%]/.test(path)) {\n    path = encodeURI(decodeURI(path))\n  }\n\n  var queryIx = path.indexOf('?'),\n      query = null\n\n  if (queryIx >= 0) {\n    query = querystring.parse(path.slice(queryIx + 1))\n    path = path.slice(0, queryIx)\n  }\n\n  this.parsedPath = {\n    path: path,\n    query: query,\n  }\n}\n\nRequestSigner.prototype.formatPath = function() {\n  var path = this.parsedPath.path,\n      query = this.parsedPath.query\n\n  if (!query) return path\n\n  // Services don't support empty query string keys\n  if (query[''] != null) delete query['']\n\n  return path + '?' + encodeRfc3986(querystring.stringify(query))\n}\n\naws4.RequestSigner = RequestSigner\n\naws4.sign = function(request, credentials) {\n  return new RequestSigner(request, credentials).sign()\n}\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/aws4/aws4.js?");

/***/ }),

/***/ "../../node_modules/aws4/lru.js":
/*!**************************************!*\
  !*** ../../node_modules/aws4/lru.js ***!
  \**************************************/
/***/ ((module) => {

eval("module.exports = function(size) {\n  return new LruCache(size)\n}\n\nfunction LruCache(size) {\n  this.capacity = size | 0\n  this.map = Object.create(null)\n  this.list = new DoublyLinkedList()\n}\n\nLruCache.prototype.get = function(key) {\n  var node = this.map[key]\n  if (node == null) return undefined\n  this.used(node)\n  return node.val\n}\n\nLruCache.prototype.set = function(key, val) {\n  var node = this.map[key]\n  if (node != null) {\n    node.val = val\n  } else {\n    if (!this.capacity) this.prune()\n    if (!this.capacity) return false\n    node = new DoublyLinkedNode(key, val)\n    this.map[key] = node\n    this.capacity--\n  }\n  this.used(node)\n  return true\n}\n\nLruCache.prototype.used = function(node) {\n  this.list.moveToFront(node)\n}\n\nLruCache.prototype.prune = function() {\n  var node = this.list.pop()\n  if (node != null) {\n    delete this.map[node.key]\n    this.capacity++\n  }\n}\n\n\nfunction DoublyLinkedList() {\n  this.firstNode = null\n  this.lastNode = null\n}\n\nDoublyLinkedList.prototype.moveToFront = function(node) {\n  if (this.firstNode == node) return\n\n  this.remove(node)\n\n  if (this.firstNode == null) {\n    this.firstNode = node\n    this.lastNode = node\n    node.prev = null\n    node.next = null\n  } else {\n    node.prev = null\n    node.next = this.firstNode\n    node.next.prev = node\n    this.firstNode = node\n  }\n}\n\nDoublyLinkedList.prototype.pop = function() {\n  var lastNode = this.lastNode\n  if (lastNode != null) {\n    this.remove(lastNode)\n  }\n  return lastNode\n}\n\nDoublyLinkedList.prototype.remove = function(node) {\n  if (this.firstNode == node) {\n    this.firstNode = node.next\n  } else if (node.prev != null) {\n    node.prev.next = node.next\n  }\n  if (this.lastNode == node) {\n    this.lastNode = node.prev\n  } else if (node.next != null) {\n    node.next.prev = node.prev\n  }\n}\n\n\nfunction DoublyLinkedNode(key, val) {\n  this.key = key\n  this.val = val\n  this.prev = null\n  this.next = null\n}\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/aws4/lru.js?");

/***/ }),

/***/ "../../node_modules/call-bind/callBound.js":
/*!*************************************************!*\
  !*** ../../node_modules/call-bind/callBound.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\n\nvar callBind = __webpack_require__(/*! ./ */ \"../../node_modules/call-bind/index.js\");\n\nvar $indexOf = callBind(GetIntrinsic('String.prototype.indexOf'));\n\nmodule.exports = function callBoundIntrinsic(name, allowMissing) {\n\tvar intrinsic = GetIntrinsic(name, !!allowMissing);\n\tif (typeof intrinsic === 'function' && $indexOf(name, '.prototype.') > -1) {\n\t\treturn callBind(intrinsic);\n\t}\n\treturn intrinsic;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/call-bind/callBound.js?");

/***/ }),

/***/ "../../node_modules/call-bind/index.js":
/*!*********************************************!*\
  !*** ../../node_modules/call-bind/index.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar bind = __webpack_require__(/*! function-bind */ \"../../node_modules/function-bind/index.js\");\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\nvar setFunctionLength = __webpack_require__(/*! set-function-length */ \"../../node_modules/set-function-length/index.js\");\n\nvar $TypeError = GetIntrinsic('%TypeError%');\nvar $apply = GetIntrinsic('%Function.prototype.apply%');\nvar $call = GetIntrinsic('%Function.prototype.call%');\nvar $reflectApply = GetIntrinsic('%Reflect.apply%', true) || bind.call($call, $apply);\n\nvar $defineProperty = GetIntrinsic('%Object.defineProperty%', true);\nvar $max = GetIntrinsic('%Math.max%');\n\nif ($defineProperty) {\n\ttry {\n\t\t$defineProperty({}, 'a', { value: 1 });\n\t} catch (e) {\n\t\t// IE 8 has a broken defineProperty\n\t\t$defineProperty = null;\n\t}\n}\n\nmodule.exports = function callBind(originalFunction) {\n\tif (typeof originalFunction !== 'function') {\n\t\tthrow new $TypeError('a function is required');\n\t}\n\tvar func = $reflectApply(bind, $call, arguments);\n\treturn setFunctionLength(\n\t\tfunc,\n\t\t1 + $max(0, originalFunction.length - (arguments.length - 1)),\n\t\ttrue\n\t);\n};\n\nvar applyBind = function applyBind() {\n\treturn $reflectApply(bind, $apply, arguments);\n};\n\nif ($defineProperty) {\n\t$defineProperty(module.exports, 'apply', { value: applyBind });\n} else {\n\tmodule.exports.apply = applyBind;\n}\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/call-bind/index.js?");

/***/ }),

/***/ "../../node_modules/define-data-property/index.js":
/*!********************************************************!*\
  !*** ../../node_modules/define-data-property/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hasPropertyDescriptors = __webpack_require__(/*! has-property-descriptors */ \"../../node_modules/has-property-descriptors/index.js\")();\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\n\nvar $defineProperty = hasPropertyDescriptors && GetIntrinsic('%Object.defineProperty%', true);\nif ($defineProperty) {\n\ttry {\n\t\t$defineProperty({}, 'a', { value: 1 });\n\t} catch (e) {\n\t\t// IE 8 has a broken defineProperty\n\t\t$defineProperty = false;\n\t}\n}\n\nvar $SyntaxError = GetIntrinsic('%SyntaxError%');\nvar $TypeError = GetIntrinsic('%TypeError%');\n\nvar gopd = __webpack_require__(/*! gopd */ \"../../node_modules/gopd/index.js\");\n\n/** @type {(obj: Record<PropertyKey, unknown>, property: PropertyKey, value: unknown, nonEnumerable?: boolean | null, nonWritable?: boolean | null, nonConfigurable?: boolean | null, loose?: boolean) => void} */\nmodule.exports = function defineDataProperty(\n\tobj,\n\tproperty,\n\tvalue\n) {\n\tif (!obj || (typeof obj !== 'object' && typeof obj !== 'function')) {\n\t\tthrow new $TypeError('`obj` must be an object or a function`');\n\t}\n\tif (typeof property !== 'string' && typeof property !== 'symbol') {\n\t\tthrow new $TypeError('`property` must be a string or a symbol`');\n\t}\n\tif (arguments.length > 3 && typeof arguments[3] !== 'boolean' && arguments[3] !== null) {\n\t\tthrow new $TypeError('`nonEnumerable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 4 && typeof arguments[4] !== 'boolean' && arguments[4] !== null) {\n\t\tthrow new $TypeError('`nonWritable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 5 && typeof arguments[5] !== 'boolean' && arguments[5] !== null) {\n\t\tthrow new $TypeError('`nonConfigurable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 6 && typeof arguments[6] !== 'boolean') {\n\t\tthrow new $TypeError('`loose`, if provided, must be a boolean');\n\t}\n\n\tvar nonEnumerable = arguments.length > 3 ? arguments[3] : null;\n\tvar nonWritable = arguments.length > 4 ? arguments[4] : null;\n\tvar nonConfigurable = arguments.length > 5 ? arguments[5] : null;\n\tvar loose = arguments.length > 6 ? arguments[6] : false;\n\n\t/* @type {false | TypedPropertyDescriptor<unknown>} */\n\tvar desc = !!gopd && gopd(obj, property);\n\n\tif ($defineProperty) {\n\t\t$defineProperty(obj, property, {\n\t\t\tconfigurable: nonConfigurable === null && desc ? desc.configurable : !nonConfigurable,\n\t\t\tenumerable: nonEnumerable === null && desc ? desc.enumerable : !nonEnumerable,\n\t\t\tvalue: value,\n\t\t\twritable: nonWritable === null && desc ? desc.writable : !nonWritable\n\t\t});\n\t} else if (loose || (!nonEnumerable && !nonWritable && !nonConfigurable)) {\n\t\t// must fall back to [[Set]], and was not explicitly asked to make non-enumerable, non-writable, or non-configurable\n\t\tobj[property] = value; // eslint-disable-line no-param-reassign\n\t} else {\n\t\tthrow new $SyntaxError('This environment does not support defining a property as non-configurable, non-writable, or non-enumerable.');\n\t}\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/define-data-property/index.js?");

/***/ }),

/***/ "../../node_modules/for-each/index.js":
/*!********************************************!*\
  !*** ../../node_modules/for-each/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar isCallable = __webpack_require__(/*! is-callable */ \"../../node_modules/is-callable/index.js\");\n\nvar toStr = Object.prototype.toString;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nvar forEachArray = function forEachArray(array, iterator, receiver) {\n    for (var i = 0, len = array.length; i < len; i++) {\n        if (hasOwnProperty.call(array, i)) {\n            if (receiver == null) {\n                iterator(array[i], i, array);\n            } else {\n                iterator.call(receiver, array[i], i, array);\n            }\n        }\n    }\n};\n\nvar forEachString = function forEachString(string, iterator, receiver) {\n    for (var i = 0, len = string.length; i < len; i++) {\n        // no such thing as a sparse string.\n        if (receiver == null) {\n            iterator(string.charAt(i), i, string);\n        } else {\n            iterator.call(receiver, string.charAt(i), i, string);\n        }\n    }\n};\n\nvar forEachObject = function forEachObject(object, iterator, receiver) {\n    for (var k in object) {\n        if (hasOwnProperty.call(object, k)) {\n            if (receiver == null) {\n                iterator(object[k], k, object);\n            } else {\n                iterator.call(receiver, object[k], k, object);\n            }\n        }\n    }\n};\n\nvar forEach = function forEach(list, iterator, thisArg) {\n    if (!isCallable(iterator)) {\n        throw new TypeError('iterator must be a function');\n    }\n\n    var receiver;\n    if (arguments.length >= 3) {\n        receiver = thisArg;\n    }\n\n    if (toStr.call(list) === '[object Array]') {\n        forEachArray(list, iterator, receiver);\n    } else if (typeof list === 'string') {\n        forEachString(list, iterator, receiver);\n    } else {\n        forEachObject(list, iterator, receiver);\n    }\n};\n\nmodule.exports = forEach;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/for-each/index.js?");

/***/ }),

/***/ "../../node_modules/function-bind/implementation.js":
/*!**********************************************************!*\
  !*** ../../node_modules/function-bind/implementation.js ***!
  \**********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* eslint no-invalid-this: 1 */\n\nvar ERROR_MESSAGE = 'Function.prototype.bind called on incompatible ';\nvar toStr = Object.prototype.toString;\nvar max = Math.max;\nvar funcType = '[object Function]';\n\nvar concatty = function concatty(a, b) {\n    var arr = [];\n\n    for (var i = 0; i < a.length; i += 1) {\n        arr[i] = a[i];\n    }\n    for (var j = 0; j < b.length; j += 1) {\n        arr[j + a.length] = b[j];\n    }\n\n    return arr;\n};\n\nvar slicy = function slicy(arrLike, offset) {\n    var arr = [];\n    for (var i = offset || 0, j = 0; i < arrLike.length; i += 1, j += 1) {\n        arr[j] = arrLike[i];\n    }\n    return arr;\n};\n\nvar joiny = function (arr, joiner) {\n    var str = '';\n    for (var i = 0; i < arr.length; i += 1) {\n        str += arr[i];\n        if (i + 1 < arr.length) {\n            str += joiner;\n        }\n    }\n    return str;\n};\n\nmodule.exports = function bind(that) {\n    var target = this;\n    if (typeof target !== 'function' || toStr.apply(target) !== funcType) {\n        throw new TypeError(ERROR_MESSAGE + target);\n    }\n    var args = slicy(arguments, 1);\n\n    var bound;\n    var binder = function () {\n        if (this instanceof bound) {\n            var result = target.apply(\n                this,\n                concatty(args, arguments)\n            );\n            if (Object(result) === result) {\n                return result;\n            }\n            return this;\n        }\n        return target.apply(\n            that,\n            concatty(args, arguments)\n        );\n\n    };\n\n    var boundLength = max(0, target.length - args.length);\n    var boundArgs = [];\n    for (var i = 0; i < boundLength; i++) {\n        boundArgs[i] = '$' + i;\n    }\n\n    bound = Function('binder', 'return function (' + joiny(boundArgs, ',') + '){ return binder.apply(this,arguments); }')(binder);\n\n    if (target.prototype) {\n        var Empty = function Empty() {};\n        Empty.prototype = target.prototype;\n        bound.prototype = new Empty();\n        Empty.prototype = null;\n    }\n\n    return bound;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/function-bind/implementation.js?");

/***/ }),

/***/ "../../node_modules/function-bind/index.js":
/*!*************************************************!*\
  !*** ../../node_modules/function-bind/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar implementation = __webpack_require__(/*! ./implementation */ \"../../node_modules/function-bind/implementation.js\");\n\nmodule.exports = Function.prototype.bind || implementation;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/function-bind/index.js?");

/***/ }),

/***/ "../../node_modules/get-intrinsic/index.js":
/*!*************************************************!*\
  !*** ../../node_modules/get-intrinsic/index.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar undefined;\n\nvar $SyntaxError = SyntaxError;\nvar $Function = Function;\nvar $TypeError = TypeError;\n\n// eslint-disable-next-line consistent-return\nvar getEvalledConstructor = function (expressionSyntax) {\n\ttry {\n\t\treturn $Function('\"use strict\"; return (' + expressionSyntax + ').constructor;')();\n\t} catch (e) {}\n};\n\nvar $gOPD = Object.getOwnPropertyDescriptor;\nif ($gOPD) {\n\ttry {\n\t\t$gOPD({}, '');\n\t} catch (e) {\n\t\t$gOPD = null; // this is IE 8, which has a broken gOPD\n\t}\n}\n\nvar throwTypeError = function () {\n\tthrow new $TypeError();\n};\nvar ThrowTypeError = $gOPD\n\t? (function () {\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-unused-expressions, no-caller, no-restricted-properties\n\t\t\targuments.callee; // IE 8 does not throw here\n\t\t\treturn throwTypeError;\n\t\t} catch (calleeThrows) {\n\t\t\ttry {\n\t\t\t\t// IE 8 throws on Object.getOwnPropertyDescriptor(arguments, '')\n\t\t\t\treturn $gOPD(arguments, 'callee').get;\n\t\t\t} catch (gOPDthrows) {\n\t\t\t\treturn throwTypeError;\n\t\t\t}\n\t\t}\n\t}())\n\t: throwTypeError;\n\nvar hasSymbols = __webpack_require__(/*! has-symbols */ \"../../node_modules/has-symbols/index.js\")();\nvar hasProto = __webpack_require__(/*! has-proto */ \"../../node_modules/has-proto/index.js\")();\n\nvar getProto = Object.getPrototypeOf || (\n\thasProto\n\t\t? function (x) { return x.__proto__; } // eslint-disable-line no-proto\n\t\t: null\n);\n\nvar needsEval = {};\n\nvar TypedArray = typeof Uint8Array === 'undefined' || !getProto ? undefined : getProto(Uint8Array);\n\nvar INTRINSICS = {\n\t'%AggregateError%': typeof AggregateError === 'undefined' ? undefined : AggregateError,\n\t'%Array%': Array,\n\t'%ArrayBuffer%': typeof ArrayBuffer === 'undefined' ? undefined : ArrayBuffer,\n\t'%ArrayIteratorPrototype%': hasSymbols && getProto ? getProto([][Symbol.iterator]()) : undefined,\n\t'%AsyncFromSyncIteratorPrototype%': undefined,\n\t'%AsyncFunction%': needsEval,\n\t'%AsyncGenerator%': needsEval,\n\t'%AsyncGeneratorFunction%': needsEval,\n\t'%AsyncIteratorPrototype%': needsEval,\n\t'%Atomics%': typeof Atomics === 'undefined' ? undefined : Atomics,\n\t'%BigInt%': typeof BigInt === 'undefined' ? undefined : BigInt,\n\t'%BigInt64Array%': typeof BigInt64Array === 'undefined' ? undefined : BigInt64Array,\n\t'%BigUint64Array%': typeof BigUint64Array === 'undefined' ? undefined : BigUint64Array,\n\t'%Boolean%': Boolean,\n\t'%DataView%': typeof DataView === 'undefined' ? undefined : DataView,\n\t'%Date%': Date,\n\t'%decodeURI%': decodeURI,\n\t'%decodeURIComponent%': decodeURIComponent,\n\t'%encodeURI%': encodeURI,\n\t'%encodeURIComponent%': encodeURIComponent,\n\t'%Error%': Error,\n\t'%eval%': eval, // eslint-disable-line no-eval\n\t'%EvalError%': EvalError,\n\t'%Float32Array%': typeof Float32Array === 'undefined' ? undefined : Float32Array,\n\t'%Float64Array%': typeof Float64Array === 'undefined' ? undefined : Float64Array,\n\t'%FinalizationRegistry%': typeof FinalizationRegistry === 'undefined' ? undefined : FinalizationRegistry,\n\t'%Function%': $Function,\n\t'%GeneratorFunction%': needsEval,\n\t'%Int8Array%': typeof Int8Array === 'undefined' ? undefined : Int8Array,\n\t'%Int16Array%': typeof Int16Array === 'undefined' ? undefined : Int16Array,\n\t'%Int32Array%': typeof Int32Array === 'undefined' ? undefined : Int32Array,\n\t'%isFinite%': isFinite,\n\t'%isNaN%': isNaN,\n\t'%IteratorPrototype%': hasSymbols && getProto ? getProto(getProto([][Symbol.iterator]())) : undefined,\n\t'%JSON%': typeof JSON === 'object' ? JSON : undefined,\n\t'%Map%': typeof Map === 'undefined' ? undefined : Map,\n\t'%MapIteratorPrototype%': typeof Map === 'undefined' || !hasSymbols || !getProto ? undefined : getProto(new Map()[Symbol.iterator]()),\n\t'%Math%': Math,\n\t'%Number%': Number,\n\t'%Object%': Object,\n\t'%parseFloat%': parseFloat,\n\t'%parseInt%': parseInt,\n\t'%Promise%': typeof Promise === 'undefined' ? undefined : Promise,\n\t'%Proxy%': typeof Proxy === 'undefined' ? undefined : Proxy,\n\t'%RangeError%': RangeError,\n\t'%ReferenceError%': ReferenceError,\n\t'%Reflect%': typeof Reflect === 'undefined' ? undefined : Reflect,\n\t'%RegExp%': RegExp,\n\t'%Set%': typeof Set === 'undefined' ? undefined : Set,\n\t'%SetIteratorPrototype%': typeof Set === 'undefined' || !hasSymbols || !getProto ? undefined : getProto(new Set()[Symbol.iterator]()),\n\t'%SharedArrayBuffer%': typeof SharedArrayBuffer === 'undefined' ? undefined : SharedArrayBuffer,\n\t'%String%': String,\n\t'%StringIteratorPrototype%': hasSymbols && getProto ? getProto(''[Symbol.iterator]()) : undefined,\n\t'%Symbol%': hasSymbols ? Symbol : undefined,\n\t'%SyntaxError%': $SyntaxError,\n\t'%ThrowTypeError%': ThrowTypeError,\n\t'%TypedArray%': TypedArray,\n\t'%TypeError%': $TypeError,\n\t'%Uint8Array%': typeof Uint8Array === 'undefined' ? undefined : Uint8Array,\n\t'%Uint8ClampedArray%': typeof Uint8ClampedArray === 'undefined' ? undefined : Uint8ClampedArray,\n\t'%Uint16Array%': typeof Uint16Array === 'undefined' ? undefined : Uint16Array,\n\t'%Uint32Array%': typeof Uint32Array === 'undefined' ? undefined : Uint32Array,\n\t'%URIError%': URIError,\n\t'%WeakMap%': typeof WeakMap === 'undefined' ? undefined : WeakMap,\n\t'%WeakRef%': typeof WeakRef === 'undefined' ? undefined : WeakRef,\n\t'%WeakSet%': typeof WeakSet === 'undefined' ? undefined : WeakSet\n};\n\nif (getProto) {\n\ttry {\n\t\tnull.error; // eslint-disable-line no-unused-expressions\n\t} catch (e) {\n\t\t// https://github.com/tc39/proposal-shadowrealm/pull/384#issuecomment-1364264229\n\t\tvar errorProto = getProto(getProto(e));\n\t\tINTRINSICS['%Error.prototype%'] = errorProto;\n\t}\n}\n\nvar doEval = function doEval(name) {\n\tvar value;\n\tif (name === '%AsyncFunction%') {\n\t\tvalue = getEvalledConstructor('async function () {}');\n\t} else if (name === '%GeneratorFunction%') {\n\t\tvalue = getEvalledConstructor('function* () {}');\n\t} else if (name === '%AsyncGeneratorFunction%') {\n\t\tvalue = getEvalledConstructor('async function* () {}');\n\t} else if (name === '%AsyncGenerator%') {\n\t\tvar fn = doEval('%AsyncGeneratorFunction%');\n\t\tif (fn) {\n\t\t\tvalue = fn.prototype;\n\t\t}\n\t} else if (name === '%AsyncIteratorPrototype%') {\n\t\tvar gen = doEval('%AsyncGenerator%');\n\t\tif (gen && getProto) {\n\t\t\tvalue = getProto(gen.prototype);\n\t\t}\n\t}\n\n\tINTRINSICS[name] = value;\n\n\treturn value;\n};\n\nvar LEGACY_ALIASES = {\n\t'%ArrayBufferPrototype%': ['ArrayBuffer', 'prototype'],\n\t'%ArrayPrototype%': ['Array', 'prototype'],\n\t'%ArrayProto_entries%': ['Array', 'prototype', 'entries'],\n\t'%ArrayProto_forEach%': ['Array', 'prototype', 'forEach'],\n\t'%ArrayProto_keys%': ['Array', 'prototype', 'keys'],\n\t'%ArrayProto_values%': ['Array', 'prototype', 'values'],\n\t'%AsyncFunctionPrototype%': ['AsyncFunction', 'prototype'],\n\t'%AsyncGenerator%': ['AsyncGeneratorFunction', 'prototype'],\n\t'%AsyncGeneratorPrototype%': ['AsyncGeneratorFunction', 'prototype', 'prototype'],\n\t'%BooleanPrototype%': ['Boolean', 'prototype'],\n\t'%DataViewPrototype%': ['DataView', 'prototype'],\n\t'%DatePrototype%': ['Date', 'prototype'],\n\t'%ErrorPrototype%': ['Error', 'prototype'],\n\t'%EvalErrorPrototype%': ['EvalError', 'prototype'],\n\t'%Float32ArrayPrototype%': ['Float32Array', 'prototype'],\n\t'%Float64ArrayPrototype%': ['Float64Array', 'prototype'],\n\t'%FunctionPrototype%': ['Function', 'prototype'],\n\t'%Generator%': ['GeneratorFunction', 'prototype'],\n\t'%GeneratorPrototype%': ['GeneratorFunction', 'prototype', 'prototype'],\n\t'%Int8ArrayPrototype%': ['Int8Array', 'prototype'],\n\t'%Int16ArrayPrototype%': ['Int16Array', 'prototype'],\n\t'%Int32ArrayPrototype%': ['Int32Array', 'prototype'],\n\t'%JSONParse%': ['JSON', 'parse'],\n\t'%JSONStringify%': ['JSON', 'stringify'],\n\t'%MapPrototype%': ['Map', 'prototype'],\n\t'%NumberPrototype%': ['Number', 'prototype'],\n\t'%ObjectPrototype%': ['Object', 'prototype'],\n\t'%ObjProto_toString%': ['Object', 'prototype', 'toString'],\n\t'%ObjProto_valueOf%': ['Object', 'prototype', 'valueOf'],\n\t'%PromisePrototype%': ['Promise', 'prototype'],\n\t'%PromiseProto_then%': ['Promise', 'prototype', 'then'],\n\t'%Promise_all%': ['Promise', 'all'],\n\t'%Promise_reject%': ['Promise', 'reject'],\n\t'%Promise_resolve%': ['Promise', 'resolve'],\n\t'%RangeErrorPrototype%': ['RangeError', 'prototype'],\n\t'%ReferenceErrorPrototype%': ['ReferenceError', 'prototype'],\n\t'%RegExpPrototype%': ['RegExp', 'prototype'],\n\t'%SetPrototype%': ['Set', 'prototype'],\n\t'%SharedArrayBufferPrototype%': ['SharedArrayBuffer', 'prototype'],\n\t'%StringPrototype%': ['String', 'prototype'],\n\t'%SymbolPrototype%': ['Symbol', 'prototype'],\n\t'%SyntaxErrorPrototype%': ['SyntaxError', 'prototype'],\n\t'%TypedArrayPrototype%': ['TypedArray', 'prototype'],\n\t'%TypeErrorPrototype%': ['TypeError', 'prototype'],\n\t'%Uint8ArrayPrototype%': ['Uint8Array', 'prototype'],\n\t'%Uint8ClampedArrayPrototype%': ['Uint8ClampedArray', 'prototype'],\n\t'%Uint16ArrayPrototype%': ['Uint16Array', 'prototype'],\n\t'%Uint32ArrayPrototype%': ['Uint32Array', 'prototype'],\n\t'%URIErrorPrototype%': ['URIError', 'prototype'],\n\t'%WeakMapPrototype%': ['WeakMap', 'prototype'],\n\t'%WeakSetPrototype%': ['WeakSet', 'prototype']\n};\n\nvar bind = __webpack_require__(/*! function-bind */ \"../../node_modules/function-bind/index.js\");\nvar hasOwn = __webpack_require__(/*! hasown */ \"../../node_modules/hasown/index.js\");\nvar $concat = bind.call(Function.call, Array.prototype.concat);\nvar $spliceApply = bind.call(Function.apply, Array.prototype.splice);\nvar $replace = bind.call(Function.call, String.prototype.replace);\nvar $strSlice = bind.call(Function.call, String.prototype.slice);\nvar $exec = bind.call(Function.call, RegExp.prototype.exec);\n\n/* adapted from https://github.com/lodash/lodash/blob/4.17.15/dist/lodash.js#L6735-L6744 */\nvar rePropName = /[^%.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|%$))/g;\nvar reEscapeChar = /\\\\(\\\\)?/g; /** Used to match backslashes in property paths. */\nvar stringToPath = function stringToPath(string) {\n\tvar first = $strSlice(string, 0, 1);\n\tvar last = $strSlice(string, -1);\n\tif (first === '%' && last !== '%') {\n\t\tthrow new $SyntaxError('invalid intrinsic syntax, expected closing `%`');\n\t} else if (last === '%' && first !== '%') {\n\t\tthrow new $SyntaxError('invalid intrinsic syntax, expected opening `%`');\n\t}\n\tvar result = [];\n\t$replace(string, rePropName, function (match, number, quote, subString) {\n\t\tresult[result.length] = quote ? $replace(subString, reEscapeChar, '$1') : number || match;\n\t});\n\treturn result;\n};\n/* end adaptation */\n\nvar getBaseIntrinsic = function getBaseIntrinsic(name, allowMissing) {\n\tvar intrinsicName = name;\n\tvar alias;\n\tif (hasOwn(LEGACY_ALIASES, intrinsicName)) {\n\t\talias = LEGACY_ALIASES[intrinsicName];\n\t\tintrinsicName = '%' + alias[0] + '%';\n\t}\n\n\tif (hasOwn(INTRINSICS, intrinsicName)) {\n\t\tvar value = INTRINSICS[intrinsicName];\n\t\tif (value === needsEval) {\n\t\t\tvalue = doEval(intrinsicName);\n\t\t}\n\t\tif (typeof value === 'undefined' && !allowMissing) {\n\t\t\tthrow new $TypeError('intrinsic ' + name + ' exists, but is not available. Please file an issue!');\n\t\t}\n\n\t\treturn {\n\t\t\talias: alias,\n\t\t\tname: intrinsicName,\n\t\t\tvalue: value\n\t\t};\n\t}\n\n\tthrow new $SyntaxError('intrinsic ' + name + ' does not exist!');\n};\n\nmodule.exports = function GetIntrinsic(name, allowMissing) {\n\tif (typeof name !== 'string' || name.length === 0) {\n\t\tthrow new $TypeError('intrinsic name must be a non-empty string');\n\t}\n\tif (arguments.length > 1 && typeof allowMissing !== 'boolean') {\n\t\tthrow new $TypeError('\"allowMissing\" argument must be a boolean');\n\t}\n\n\tif ($exec(/^%?[^%]*%?$/, name) === null) {\n\t\tthrow new $SyntaxError('`%` may not be present anywhere but at the beginning and end of the intrinsic name');\n\t}\n\tvar parts = stringToPath(name);\n\tvar intrinsicBaseName = parts.length > 0 ? parts[0] : '';\n\n\tvar intrinsic = getBaseIntrinsic('%' + intrinsicBaseName + '%', allowMissing);\n\tvar intrinsicRealName = intrinsic.name;\n\tvar value = intrinsic.value;\n\tvar skipFurtherCaching = false;\n\n\tvar alias = intrinsic.alias;\n\tif (alias) {\n\t\tintrinsicBaseName = alias[0];\n\t\t$spliceApply(parts, $concat([0, 1], alias));\n\t}\n\n\tfor (var i = 1, isOwn = true; i < parts.length; i += 1) {\n\t\tvar part = parts[i];\n\t\tvar first = $strSlice(part, 0, 1);\n\t\tvar last = $strSlice(part, -1);\n\t\tif (\n\t\t\t(\n\t\t\t\t(first === '\"' || first === \"'\" || first === '`')\n\t\t\t\t|| (last === '\"' || last === \"'\" || last === '`')\n\t\t\t)\n\t\t\t&& first !== last\n\t\t) {\n\t\t\tthrow new $SyntaxError('property names with quotes must have matching quotes');\n\t\t}\n\t\tif (part === 'constructor' || !isOwn) {\n\t\t\tskipFurtherCaching = true;\n\t\t}\n\n\t\tintrinsicBaseName += '.' + part;\n\t\tintrinsicRealName = '%' + intrinsicBaseName + '%';\n\n\t\tif (hasOwn(INTRINSICS, intrinsicRealName)) {\n\t\t\tvalue = INTRINSICS[intrinsicRealName];\n\t\t} else if (value != null) {\n\t\t\tif (!(part in value)) {\n\t\t\t\tif (!allowMissing) {\n\t\t\t\t\tthrow new $TypeError('base intrinsic for ' + name + ' exists, but the property is not available.');\n\t\t\t\t}\n\t\t\t\treturn void undefined;\n\t\t\t}\n\t\t\tif ($gOPD && (i + 1) >= parts.length) {\n\t\t\t\tvar desc = $gOPD(value, part);\n\t\t\t\tisOwn = !!desc;\n\n\t\t\t\t// By convention, when a data property is converted to an accessor\n\t\t\t\t// property to emulate a data property that does not suffer from\n\t\t\t\t// the override mistake, that accessor's getter is marked with\n\t\t\t\t// an `originalValue` property. Here, when we detect this, we\n\t\t\t\t// uphold the illusion by pretending to see that original data\n\t\t\t\t// property, i.e., returning the value rather than the getter\n\t\t\t\t// itself.\n\t\t\t\tif (isOwn && 'get' in desc && !('originalValue' in desc.get)) {\n\t\t\t\t\tvalue = desc.get;\n\t\t\t\t} else {\n\t\t\t\t\tvalue = value[part];\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tisOwn = hasOwn(value, part);\n\t\t\t\tvalue = value[part];\n\t\t\t}\n\n\t\t\tif (isOwn && !skipFurtherCaching) {\n\t\t\t\tINTRINSICS[intrinsicRealName] = value;\n\t\t\t}\n\t\t}\n\t}\n\treturn value;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/get-intrinsic/index.js?");

/***/ }),

/***/ "../../node_modules/gopd/index.js":
/*!****************************************!*\
  !*** ../../node_modules/gopd/index.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\n\nvar $gOPD = GetIntrinsic('%Object.getOwnPropertyDescriptor%', true);\n\nif ($gOPD) {\n\ttry {\n\t\t$gOPD([], 'length');\n\t} catch (e) {\n\t\t// IE 8 has a broken gOPD\n\t\t$gOPD = null;\n\t}\n}\n\nmodule.exports = $gOPD;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/gopd/index.js?");

/***/ }),

/***/ "../../node_modules/has-property-descriptors/index.js":
/*!************************************************************!*\
  !*** ../../node_modules/has-property-descriptors/index.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\n\nvar $defineProperty = GetIntrinsic('%Object.defineProperty%', true);\n\nvar hasPropertyDescriptors = function hasPropertyDescriptors() {\n\tif ($defineProperty) {\n\t\ttry {\n\t\t\t$defineProperty({}, 'a', { value: 1 });\n\t\t\treturn true;\n\t\t} catch (e) {\n\t\t\t// IE 8 has a broken defineProperty\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn false;\n};\n\nhasPropertyDescriptors.hasArrayLengthDefineBug = function hasArrayLengthDefineBug() {\n\t// node v0.6 has a bug where array lengths can be Set but not Defined\n\tif (!hasPropertyDescriptors()) {\n\t\treturn null;\n\t}\n\ttry {\n\t\treturn $defineProperty([], 'length', { value: 1 }).length !== 1;\n\t} catch (e) {\n\t\t// In Firefox 4-22, defining length on an array throws an exception.\n\t\treturn true;\n\t}\n};\n\nmodule.exports = hasPropertyDescriptors;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/has-property-descriptors/index.js?");

/***/ }),

/***/ "../../node_modules/has-proto/index.js":
/*!*********************************************!*\
  !*** ../../node_modules/has-proto/index.js ***!
  \*********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar test = {\n\tfoo: {}\n};\n\nvar $Object = Object;\n\nmodule.exports = function hasProto() {\n\treturn { __proto__: test }.foo === test.foo && !({ __proto__: null } instanceof $Object);\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/has-proto/index.js?");

/***/ }),

/***/ "../../node_modules/has-symbols/index.js":
/*!***********************************************!*\
  !*** ../../node_modules/has-symbols/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar origSymbol = typeof Symbol !== 'undefined' && Symbol;\nvar hasSymbolSham = __webpack_require__(/*! ./shams */ \"../../node_modules/has-symbols/shams.js\");\n\nmodule.exports = function hasNativeSymbols() {\n\tif (typeof origSymbol !== 'function') { return false; }\n\tif (typeof Symbol !== 'function') { return false; }\n\tif (typeof origSymbol('foo') !== 'symbol') { return false; }\n\tif (typeof Symbol('bar') !== 'symbol') { return false; }\n\n\treturn hasSymbolSham();\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/has-symbols/index.js?");

/***/ }),

/***/ "../../node_modules/has-symbols/shams.js":
/*!***********************************************!*\
  !*** ../../node_modules/has-symbols/shams.js ***!
  \***********************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* eslint complexity: [2, 18], max-statements: [2, 33] */\nmodule.exports = function hasSymbols() {\n\tif (typeof Symbol !== 'function' || typeof Object.getOwnPropertySymbols !== 'function') { return false; }\n\tif (typeof Symbol.iterator === 'symbol') { return true; }\n\n\tvar obj = {};\n\tvar sym = Symbol('test');\n\tvar symObj = Object(sym);\n\tif (typeof sym === 'string') { return false; }\n\n\tif (Object.prototype.toString.call(sym) !== '[object Symbol]') { return false; }\n\tif (Object.prototype.toString.call(symObj) !== '[object Symbol]') { return false; }\n\n\t// temp disabled per https://github.com/ljharb/object.assign/issues/17\n\t// if (sym instanceof Symbol) { return false; }\n\t// temp disabled per https://github.com/WebReflection/get-own-property-symbols/issues/4\n\t// if (!(symObj instanceof Symbol)) { return false; }\n\n\t// if (typeof Symbol.prototype.toString !== 'function') { return false; }\n\t// if (String(sym) !== Symbol.prototype.toString.call(sym)) { return false; }\n\n\tvar symVal = 42;\n\tobj[sym] = symVal;\n\tfor (sym in obj) { return false; } // eslint-disable-line no-restricted-syntax, no-unreachable-loop\n\tif (typeof Object.keys === 'function' && Object.keys(obj).length !== 0) { return false; }\n\n\tif (typeof Object.getOwnPropertyNames === 'function' && Object.getOwnPropertyNames(obj).length !== 0) { return false; }\n\n\tvar syms = Object.getOwnPropertySymbols(obj);\n\tif (syms.length !== 1 || syms[0] !== sym) { return false; }\n\n\tif (!Object.prototype.propertyIsEnumerable.call(obj, sym)) { return false; }\n\n\tif (typeof Object.getOwnPropertyDescriptor === 'function') {\n\t\tvar descriptor = Object.getOwnPropertyDescriptor(obj, sym);\n\t\tif (descriptor.value !== symVal || descriptor.enumerable !== true) { return false; }\n\t}\n\n\treturn true;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/has-symbols/shams.js?");

/***/ }),

/***/ "../../node_modules/has-tostringtag/shams.js":
/*!***************************************************!*\
  !*** ../../node_modules/has-tostringtag/shams.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hasSymbols = __webpack_require__(/*! has-symbols/shams */ \"../../node_modules/has-symbols/shams.js\");\n\nmodule.exports = function hasToStringTagShams() {\n\treturn hasSymbols() && !!Symbol.toStringTag;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/has-tostringtag/shams.js?");

/***/ }),

/***/ "../../node_modules/hasown/index.js":
/*!******************************************!*\
  !*** ../../node_modules/hasown/index.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar call = Function.prototype.call;\nvar $hasOwn = Object.prototype.hasOwnProperty;\nvar bind = __webpack_require__(/*! function-bind */ \"../../node_modules/function-bind/index.js\");\n\n/** @type {(o: {}, p: PropertyKey) => p is keyof o} */\nmodule.exports = bind.call(call, $hasOwn);\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/hasown/index.js?");

/***/ }),

/***/ "../../node_modules/inherits/inherits_browser.js":
/*!*******************************************************!*\
  !*** ../../node_modules/inherits/inherits_browser.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "../../node_modules/is-arguments/index.js":
/*!************************************************!*\
  !*** ../../node_modules/is-arguments/index.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar hasToStringTag = __webpack_require__(/*! has-tostringtag/shams */ \"../../node_modules/has-tostringtag/shams.js\")();\nvar callBound = __webpack_require__(/*! call-bind/callBound */ \"../../node_modules/call-bind/callBound.js\");\n\nvar $toString = callBound('Object.prototype.toString');\n\nvar isStandardArguments = function isArguments(value) {\n\tif (hasToStringTag && value && typeof value === 'object' && Symbol.toStringTag in value) {\n\t\treturn false;\n\t}\n\treturn $toString(value) === '[object Arguments]';\n};\n\nvar isLegacyArguments = function isArguments(value) {\n\tif (isStandardArguments(value)) {\n\t\treturn true;\n\t}\n\treturn value !== null &&\n\t\ttypeof value === 'object' &&\n\t\ttypeof value.length === 'number' &&\n\t\tvalue.length >= 0 &&\n\t\t$toString(value) !== '[object Array]' &&\n\t\t$toString(value.callee) === '[object Function]';\n};\n\nvar supportsStandardArguments = (function () {\n\treturn isStandardArguments(arguments);\n}());\n\nisStandardArguments.isLegacyArguments = isLegacyArguments; // for tests\n\nmodule.exports = supportsStandardArguments ? isStandardArguments : isLegacyArguments;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/is-arguments/index.js?");

/***/ }),

/***/ "../../node_modules/is-callable/index.js":
/*!***********************************************!*\
  !*** ../../node_modules/is-callable/index.js ***!
  \***********************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar fnToStr = Function.prototype.toString;\nvar reflectApply = typeof Reflect === 'object' && Reflect !== null && Reflect.apply;\nvar badArrayLike;\nvar isCallableMarker;\nif (typeof reflectApply === 'function' && typeof Object.defineProperty === 'function') {\n\ttry {\n\t\tbadArrayLike = Object.defineProperty({}, 'length', {\n\t\t\tget: function () {\n\t\t\t\tthrow isCallableMarker;\n\t\t\t}\n\t\t});\n\t\tisCallableMarker = {};\n\t\t// eslint-disable-next-line no-throw-literal\n\t\treflectApply(function () { throw 42; }, null, badArrayLike);\n\t} catch (_) {\n\t\tif (_ !== isCallableMarker) {\n\t\t\treflectApply = null;\n\t\t}\n\t}\n} else {\n\treflectApply = null;\n}\n\nvar constructorRegex = /^\\s*class\\b/;\nvar isES6ClassFn = function isES6ClassFunction(value) {\n\ttry {\n\t\tvar fnStr = fnToStr.call(value);\n\t\treturn constructorRegex.test(fnStr);\n\t} catch (e) {\n\t\treturn false; // not a function\n\t}\n};\n\nvar tryFunctionObject = function tryFunctionToStr(value) {\n\ttry {\n\t\tif (isES6ClassFn(value)) { return false; }\n\t\tfnToStr.call(value);\n\t\treturn true;\n\t} catch (e) {\n\t\treturn false;\n\t}\n};\nvar toStr = Object.prototype.toString;\nvar objectClass = '[object Object]';\nvar fnClass = '[object Function]';\nvar genClass = '[object GeneratorFunction]';\nvar ddaClass = '[object HTMLAllCollection]'; // IE 11\nvar ddaClass2 = '[object HTML document.all class]';\nvar ddaClass3 = '[object HTMLCollection]'; // IE 9-10\nvar hasToStringTag = typeof Symbol === 'function' && !!Symbol.toStringTag; // better: use `has-tostringtag`\n\nvar isIE68 = !(0 in [,]); // eslint-disable-line no-sparse-arrays, comma-spacing\n\nvar isDDA = function isDocumentDotAll() { return false; };\nif (typeof document === 'object') {\n\t// Firefox 3 canonicalizes DDA to undefined when it's not accessed directly\n\tvar all = document.all;\n\tif (toStr.call(all) === toStr.call(document.all)) {\n\t\tisDDA = function isDocumentDotAll(value) {\n\t\t\t/* globals document: false */\n\t\t\t// in IE 6-8, typeof document.all is \"object\" and it's truthy\n\t\t\tif ((isIE68 || !value) && (typeof value === 'undefined' || typeof value === 'object')) {\n\t\t\t\ttry {\n\t\t\t\t\tvar str = toStr.call(value);\n\t\t\t\t\treturn (\n\t\t\t\t\t\tstr === ddaClass\n\t\t\t\t\t\t|| str === ddaClass2\n\t\t\t\t\t\t|| str === ddaClass3 // opera 12.16\n\t\t\t\t\t\t|| str === objectClass // IE 6-8\n\t\t\t\t\t) && value('') == null; // eslint-disable-line eqeqeq\n\t\t\t\t} catch (e) { /**/ }\n\t\t\t}\n\t\t\treturn false;\n\t\t};\n\t}\n}\n\nmodule.exports = reflectApply\n\t? function isCallable(value) {\n\t\tif (isDDA(value)) { return true; }\n\t\tif (!value) { return false; }\n\t\tif (typeof value !== 'function' && typeof value !== 'object') { return false; }\n\t\ttry {\n\t\t\treflectApply(value, null, badArrayLike);\n\t\t} catch (e) {\n\t\t\tif (e !== isCallableMarker) { return false; }\n\t\t}\n\t\treturn !isES6ClassFn(value) && tryFunctionObject(value);\n\t}\n\t: function isCallable(value) {\n\t\tif (isDDA(value)) { return true; }\n\t\tif (!value) { return false; }\n\t\tif (typeof value !== 'function' && typeof value !== 'object') { return false; }\n\t\tif (hasToStringTag) { return tryFunctionObject(value); }\n\t\tif (isES6ClassFn(value)) { return false; }\n\t\tvar strClass = toStr.call(value);\n\t\tif (strClass !== fnClass && strClass !== genClass && !(/^\\[object HTML/).test(strClass)) { return false; }\n\t\treturn tryFunctionObject(value);\n\t};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/is-callable/index.js?");

/***/ }),

/***/ "../../node_modules/is-generator-function/index.js":
/*!*********************************************************!*\
  !*** ../../node_modules/is-generator-function/index.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar toStr = Object.prototype.toString;\nvar fnToStr = Function.prototype.toString;\nvar isFnRegex = /^\\s*(?:function)?\\*/;\nvar hasToStringTag = __webpack_require__(/*! has-tostringtag/shams */ \"../../node_modules/has-tostringtag/shams.js\")();\nvar getProto = Object.getPrototypeOf;\nvar getGeneratorFunc = function () { // eslint-disable-line consistent-return\n\tif (!hasToStringTag) {\n\t\treturn false;\n\t}\n\ttry {\n\t\treturn Function('return function*() {}')();\n\t} catch (e) {\n\t}\n};\nvar GeneratorFunction;\n\nmodule.exports = function isGeneratorFunction(fn) {\n\tif (typeof fn !== 'function') {\n\t\treturn false;\n\t}\n\tif (isFnRegex.test(fnToStr.call(fn))) {\n\t\treturn true;\n\t}\n\tif (!hasToStringTag) {\n\t\tvar str = toStr.call(fn);\n\t\treturn str === '[object GeneratorFunction]';\n\t}\n\tif (!getProto) {\n\t\treturn false;\n\t}\n\tif (typeof GeneratorFunction === 'undefined') {\n\t\tvar generatorFunc = getGeneratorFunc();\n\t\tGeneratorFunction = generatorFunc ? getProto(generatorFunc) : false;\n\t}\n\treturn getProto(fn) === GeneratorFunction;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/is-generator-function/index.js?");

/***/ }),

/***/ "../../node_modules/is-typed-array/index.js":
/*!**************************************************!*\
  !*** ../../node_modules/is-typed-array/index.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar whichTypedArray = __webpack_require__(/*! which-typed-array */ \"../../node_modules/which-typed-array/index.js\");\n\nmodule.exports = function isTypedArray(value) {\n\treturn !!whichTypedArray(value);\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/is-typed-array/index.js?");

/***/ }),

/***/ "../../node_modules/process/browser.js":
/*!*********************************************!*\
  !*** ../../node_modules/process/browser.js ***!
  \*********************************************/
/***/ ((module) => {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/process/browser.js?");

/***/ }),

/***/ "../../node_modules/set-function-length/index.js":
/*!*******************************************************!*\
  !*** ../../node_modules/set-function-length/index.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"../../node_modules/get-intrinsic/index.js\");\nvar define = __webpack_require__(/*! define-data-property */ \"../../node_modules/define-data-property/index.js\");\nvar hasDescriptors = __webpack_require__(/*! has-property-descriptors */ \"../../node_modules/has-property-descriptors/index.js\")();\nvar gOPD = __webpack_require__(/*! gopd */ \"../../node_modules/gopd/index.js\");\n\nvar $TypeError = GetIntrinsic('%TypeError%');\nvar $floor = GetIntrinsic('%Math.floor%');\n\nmodule.exports = function setFunctionLength(fn, length) {\n\tif (typeof fn !== 'function') {\n\t\tthrow new $TypeError('`fn` is not a function');\n\t}\n\tif (typeof length !== 'number' || length < 0 || length > 0xFFFFFFFF || $floor(length) !== length) {\n\t\tthrow new $TypeError('`length` must be a positive 32-bit integer');\n\t}\n\n\tvar loose = arguments.length > 2 && !!arguments[2];\n\n\tvar functionLengthIsConfigurable = true;\n\tvar functionLengthIsWritable = true;\n\tif ('length' in fn && gOPD) {\n\t\tvar desc = gOPD(fn, 'length');\n\t\tif (desc && !desc.configurable) {\n\t\t\tfunctionLengthIsConfigurable = false;\n\t\t}\n\t\tif (desc && !desc.writable) {\n\t\t\tfunctionLengthIsWritable = false;\n\t\t}\n\t}\n\n\tif (functionLengthIsConfigurable || functionLengthIsWritable || !loose) {\n\t\tif (hasDescriptors) {\n\t\t\tdefine(fn, 'length', length, true, true);\n\t\t} else {\n\t\t\tdefine(fn, 'length', length);\n\t\t}\n\t}\n\treturn fn;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/set-function-length/index.js?");

/***/ }),

/***/ "../../node_modules/util/support/isBufferBrowser.js":
/*!**********************************************************!*\
  !*** ../../node_modules/util/support/isBufferBrowser.js ***!
  \**********************************************************/
/***/ ((module) => {

eval("module.exports = function isBuffer(arg) {\n  return arg && typeof arg === 'object'\n    && typeof arg.copy === 'function'\n    && typeof arg.fill === 'function'\n    && typeof arg.readUInt8 === 'function';\n}\n\n//# sourceURL=webpack://oracle2/../../node_modules/util/support/isBufferBrowser.js?");

/***/ }),

/***/ "../../node_modules/util/support/types.js":
/*!************************************************!*\
  !*** ../../node_modules/util/support/types.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Currently in sync with Node.js lib/internal/util/types.js\n// https://github.com/nodejs/node/commit/112cc7c27551254aa2b17098fb774867f05ed0d9\n\n\n\nvar isArgumentsObject = __webpack_require__(/*! is-arguments */ \"../../node_modules/is-arguments/index.js\");\nvar isGeneratorFunction = __webpack_require__(/*! is-generator-function */ \"../../node_modules/is-generator-function/index.js\");\nvar whichTypedArray = __webpack_require__(/*! which-typed-array */ \"../../node_modules/which-typed-array/index.js\");\nvar isTypedArray = __webpack_require__(/*! is-typed-array */ \"../../node_modules/is-typed-array/index.js\");\n\nfunction uncurryThis(f) {\n  return f.call.bind(f);\n}\n\nvar BigIntSupported = typeof BigInt !== 'undefined';\nvar SymbolSupported = typeof Symbol !== 'undefined';\n\nvar ObjectToString = uncurryThis(Object.prototype.toString);\n\nvar numberValue = uncurryThis(Number.prototype.valueOf);\nvar stringValue = uncurryThis(String.prototype.valueOf);\nvar booleanValue = uncurryThis(Boolean.prototype.valueOf);\n\nif (BigIntSupported) {\n  var bigIntValue = uncurryThis(BigInt.prototype.valueOf);\n}\n\nif (SymbolSupported) {\n  var symbolValue = uncurryThis(Symbol.prototype.valueOf);\n}\n\nfunction checkBoxedPrimitive(value, prototypeValueOf) {\n  if (typeof value !== 'object') {\n    return false;\n  }\n  try {\n    prototypeValueOf(value);\n    return true;\n  } catch(e) {\n    return false;\n  }\n}\n\nexports.isArgumentsObject = isArgumentsObject;\nexports.isGeneratorFunction = isGeneratorFunction;\nexports.isTypedArray = isTypedArray;\n\n// Taken from here and modified for better browser support\n// https://github.com/sindresorhus/p-is-promise/blob/cda35a513bda03f977ad5cde3a079d237e82d7ef/index.js\nfunction isPromise(input) {\n\treturn (\n\t\t(\n\t\t\ttypeof Promise !== 'undefined' &&\n\t\t\tinput instanceof Promise\n\t\t) ||\n\t\t(\n\t\t\tinput !== null &&\n\t\t\ttypeof input === 'object' &&\n\t\t\ttypeof input.then === 'function' &&\n\t\t\ttypeof input.catch === 'function'\n\t\t)\n\t);\n}\nexports.isPromise = isPromise;\n\nfunction isArrayBufferView(value) {\n  if (typeof ArrayBuffer !== 'undefined' && ArrayBuffer.isView) {\n    return ArrayBuffer.isView(value);\n  }\n\n  return (\n    isTypedArray(value) ||\n    isDataView(value)\n  );\n}\nexports.isArrayBufferView = isArrayBufferView;\n\n\nfunction isUint8Array(value) {\n  return whichTypedArray(value) === 'Uint8Array';\n}\nexports.isUint8Array = isUint8Array;\n\nfunction isUint8ClampedArray(value) {\n  return whichTypedArray(value) === 'Uint8ClampedArray';\n}\nexports.isUint8ClampedArray = isUint8ClampedArray;\n\nfunction isUint16Array(value) {\n  return whichTypedArray(value) === 'Uint16Array';\n}\nexports.isUint16Array = isUint16Array;\n\nfunction isUint32Array(value) {\n  return whichTypedArray(value) === 'Uint32Array';\n}\nexports.isUint32Array = isUint32Array;\n\nfunction isInt8Array(value) {\n  return whichTypedArray(value) === 'Int8Array';\n}\nexports.isInt8Array = isInt8Array;\n\nfunction isInt16Array(value) {\n  return whichTypedArray(value) === 'Int16Array';\n}\nexports.isInt16Array = isInt16Array;\n\nfunction isInt32Array(value) {\n  return whichTypedArray(value) === 'Int32Array';\n}\nexports.isInt32Array = isInt32Array;\n\nfunction isFloat32Array(value) {\n  return whichTypedArray(value) === 'Float32Array';\n}\nexports.isFloat32Array = isFloat32Array;\n\nfunction isFloat64Array(value) {\n  return whichTypedArray(value) === 'Float64Array';\n}\nexports.isFloat64Array = isFloat64Array;\n\nfunction isBigInt64Array(value) {\n  return whichTypedArray(value) === 'BigInt64Array';\n}\nexports.isBigInt64Array = isBigInt64Array;\n\nfunction isBigUint64Array(value) {\n  return whichTypedArray(value) === 'BigUint64Array';\n}\nexports.isBigUint64Array = isBigUint64Array;\n\nfunction isMapToString(value) {\n  return ObjectToString(value) === '[object Map]';\n}\nisMapToString.working = (\n  typeof Map !== 'undefined' &&\n  isMapToString(new Map())\n);\n\nfunction isMap(value) {\n  if (typeof Map === 'undefined') {\n    return false;\n  }\n\n  return isMapToString.working\n    ? isMapToString(value)\n    : value instanceof Map;\n}\nexports.isMap = isMap;\n\nfunction isSetToString(value) {\n  return ObjectToString(value) === '[object Set]';\n}\nisSetToString.working = (\n  typeof Set !== 'undefined' &&\n  isSetToString(new Set())\n);\nfunction isSet(value) {\n  if (typeof Set === 'undefined') {\n    return false;\n  }\n\n  return isSetToString.working\n    ? isSetToString(value)\n    : value instanceof Set;\n}\nexports.isSet = isSet;\n\nfunction isWeakMapToString(value) {\n  return ObjectToString(value) === '[object WeakMap]';\n}\nisWeakMapToString.working = (\n  typeof WeakMap !== 'undefined' &&\n  isWeakMapToString(new WeakMap())\n);\nfunction isWeakMap(value) {\n  if (typeof WeakMap === 'undefined') {\n    return false;\n  }\n\n  return isWeakMapToString.working\n    ? isWeakMapToString(value)\n    : value instanceof WeakMap;\n}\nexports.isWeakMap = isWeakMap;\n\nfunction isWeakSetToString(value) {\n  return ObjectToString(value) === '[object WeakSet]';\n}\nisWeakSetToString.working = (\n  typeof WeakSet !== 'undefined' &&\n  isWeakSetToString(new WeakSet())\n);\nfunction isWeakSet(value) {\n  return isWeakSetToString(value);\n}\nexports.isWeakSet = isWeakSet;\n\nfunction isArrayBufferToString(value) {\n  return ObjectToString(value) === '[object ArrayBuffer]';\n}\nisArrayBufferToString.working = (\n  typeof ArrayBuffer !== 'undefined' &&\n  isArrayBufferToString(new ArrayBuffer())\n);\nfunction isArrayBuffer(value) {\n  if (typeof ArrayBuffer === 'undefined') {\n    return false;\n  }\n\n  return isArrayBufferToString.working\n    ? isArrayBufferToString(value)\n    : value instanceof ArrayBuffer;\n}\nexports.isArrayBuffer = isArrayBuffer;\n\nfunction isDataViewToString(value) {\n  return ObjectToString(value) === '[object DataView]';\n}\nisDataViewToString.working = (\n  typeof ArrayBuffer !== 'undefined' &&\n  typeof DataView !== 'undefined' &&\n  isDataViewToString(new DataView(new ArrayBuffer(1), 0, 1))\n);\nfunction isDataView(value) {\n  if (typeof DataView === 'undefined') {\n    return false;\n  }\n\n  return isDataViewToString.working\n    ? isDataViewToString(value)\n    : value instanceof DataView;\n}\nexports.isDataView = isDataView;\n\n// Store a copy of SharedArrayBuffer in case it's deleted elsewhere\nvar SharedArrayBufferCopy = typeof SharedArrayBuffer !== 'undefined' ? SharedArrayBuffer : undefined;\nfunction isSharedArrayBufferToString(value) {\n  return ObjectToString(value) === '[object SharedArrayBuffer]';\n}\nfunction isSharedArrayBuffer(value) {\n  if (typeof SharedArrayBufferCopy === 'undefined') {\n    return false;\n  }\n\n  if (typeof isSharedArrayBufferToString.working === 'undefined') {\n    isSharedArrayBufferToString.working = isSharedArrayBufferToString(new SharedArrayBufferCopy());\n  }\n\n  return isSharedArrayBufferToString.working\n    ? isSharedArrayBufferToString(value)\n    : value instanceof SharedArrayBufferCopy;\n}\nexports.isSharedArrayBuffer = isSharedArrayBuffer;\n\nfunction isAsyncFunction(value) {\n  return ObjectToString(value) === '[object AsyncFunction]';\n}\nexports.isAsyncFunction = isAsyncFunction;\n\nfunction isMapIterator(value) {\n  return ObjectToString(value) === '[object Map Iterator]';\n}\nexports.isMapIterator = isMapIterator;\n\nfunction isSetIterator(value) {\n  return ObjectToString(value) === '[object Set Iterator]';\n}\nexports.isSetIterator = isSetIterator;\n\nfunction isGeneratorObject(value) {\n  return ObjectToString(value) === '[object Generator]';\n}\nexports.isGeneratorObject = isGeneratorObject;\n\nfunction isWebAssemblyCompiledModule(value) {\n  return ObjectToString(value) === '[object WebAssembly.Module]';\n}\nexports.isWebAssemblyCompiledModule = isWebAssemblyCompiledModule;\n\nfunction isNumberObject(value) {\n  return checkBoxedPrimitive(value, numberValue);\n}\nexports.isNumberObject = isNumberObject;\n\nfunction isStringObject(value) {\n  return checkBoxedPrimitive(value, stringValue);\n}\nexports.isStringObject = isStringObject;\n\nfunction isBooleanObject(value) {\n  return checkBoxedPrimitive(value, booleanValue);\n}\nexports.isBooleanObject = isBooleanObject;\n\nfunction isBigIntObject(value) {\n  return BigIntSupported && checkBoxedPrimitive(value, bigIntValue);\n}\nexports.isBigIntObject = isBigIntObject;\n\nfunction isSymbolObject(value) {\n  return SymbolSupported && checkBoxedPrimitive(value, symbolValue);\n}\nexports.isSymbolObject = isSymbolObject;\n\nfunction isBoxedPrimitive(value) {\n  return (\n    isNumberObject(value) ||\n    isStringObject(value) ||\n    isBooleanObject(value) ||\n    isBigIntObject(value) ||\n    isSymbolObject(value)\n  );\n}\nexports.isBoxedPrimitive = isBoxedPrimitive;\n\nfunction isAnyArrayBuffer(value) {\n  return typeof Uint8Array !== 'undefined' && (\n    isArrayBuffer(value) ||\n    isSharedArrayBuffer(value)\n  );\n}\nexports.isAnyArrayBuffer = isAnyArrayBuffer;\n\n['isProxy', 'isExternal', 'isModuleNamespaceObject'].forEach(function(method) {\n  Object.defineProperty(exports, method, {\n    enumerable: false,\n    value: function() {\n      throw new Error(method + ' is not supported in userland');\n    }\n  });\n});\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/util/support/types.js?");

/***/ }),

/***/ "../../node_modules/util/util.js":
/*!***************************************!*\
  !*** ../../node_modules/util/util.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar getOwnPropertyDescriptors = Object.getOwnPropertyDescriptors ||\n  function getOwnPropertyDescriptors(obj) {\n    var keys = Object.keys(obj);\n    var descriptors = {};\n    for (var i = 0; i < keys.length; i++) {\n      descriptors[keys[i]] = Object.getOwnPropertyDescriptor(obj, keys[i]);\n    }\n    return descriptors;\n  };\n\nvar formatRegExp = /%[sdj%]/g;\nexports.format = function(f) {\n  if (!isString(f)) {\n    var objects = [];\n    for (var i = 0; i < arguments.length; i++) {\n      objects.push(inspect(arguments[i]));\n    }\n    return objects.join(' ');\n  }\n\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  var str = String(f).replace(formatRegExp, function(x) {\n    if (x === '%%') return '%';\n    if (i >= len) return x;\n    switch (x) {\n      case '%s': return String(args[i++]);\n      case '%d': return Number(args[i++]);\n      case '%j':\n        try {\n          return JSON.stringify(args[i++]);\n        } catch (_) {\n          return '[Circular]';\n        }\n      default:\n        return x;\n    }\n  });\n  for (var x = args[i]; i < len; x = args[++i]) {\n    if (isNull(x) || !isObject(x)) {\n      str += ' ' + x;\n    } else {\n      str += ' ' + inspect(x);\n    }\n  }\n  return str;\n};\n\n\n// Mark that a method should not be used.\n// Returns a modified function which warns once by default.\n// If --no-deprecation is set, then it is a no-op.\nexports.deprecate = function(fn, msg) {\n  if (typeof process !== 'undefined' && process.noDeprecation === true) {\n    return fn;\n  }\n\n  // Allow for deprecating things in the process of starting up.\n  if (typeof process === 'undefined') {\n    return function() {\n      return exports.deprecate(fn, msg).apply(this, arguments);\n    };\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (process.throwDeprecation) {\n        throw new Error(msg);\n      } else if (process.traceDeprecation) {\n        console.trace(msg);\n      } else {\n        console.error(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n};\n\n\nvar debugs = {};\nvar debugEnvRegex = /^$/;\n\nif (process.env.NODE_DEBUG) {\n  var debugEnv = process.env.NODE_DEBUG;\n  debugEnv = debugEnv.replace(/[|\\\\{}()[\\]^$+?.]/g, '\\\\$&')\n    .replace(/\\*/g, '.*')\n    .replace(/,/g, '$|^')\n    .toUpperCase();\n  debugEnvRegex = new RegExp('^' + debugEnv + '$', 'i');\n}\nexports.debuglog = function(set) {\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (debugEnvRegex.test(set)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = exports.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n\n\n/**\n * Echos the value of a value. Trys to print the value out\n * in the best way possible given the different types.\n *\n * @param {Object} obj The object to print out.\n * @param {Object} opts Optional options object that alters the output.\n */\n/* legacy: obj, showHidden, depth, colors*/\nfunction inspect(obj, opts) {\n  // default options\n  var ctx = {\n    seen: [],\n    stylize: stylizeNoColor\n  };\n  // legacy...\n  if (arguments.length >= 3) ctx.depth = arguments[2];\n  if (arguments.length >= 4) ctx.colors = arguments[3];\n  if (isBoolean(opts)) {\n    // legacy...\n    ctx.showHidden = opts;\n  } else if (opts) {\n    // got an \"options\" object\n    exports._extend(ctx, opts);\n  }\n  // set default options\n  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n  if (isUndefined(ctx.depth)) ctx.depth = 2;\n  if (isUndefined(ctx.colors)) ctx.colors = false;\n  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n  if (ctx.colors) ctx.stylize = stylizeWithColor;\n  return formatValue(ctx, obj, ctx.depth);\n}\nexports.inspect = inspect;\n\n\n// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\ninspect.colors = {\n  'bold' : [1, 22],\n  'italic' : [3, 23],\n  'underline' : [4, 24],\n  'inverse' : [7, 27],\n  'white' : [37, 39],\n  'grey' : [90, 39],\n  'black' : [30, 39],\n  'blue' : [34, 39],\n  'cyan' : [36, 39],\n  'green' : [32, 39],\n  'magenta' : [35, 39],\n  'red' : [31, 39],\n  'yellow' : [33, 39]\n};\n\n// Don't use 'blue' not visible on cmd.exe\ninspect.styles = {\n  'special': 'cyan',\n  'number': 'yellow',\n  'boolean': 'yellow',\n  'undefined': 'grey',\n  'null': 'bold',\n  'string': 'green',\n  'date': 'magenta',\n  // \"name\": intentionally not styling\n  'regexp': 'red'\n};\n\n\nfunction stylizeWithColor(str, styleType) {\n  var style = inspect.styles[styleType];\n\n  if (style) {\n    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n           '\\u001b[' + inspect.colors[style][1] + 'm';\n  } else {\n    return str;\n  }\n}\n\n\nfunction stylizeNoColor(str, styleType) {\n  return str;\n}\n\n\nfunction arrayToHash(array) {\n  var hash = {};\n\n  array.forEach(function(val, idx) {\n    hash[val] = true;\n  });\n\n  return hash;\n}\n\n\nfunction formatValue(ctx, value, recurseTimes) {\n  // Provide a hook for user-specified inspect functions.\n  // Check that value is an object with an inspect function on it\n  if (ctx.customInspect &&\n      value &&\n      isFunction(value.inspect) &&\n      // Filter out the util module, it's inspect function is special\n      value.inspect !== exports.inspect &&\n      // Also filter out any prototype objects using the circular check.\n      !(value.constructor && value.constructor.prototype === value)) {\n    var ret = value.inspect(recurseTimes, ctx);\n    if (!isString(ret)) {\n      ret = formatValue(ctx, ret, recurseTimes);\n    }\n    return ret;\n  }\n\n  // Primitive types cannot have properties\n  var primitive = formatPrimitive(ctx, value);\n  if (primitive) {\n    return primitive;\n  }\n\n  // Look up the keys of the object.\n  var keys = Object.keys(value);\n  var visibleKeys = arrayToHash(keys);\n\n  if (ctx.showHidden) {\n    keys = Object.getOwnPropertyNames(value);\n  }\n\n  // IE doesn't make error fields non-enumerable\n  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx\n  if (isError(value)\n      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {\n    return formatError(value);\n  }\n\n  // Some type of object without properties can be shortcutted.\n  if (keys.length === 0) {\n    if (isFunction(value)) {\n      var name = value.name ? ': ' + value.name : '';\n      return ctx.stylize('[Function' + name + ']', 'special');\n    }\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    }\n    if (isDate(value)) {\n      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n    }\n    if (isError(value)) {\n      return formatError(value);\n    }\n  }\n\n  var base = '', array = false, braces = ['{', '}'];\n\n  // Make Array say that they are Array\n  if (isArray(value)) {\n    array = true;\n    braces = ['[', ']'];\n  }\n\n  // Make functions say that they are functions\n  if (isFunction(value)) {\n    var n = value.name ? ': ' + value.name : '';\n    base = ' [Function' + n + ']';\n  }\n\n  // Make RegExps say that they are RegExps\n  if (isRegExp(value)) {\n    base = ' ' + RegExp.prototype.toString.call(value);\n  }\n\n  // Make dates with properties first say the date\n  if (isDate(value)) {\n    base = ' ' + Date.prototype.toUTCString.call(value);\n  }\n\n  // Make error with message first say the error\n  if (isError(value)) {\n    base = ' ' + formatError(value);\n  }\n\n  if (keys.length === 0 && (!array || value.length == 0)) {\n    return braces[0] + base + braces[1];\n  }\n\n  if (recurseTimes < 0) {\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    } else {\n      return ctx.stylize('[Object]', 'special');\n    }\n  }\n\n  ctx.seen.push(value);\n\n  var output;\n  if (array) {\n    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n  } else {\n    output = keys.map(function(key) {\n      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n    });\n  }\n\n  ctx.seen.pop();\n\n  return reduceToSingleString(output, base, braces);\n}\n\n\nfunction formatPrimitive(ctx, value) {\n  if (isUndefined(value))\n    return ctx.stylize('undefined', 'undefined');\n  if (isString(value)) {\n    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n                                             .replace(/'/g, \"\\\\'\")\n                                             .replace(/\\\\\"/g, '\"') + '\\'';\n    return ctx.stylize(simple, 'string');\n  }\n  if (isNumber(value))\n    return ctx.stylize('' + value, 'number');\n  if (isBoolean(value))\n    return ctx.stylize('' + value, 'boolean');\n  // For some reason typeof null is \"object\", so special case here.\n  if (isNull(value))\n    return ctx.stylize('null', 'null');\n}\n\n\nfunction formatError(value) {\n  return '[' + Error.prototype.toString.call(value) + ']';\n}\n\n\nfunction formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n  var output = [];\n  for (var i = 0, l = value.length; i < l; ++i) {\n    if (hasOwnProperty(value, String(i))) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          String(i), true));\n    } else {\n      output.push('');\n    }\n  }\n  keys.forEach(function(key) {\n    if (!key.match(/^\\d+$/)) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          key, true));\n    }\n  });\n  return output;\n}\n\n\nfunction formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n  var name, str, desc;\n  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n  if (desc.get) {\n    if (desc.set) {\n      str = ctx.stylize('[Getter/Setter]', 'special');\n    } else {\n      str = ctx.stylize('[Getter]', 'special');\n    }\n  } else {\n    if (desc.set) {\n      str = ctx.stylize('[Setter]', 'special');\n    }\n  }\n  if (!hasOwnProperty(visibleKeys, key)) {\n    name = '[' + key + ']';\n  }\n  if (!str) {\n    if (ctx.seen.indexOf(desc.value) < 0) {\n      if (isNull(recurseTimes)) {\n        str = formatValue(ctx, desc.value, null);\n      } else {\n        str = formatValue(ctx, desc.value, recurseTimes - 1);\n      }\n      if (str.indexOf('\\n') > -1) {\n        if (array) {\n          str = str.split('\\n').map(function(line) {\n            return '  ' + line;\n          }).join('\\n').slice(2);\n        } else {\n          str = '\\n' + str.split('\\n').map(function(line) {\n            return '   ' + line;\n          }).join('\\n');\n        }\n      }\n    } else {\n      str = ctx.stylize('[Circular]', 'special');\n    }\n  }\n  if (isUndefined(name)) {\n    if (array && key.match(/^\\d+$/)) {\n      return str;\n    }\n    name = JSON.stringify('' + key);\n    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n      name = name.slice(1, -1);\n      name = ctx.stylize(name, 'name');\n    } else {\n      name = name.replace(/'/g, \"\\\\'\")\n                 .replace(/\\\\\"/g, '\"')\n                 .replace(/(^\"|\"$)/g, \"'\");\n      name = ctx.stylize(name, 'string');\n    }\n  }\n\n  return name + ': ' + str;\n}\n\n\nfunction reduceToSingleString(output, base, braces) {\n  var numLinesEst = 0;\n  var length = output.reduce(function(prev, cur) {\n    numLinesEst++;\n    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n  }, 0);\n\n  if (length > 60) {\n    return braces[0] +\n           (base === '' ? '' : base + '\\n ') +\n           ' ' +\n           output.join(',\\n  ') +\n           ' ' +\n           braces[1];\n  }\n\n  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n}\n\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\nexports.types = __webpack_require__(/*! ./support/types */ \"../../node_modules/util/support/types.js\");\n\nfunction isArray(ar) {\n  return Array.isArray(ar);\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return isObject(re) && objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\nexports.types.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return isObject(d) && objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\nexports.types.isDate = isDate;\n\nfunction isError(e) {\n  return isObject(e) &&\n      (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\nexports.types.isNativeError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = __webpack_require__(/*! ./support/isBuffer */ \"../../node_modules/util/support/isBufferBrowser.js\");\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\nfunction pad(n) {\n  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n}\n\n\nvar months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n              'Oct', 'Nov', 'Dec'];\n\n// 26 Feb 16:19:34\nfunction timestamp() {\n  var d = new Date();\n  var time = [pad(d.getHours()),\n              pad(d.getMinutes()),\n              pad(d.getSeconds())].join(':');\n  return [d.getDate(), months[d.getMonth()], time].join(' ');\n}\n\n\n// log is just a thin wrapper to console.log that prepends a timestamp\nexports.log = function() {\n  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n};\n\n\n/**\n * Inherit the prototype methods from one constructor into another.\n *\n * The Function.prototype.inherits from lang.js rewritten as a standalone\n * function (not on Function.prototype). NOTE: If this file is to be loaded\n * during bootstrapping this function needs to be rewritten using some native\n * functions as prototype setup using normal JavaScript does not work as\n * expected during bootstrapping (see mirror.js in r114903).\n *\n * @param {function} ctor Constructor function which needs to inherit the\n *     prototype.\n * @param {function} superCtor Constructor function to inherit prototype from.\n */\nexports.inherits = __webpack_require__(/*! inherits */ \"../../node_modules/inherits/inherits_browser.js\");\n\nexports._extend = function(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || !isObject(add)) return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n};\n\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\nvar kCustomPromisifiedSymbol = typeof Symbol !== 'undefined' ? Symbol('util.promisify.custom') : undefined;\n\nexports.promisify = function promisify(original) {\n  if (typeof original !== 'function')\n    throw new TypeError('The \"original\" argument must be of type Function');\n\n  if (kCustomPromisifiedSymbol && original[kCustomPromisifiedSymbol]) {\n    var fn = original[kCustomPromisifiedSymbol];\n    if (typeof fn !== 'function') {\n      throw new TypeError('The \"util.promisify.custom\" argument must be of type Function');\n    }\n    Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n      value: fn, enumerable: false, writable: false, configurable: true\n    });\n    return fn;\n  }\n\n  function fn() {\n    var promiseResolve, promiseReject;\n    var promise = new Promise(function (resolve, reject) {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n    args.push(function (err, value) {\n      if (err) {\n        promiseReject(err);\n      } else {\n        promiseResolve(value);\n      }\n    });\n\n    try {\n      original.apply(this, args);\n    } catch (err) {\n      promiseReject(err);\n    }\n\n    return promise;\n  }\n\n  Object.setPrototypeOf(fn, Object.getPrototypeOf(original));\n\n  if (kCustomPromisifiedSymbol) Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n    value: fn, enumerable: false, writable: false, configurable: true\n  });\n  return Object.defineProperties(\n    fn,\n    getOwnPropertyDescriptors(original)\n  );\n}\n\nexports.promisify.custom = kCustomPromisifiedSymbol\n\nfunction callbackifyOnRejected(reason, cb) {\n  // `!reason` guard inspired by bluebird (Ref: https://goo.gl/t5IS6M).\n  // Because `null` is a special error value in callbacks which means \"no error\n  // occurred\", we error-wrap so the callback consumer can distinguish between\n  // \"the promise rejected with null\" or \"the promise fulfilled with undefined\".\n  if (!reason) {\n    var newReason = new Error('Promise was rejected with a falsy value');\n    newReason.reason = reason;\n    reason = newReason;\n  }\n  return cb(reason);\n}\n\nfunction callbackify(original) {\n  if (typeof original !== 'function') {\n    throw new TypeError('The \"original\" argument must be of type Function');\n  }\n\n  // We DO NOT return the promise as it gives the user a false sense that\n  // the promise is actually somehow related to the callback's execution\n  // and that the callback throwing will reject the promise.\n  function callbackified() {\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n\n    var maybeCb = args.pop();\n    if (typeof maybeCb !== 'function') {\n      throw new TypeError('The last argument must be of type Function');\n    }\n    var self = this;\n    var cb = function() {\n      return maybeCb.apply(self, arguments);\n    };\n    // In true node style we process the callback on `nextTick` with all the\n    // implications (stack, `uncaughtException`, `async_hooks`)\n    original.apply(this, args)\n      .then(function(ret) { process.nextTick(cb.bind(null, null, ret)) },\n            function(rej) { process.nextTick(callbackifyOnRejected.bind(null, rej, cb)) });\n  }\n\n  Object.setPrototypeOf(callbackified, Object.getPrototypeOf(original));\n  Object.defineProperties(callbackified,\n                          getOwnPropertyDescriptors(original));\n  return callbackified;\n}\nexports.callbackify = callbackify;\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/util/util.js?");

/***/ }),

/***/ "../../node_modules/which-typed-array/index.js":
/*!*****************************************************!*\
  !*** ../../node_modules/which-typed-array/index.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar forEach = __webpack_require__(/*! for-each */ \"../../node_modules/for-each/index.js\");\nvar availableTypedArrays = __webpack_require__(/*! available-typed-arrays */ \"../../node_modules/available-typed-arrays/index.js\");\nvar callBind = __webpack_require__(/*! call-bind */ \"../../node_modules/call-bind/index.js\");\nvar callBound = __webpack_require__(/*! call-bind/callBound */ \"../../node_modules/call-bind/callBound.js\");\nvar gOPD = __webpack_require__(/*! gopd */ \"../../node_modules/gopd/index.js\");\n\nvar $toString = callBound('Object.prototype.toString');\nvar hasToStringTag = __webpack_require__(/*! has-tostringtag/shams */ \"../../node_modules/has-tostringtag/shams.js\")();\n\nvar g = typeof globalThis === 'undefined' ? __webpack_require__.g : globalThis;\nvar typedArrays = availableTypedArrays();\n\nvar $slice = callBound('String.prototype.slice');\nvar getPrototypeOf = Object.getPrototypeOf; // require('getprototypeof');\n\nvar $indexOf = callBound('Array.prototype.indexOf', true) || function indexOf(array, value) {\n\tfor (var i = 0; i < array.length; i += 1) {\n\t\tif (array[i] === value) {\n\t\t\treturn i;\n\t\t}\n\t}\n\treturn -1;\n};\nvar cache = { __proto__: null };\nif (hasToStringTag && gOPD && getPrototypeOf) {\n\tforEach(typedArrays, function (typedArray) {\n\t\tvar arr = new g[typedArray]();\n\t\tif (Symbol.toStringTag in arr) {\n\t\t\tvar proto = getPrototypeOf(arr);\n\t\t\tvar descriptor = gOPD(proto, Symbol.toStringTag);\n\t\t\tif (!descriptor) {\n\t\t\t\tvar superProto = getPrototypeOf(proto);\n\t\t\t\tdescriptor = gOPD(superProto, Symbol.toStringTag);\n\t\t\t}\n\t\t\tcache['$' + typedArray] = callBind(descriptor.get);\n\t\t}\n\t});\n} else {\n\tforEach(typedArrays, function (typedArray) {\n\t\tvar arr = new g[typedArray]();\n\t\tvar fn = arr.slice || arr.set;\n\t\tif (fn) {\n\t\t\tcache['$' + typedArray] = callBind(fn);\n\t\t}\n\t});\n}\n\nvar tryTypedArrays = function tryAllTypedArrays(value) {\n\tvar found = false;\n\tforEach(cache, function (getter, typedArray) {\n\t\tif (!found) {\n\t\t\ttry {\n\t\t\t\tif ('$' + getter(value) === typedArray) {\n\t\t\t\t\tfound = $slice(typedArray, 1);\n\t\t\t\t}\n\t\t\t} catch (e) { /**/ }\n\t\t}\n\t});\n\treturn found;\n};\n\nvar trySlices = function tryAllSlices(value) {\n\tvar found = false;\n\tforEach(cache, function (getter, name) {\n\t\tif (!found) {\n\t\t\ttry {\n\t\t\t\tgetter(value);\n\t\t\t\tfound = $slice(name, 1);\n\t\t\t} catch (e) { /**/ }\n\t\t}\n\t});\n\treturn found;\n};\n\nmodule.exports = function whichTypedArray(value) {\n\tif (!value || typeof value !== 'object') { return false; }\n\tif (!hasToStringTag) {\n\t\tvar tag = $slice($toString(value), 8, -1);\n\t\tif ($indexOf(typedArrays, tag) > -1) {\n\t\t\treturn tag;\n\t\t}\n\t\tif (tag !== 'Object') {\n\t\t\treturn false;\n\t\t}\n\t\t// node < 0.6 hits here on real Typed Arrays\n\t\treturn trySlices(value);\n\t}\n\tif (!gOPD) { return null; } // unknown engine\n\treturn tryTypedArrays(value);\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/which-typed-array/index.js?");

/***/ }),

/***/ "?a0c3":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://oracle2/fs_(ignored)?");

/***/ }),

/***/ "./node_modules/bson/lib/bson.cjs":
/*!****************************************!*\
  !*** ./node_modules/bson/lib/bson.cjs ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nfunction isAnyArrayBuffer(value) {\n    return ['[object ArrayBuffer]', '[object SharedArrayBuffer]'].includes(Object.prototype.toString.call(value));\n}\nfunction isUint8Array(value) {\n    return Object.prototype.toString.call(value) === '[object Uint8Array]';\n}\nfunction isRegExp(d) {\n    return Object.prototype.toString.call(d) === '[object RegExp]';\n}\nfunction isMap(d) {\n    return Object.prototype.toString.call(d) === '[object Map]';\n}\nfunction isDate(d) {\n    return Object.prototype.toString.call(d) === '[object Date]';\n}\nfunction defaultInspect(x, _options) {\n    return JSON.stringify(x, (k, v) => {\n        if (typeof v === 'bigint') {\n            return { $numberLong: `${v}` };\n        }\n        else if (isMap(v)) {\n            return Object.fromEntries(v);\n        }\n        return v;\n    });\n}\nfunction getStylizeFunction(options) {\n    const stylizeExists = options != null &&\n        typeof options === 'object' &&\n        'stylize' in options &&\n        typeof options.stylize === 'function';\n    if (stylizeExists) {\n        return options.stylize;\n    }\n}\n\nconst BSON_MAJOR_VERSION = 6;\nconst BSON_INT32_MAX = 0x7fffffff;\nconst BSON_INT32_MIN = -0x80000000;\nconst BSON_INT64_MAX = Math.pow(2, 63) - 1;\nconst BSON_INT64_MIN = -Math.pow(2, 63);\nconst JS_INT_MAX = Math.pow(2, 53);\nconst JS_INT_MIN = -Math.pow(2, 53);\nconst BSON_DATA_NUMBER = 1;\nconst BSON_DATA_STRING = 2;\nconst BSON_DATA_OBJECT = 3;\nconst BSON_DATA_ARRAY = 4;\nconst BSON_DATA_BINARY = 5;\nconst BSON_DATA_UNDEFINED = 6;\nconst BSON_DATA_OID = 7;\nconst BSON_DATA_BOOLEAN = 8;\nconst BSON_DATA_DATE = 9;\nconst BSON_DATA_NULL = 10;\nconst BSON_DATA_REGEXP = 11;\nconst BSON_DATA_DBPOINTER = 12;\nconst BSON_DATA_CODE = 13;\nconst BSON_DATA_SYMBOL = 14;\nconst BSON_DATA_CODE_W_SCOPE = 15;\nconst BSON_DATA_INT = 16;\nconst BSON_DATA_TIMESTAMP = 17;\nconst BSON_DATA_LONG = 18;\nconst BSON_DATA_DECIMAL128 = 19;\nconst BSON_DATA_MIN_KEY = 0xff;\nconst BSON_DATA_MAX_KEY = 0x7f;\nconst BSON_BINARY_SUBTYPE_DEFAULT = 0;\nconst BSON_BINARY_SUBTYPE_UUID_NEW = 4;\nconst BSONType = Object.freeze({\n    double: 1,\n    string: 2,\n    object: 3,\n    array: 4,\n    binData: 5,\n    undefined: 6,\n    objectId: 7,\n    bool: 8,\n    date: 9,\n    null: 10,\n    regex: 11,\n    dbPointer: 12,\n    javascript: 13,\n    symbol: 14,\n    javascriptWithScope: 15,\n    int: 16,\n    timestamp: 17,\n    long: 18,\n    decimal: 19,\n    minKey: -1,\n    maxKey: 127\n});\n\nclass BSONError extends Error {\n    get bsonError() {\n        return true;\n    }\n    get name() {\n        return 'BSONError';\n    }\n    constructor(message) {\n        super(message);\n    }\n    static isBSONError(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            'bsonError' in value &&\n            value.bsonError === true &&\n            'name' in value &&\n            'message' in value &&\n            'stack' in value);\n    }\n}\nclass BSONVersionError extends BSONError {\n    get name() {\n        return 'BSONVersionError';\n    }\n    constructor() {\n        super(`Unsupported BSON version, bson types must be from bson ${BSON_MAJOR_VERSION}.x.x`);\n    }\n}\nclass BSONRuntimeError extends BSONError {\n    get name() {\n        return 'BSONRuntimeError';\n    }\n    constructor(message) {\n        super(message);\n    }\n}\n\nfunction nodejsMathRandomBytes(byteLength) {\n    return nodeJsByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst nodejsRandomBytes = (() => {\n    try {\n        return Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n    }\n    catch {\n        return nodejsMathRandomBytes;\n    }\n})();\nconst nodeJsByteUtils = {\n    toLocalBufferType(potentialBuffer) {\n        if (Buffer.isBuffer(potentialBuffer)) {\n            return potentialBuffer;\n        }\n        if (ArrayBuffer.isView(potentialBuffer)) {\n            return Buffer.from(potentialBuffer.buffer, potentialBuffer.byteOffset, potentialBuffer.byteLength);\n        }\n        const stringTag = potentialBuffer?.[Symbol.toStringTag] ?? Object.prototype.toString.call(potentialBuffer);\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return Buffer.from(potentialBuffer);\n        }\n        throw new BSONError(`Cannot create Buffer from ${String(potentialBuffer)}`);\n    },\n    allocate(size) {\n        return Buffer.alloc(size);\n    },\n    equals(a, b) {\n        return nodeJsByteUtils.toLocalBufferType(a).equals(b);\n    },\n    fromNumberArray(array) {\n        return Buffer.from(array);\n    },\n    fromBase64(base64) {\n        return Buffer.from(base64, 'base64');\n    },\n    toBase64(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('base64');\n    },\n    fromISO88591(codePoints) {\n        return Buffer.from(codePoints, 'binary');\n    },\n    toISO88591(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('binary');\n    },\n    fromHex(hex) {\n        return Buffer.from(hex, 'hex');\n    },\n    toHex(buffer) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('hex');\n    },\n    fromUTF8(text) {\n        return Buffer.from(text, 'utf8');\n    },\n    toUTF8(buffer, start, end) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).toString('utf8', start, end);\n    },\n    utf8ByteLength(input) {\n        return Buffer.byteLength(input, 'utf8');\n    },\n    encodeUTF8Into(buffer, source, byteOffset) {\n        return nodeJsByteUtils.toLocalBufferType(buffer).write(source, byteOffset, undefined, 'utf8');\n    },\n    randomBytes: nodejsRandomBytes\n};\n\nfunction isReactNative() {\n    const { navigator } = globalThis;\n    return typeof navigator === 'object' && navigator.product === 'ReactNative';\n}\nfunction webMathRandomBytes(byteLength) {\n    if (byteLength < 0) {\n        throw new RangeError(`The argument 'byteLength' is invalid. Received ${byteLength}`);\n    }\n    return webByteUtils.fromNumberArray(Array.from({ length: byteLength }, () => Math.floor(Math.random() * 256)));\n}\nconst webRandomBytes = (() => {\n    const { crypto } = globalThis;\n    if (crypto != null && typeof crypto.getRandomValues === 'function') {\n        return (byteLength) => {\n            return crypto.getRandomValues(webByteUtils.allocate(byteLength));\n        };\n    }\n    else {\n        if (isReactNative()) {\n            const { console } = globalThis;\n            console?.warn?.('BSON: For React Native please polyfill crypto.getRandomValues, e.g. using: https://www.npmjs.com/package/react-native-get-random-values.');\n        }\n        return webMathRandomBytes;\n    }\n})();\nconst HEX_DIGIT = /(\\d|[a-f])/i;\nconst webByteUtils = {\n    toLocalBufferType(potentialUint8array) {\n        const stringTag = potentialUint8array?.[Symbol.toStringTag] ??\n            Object.prototype.toString.call(potentialUint8array);\n        if (stringTag === 'Uint8Array') {\n            return potentialUint8array;\n        }\n        if (ArrayBuffer.isView(potentialUint8array)) {\n            return new Uint8Array(potentialUint8array.buffer.slice(potentialUint8array.byteOffset, potentialUint8array.byteOffset + potentialUint8array.byteLength));\n        }\n        if (stringTag === 'ArrayBuffer' ||\n            stringTag === 'SharedArrayBuffer' ||\n            stringTag === '[object ArrayBuffer]' ||\n            stringTag === '[object SharedArrayBuffer]') {\n            return new Uint8Array(potentialUint8array);\n        }\n        throw new BSONError(`Cannot make a Uint8Array from ${String(potentialUint8array)}`);\n    },\n    allocate(size) {\n        if (typeof size !== 'number') {\n            throw new TypeError(`The \"size\" argument must be of type number. Received ${String(size)}`);\n        }\n        return new Uint8Array(size);\n    },\n    equals(a, b) {\n        if (a.byteLength !== b.byteLength) {\n            return false;\n        }\n        for (let i = 0; i < a.byteLength; i++) {\n            if (a[i] !== b[i]) {\n                return false;\n            }\n        }\n        return true;\n    },\n    fromNumberArray(array) {\n        return Uint8Array.from(array);\n    },\n    fromBase64(base64) {\n        return Uint8Array.from(atob(base64), c => c.charCodeAt(0));\n    },\n    toBase64(uint8array) {\n        return btoa(webByteUtils.toISO88591(uint8array));\n    },\n    fromISO88591(codePoints) {\n        return Uint8Array.from(codePoints, c => c.charCodeAt(0) & 0xff);\n    },\n    toISO88591(uint8array) {\n        return Array.from(Uint16Array.from(uint8array), b => String.fromCharCode(b)).join('');\n    },\n    fromHex(hex) {\n        const evenLengthHex = hex.length % 2 === 0 ? hex : hex.slice(0, hex.length - 1);\n        const buffer = [];\n        for (let i = 0; i < evenLengthHex.length; i += 2) {\n            const firstDigit = evenLengthHex[i];\n            const secondDigit = evenLengthHex[i + 1];\n            if (!HEX_DIGIT.test(firstDigit)) {\n                break;\n            }\n            if (!HEX_DIGIT.test(secondDigit)) {\n                break;\n            }\n            const hexDigit = Number.parseInt(`${firstDigit}${secondDigit}`, 16);\n            buffer.push(hexDigit);\n        }\n        return Uint8Array.from(buffer);\n    },\n    toHex(uint8array) {\n        return Array.from(uint8array, byte => byte.toString(16).padStart(2, '0')).join('');\n    },\n    fromUTF8(text) {\n        return new TextEncoder().encode(text);\n    },\n    toUTF8(uint8array, start, end) {\n        return new TextDecoder('utf8', { fatal: false }).decode(uint8array.slice(start, end));\n    },\n    utf8ByteLength(input) {\n        return webByteUtils.fromUTF8(input).byteLength;\n    },\n    encodeUTF8Into(buffer, source, byteOffset) {\n        const bytes = webByteUtils.fromUTF8(source);\n        buffer.set(bytes, byteOffset);\n        return bytes.byteLength;\n    },\n    randomBytes: webRandomBytes\n};\n\nconst hasGlobalBuffer = typeof Buffer === 'function' && Buffer.prototype?._isBuffer !== true;\nconst ByteUtils = hasGlobalBuffer ? nodeJsByteUtils : webByteUtils;\nclass BSONDataView extends DataView {\n    static fromUint8Array(input) {\n        return new DataView(input.buffer, input.byteOffset, input.byteLength);\n    }\n}\n\nclass BSONValue {\n    get [Symbol.for('@@mdb.bson.version')]() {\n        return BSON_MAJOR_VERSION;\n    }\n    [Symbol.for('nodejs.util.inspect.custom')](depth, options, inspect) {\n        return this.inspect(depth, options, inspect);\n    }\n}\n\nclass Binary extends BSONValue {\n    get _bsontype() {\n        return 'Binary';\n    }\n    constructor(buffer, subType) {\n        super();\n        if (!(buffer == null) &&\n            typeof buffer === 'string' &&\n            !ArrayBuffer.isView(buffer) &&\n            !isAnyArrayBuffer(buffer) &&\n            !Array.isArray(buffer)) {\n            throw new BSONError('Binary can only be constructed from Uint8Array or number[]');\n        }\n        this.sub_type = subType ?? Binary.BSON_BINARY_SUBTYPE_DEFAULT;\n        if (buffer == null) {\n            this.buffer = ByteUtils.allocate(Binary.BUFFER_SIZE);\n            this.position = 0;\n        }\n        else {\n            this.buffer = Array.isArray(buffer)\n                ? ByteUtils.fromNumberArray(buffer)\n                : ByteUtils.toLocalBufferType(buffer);\n            this.position = this.buffer.byteLength;\n        }\n    }\n    put(byteValue) {\n        if (typeof byteValue === 'string' && byteValue.length !== 1) {\n            throw new BSONError('only accepts single character String');\n        }\n        else if (typeof byteValue !== 'number' && byteValue.length !== 1)\n            throw new BSONError('only accepts single character Uint8Array or Array');\n        let decodedByte;\n        if (typeof byteValue === 'string') {\n            decodedByte = byteValue.charCodeAt(0);\n        }\n        else if (typeof byteValue === 'number') {\n            decodedByte = byteValue;\n        }\n        else {\n            decodedByte = byteValue[0];\n        }\n        if (decodedByte < 0 || decodedByte > 255) {\n            throw new BSONError('only accepts number in a valid unsigned byte range 0-255');\n        }\n        if (this.buffer.byteLength > this.position) {\n            this.buffer[this.position++] = decodedByte;\n        }\n        else {\n            const newSpace = ByteUtils.allocate(Binary.BUFFER_SIZE + this.buffer.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n            this.buffer[this.position++] = decodedByte;\n        }\n    }\n    write(sequence, offset) {\n        offset = typeof offset === 'number' ? offset : this.position;\n        if (this.buffer.byteLength < offset + sequence.length) {\n            const newSpace = ByteUtils.allocate(this.buffer.byteLength + sequence.length);\n            newSpace.set(this.buffer, 0);\n            this.buffer = newSpace;\n        }\n        if (ArrayBuffer.isView(sequence)) {\n            this.buffer.set(ByteUtils.toLocalBufferType(sequence), offset);\n            this.position =\n                offset + sequence.byteLength > this.position ? offset + sequence.length : this.position;\n        }\n        else if (typeof sequence === 'string') {\n            throw new BSONError('input cannot be string');\n        }\n    }\n    read(position, length) {\n        length = length && length > 0 ? length : this.position;\n        return this.buffer.slice(position, position + length);\n    }\n    value() {\n        return this.buffer.length === this.position\n            ? this.buffer\n            : this.buffer.subarray(0, this.position);\n    }\n    length() {\n        return this.position;\n    }\n    toJSON() {\n        return ByteUtils.toBase64(this.buffer);\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.buffer);\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.buffer);\n        if (encoding === 'utf8' || encoding === 'utf-8')\n            return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);\n        return ByteUtils.toUTF8(this.buffer, 0, this.buffer.byteLength);\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        const base64String = ByteUtils.toBase64(this.buffer);\n        const subType = Number(this.sub_type).toString(16);\n        if (options.legacy) {\n            return {\n                $binary: base64String,\n                $type: subType.length === 1 ? '0' + subType : subType\n            };\n        }\n        return {\n            $binary: {\n                base64: base64String,\n                subType: subType.length === 1 ? '0' + subType : subType\n            }\n        };\n    }\n    toUUID() {\n        if (this.sub_type === Binary.SUBTYPE_UUID) {\n            return new UUID(this.buffer.slice(0, this.position));\n        }\n        throw new BSONError(`Binary sub_type \"${this.sub_type}\" is not supported for converting to UUID. Only \"${Binary.SUBTYPE_UUID}\" is currently supported.`);\n    }\n    static createFromHexString(hex, subType) {\n        return new Binary(ByteUtils.fromHex(hex), subType);\n    }\n    static createFromBase64(base64, subType) {\n        return new Binary(ByteUtils.fromBase64(base64), subType);\n    }\n    static fromExtendedJSON(doc, options) {\n        options = options || {};\n        let data;\n        let type;\n        if ('$binary' in doc) {\n            if (options.legacy && typeof doc.$binary === 'string' && '$type' in doc) {\n                type = doc.$type ? parseInt(doc.$type, 16) : 0;\n                data = ByteUtils.fromBase64(doc.$binary);\n            }\n            else {\n                if (typeof doc.$binary !== 'string') {\n                    type = doc.$binary.subType ? parseInt(doc.$binary.subType, 16) : 0;\n                    data = ByteUtils.fromBase64(doc.$binary.base64);\n                }\n            }\n        }\n        else if ('$uuid' in doc) {\n            type = 4;\n            data = UUID.bytesFromString(doc.$uuid);\n        }\n        if (!data) {\n            throw new BSONError(`Unexpected Binary Extended JSON format ${JSON.stringify(doc)}`);\n        }\n        return type === BSON_BINARY_SUBTYPE_UUID_NEW ? new UUID(data) : new Binary(data, type);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const base64 = ByteUtils.toBase64(this.buffer.subarray(0, this.position));\n        const base64Arg = inspect(base64, options);\n        const subTypeArg = inspect(this.sub_type, options);\n        return `Binary.createFromBase64(${base64Arg}, ${subTypeArg})`;\n    }\n}\nBinary.BSON_BINARY_SUBTYPE_DEFAULT = 0;\nBinary.BUFFER_SIZE = 256;\nBinary.SUBTYPE_DEFAULT = 0;\nBinary.SUBTYPE_FUNCTION = 1;\nBinary.SUBTYPE_BYTE_ARRAY = 2;\nBinary.SUBTYPE_UUID_OLD = 3;\nBinary.SUBTYPE_UUID = 4;\nBinary.SUBTYPE_MD5 = 5;\nBinary.SUBTYPE_ENCRYPTED = 6;\nBinary.SUBTYPE_COLUMN = 7;\nBinary.SUBTYPE_USER_DEFINED = 128;\nconst UUID_BYTE_LENGTH = 16;\nconst UUID_WITHOUT_DASHES = /^[0-9A-F]{32}$/i;\nconst UUID_WITH_DASHES = /^[0-9A-F]{8}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{4}-[0-9A-F]{12}$/i;\nclass UUID extends Binary {\n    constructor(input) {\n        let bytes;\n        if (input == null) {\n            bytes = UUID.generate();\n        }\n        else if (input instanceof UUID) {\n            bytes = ByteUtils.toLocalBufferType(new Uint8Array(input.buffer));\n        }\n        else if (ArrayBuffer.isView(input) && input.byteLength === UUID_BYTE_LENGTH) {\n            bytes = ByteUtils.toLocalBufferType(input);\n        }\n        else if (typeof input === 'string') {\n            bytes = UUID.bytesFromString(input);\n        }\n        else {\n            throw new BSONError('Argument passed in UUID constructor must be a UUID, a 16 byte Buffer or a 32/36 character hex string (dashes excluded/included, format: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx).');\n        }\n        super(bytes, BSON_BINARY_SUBTYPE_UUID_NEW);\n    }\n    get id() {\n        return this.buffer;\n    }\n    set id(value) {\n        this.buffer = value;\n    }\n    toHexString(includeDashes = true) {\n        if (includeDashes) {\n            return [\n                ByteUtils.toHex(this.buffer.subarray(0, 4)),\n                ByteUtils.toHex(this.buffer.subarray(4, 6)),\n                ByteUtils.toHex(this.buffer.subarray(6, 8)),\n                ByteUtils.toHex(this.buffer.subarray(8, 10)),\n                ByteUtils.toHex(this.buffer.subarray(10, 16))\n            ].join('-');\n        }\n        return ByteUtils.toHex(this.buffer);\n    }\n    toString(encoding) {\n        if (encoding === 'hex')\n            return ByteUtils.toHex(this.id);\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    equals(otherId) {\n        if (!otherId) {\n            return false;\n        }\n        if (otherId instanceof UUID) {\n            return ByteUtils.equals(otherId.id, this.id);\n        }\n        try {\n            return ByteUtils.equals(new UUID(otherId).id, this.id);\n        }\n        catch {\n            return false;\n        }\n    }\n    toBinary() {\n        return new Binary(this.id, Binary.SUBTYPE_UUID);\n    }\n    static generate() {\n        const bytes = ByteUtils.randomBytes(UUID_BYTE_LENGTH);\n        bytes[6] = (bytes[6] & 0x0f) | 0x40;\n        bytes[8] = (bytes[8] & 0x3f) | 0x80;\n        return bytes;\n    }\n    static isValid(input) {\n        if (!input) {\n            return false;\n        }\n        if (typeof input === 'string') {\n            return UUID.isValidUUIDString(input);\n        }\n        if (isUint8Array(input)) {\n            return input.byteLength === UUID_BYTE_LENGTH;\n        }\n        return (input._bsontype === 'Binary' &&\n            input.sub_type === this.SUBTYPE_UUID &&\n            input.buffer.byteLength === 16);\n    }\n    static createFromHexString(hexString) {\n        const buffer = UUID.bytesFromString(hexString);\n        return new UUID(buffer);\n    }\n    static createFromBase64(base64) {\n        return new UUID(ByteUtils.fromBase64(base64));\n    }\n    static bytesFromString(representation) {\n        if (!UUID.isValidUUIDString(representation)) {\n            throw new BSONError('UUID string representation must be 32 hex digits or canonical hyphenated representation');\n        }\n        return ByteUtils.fromHex(representation.replace(/-/g, ''));\n    }\n    static isValidUUIDString(representation) {\n        return UUID_WITHOUT_DASHES.test(representation) || UUID_WITH_DASHES.test(representation);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new UUID(${inspect(this.toHexString(), options)})`;\n    }\n}\n\nclass Code extends BSONValue {\n    get _bsontype() {\n        return 'Code';\n    }\n    constructor(code, scope) {\n        super();\n        this.code = code.toString();\n        this.scope = scope ?? null;\n    }\n    toJSON() {\n        if (this.scope != null) {\n            return { code: this.code, scope: this.scope };\n        }\n        return { code: this.code };\n    }\n    toExtendedJSON() {\n        if (this.scope) {\n            return { $code: this.code, $scope: this.scope };\n        }\n        return { $code: this.code };\n    }\n    static fromExtendedJSON(doc) {\n        return new Code(doc.$code, doc.$scope);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        let parametersString = inspect(this.code, options);\n        const multiLineFn = parametersString.includes('\\n');\n        if (this.scope != null) {\n            parametersString += `,${multiLineFn ? '\\n' : ' '}${inspect(this.scope, options)}`;\n        }\n        const endingNewline = multiLineFn && this.scope === null;\n        return `new Code(${multiLineFn ? '\\n' : ''}${parametersString}${endingNewline ? '\\n' : ''})`;\n    }\n}\n\nfunction isDBRefLike(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '$id' in value &&\n        value.$id != null &&\n        '$ref' in value &&\n        typeof value.$ref === 'string' &&\n        (!('$db' in value) || ('$db' in value && typeof value.$db === 'string')));\n}\nclass DBRef extends BSONValue {\n    get _bsontype() {\n        return 'DBRef';\n    }\n    constructor(collection, oid, db, fields) {\n        super();\n        const parts = collection.split('.');\n        if (parts.length === 2) {\n            db = parts.shift();\n            collection = parts.shift();\n        }\n        this.collection = collection;\n        this.oid = oid;\n        this.db = db;\n        this.fields = fields || {};\n    }\n    get namespace() {\n        return this.collection;\n    }\n    set namespace(value) {\n        this.collection = value;\n    }\n    toJSON() {\n        const o = Object.assign({\n            $ref: this.collection,\n            $id: this.oid\n        }, this.fields);\n        if (this.db != null)\n            o.$db = this.db;\n        return o;\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        let o = {\n            $ref: this.collection,\n            $id: this.oid\n        };\n        if (options.legacy) {\n            return o;\n        }\n        if (this.db)\n            o.$db = this.db;\n        o = Object.assign(o, this.fields);\n        return o;\n    }\n    static fromExtendedJSON(doc) {\n        const copy = Object.assign({}, doc);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(doc.$ref, doc.$id, doc.$db, copy);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const args = [\n            inspect(this.namespace, options),\n            inspect(this.oid, options),\n            ...(this.db ? [inspect(this.db, options)] : []),\n            ...(Object.keys(this.fields).length > 0 ? [inspect(this.fields, options)] : [])\n        ];\n        args[1] = inspect === defaultInspect ? `new ObjectId(${args[1]})` : args[1];\n        return `new DBRef(${args.join(', ')})`;\n    }\n}\n\nlet wasm = undefined;\ntry {\n    wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;\n}\ncatch {\n}\nconst TWO_PWR_16_DBL = 1 << 16;\nconst TWO_PWR_24_DBL = 1 << 24;\nconst TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;\nconst TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;\nconst TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;\nconst INT_CACHE = {};\nconst UINT_CACHE = {};\nconst MAX_INT64_STRING_LENGTH = 20;\nconst DECIMAL_REG_EX = /^(\\+?0|(\\+|-)?[1-9][0-9]*)$/;\nclass Long extends BSONValue {\n    get _bsontype() {\n        return 'Long';\n    }\n    get __isLong__() {\n        return true;\n    }\n    constructor(low = 0, high, unsigned) {\n        super();\n        if (typeof low === 'bigint') {\n            Object.assign(this, Long.fromBigInt(low, !!high));\n        }\n        else if (typeof low === 'string') {\n            Object.assign(this, Long.fromString(low, !!high));\n        }\n        else {\n            this.low = low | 0;\n            this.high = high | 0;\n            this.unsigned = !!unsigned;\n        }\n    }\n    static fromBits(lowBits, highBits, unsigned) {\n        return new Long(lowBits, highBits, unsigned);\n    }\n    static fromInt(value, unsigned) {\n        let obj, cachedObj, cache;\n        if (unsigned) {\n            value >>>= 0;\n            if ((cache = 0 <= value && value < 256)) {\n                cachedObj = UINT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, (value | 0) < 0 ? -1 : 0, true);\n            if (cache)\n                UINT_CACHE[value] = obj;\n            return obj;\n        }\n        else {\n            value |= 0;\n            if ((cache = -128 <= value && value < 128)) {\n                cachedObj = INT_CACHE[value];\n                if (cachedObj)\n                    return cachedObj;\n            }\n            obj = Long.fromBits(value, value < 0 ? -1 : 0, false);\n            if (cache)\n                INT_CACHE[value] = obj;\n            return obj;\n        }\n    }\n    static fromNumber(value, unsigned) {\n        if (isNaN(value))\n            return unsigned ? Long.UZERO : Long.ZERO;\n        if (unsigned) {\n            if (value < 0)\n                return Long.UZERO;\n            if (value >= TWO_PWR_64_DBL)\n                return Long.MAX_UNSIGNED_VALUE;\n        }\n        else {\n            if (value <= -TWO_PWR_63_DBL)\n                return Long.MIN_VALUE;\n            if (value + 1 >= TWO_PWR_63_DBL)\n                return Long.MAX_VALUE;\n        }\n        if (value < 0)\n            return Long.fromNumber(-value, unsigned).neg();\n        return Long.fromBits(value % TWO_PWR_32_DBL | 0, (value / TWO_PWR_32_DBL) | 0, unsigned);\n    }\n    static fromBigInt(value, unsigned) {\n        return Long.fromString(value.toString(), unsigned);\n    }\n    static fromString(str, unsigned, radix) {\n        if (str.length === 0)\n            throw new BSONError('empty string');\n        if (str === 'NaN' || str === 'Infinity' || str === '+Infinity' || str === '-Infinity')\n            return Long.ZERO;\n        if (typeof unsigned === 'number') {\n            (radix = unsigned), (unsigned = false);\n        }\n        else {\n            unsigned = !!unsigned;\n        }\n        radix = radix || 10;\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        let p;\n        if ((p = str.indexOf('-')) > 0)\n            throw new BSONError('interior hyphen');\n        else if (p === 0) {\n            return Long.fromString(str.substring(1), unsigned, radix).neg();\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 8));\n        let result = Long.ZERO;\n        for (let i = 0; i < str.length; i += 8) {\n            const size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);\n            if (size < 8) {\n                const power = Long.fromNumber(Math.pow(radix, size));\n                result = result.mul(power).add(Long.fromNumber(value));\n            }\n            else {\n                result = result.mul(radixToPower);\n                result = result.add(Long.fromNumber(value));\n            }\n        }\n        result.unsigned = unsigned;\n        return result;\n    }\n    static fromBytes(bytes, unsigned, le) {\n        return le ? Long.fromBytesLE(bytes, unsigned) : Long.fromBytesBE(bytes, unsigned);\n    }\n    static fromBytesLE(bytes, unsigned) {\n        return new Long(bytes[0] | (bytes[1] << 8) | (bytes[2] << 16) | (bytes[3] << 24), bytes[4] | (bytes[5] << 8) | (bytes[6] << 16) | (bytes[7] << 24), unsigned);\n    }\n    static fromBytesBE(bytes, unsigned) {\n        return new Long((bytes[4] << 24) | (bytes[5] << 16) | (bytes[6] << 8) | bytes[7], (bytes[0] << 24) | (bytes[1] << 16) | (bytes[2] << 8) | bytes[3], unsigned);\n    }\n    static isLong(value) {\n        return (value != null &&\n            typeof value === 'object' &&\n            '__isLong__' in value &&\n            value.__isLong__ === true);\n    }\n    static fromValue(val, unsigned) {\n        if (typeof val === 'number')\n            return Long.fromNumber(val, unsigned);\n        if (typeof val === 'string')\n            return Long.fromString(val, unsigned);\n        return Long.fromBits(val.low, val.high, typeof unsigned === 'boolean' ? unsigned : val.unsigned);\n    }\n    add(addend) {\n        if (!Long.isLong(addend))\n            addend = Long.fromValue(addend);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = addend.high >>> 16;\n        const b32 = addend.high & 0xffff;\n        const b16 = addend.low >>> 16;\n        const b00 = addend.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 + b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 + b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 + b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 + b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    and(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low & other.low, this.high & other.high, this.unsigned);\n    }\n    compare(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.eq(other))\n            return 0;\n        const thisNeg = this.isNegative(), otherNeg = other.isNegative();\n        if (thisNeg && !otherNeg)\n            return -1;\n        if (!thisNeg && otherNeg)\n            return 1;\n        if (!this.unsigned)\n            return this.sub(other).isNegative() ? -1 : 1;\n        return other.high >>> 0 > this.high >>> 0 ||\n            (other.high === this.high && other.low >>> 0 > this.low >>> 0)\n            ? -1\n            : 1;\n    }\n    comp(other) {\n        return this.compare(other);\n    }\n    divide(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (divisor.isZero())\n            throw new BSONError('division by zero');\n        if (wasm) {\n            if (!this.unsigned &&\n                this.high === -0x80000000 &&\n                divisor.low === -1 &&\n                divisor.high === -1) {\n                return this;\n            }\n            const low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (this.isZero())\n            return this.unsigned ? Long.UZERO : Long.ZERO;\n        let approx, rem, res;\n        if (!this.unsigned) {\n            if (this.eq(Long.MIN_VALUE)) {\n                if (divisor.eq(Long.ONE) || divisor.eq(Long.NEG_ONE))\n                    return Long.MIN_VALUE;\n                else if (divisor.eq(Long.MIN_VALUE))\n                    return Long.ONE;\n                else {\n                    const halfThis = this.shr(1);\n                    approx = halfThis.div(divisor).shl(1);\n                    if (approx.eq(Long.ZERO)) {\n                        return divisor.isNegative() ? Long.ONE : Long.NEG_ONE;\n                    }\n                    else {\n                        rem = this.sub(divisor.mul(approx));\n                        res = approx.add(rem.div(divisor));\n                        return res;\n                    }\n                }\n            }\n            else if (divisor.eq(Long.MIN_VALUE))\n                return this.unsigned ? Long.UZERO : Long.ZERO;\n            if (this.isNegative()) {\n                if (divisor.isNegative())\n                    return this.neg().div(divisor.neg());\n                return this.neg().div(divisor).neg();\n            }\n            else if (divisor.isNegative())\n                return this.div(divisor.neg()).neg();\n            res = Long.ZERO;\n        }\n        else {\n            if (!divisor.unsigned)\n                divisor = divisor.toUnsigned();\n            if (divisor.gt(this))\n                return Long.UZERO;\n            if (divisor.gt(this.shru(1)))\n                return Long.UONE;\n            res = Long.UZERO;\n        }\n        rem = this;\n        while (rem.gte(divisor)) {\n            approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));\n            const log2 = Math.ceil(Math.log(approx) / Math.LN2);\n            const delta = log2 <= 48 ? 1 : Math.pow(2, log2 - 48);\n            let approxRes = Long.fromNumber(approx);\n            let approxRem = approxRes.mul(divisor);\n            while (approxRem.isNegative() || approxRem.gt(rem)) {\n                approx -= delta;\n                approxRes = Long.fromNumber(approx, this.unsigned);\n                approxRem = approxRes.mul(divisor);\n            }\n            if (approxRes.isZero())\n                approxRes = Long.ONE;\n            res = res.add(approxRes);\n            rem = rem.sub(approxRem);\n        }\n        return res;\n    }\n    div(divisor) {\n        return this.divide(divisor);\n    }\n    equals(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)\n            return false;\n        return this.high === other.high && this.low === other.low;\n    }\n    eq(other) {\n        return this.equals(other);\n    }\n    getHighBits() {\n        return this.high;\n    }\n    getHighBitsUnsigned() {\n        return this.high >>> 0;\n    }\n    getLowBits() {\n        return this.low;\n    }\n    getLowBitsUnsigned() {\n        return this.low >>> 0;\n    }\n    getNumBitsAbs() {\n        if (this.isNegative()) {\n            return this.eq(Long.MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();\n        }\n        const val = this.high !== 0 ? this.high : this.low;\n        let bit;\n        for (bit = 31; bit > 0; bit--)\n            if ((val & (1 << bit)) !== 0)\n                break;\n        return this.high !== 0 ? bit + 33 : bit + 1;\n    }\n    greaterThan(other) {\n        return this.comp(other) > 0;\n    }\n    gt(other) {\n        return this.greaterThan(other);\n    }\n    greaterThanOrEqual(other) {\n        return this.comp(other) >= 0;\n    }\n    gte(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    ge(other) {\n        return this.greaterThanOrEqual(other);\n    }\n    isEven() {\n        return (this.low & 1) === 0;\n    }\n    isNegative() {\n        return !this.unsigned && this.high < 0;\n    }\n    isOdd() {\n        return (this.low & 1) === 1;\n    }\n    isPositive() {\n        return this.unsigned || this.high >= 0;\n    }\n    isZero() {\n        return this.high === 0 && this.low === 0;\n    }\n    lessThan(other) {\n        return this.comp(other) < 0;\n    }\n    lt(other) {\n        return this.lessThan(other);\n    }\n    lessThanOrEqual(other) {\n        return this.comp(other) <= 0;\n    }\n    lte(other) {\n        return this.lessThanOrEqual(other);\n    }\n    modulo(divisor) {\n        if (!Long.isLong(divisor))\n            divisor = Long.fromValue(divisor);\n        if (wasm) {\n            const low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        return this.sub(this.div(divisor).mul(divisor));\n    }\n    mod(divisor) {\n        return this.modulo(divisor);\n    }\n    rem(divisor) {\n        return this.modulo(divisor);\n    }\n    multiply(multiplier) {\n        if (this.isZero())\n            return Long.ZERO;\n        if (!Long.isLong(multiplier))\n            multiplier = Long.fromValue(multiplier);\n        if (wasm) {\n            const low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);\n            return Long.fromBits(low, wasm.get_high(), this.unsigned);\n        }\n        if (multiplier.isZero())\n            return Long.ZERO;\n        if (this.eq(Long.MIN_VALUE))\n            return multiplier.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (multiplier.eq(Long.MIN_VALUE))\n            return this.isOdd() ? Long.MIN_VALUE : Long.ZERO;\n        if (this.isNegative()) {\n            if (multiplier.isNegative())\n                return this.neg().mul(multiplier.neg());\n            else\n                return this.neg().mul(multiplier).neg();\n        }\n        else if (multiplier.isNegative())\n            return this.mul(multiplier.neg()).neg();\n        if (this.lt(Long.TWO_PWR_24) && multiplier.lt(Long.TWO_PWR_24))\n            return Long.fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);\n        const a48 = this.high >>> 16;\n        const a32 = this.high & 0xffff;\n        const a16 = this.low >>> 16;\n        const a00 = this.low & 0xffff;\n        const b48 = multiplier.high >>> 16;\n        const b32 = multiplier.high & 0xffff;\n        const b16 = multiplier.low >>> 16;\n        const b00 = multiplier.low & 0xffff;\n        let c48 = 0, c32 = 0, c16 = 0, c00 = 0;\n        c00 += a00 * b00;\n        c16 += c00 >>> 16;\n        c00 &= 0xffff;\n        c16 += a16 * b00;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c16 += a00 * b16;\n        c32 += c16 >>> 16;\n        c16 &= 0xffff;\n        c32 += a32 * b00;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a16 * b16;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c32 += a00 * b32;\n        c48 += c32 >>> 16;\n        c32 &= 0xffff;\n        c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;\n        c48 &= 0xffff;\n        return Long.fromBits((c16 << 16) | c00, (c48 << 16) | c32, this.unsigned);\n    }\n    mul(multiplier) {\n        return this.multiply(multiplier);\n    }\n    negate() {\n        if (!this.unsigned && this.eq(Long.MIN_VALUE))\n            return Long.MIN_VALUE;\n        return this.not().add(Long.ONE);\n    }\n    neg() {\n        return this.negate();\n    }\n    not() {\n        return Long.fromBits(~this.low, ~this.high, this.unsigned);\n    }\n    notEquals(other) {\n        return !this.equals(other);\n    }\n    neq(other) {\n        return this.notEquals(other);\n    }\n    ne(other) {\n        return this.notEquals(other);\n    }\n    or(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low | other.low, this.high | other.high, this.unsigned);\n    }\n    shiftLeft(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits(this.low << numBits, (this.high << numBits) | (this.low >>> (32 - numBits)), this.unsigned);\n        else\n            return Long.fromBits(0, this.low << (numBits - 32), this.unsigned);\n    }\n    shl(numBits) {\n        return this.shiftLeft(numBits);\n    }\n    shiftRight(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        if ((numBits &= 63) === 0)\n            return this;\n        else if (numBits < 32)\n            return Long.fromBits((this.low >>> numBits) | (this.high << (32 - numBits)), this.high >> numBits, this.unsigned);\n        else\n            return Long.fromBits(this.high >> (numBits - 32), this.high >= 0 ? 0 : -1, this.unsigned);\n    }\n    shr(numBits) {\n        return this.shiftRight(numBits);\n    }\n    shiftRightUnsigned(numBits) {\n        if (Long.isLong(numBits))\n            numBits = numBits.toInt();\n        numBits &= 63;\n        if (numBits === 0)\n            return this;\n        else {\n            const high = this.high;\n            if (numBits < 32) {\n                const low = this.low;\n                return Long.fromBits((low >>> numBits) | (high << (32 - numBits)), high >>> numBits, this.unsigned);\n            }\n            else if (numBits === 32)\n                return Long.fromBits(high, 0, this.unsigned);\n            else\n                return Long.fromBits(high >>> (numBits - 32), 0, this.unsigned);\n        }\n    }\n    shr_u(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    shru(numBits) {\n        return this.shiftRightUnsigned(numBits);\n    }\n    subtract(subtrahend) {\n        if (!Long.isLong(subtrahend))\n            subtrahend = Long.fromValue(subtrahend);\n        return this.add(subtrahend.neg());\n    }\n    sub(subtrahend) {\n        return this.subtract(subtrahend);\n    }\n    toInt() {\n        return this.unsigned ? this.low >>> 0 : this.low;\n    }\n    toNumber() {\n        if (this.unsigned)\n            return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);\n        return this.high * TWO_PWR_32_DBL + (this.low >>> 0);\n    }\n    toBigInt() {\n        return BigInt(this.toString());\n    }\n    toBytes(le) {\n        return le ? this.toBytesLE() : this.toBytesBE();\n    }\n    toBytesLE() {\n        const hi = this.high, lo = this.low;\n        return [\n            lo & 0xff,\n            (lo >>> 8) & 0xff,\n            (lo >>> 16) & 0xff,\n            lo >>> 24,\n            hi & 0xff,\n            (hi >>> 8) & 0xff,\n            (hi >>> 16) & 0xff,\n            hi >>> 24\n        ];\n    }\n    toBytesBE() {\n        const hi = this.high, lo = this.low;\n        return [\n            hi >>> 24,\n            (hi >>> 16) & 0xff,\n            (hi >>> 8) & 0xff,\n            hi & 0xff,\n            lo >>> 24,\n            (lo >>> 16) & 0xff,\n            (lo >>> 8) & 0xff,\n            lo & 0xff\n        ];\n    }\n    toSigned() {\n        if (!this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, false);\n    }\n    toString(radix) {\n        radix = radix || 10;\n        if (radix < 2 || 36 < radix)\n            throw new BSONError('radix');\n        if (this.isZero())\n            return '0';\n        if (this.isNegative()) {\n            if (this.eq(Long.MIN_VALUE)) {\n                const radixLong = Long.fromNumber(radix), div = this.div(radixLong), rem1 = div.mul(radixLong).sub(this);\n                return div.toString(radix) + rem1.toInt().toString(radix);\n            }\n            else\n                return '-' + this.neg().toString(radix);\n        }\n        const radixToPower = Long.fromNumber(Math.pow(radix, 6), this.unsigned);\n        let rem = this;\n        let result = '';\n        while (true) {\n            const remDiv = rem.div(radixToPower);\n            const intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0;\n            let digits = intval.toString(radix);\n            rem = remDiv;\n            if (rem.isZero()) {\n                return digits + result;\n            }\n            else {\n                while (digits.length < 6)\n                    digits = '0' + digits;\n                result = '' + digits + result;\n            }\n        }\n    }\n    toUnsigned() {\n        if (this.unsigned)\n            return this;\n        return Long.fromBits(this.low, this.high, true);\n    }\n    xor(other) {\n        if (!Long.isLong(other))\n            other = Long.fromValue(other);\n        return Long.fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);\n    }\n    eqz() {\n        return this.isZero();\n    }\n    le(other) {\n        return this.lessThanOrEqual(other);\n    }\n    toExtendedJSON(options) {\n        if (options && options.relaxed)\n            return this.toNumber();\n        return { $numberLong: this.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        const { useBigInt64 = false, relaxed = true } = { ...options };\n        if (doc.$numberLong.length > MAX_INT64_STRING_LENGTH) {\n            throw new BSONError('$numberLong string is too long');\n        }\n        if (!DECIMAL_REG_EX.test(doc.$numberLong)) {\n            throw new BSONError(`$numberLong string \"${doc.$numberLong}\" is in an invalid format`);\n        }\n        if (useBigInt64) {\n            const bigIntResult = BigInt(doc.$numberLong);\n            return BigInt.asIntN(64, bigIntResult);\n        }\n        const longResult = Long.fromString(doc.$numberLong);\n        if (relaxed) {\n            return longResult.toNumber();\n        }\n        return longResult;\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const longVal = inspect(this.toString(), options);\n        const unsignedVal = this.unsigned ? `, ${inspect(this.unsigned, options)}` : '';\n        return `new Long(${longVal}${unsignedVal})`;\n    }\n}\nLong.TWO_PWR_24 = Long.fromInt(TWO_PWR_24_DBL);\nLong.MAX_UNSIGNED_VALUE = Long.fromBits(0xffffffff | 0, 0xffffffff | 0, true);\nLong.ZERO = Long.fromInt(0);\nLong.UZERO = Long.fromInt(0, true);\nLong.ONE = Long.fromInt(1);\nLong.UONE = Long.fromInt(1, true);\nLong.NEG_ONE = Long.fromInt(-1);\nLong.MAX_VALUE = Long.fromBits(0xffffffff | 0, 0x7fffffff | 0, false);\nLong.MIN_VALUE = Long.fromBits(0, 0x80000000 | 0, false);\n\nconst PARSE_STRING_REGEXP = /^(\\+|-)?(\\d+|(\\d*\\.\\d*))?(E|e)?([-+])?(\\d+)?$/;\nconst PARSE_INF_REGEXP = /^(\\+|-)?(Infinity|inf)$/i;\nconst PARSE_NAN_REGEXP = /^(\\+|-)?NaN$/i;\nconst EXPONENT_MAX = 6111;\nconst EXPONENT_MIN = -6176;\nconst EXPONENT_BIAS = 6176;\nconst MAX_DIGITS = 34;\nconst NAN_BUFFER = ByteUtils.fromNumberArray([\n    0x7c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_NEGATIVE_BUFFER = ByteUtils.fromNumberArray([\n    0xf8, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst INF_POSITIVE_BUFFER = ByteUtils.fromNumberArray([\n    0x78, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00\n].reverse());\nconst EXPONENT_REGEX = /^([-+])?(\\d+)?$/;\nconst COMBINATION_MASK = 0x1f;\nconst EXPONENT_MASK = 0x3fff;\nconst COMBINATION_INFINITY = 30;\nconst COMBINATION_NAN = 31;\nfunction isDigit(value) {\n    return !isNaN(parseInt(value, 10));\n}\nfunction divideu128(value) {\n    const DIVISOR = Long.fromNumber(1000 * 1000 * 1000);\n    let _rem = Long.fromNumber(0);\n    if (!value.parts[0] && !value.parts[1] && !value.parts[2] && !value.parts[3]) {\n        return { quotient: value, rem: _rem };\n    }\n    for (let i = 0; i <= 3; i++) {\n        _rem = _rem.shiftLeft(32);\n        _rem = _rem.add(new Long(value.parts[i], 0));\n        value.parts[i] = _rem.div(DIVISOR).low;\n        _rem = _rem.modulo(DIVISOR);\n    }\n    return { quotient: value, rem: _rem };\n}\nfunction multiply64x2(left, right) {\n    if (!left && !right) {\n        return { high: Long.fromNumber(0), low: Long.fromNumber(0) };\n    }\n    const leftHigh = left.shiftRightUnsigned(32);\n    const leftLow = new Long(left.getLowBits(), 0);\n    const rightHigh = right.shiftRightUnsigned(32);\n    const rightLow = new Long(right.getLowBits(), 0);\n    let productHigh = leftHigh.multiply(rightHigh);\n    let productMid = leftHigh.multiply(rightLow);\n    const productMid2 = leftLow.multiply(rightHigh);\n    let productLow = leftLow.multiply(rightLow);\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productMid = new Long(productMid.getLowBits(), 0)\n        .add(productMid2)\n        .add(productLow.shiftRightUnsigned(32));\n    productHigh = productHigh.add(productMid.shiftRightUnsigned(32));\n    productLow = productMid.shiftLeft(32).add(new Long(productLow.getLowBits(), 0));\n    return { high: productHigh, low: productLow };\n}\nfunction lessThan(left, right) {\n    const uhleft = left.high >>> 0;\n    const uhright = right.high >>> 0;\n    if (uhleft < uhright) {\n        return true;\n    }\n    else if (uhleft === uhright) {\n        const ulleft = left.low >>> 0;\n        const ulright = right.low >>> 0;\n        if (ulleft < ulright)\n            return true;\n    }\n    return false;\n}\nfunction invalidErr(string, message) {\n    throw new BSONError(`\"${string}\" is not a valid Decimal128 string - ${message}`);\n}\nclass Decimal128 extends BSONValue {\n    get _bsontype() {\n        return 'Decimal128';\n    }\n    constructor(bytes) {\n        super();\n        if (typeof bytes === 'string') {\n            this.bytes = Decimal128.fromString(bytes).bytes;\n        }\n        else if (isUint8Array(bytes)) {\n            if (bytes.byteLength !== 16) {\n                throw new BSONError('Decimal128 must take a Buffer of 16 bytes');\n            }\n            this.bytes = bytes;\n        }\n        else {\n            throw new BSONError('Decimal128 must take a Buffer or string');\n        }\n    }\n    static fromString(representation) {\n        return Decimal128._fromString(representation, { allowRounding: false });\n    }\n    static fromStringWithRounding(representation) {\n        return Decimal128._fromString(representation, { allowRounding: true });\n    }\n    static _fromString(representation, options) {\n        let isNegative = false;\n        let sawSign = false;\n        let sawRadix = false;\n        let foundNonZero = false;\n        let significantDigits = 0;\n        let nDigitsRead = 0;\n        let nDigits = 0;\n        let radixPosition = 0;\n        let firstNonZero = 0;\n        const digits = [0];\n        let nDigitsStored = 0;\n        let digitsInsert = 0;\n        let lastDigit = 0;\n        let exponent = 0;\n        let significandHigh = new Long(0, 0);\n        let significandLow = new Long(0, 0);\n        let biasedExponent = 0;\n        let index = 0;\n        if (representation.length >= 7000) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        const stringMatch = representation.match(PARSE_STRING_REGEXP);\n        const infMatch = representation.match(PARSE_INF_REGEXP);\n        const nanMatch = representation.match(PARSE_NAN_REGEXP);\n        if ((!stringMatch && !infMatch && !nanMatch) || representation.length === 0) {\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        }\n        if (stringMatch) {\n            const unsignedNumber = stringMatch[2];\n            const e = stringMatch[4];\n            const expSign = stringMatch[5];\n            const expNumber = stringMatch[6];\n            if (e && expNumber === undefined)\n                invalidErr(representation, 'missing exponent power');\n            if (e && unsignedNumber === undefined)\n                invalidErr(representation, 'missing exponent base');\n            if (e === undefined && (expSign || expNumber)) {\n                invalidErr(representation, 'missing e before exponent');\n            }\n        }\n        if (representation[index] === '+' || representation[index] === '-') {\n            sawSign = true;\n            isNegative = representation[index++] === '-';\n        }\n        if (!isDigit(representation[index]) && representation[index] !== '.') {\n            if (representation[index] === 'i' || representation[index] === 'I') {\n                return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n            }\n            else if (representation[index] === 'N') {\n                return new Decimal128(NAN_BUFFER);\n            }\n        }\n        while (isDigit(representation[index]) || representation[index] === '.') {\n            if (representation[index] === '.') {\n                if (sawRadix)\n                    invalidErr(representation, 'contains multiple periods');\n                sawRadix = true;\n                index = index + 1;\n                continue;\n            }\n            if (nDigitsStored < MAX_DIGITS) {\n                if (representation[index] !== '0' || foundNonZero) {\n                    if (!foundNonZero) {\n                        firstNonZero = nDigitsRead;\n                    }\n                    foundNonZero = true;\n                    digits[digitsInsert++] = parseInt(representation[index], 10);\n                    nDigitsStored = nDigitsStored + 1;\n                }\n            }\n            if (foundNonZero)\n                nDigits = nDigits + 1;\n            if (sawRadix)\n                radixPosition = radixPosition + 1;\n            nDigitsRead = nDigitsRead + 1;\n            index = index + 1;\n        }\n        if (sawRadix && !nDigitsRead)\n            throw new BSONError('' + representation + ' not a valid Decimal128 string');\n        if (representation[index] === 'e' || representation[index] === 'E') {\n            const match = representation.substr(++index).match(EXPONENT_REGEX);\n            if (!match || !match[2])\n                return new Decimal128(NAN_BUFFER);\n            exponent = parseInt(match[0], 10);\n            index = index + match[0].length;\n        }\n        if (representation[index])\n            return new Decimal128(NAN_BUFFER);\n        if (!nDigitsStored) {\n            digits[0] = 0;\n            nDigits = 1;\n            nDigitsStored = 1;\n            significantDigits = 0;\n        }\n        else {\n            lastDigit = nDigitsStored - 1;\n            significantDigits = nDigits;\n            if (significantDigits !== 1) {\n                while (representation[firstNonZero + significantDigits - 1 + Number(sawSign) + Number(sawRadix)] === '0') {\n                    significantDigits = significantDigits - 1;\n                }\n            }\n        }\n        if (exponent <= radixPosition && radixPosition > exponent + (1 << 14)) {\n            exponent = EXPONENT_MIN;\n        }\n        else {\n            exponent = exponent - radixPosition;\n        }\n        while (exponent > EXPONENT_MAX) {\n            lastDigit = lastDigit + 1;\n            if (lastDigit >= MAX_DIGITS) {\n                if (significantDigits === 0) {\n                    exponent = EXPONENT_MAX;\n                    break;\n                }\n                invalidErr(representation, 'overflow');\n            }\n            exponent = exponent - 1;\n        }\n        if (options.allowRounding) {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0 && significantDigits < nDigitsStored) {\n                    exponent = EXPONENT_MIN;\n                    significantDigits = 0;\n                    break;\n                }\n                if (nDigitsStored < nDigits) {\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    const digitsString = digits.join('');\n                    if (digitsString.match(/^0+$/)) {\n                        exponent = EXPONENT_MAX;\n                        break;\n                    }\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                let endOfString = nDigitsRead;\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                    endOfString = endOfString + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                let roundBit = 0;\n                if (roundDigit >= 5) {\n                    roundBit = 1;\n                    if (roundDigit === 5) {\n                        roundBit = digits[lastDigit] % 2 === 1 ? 1 : 0;\n                        for (let i = firstNonZero + lastDigit + 2; i < endOfString; i++) {\n                            if (parseInt(representation[i], 10)) {\n                                roundBit = 1;\n                                break;\n                            }\n                        }\n                    }\n                }\n                if (roundBit) {\n                    let dIdx = lastDigit;\n                    for (; dIdx >= 0; dIdx--) {\n                        if (++digits[dIdx] > 9) {\n                            digits[dIdx] = 0;\n                            if (dIdx === 0) {\n                                if (exponent < EXPONENT_MAX) {\n                                    exponent = exponent + 1;\n                                    digits[dIdx] = 1;\n                                }\n                                else {\n                                    return new Decimal128(isNegative ? INF_NEGATIVE_BUFFER : INF_POSITIVE_BUFFER);\n                                }\n                            }\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                }\n            }\n        }\n        else {\n            while (exponent < EXPONENT_MIN || nDigitsStored < nDigits) {\n                if (lastDigit === 0) {\n                    if (significantDigits === 0) {\n                        exponent = EXPONENT_MIN;\n                        break;\n                    }\n                    invalidErr(representation, 'exponent underflow');\n                }\n                if (nDigitsStored < nDigits) {\n                    if (representation[nDigits - 1 + Number(sawSign) + Number(sawRadix)] !== '0' &&\n                        significantDigits !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    nDigits = nDigits - 1;\n                }\n                else {\n                    if (digits[lastDigit] !== 0) {\n                        invalidErr(representation, 'inexact rounding');\n                    }\n                    lastDigit = lastDigit - 1;\n                }\n                if (exponent < EXPONENT_MAX) {\n                    exponent = exponent + 1;\n                }\n                else {\n                    invalidErr(representation, 'overflow');\n                }\n            }\n            if (lastDigit + 1 < significantDigits) {\n                if (sawRadix) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                if (sawSign) {\n                    firstNonZero = firstNonZero + 1;\n                }\n                const roundDigit = parseInt(representation[firstNonZero + lastDigit + 1], 10);\n                if (roundDigit !== 0) {\n                    invalidErr(representation, 'inexact rounding');\n                }\n            }\n        }\n        significandHigh = Long.fromNumber(0);\n        significandLow = Long.fromNumber(0);\n        if (significantDigits === 0) {\n            significandHigh = Long.fromNumber(0);\n            significandLow = Long.fromNumber(0);\n        }\n        else if (lastDigit < 17) {\n            let dIdx = 0;\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            significandHigh = new Long(0, 0);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        else {\n            let dIdx = 0;\n            significandHigh = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit - 17; dIdx++) {\n                significandHigh = significandHigh.multiply(Long.fromNumber(10));\n                significandHigh = significandHigh.add(Long.fromNumber(digits[dIdx]));\n            }\n            significandLow = Long.fromNumber(digits[dIdx++]);\n            for (; dIdx <= lastDigit; dIdx++) {\n                significandLow = significandLow.multiply(Long.fromNumber(10));\n                significandLow = significandLow.add(Long.fromNumber(digits[dIdx]));\n            }\n        }\n        const significand = multiply64x2(significandHigh, Long.fromString('100000000000000000'));\n        significand.low = significand.low.add(significandLow);\n        if (lessThan(significand.low, significandLow)) {\n            significand.high = significand.high.add(Long.fromNumber(1));\n        }\n        biasedExponent = exponent + EXPONENT_BIAS;\n        const dec = { low: Long.fromNumber(0), high: Long.fromNumber(0) };\n        if (significand.high.shiftRightUnsigned(49).and(Long.fromNumber(1)).equals(Long.fromNumber(1))) {\n            dec.high = dec.high.or(Long.fromNumber(0x3).shiftLeft(61));\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent).and(Long.fromNumber(0x3fff).shiftLeft(47)));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x7fffffffffff)));\n        }\n        else {\n            dec.high = dec.high.or(Long.fromNumber(biasedExponent & 0x3fff).shiftLeft(49));\n            dec.high = dec.high.or(significand.high.and(Long.fromNumber(0x1ffffffffffff)));\n        }\n        dec.low = significand.low;\n        if (isNegative) {\n            dec.high = dec.high.or(Long.fromString('9223372036854775808'));\n        }\n        const buffer = ByteUtils.allocate(16);\n        index = 0;\n        buffer[index++] = dec.low.low & 0xff;\n        buffer[index++] = (dec.low.low >> 8) & 0xff;\n        buffer[index++] = (dec.low.low >> 16) & 0xff;\n        buffer[index++] = (dec.low.low >> 24) & 0xff;\n        buffer[index++] = dec.low.high & 0xff;\n        buffer[index++] = (dec.low.high >> 8) & 0xff;\n        buffer[index++] = (dec.low.high >> 16) & 0xff;\n        buffer[index++] = (dec.low.high >> 24) & 0xff;\n        buffer[index++] = dec.high.low & 0xff;\n        buffer[index++] = (dec.high.low >> 8) & 0xff;\n        buffer[index++] = (dec.high.low >> 16) & 0xff;\n        buffer[index++] = (dec.high.low >> 24) & 0xff;\n        buffer[index++] = dec.high.high & 0xff;\n        buffer[index++] = (dec.high.high >> 8) & 0xff;\n        buffer[index++] = (dec.high.high >> 16) & 0xff;\n        buffer[index++] = (dec.high.high >> 24) & 0xff;\n        return new Decimal128(buffer);\n    }\n    toString() {\n        let biased_exponent;\n        let significand_digits = 0;\n        const significand = new Array(36);\n        for (let i = 0; i < significand.length; i++)\n            significand[i] = 0;\n        let index = 0;\n        let is_zero = false;\n        let significand_msb;\n        let significand128 = { parts: [0, 0, 0, 0] };\n        let j, k;\n        const string = [];\n        index = 0;\n        const buffer = this.bytes;\n        const low = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midl = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const midh = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        const high = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n        index = 0;\n        const dec = {\n            low: new Long(low, midl),\n            high: new Long(midh, high)\n        };\n        if (dec.high.lessThan(Long.ZERO)) {\n            string.push('-');\n        }\n        const combination = (high >> 26) & COMBINATION_MASK;\n        if (combination >> 3 === 3) {\n            if (combination === COMBINATION_INFINITY) {\n                return string.join('') + 'Infinity';\n            }\n            else if (combination === COMBINATION_NAN) {\n                return 'NaN';\n            }\n            else {\n                biased_exponent = (high >> 15) & EXPONENT_MASK;\n                significand_msb = 0x08 + ((high >> 14) & 0x01);\n            }\n        }\n        else {\n            significand_msb = (high >> 14) & 0x07;\n            biased_exponent = (high >> 17) & EXPONENT_MASK;\n        }\n        const exponent = biased_exponent - EXPONENT_BIAS;\n        significand128.parts[0] = (high & 0x3fff) + ((significand_msb & 0xf) << 14);\n        significand128.parts[1] = midh;\n        significand128.parts[2] = midl;\n        significand128.parts[3] = low;\n        if (significand128.parts[0] === 0 &&\n            significand128.parts[1] === 0 &&\n            significand128.parts[2] === 0 &&\n            significand128.parts[3] === 0) {\n            is_zero = true;\n        }\n        else {\n            for (k = 3; k >= 0; k--) {\n                let least_digits = 0;\n                const result = divideu128(significand128);\n                significand128 = result.quotient;\n                least_digits = result.rem.low;\n                if (!least_digits)\n                    continue;\n                for (j = 8; j >= 0; j--) {\n                    significand[k * 9 + j] = least_digits % 10;\n                    least_digits = Math.floor(least_digits / 10);\n                }\n            }\n        }\n        if (is_zero) {\n            significand_digits = 1;\n            significand[index] = 0;\n        }\n        else {\n            significand_digits = 36;\n            while (!significand[index]) {\n                significand_digits = significand_digits - 1;\n                index = index + 1;\n            }\n        }\n        const scientific_exponent = significand_digits - 1 + exponent;\n        if (scientific_exponent >= 34 || scientific_exponent <= -7 || exponent > 0) {\n            if (significand_digits > 34) {\n                string.push(`${0}`);\n                if (exponent > 0)\n                    string.push(`E+${exponent}`);\n                else if (exponent < 0)\n                    string.push(`E${exponent}`);\n                return string.join('');\n            }\n            string.push(`${significand[index++]}`);\n            significand_digits = significand_digits - 1;\n            if (significand_digits) {\n                string.push('.');\n            }\n            for (let i = 0; i < significand_digits; i++) {\n                string.push(`${significand[index++]}`);\n            }\n            string.push('E');\n            if (scientific_exponent > 0) {\n                string.push(`+${scientific_exponent}`);\n            }\n            else {\n                string.push(`${scientific_exponent}`);\n            }\n        }\n        else {\n            if (exponent >= 0) {\n                for (let i = 0; i < significand_digits; i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n            else {\n                let radix_position = significand_digits + exponent;\n                if (radix_position > 0) {\n                    for (let i = 0; i < radix_position; i++) {\n                        string.push(`${significand[index++]}`);\n                    }\n                }\n                else {\n                    string.push('0');\n                }\n                string.push('.');\n                while (radix_position++ < 0) {\n                    string.push('0');\n                }\n                for (let i = 0; i < significand_digits - Math.max(radix_position - 1, 0); i++) {\n                    string.push(`${significand[index++]}`);\n                }\n            }\n        }\n        return string.join('');\n    }\n    toJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    toExtendedJSON() {\n        return { $numberDecimal: this.toString() };\n    }\n    static fromExtendedJSON(doc) {\n        return Decimal128.fromString(doc.$numberDecimal);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const d128string = inspect(this.toString(), options);\n        return `new Decimal128(${d128string})`;\n    }\n}\n\nclass Double extends BSONValue {\n    get _bsontype() {\n        return 'Double';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toExtendedJSON(options) {\n        if (options && (options.legacy || (options.relaxed && isFinite(this.value)))) {\n            return this.value;\n        }\n        if (Object.is(Math.sign(this.value), -0)) {\n            return { $numberDouble: '-0.0' };\n        }\n        return {\n            $numberDouble: Number.isInteger(this.value) ? this.value.toFixed(1) : this.value.toString()\n        };\n    }\n    static fromExtendedJSON(doc, options) {\n        const doubleValue = parseFloat(doc.$numberDouble);\n        return options && options.relaxed ? doubleValue : new Double(doubleValue);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Double(${inspect(this.value, options)})`;\n    }\n}\n\nclass Int32 extends BSONValue {\n    get _bsontype() {\n        return 'Int32';\n    }\n    constructor(value) {\n        super();\n        if (value instanceof Number) {\n            value = value.valueOf();\n        }\n        this.value = +value | 0;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString(radix) {\n        return this.value.toString(radix);\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON(options) {\n        if (options && (options.relaxed || options.legacy))\n            return this.value;\n        return { $numberInt: this.value.toString() };\n    }\n    static fromExtendedJSON(doc, options) {\n        return options && options.relaxed ? parseInt(doc.$numberInt, 10) : new Int32(doc.$numberInt);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new Int32(${inspect(this.value, options)})`;\n    }\n}\n\nclass MaxKey extends BSONValue {\n    get _bsontype() {\n        return 'MaxKey';\n    }\n    toExtendedJSON() {\n        return { $maxKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MaxKey();\n    }\n    inspect() {\n        return 'new MaxKey()';\n    }\n}\n\nclass MinKey extends BSONValue {\n    get _bsontype() {\n        return 'MinKey';\n    }\n    toExtendedJSON() {\n        return { $minKey: 1 };\n    }\n    static fromExtendedJSON() {\n        return new MinKey();\n    }\n    inspect() {\n        return 'new MinKey()';\n    }\n}\n\nconst checkForHexRegExp = new RegExp('^[0-9a-fA-F]{24}$');\nlet PROCESS_UNIQUE = null;\nconst kId = Symbol('id');\nclass ObjectId extends BSONValue {\n    get _bsontype() {\n        return 'ObjectId';\n    }\n    constructor(inputId) {\n        super();\n        let workingId;\n        if (typeof inputId === 'object' && inputId && 'id' in inputId) {\n            if (typeof inputId.id !== 'string' && !ArrayBuffer.isView(inputId.id)) {\n                throw new BSONError('Argument passed in must have an id that is of type string or Buffer');\n            }\n            if ('toHexString' in inputId && typeof inputId.toHexString === 'function') {\n                workingId = ByteUtils.fromHex(inputId.toHexString());\n            }\n            else {\n                workingId = inputId.id;\n            }\n        }\n        else {\n            workingId = inputId;\n        }\n        if (workingId == null || typeof workingId === 'number') {\n            this[kId] = ObjectId.generate(typeof workingId === 'number' ? workingId : undefined);\n        }\n        else if (ArrayBuffer.isView(workingId) && workingId.byteLength === 12) {\n            this[kId] = ByteUtils.toLocalBufferType(workingId);\n        }\n        else if (typeof workingId === 'string') {\n            if (workingId.length === 24 && checkForHexRegExp.test(workingId)) {\n                this[kId] = ByteUtils.fromHex(workingId);\n            }\n            else {\n                throw new BSONError('input must be a 24 character hex string, 12 byte Uint8Array, or an integer');\n            }\n        }\n        else {\n            throw new BSONError('Argument passed in does not match the accepted types');\n        }\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(this.id);\n        }\n    }\n    get id() {\n        return this[kId];\n    }\n    set id(value) {\n        this[kId] = value;\n        if (ObjectId.cacheHexString) {\n            this.__id = ByteUtils.toHex(value);\n        }\n    }\n    toHexString() {\n        if (ObjectId.cacheHexString && this.__id) {\n            return this.__id;\n        }\n        const hexString = ByteUtils.toHex(this.id);\n        if (ObjectId.cacheHexString && !this.__id) {\n            this.__id = hexString;\n        }\n        return hexString;\n    }\n    static getInc() {\n        return (ObjectId.index = (ObjectId.index + 1) % 0xffffff);\n    }\n    static generate(time) {\n        if ('number' !== typeof time) {\n            time = Math.floor(Date.now() / 1000);\n        }\n        const inc = ObjectId.getInc();\n        const buffer = ByteUtils.allocate(12);\n        BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);\n        if (PROCESS_UNIQUE === null) {\n            PROCESS_UNIQUE = ByteUtils.randomBytes(5);\n        }\n        buffer[4] = PROCESS_UNIQUE[0];\n        buffer[5] = PROCESS_UNIQUE[1];\n        buffer[6] = PROCESS_UNIQUE[2];\n        buffer[7] = PROCESS_UNIQUE[3];\n        buffer[8] = PROCESS_UNIQUE[4];\n        buffer[11] = inc & 0xff;\n        buffer[10] = (inc >> 8) & 0xff;\n        buffer[9] = (inc >> 16) & 0xff;\n        return buffer;\n    }\n    toString(encoding) {\n        if (encoding === 'base64')\n            return ByteUtils.toBase64(this.id);\n        if (encoding === 'hex')\n            return this.toHexString();\n        return this.toHexString();\n    }\n    toJSON() {\n        return this.toHexString();\n    }\n    static is(variable) {\n        return (variable != null &&\n            typeof variable === 'object' &&\n            '_bsontype' in variable &&\n            variable._bsontype === 'ObjectId');\n    }\n    equals(otherId) {\n        if (otherId === undefined || otherId === null) {\n            return false;\n        }\n        if (ObjectId.is(otherId)) {\n            return this[kId][11] === otherId[kId][11] && ByteUtils.equals(this[kId], otherId[kId]);\n        }\n        if (typeof otherId === 'string') {\n            return otherId.toLowerCase() === this.toHexString();\n        }\n        if (typeof otherId === 'object' && typeof otherId.toHexString === 'function') {\n            const otherIdString = otherId.toHexString();\n            const thisIdString = this.toHexString();\n            return typeof otherIdString === 'string' && otherIdString.toLowerCase() === thisIdString;\n        }\n        return false;\n    }\n    getTimestamp() {\n        const timestamp = new Date();\n        const time = BSONDataView.fromUint8Array(this.id).getUint32(0, false);\n        timestamp.setTime(Math.floor(time) * 1000);\n        return timestamp;\n    }\n    static createPk() {\n        return new ObjectId();\n    }\n    static createFromTime(time) {\n        const buffer = ByteUtils.fromNumberArray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);\n        BSONDataView.fromUint8Array(buffer).setUint32(0, time, false);\n        return new ObjectId(buffer);\n    }\n    static createFromHexString(hexString) {\n        if (hexString?.length !== 24) {\n            throw new BSONError('hex string must be 24 characters');\n        }\n        return new ObjectId(ByteUtils.fromHex(hexString));\n    }\n    static createFromBase64(base64) {\n        if (base64?.length !== 16) {\n            throw new BSONError('base64 string must be 16 characters');\n        }\n        return new ObjectId(ByteUtils.fromBase64(base64));\n    }\n    static isValid(id) {\n        if (id == null)\n            return false;\n        try {\n            new ObjectId(id);\n            return true;\n        }\n        catch {\n            return false;\n        }\n    }\n    toExtendedJSON() {\n        if (this.toHexString)\n            return { $oid: this.toHexString() };\n        return { $oid: this.toString('hex') };\n    }\n    static fromExtendedJSON(doc) {\n        return new ObjectId(doc.$oid);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new ObjectId(${inspect(this.toHexString(), options)})`;\n    }\n}\nObjectId.index = Math.floor(Math.random() * 0xffffff);\n\nfunction internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined) {\n    let totalLength = 4 + 1;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            totalLength += calculateElement(i.toString(), object[i], serializeFunctions, true, ignoreUndefined);\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n        }\n        for (const key of Object.keys(object)) {\n            totalLength += calculateElement(key, object[key], serializeFunctions, false, ignoreUndefined);\n        }\n    }\n    return totalLength;\n}\nfunction calculateElement(name, value, serializeFunctions = false, isArray = false, ignoreUndefined = false) {\n    if (typeof value?.toBSON === 'function') {\n        value = value.toBSON();\n    }\n    switch (typeof value) {\n        case 'string':\n            return 1 + ByteUtils.utf8ByteLength(name) + 1 + 4 + ByteUtils.utf8ByteLength(value) + 1;\n        case 'number':\n            if (Math.floor(value) === value &&\n                value >= JS_INT_MIN &&\n                value <= JS_INT_MAX) {\n                if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (4 + 1);\n                }\n                else {\n                    return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n                }\n            }\n            else {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n        case 'undefined':\n            if (isArray || !ignoreUndefined)\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            return 0;\n        case 'boolean':\n            return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 1);\n        case 'object':\n            if (value != null &&\n                typeof value._bsontype === 'string' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value == null || value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + 1;\n            }\n            else if (value._bsontype === 'ObjectId') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (12 + 1);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (ArrayBuffer.isView(value) ||\n                value instanceof ArrayBuffer ||\n                isAnyArrayBuffer(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (1 + 4 + 1) + value.byteLength);\n            }\n            else if (value._bsontype === 'Long' ||\n                value._bsontype === 'Double' ||\n                value._bsontype === 'Timestamp') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (8 + 1);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                return (name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (16 + 1);\n            }\n            else if (value._bsontype === 'Code') {\n                if (value.scope != null && Object.keys(value.scope).length > 0) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1 +\n                        internalCalculateObjectSize(value.scope, serializeFunctions, ignoreUndefined));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        1 +\n                        4 +\n                        ByteUtils.utf8ByteLength(value.code.toString()) +\n                        1);\n                }\n            }\n            else if (value._bsontype === 'Binary') {\n                const binary = value;\n                if (binary.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                        (binary.position + 1 + 4 + 1 + 4));\n                }\n                else {\n                    return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) + (binary.position + 1 + 4 + 1));\n                }\n            }\n            else if (value._bsontype === 'Symbol') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    ByteUtils.utf8ByteLength(value.value) +\n                    4 +\n                    1 +\n                    1);\n            }\n            else if (value._bsontype === 'DBRef') {\n                const ordered_values = Object.assign({\n                    $ref: value.collection,\n                    $id: value.oid\n                }, value.fields);\n                if (value.db != null) {\n                    ordered_values['$db'] = value.db;\n                }\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    internalCalculateObjectSize(ordered_values, serializeFunctions, ignoreUndefined));\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.source) +\n                    1 +\n                    (value.global ? 1 : 0) +\n                    (value.ignoreCase ? 1 : 0) +\n                    (value.multiline ? 1 : 0) +\n                    1);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.pattern) +\n                    1 +\n                    ByteUtils.utf8ByteLength(value.options) +\n                    1);\n            }\n            else {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    internalCalculateObjectSize(value, serializeFunctions, ignoreUndefined) +\n                    1);\n            }\n        case 'function':\n            if (serializeFunctions) {\n                return ((name != null ? ByteUtils.utf8ByteLength(name) + 1 : 0) +\n                    1 +\n                    4 +\n                    ByteUtils.utf8ByteLength(value.toString()) +\n                    1);\n            }\n    }\n    return 0;\n}\n\nfunction alphabetize(str) {\n    return str.split('').sort().join('');\n}\nclass BSONRegExp extends BSONValue {\n    get _bsontype() {\n        return 'BSONRegExp';\n    }\n    constructor(pattern, options) {\n        super();\n        this.pattern = pattern;\n        this.options = alphabetize(options ?? '');\n        if (this.pattern.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex patterns cannot contain null bytes, found: ${JSON.stringify(this.pattern)}`);\n        }\n        if (this.options.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Regex options cannot contain null bytes, found: ${JSON.stringify(this.options)}`);\n        }\n        for (let i = 0; i < this.options.length; i++) {\n            if (!(this.options[i] === 'i' ||\n                this.options[i] === 'm' ||\n                this.options[i] === 'x' ||\n                this.options[i] === 'l' ||\n                this.options[i] === 's' ||\n                this.options[i] === 'u')) {\n                throw new BSONError(`The regular expression option [${this.options[i]}] is not supported`);\n            }\n        }\n    }\n    static parseOptions(options) {\n        return options ? options.split('').sort().join('') : '';\n    }\n    toExtendedJSON(options) {\n        options = options || {};\n        if (options.legacy) {\n            return { $regex: this.pattern, $options: this.options };\n        }\n        return { $regularExpression: { pattern: this.pattern, options: this.options } };\n    }\n    static fromExtendedJSON(doc) {\n        if ('$regex' in doc) {\n            if (typeof doc.$regex !== 'string') {\n                if (doc.$regex._bsontype === 'BSONRegExp') {\n                    return doc;\n                }\n            }\n            else {\n                return new BSONRegExp(doc.$regex, BSONRegExp.parseOptions(doc.$options));\n            }\n        }\n        if ('$regularExpression' in doc) {\n            return new BSONRegExp(doc.$regularExpression.pattern, BSONRegExp.parseOptions(doc.$regularExpression.options));\n        }\n        throw new BSONError(`Unexpected BSONRegExp EJSON object form: ${JSON.stringify(doc)}`);\n    }\n    inspect(depth, options, inspect) {\n        const stylize = getStylizeFunction(options) ?? (v => v);\n        inspect ??= defaultInspect;\n        const pattern = stylize(inspect(this.pattern), 'regexp');\n        const flags = stylize(inspect(this.options), 'regexp');\n        return `new BSONRegExp(${pattern}, ${flags})`;\n    }\n}\n\nclass BSONSymbol extends BSONValue {\n    get _bsontype() {\n        return 'BSONSymbol';\n    }\n    constructor(value) {\n        super();\n        this.value = value;\n    }\n    valueOf() {\n        return this.value;\n    }\n    toString() {\n        return this.value;\n    }\n    toJSON() {\n        return this.value;\n    }\n    toExtendedJSON() {\n        return { $symbol: this.value };\n    }\n    static fromExtendedJSON(doc) {\n        return new BSONSymbol(doc.$symbol);\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        return `new BSONSymbol(${inspect(this.value, options)})`;\n    }\n}\n\nconst LongWithoutOverridesClass = Long;\nclass Timestamp extends LongWithoutOverridesClass {\n    get _bsontype() {\n        return 'Timestamp';\n    }\n    constructor(low) {\n        if (low == null) {\n            super(0, 0, true);\n        }\n        else if (typeof low === 'bigint') {\n            super(low, true);\n        }\n        else if (Long.isLong(low)) {\n            super(low.low, low.high, true);\n        }\n        else if (typeof low === 'object' && 't' in low && 'i' in low) {\n            if (typeof low.t !== 'number' && (typeof low.t !== 'object' || low.t._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t as a number');\n            }\n            if (typeof low.i !== 'number' && (typeof low.i !== 'object' || low.i._bsontype !== 'Int32')) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i as a number');\n            }\n            const t = Number(low.t);\n            const i = Number(low.i);\n            if (t < 0 || Number.isNaN(t)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive t');\n            }\n            if (i < 0 || Number.isNaN(i)) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide a positive i');\n            }\n            if (t > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide t equal or less than uint32 max');\n            }\n            if (i > 4294967295) {\n                throw new BSONError('Timestamp constructed from { t, i } must provide i equal or less than uint32 max');\n            }\n            super(i, t, true);\n        }\n        else {\n            throw new BSONError('A Timestamp can only be constructed with: bigint, Long, or { t: number; i: number }');\n        }\n    }\n    toJSON() {\n        return {\n            $timestamp: this.toString()\n        };\n    }\n    static fromInt(value) {\n        return new Timestamp(Long.fromInt(value, true));\n    }\n    static fromNumber(value) {\n        return new Timestamp(Long.fromNumber(value, true));\n    }\n    static fromBits(lowBits, highBits) {\n        return new Timestamp({ i: lowBits, t: highBits });\n    }\n    static fromString(str, optRadix) {\n        return new Timestamp(Long.fromString(str, true, optRadix));\n    }\n    toExtendedJSON() {\n        return { $timestamp: { t: this.high >>> 0, i: this.low >>> 0 } };\n    }\n    static fromExtendedJSON(doc) {\n        const i = Long.isLong(doc.$timestamp.i)\n            ? doc.$timestamp.i.getLowBitsUnsigned()\n            : doc.$timestamp.i;\n        const t = Long.isLong(doc.$timestamp.t)\n            ? doc.$timestamp.t.getLowBitsUnsigned()\n            : doc.$timestamp.t;\n        return new Timestamp({ t, i });\n    }\n    inspect(depth, options, inspect) {\n        inspect ??= defaultInspect;\n        const t = inspect(this.high >>> 0, options);\n        const i = inspect(this.low >>> 0, options);\n        return `new Timestamp({ t: ${t}, i: ${i} })`;\n    }\n}\nTimestamp.MAX_VALUE = Long.MAX_UNSIGNED_VALUE;\n\nconst FIRST_BIT = 0x80;\nconst FIRST_TWO_BITS = 0xc0;\nconst FIRST_THREE_BITS = 0xe0;\nconst FIRST_FOUR_BITS = 0xf0;\nconst FIRST_FIVE_BITS = 0xf8;\nconst TWO_BIT_CHAR = 0xc0;\nconst THREE_BIT_CHAR = 0xe0;\nconst FOUR_BIT_CHAR = 0xf0;\nconst CONTINUING_CHAR = 0x80;\nfunction validateUtf8(bytes, start, end) {\n    let continuation = 0;\n    for (let i = start; i < end; i += 1) {\n        const byte = bytes[i];\n        if (continuation) {\n            if ((byte & FIRST_TWO_BITS) !== CONTINUING_CHAR) {\n                return false;\n            }\n            continuation -= 1;\n        }\n        else if (byte & FIRST_BIT) {\n            if ((byte & FIRST_THREE_BITS) === TWO_BIT_CHAR) {\n                continuation = 1;\n            }\n            else if ((byte & FIRST_FOUR_BITS) === THREE_BIT_CHAR) {\n                continuation = 2;\n            }\n            else if ((byte & FIRST_FIVE_BITS) === FOUR_BIT_CHAR) {\n                continuation = 3;\n            }\n            else {\n                return false;\n            }\n        }\n    }\n    return !continuation;\n}\n\nconst JS_INT_MAX_LONG = Long.fromNumber(JS_INT_MAX);\nconst JS_INT_MIN_LONG = Long.fromNumber(JS_INT_MIN);\nfunction internalDeserialize(buffer, options, isArray) {\n    options = options == null ? {} : options;\n    const index = options && options.index ? options.index : 0;\n    const size = buffer[index] |\n        (buffer[index + 1] << 8) |\n        (buffer[index + 2] << 16) |\n        (buffer[index + 3] << 24);\n    if (size < 5) {\n        throw new BSONError(`bson size must be >= 5, is ${size}`);\n    }\n    if (options.allowObjectSmallerThanBufferSize && buffer.length < size) {\n        throw new BSONError(`buffer length ${buffer.length} must be >= bson size ${size}`);\n    }\n    if (!options.allowObjectSmallerThanBufferSize && buffer.length !== size) {\n        throw new BSONError(`buffer length ${buffer.length} must === bson size ${size}`);\n    }\n    if (size + index > buffer.byteLength) {\n        throw new BSONError(`(bson size ${size} + options.index ${index} must be <= buffer length ${buffer.byteLength})`);\n    }\n    if (buffer[index + size - 1] !== 0) {\n        throw new BSONError(\"One object, sized correctly, with a spot for an EOO, but the EOO isn't 0x00\");\n    }\n    return deserializeObject(buffer, index, options, isArray);\n}\nconst allowedDBRefKeys = /^\\$ref$|^\\$id$|^\\$db$/;\nfunction deserializeObject(buffer, index, options, isArray = false) {\n    const fieldsAsRaw = options['fieldsAsRaw'] == null ? null : options['fieldsAsRaw'];\n    const raw = options['raw'] == null ? false : options['raw'];\n    const bsonRegExp = typeof options['bsonRegExp'] === 'boolean' ? options['bsonRegExp'] : false;\n    const promoteBuffers = options.promoteBuffers ?? false;\n    const promoteLongs = options.promoteLongs ?? true;\n    const promoteValues = options.promoteValues ?? true;\n    const useBigInt64 = options.useBigInt64 ?? false;\n    if (useBigInt64 && !promoteValues) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    if (useBigInt64 && !promoteLongs) {\n        throw new BSONError('Must either request bigint or Long for int64 deserialization');\n    }\n    const validation = options.validation == null ? { utf8: true } : options.validation;\n    let globalUTFValidation = true;\n    let validationSetting;\n    const utf8KeysSet = new Set();\n    const utf8ValidatedKeys = validation.utf8;\n    if (typeof utf8ValidatedKeys === 'boolean') {\n        validationSetting = utf8ValidatedKeys;\n    }\n    else {\n        globalUTFValidation = false;\n        const utf8ValidationValues = Object.keys(utf8ValidatedKeys).map(function (key) {\n            return utf8ValidatedKeys[key];\n        });\n        if (utf8ValidationValues.length === 0) {\n            throw new BSONError('UTF-8 validation setting cannot be empty');\n        }\n        if (typeof utf8ValidationValues[0] !== 'boolean') {\n            throw new BSONError('Invalid UTF-8 validation option, must specify boolean values');\n        }\n        validationSetting = utf8ValidationValues[0];\n        if (!utf8ValidationValues.every(item => item === validationSetting)) {\n            throw new BSONError('Invalid UTF-8 validation option - keys must be all true or all false');\n        }\n    }\n    if (!globalUTFValidation) {\n        for (const key of Object.keys(utf8ValidatedKeys)) {\n            utf8KeysSet.add(key);\n        }\n    }\n    const startIndex = index;\n    if (buffer.length < 5)\n        throw new BSONError('corrupt bson message < 5 bytes long');\n    const size = buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24);\n    if (size < 5 || size > buffer.length)\n        throw new BSONError('corrupt bson message');\n    const object = isArray ? [] : {};\n    let arrayIndex = 0;\n    const done = false;\n    let isPossibleDBRef = isArray ? false : null;\n    const dataview = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n    while (!done) {\n        const elementType = buffer[index++];\n        if (elementType === 0)\n            break;\n        let i = index;\n        while (buffer[i] !== 0x00 && i < buffer.length) {\n            i++;\n        }\n        if (i >= buffer.byteLength)\n            throw new BSONError('Bad BSON Document: illegal CString');\n        const name = isArray ? arrayIndex++ : ByteUtils.toUTF8(buffer, index, i);\n        let shouldValidateKey = true;\n        if (globalUTFValidation || utf8KeysSet.has(name)) {\n            shouldValidateKey = validationSetting;\n        }\n        else {\n            shouldValidateKey = !validationSetting;\n        }\n        if (isPossibleDBRef !== false && name[0] === '$') {\n            isPossibleDBRef = allowedDBRefKeys.test(name);\n        }\n        let value;\n        index = i + 1;\n        if (elementType === BSON_DATA_STRING) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            value = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_OID) {\n            const oid = ByteUtils.allocate(12);\n            oid.set(buffer.subarray(index, index + 12));\n            value = new ObjectId(oid);\n            index = index + 12;\n        }\n        else if (elementType === BSON_DATA_INT && promoteValues === false) {\n            value = new Int32(buffer[index++] | (buffer[index++] << 8) | (buffer[index++] << 16) | (buffer[index++] << 24));\n        }\n        else if (elementType === BSON_DATA_INT) {\n            value =\n                buffer[index++] |\n                    (buffer[index++] << 8) |\n                    (buffer[index++] << 16) |\n                    (buffer[index++] << 24);\n        }\n        else if (elementType === BSON_DATA_NUMBER && promoteValues === false) {\n            value = new Double(dataview.getFloat64(index, true));\n            index = index + 8;\n        }\n        else if (elementType === BSON_DATA_NUMBER) {\n            value = dataview.getFloat64(index, true);\n            index = index + 8;\n        }\n        else if (elementType === BSON_DATA_DATE) {\n            const lowBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const highBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            value = new Date(new Long(lowBits, highBits).toNumber());\n        }\n        else if (elementType === BSON_DATA_BOOLEAN) {\n            if (buffer[index] !== 0 && buffer[index] !== 1)\n                throw new BSONError('illegal boolean type value');\n            value = buffer[index++] === 1;\n        }\n        else if (elementType === BSON_DATA_OBJECT) {\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            if (objectSize <= 0 || objectSize > buffer.length - index)\n                throw new BSONError('bad embedded document length in bson');\n            if (raw) {\n                value = buffer.slice(index, index + objectSize);\n            }\n            else {\n                let objectOptions = options;\n                if (!globalUTFValidation) {\n                    objectOptions = { ...options, validation: { utf8: shouldValidateKey } };\n                }\n                value = deserializeObject(buffer, _index, objectOptions, false);\n            }\n            index = index + objectSize;\n        }\n        else if (elementType === BSON_DATA_ARRAY) {\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            let arrayOptions = options;\n            const stopIndex = index + objectSize;\n            if (fieldsAsRaw && fieldsAsRaw[name]) {\n                arrayOptions = { ...options, raw: true };\n            }\n            if (!globalUTFValidation) {\n                arrayOptions = { ...arrayOptions, validation: { utf8: shouldValidateKey } };\n            }\n            value = deserializeObject(buffer, _index, arrayOptions, true);\n            index = index + objectSize;\n            if (buffer[index - 1] !== 0)\n                throw new BSONError('invalid array terminator byte');\n            if (index !== stopIndex)\n                throw new BSONError('corrupted array bson');\n        }\n        else if (elementType === BSON_DATA_UNDEFINED) {\n            value = undefined;\n        }\n        else if (elementType === BSON_DATA_NULL) {\n            value = null;\n        }\n        else if (elementType === BSON_DATA_LONG) {\n            const dataview = BSONDataView.fromUint8Array(buffer.subarray(index, index + 8));\n            const lowBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const highBits = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const long = new Long(lowBits, highBits);\n            if (useBigInt64) {\n                value = dataview.getBigInt64(0, true);\n            }\n            else if (promoteLongs && promoteValues === true) {\n                value =\n                    long.lessThanOrEqual(JS_INT_MAX_LONG) && long.greaterThanOrEqual(JS_INT_MIN_LONG)\n                        ? long.toNumber()\n                        : long;\n            }\n            else {\n                value = long;\n            }\n        }\n        else if (elementType === BSON_DATA_DECIMAL128) {\n            const bytes = ByteUtils.allocate(16);\n            bytes.set(buffer.subarray(index, index + 16), 0);\n            index = index + 16;\n            value = new Decimal128(bytes);\n        }\n        else if (elementType === BSON_DATA_BINARY) {\n            let binarySize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            const totalBinarySize = binarySize;\n            const subType = buffer[index++];\n            if (binarySize < 0)\n                throw new BSONError('Negative binary type element size found');\n            if (binarySize > buffer.byteLength)\n                throw new BSONError('Binary type size larger than document size');\n            if (buffer['slice'] != null) {\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize =\n                        buffer[index++] |\n                            (buffer[index++] << 8) |\n                            (buffer[index++] << 16) |\n                            (buffer[index++] << 24);\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = ByteUtils.toLocalBufferType(buffer.slice(index, index + binarySize));\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            else {\n                const _buffer = ByteUtils.allocate(binarySize);\n                if (subType === Binary.SUBTYPE_BYTE_ARRAY) {\n                    binarySize =\n                        buffer[index++] |\n                            (buffer[index++] << 8) |\n                            (buffer[index++] << 16) |\n                            (buffer[index++] << 24);\n                    if (binarySize < 0)\n                        throw new BSONError('Negative binary type element size found for subtype 0x02');\n                    if (binarySize > totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too long binary size');\n                    if (binarySize < totalBinarySize - 4)\n                        throw new BSONError('Binary type with subtype 0x02 contains too short binary size');\n                }\n                for (i = 0; i < binarySize; i++) {\n                    _buffer[i] = buffer[index + i];\n                }\n                if (promoteBuffers && promoteValues) {\n                    value = _buffer;\n                }\n                else {\n                    value = new Binary(buffer.slice(index, index + binarySize), subType);\n                    if (subType === BSON_BINARY_SUBTYPE_UUID_NEW && UUID.isValid(value)) {\n                        value = value.toUUID();\n                    }\n                }\n            }\n            index = index + binarySize;\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === false) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            const optionsArray = new Array(regExpOptions.length);\n            for (i = 0; i < regExpOptions.length; i++) {\n                switch (regExpOptions[i]) {\n                    case 'm':\n                        optionsArray[i] = 'm';\n                        break;\n                    case 's':\n                        optionsArray[i] = 'g';\n                        break;\n                    case 'i':\n                        optionsArray[i] = 'i';\n                        break;\n                }\n            }\n            value = new RegExp(source, optionsArray.join(''));\n        }\n        else if (elementType === BSON_DATA_REGEXP && bsonRegExp === true) {\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const source = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            i = index;\n            while (buffer[i] !== 0x00 && i < buffer.length) {\n                i++;\n            }\n            if (i >= buffer.length)\n                throw new BSONError('Bad BSON Document: illegal CString');\n            const regExpOptions = ByteUtils.toUTF8(buffer, index, i);\n            index = i + 1;\n            value = new BSONRegExp(source, regExpOptions);\n        }\n        else if (elementType === BSON_DATA_SYMBOL) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const symbol = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = promoteValues ? symbol : new BSONSymbol(symbol);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_TIMESTAMP) {\n            const i = buffer[index++] +\n                buffer[index++] * (1 << 8) +\n                buffer[index++] * (1 << 16) +\n                buffer[index++] * (1 << 24);\n            const t = buffer[index++] +\n                buffer[index++] * (1 << 8) +\n                buffer[index++] * (1 << 16) +\n                buffer[index++] * (1 << 24);\n            value = new Timestamp({ i, t });\n        }\n        else if (elementType === BSON_DATA_MIN_KEY) {\n            value = new MinKey();\n        }\n        else if (elementType === BSON_DATA_MAX_KEY) {\n            value = new MaxKey();\n        }\n        else if (elementType === BSON_DATA_CODE) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            value = new Code(functionString);\n            index = index + stringSize;\n        }\n        else if (elementType === BSON_DATA_CODE_W_SCOPE) {\n            const totalSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (totalSize < 4 + 4 + 4 + 1) {\n                throw new BSONError('code_w_scope total size shorter minimum expected length');\n            }\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0) {\n                throw new BSONError('bad string length in bson');\n            }\n            const functionString = getValidatedString(buffer, index, index + stringSize - 1, shouldValidateKey);\n            index = index + stringSize;\n            const _index = index;\n            const objectSize = buffer[index] |\n                (buffer[index + 1] << 8) |\n                (buffer[index + 2] << 16) |\n                (buffer[index + 3] << 24);\n            const scopeObject = deserializeObject(buffer, _index, options, false);\n            index = index + objectSize;\n            if (totalSize < 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too short, truncating scope');\n            }\n            if (totalSize > 4 + 4 + objectSize + stringSize) {\n                throw new BSONError('code_w_scope total size is too long, clips outer document');\n            }\n            value = new Code(functionString, scopeObject);\n        }\n        else if (elementType === BSON_DATA_DBPOINTER) {\n            const stringSize = buffer[index++] |\n                (buffer[index++] << 8) |\n                (buffer[index++] << 16) |\n                (buffer[index++] << 24);\n            if (stringSize <= 0 ||\n                stringSize > buffer.length - index ||\n                buffer[index + stringSize - 1] !== 0)\n                throw new BSONError('bad string length in bson');\n            if (validation != null && validation.utf8) {\n                if (!validateUtf8(buffer, index, index + stringSize - 1)) {\n                    throw new BSONError('Invalid UTF-8 string in BSON document');\n                }\n            }\n            const namespace = ByteUtils.toUTF8(buffer, index, index + stringSize - 1);\n            index = index + stringSize;\n            const oidBuffer = ByteUtils.allocate(12);\n            oidBuffer.set(buffer.subarray(index, index + 12), 0);\n            const oid = new ObjectId(oidBuffer);\n            index = index + 12;\n            value = new DBRef(namespace, oid);\n        }\n        else {\n            throw new BSONError(`Detected unknown BSON type ${elementType.toString(16)} for fieldname \"${name}\"`);\n        }\n        if (name === '__proto__') {\n            Object.defineProperty(object, name, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n        else {\n            object[name] = value;\n        }\n    }\n    if (size !== index - startIndex) {\n        if (isArray)\n            throw new BSONError('corrupt array bson');\n        throw new BSONError('corrupt object bson');\n    }\n    if (!isPossibleDBRef)\n        return object;\n    if (isDBRefLike(object)) {\n        const copy = Object.assign({}, object);\n        delete copy.$ref;\n        delete copy.$id;\n        delete copy.$db;\n        return new DBRef(object.$ref, object.$id, object.$db, copy);\n    }\n    return object;\n}\nfunction getValidatedString(buffer, start, end, shouldValidateUtf8) {\n    const value = ByteUtils.toUTF8(buffer, start, end);\n    if (shouldValidateUtf8) {\n        for (let i = 0; i < value.length; i++) {\n            if (value.charCodeAt(i) === 0xfffd) {\n                if (!validateUtf8(buffer, start, end)) {\n                    throw new BSONError('Invalid UTF-8 string in BSON document');\n                }\n                break;\n            }\n        }\n    }\n    return value;\n}\n\nconst regexp = /\\x00/;\nconst ignoreKeys = new Set(['$db', '$ref', '$id', '$clusterTime']);\nfunction serializeString(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_STRING;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes + 1;\n    buffer[index - 1] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value, index + 4);\n    buffer[index + 3] = ((size + 1) >> 24) & 0xff;\n    buffer[index + 2] = ((size + 1) >> 16) & 0xff;\n    buffer[index + 1] = ((size + 1) >> 8) & 0xff;\n    buffer[index] = (size + 1) & 0xff;\n    index = index + 4 + size;\n    buffer[index++] = 0;\n    return index;\n}\nconst NUMBER_SPACE = new DataView(new ArrayBuffer(8), 0, 8);\nconst FOUR_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 4);\nconst EIGHT_BYTE_VIEW_ON_NUMBER = new Uint8Array(NUMBER_SPACE.buffer, 0, 8);\nfunction serializeNumber(buffer, key, value, index) {\n    const isNegativeZero = Object.is(value, -0);\n    const type = !isNegativeZero &&\n        Number.isSafeInteger(value) &&\n        value <= BSON_INT32_MAX &&\n        value >= BSON_INT32_MIN\n        ? BSON_DATA_INT\n        : BSON_DATA_NUMBER;\n    if (type === BSON_DATA_INT) {\n        NUMBER_SPACE.setInt32(0, value, true);\n    }\n    else {\n        NUMBER_SPACE.setFloat64(0, value, true);\n    }\n    const bytes = type === BSON_DATA_INT ? FOUR_BYTE_VIEW_ON_NUMBER : EIGHT_BYTE_VIEW_ON_NUMBER;\n    buffer[index++] = type;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0x00;\n    buffer.set(bytes, index);\n    index += bytes.byteLength;\n    return index;\n}\nfunction serializeBigInt(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_LONG;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index += numberOfWrittenBytes;\n    buffer[index++] = 0;\n    NUMBER_SPACE.setBigInt64(0, value, true);\n    buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);\n    index += EIGHT_BYTE_VIEW_ON_NUMBER.byteLength;\n    return index;\n}\nfunction serializeNull(buffer, key, _, index) {\n    buffer[index++] = BSON_DATA_NULL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeBoolean(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BOOLEAN;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer[index++] = value ? 1 : 0;\n    return index;\n}\nfunction serializeDate(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DATE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const dateInMilis = Long.fromNumber(value.getTime());\n    const lowBits = dateInMilis.getLowBits();\n    const highBits = dateInMilis.getHighBits();\n    buffer[index++] = lowBits & 0xff;\n    buffer[index++] = (lowBits >> 8) & 0xff;\n    buffer[index++] = (lowBits >> 16) & 0xff;\n    buffer[index++] = (lowBits >> 24) & 0xff;\n    buffer[index++] = highBits & 0xff;\n    buffer[index++] = (highBits >> 8) & 0xff;\n    buffer[index++] = (highBits >> 16) & 0xff;\n    buffer[index++] = (highBits >> 24) & 0xff;\n    return index;\n}\nfunction serializeRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.source && value.source.match(regexp) != null) {\n        throw new BSONError('value ' + value.source + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.source, index);\n    buffer[index++] = 0x00;\n    if (value.ignoreCase)\n        buffer[index++] = 0x69;\n    if (value.global)\n        buffer[index++] = 0x73;\n    if (value.multiline)\n        buffer[index++] = 0x6d;\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeBSONRegExp(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_REGEXP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    if (value.pattern.match(regexp) != null) {\n        throw new BSONError('pattern ' + value.pattern + ' must not contain null bytes');\n    }\n    index = index + ByteUtils.encodeUTF8Into(buffer, value.pattern, index);\n    buffer[index++] = 0x00;\n    const sortedOptions = value.options.split('').sort().join('');\n    index = index + ByteUtils.encodeUTF8Into(buffer, sortedOptions, index);\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeMinMax(buffer, key, value, index) {\n    if (value === null) {\n        buffer[index++] = BSON_DATA_NULL;\n    }\n    else if (value._bsontype === 'MinKey') {\n        buffer[index++] = BSON_DATA_MIN_KEY;\n    }\n    else {\n        buffer[index++] = BSON_DATA_MAX_KEY;\n    }\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeObjectId(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_OID;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const idValue = value.id;\n    if (isUint8Array(idValue)) {\n        for (let i = 0; i < 12; i++) {\n            buffer[index++] = idValue[i];\n        }\n    }\n    else {\n        throw new BSONError('object [' + JSON.stringify(value) + '] is not a valid ObjectId');\n    }\n    return index;\n}\nfunction serializeBuffer(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = value.length;\n    buffer[index++] = size & 0xff;\n    buffer[index++] = (size >> 8) & 0xff;\n    buffer[index++] = (size >> 16) & 0xff;\n    buffer[index++] = (size >> 24) & 0xff;\n    buffer[index++] = BSON_BINARY_SUBTYPE_DEFAULT;\n    buffer.set(value, index);\n    index = index + size;\n    return index;\n}\nfunction serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path.has(value)) {\n        throw new BSONError('Cannot convert circular structure to BSON');\n    }\n    path.add(value);\n    buffer[index++] = Array.isArray(value) ? BSON_DATA_ARRAY : BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const endIndex = serializeInto(buffer, value, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n    path.delete(value);\n    return endIndex;\n}\nfunction serializeDecimal128(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_DECIMAL128;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer.set(value.bytes.subarray(0, 16), index);\n    return index + 16;\n}\nfunction serializeLong(buffer, key, value, index) {\n    buffer[index++] =\n        value._bsontype === 'Long' ? BSON_DATA_LONG : BSON_DATA_TIMESTAMP;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const lowBits = value.getLowBits();\n    const highBits = value.getHighBits();\n    buffer[index++] = lowBits & 0xff;\n    buffer[index++] = (lowBits >> 8) & 0xff;\n    buffer[index++] = (lowBits >> 16) & 0xff;\n    buffer[index++] = (lowBits >> 24) & 0xff;\n    buffer[index++] = highBits & 0xff;\n    buffer[index++] = (highBits >> 8) & 0xff;\n    buffer[index++] = (highBits >> 16) & 0xff;\n    buffer[index++] = (highBits >> 24) & 0xff;\n    return index;\n}\nfunction serializeInt32(buffer, key, value, index) {\n    value = value.valueOf();\n    buffer[index++] = BSON_DATA_INT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    buffer[index++] = value & 0xff;\n    buffer[index++] = (value >> 8) & 0xff;\n    buffer[index++] = (value >> 16) & 0xff;\n    buffer[index++] = (value >> 24) & 0xff;\n    return index;\n}\nfunction serializeDouble(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_NUMBER;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    NUMBER_SPACE.setFloat64(0, value.value, true);\n    buffer.set(EIGHT_BYTE_VIEW_ON_NUMBER, index);\n    index = index + 8;\n    return index;\n}\nfunction serializeFunction(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_CODE;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const functionString = value.toString();\n    const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n    buffer[index] = size & 0xff;\n    buffer[index + 1] = (size >> 8) & 0xff;\n    buffer[index + 2] = (size >> 16) & 0xff;\n    buffer[index + 3] = (size >> 24) & 0xff;\n    index = index + 4 + size - 1;\n    buffer[index++] = 0;\n    return index;\n}\nfunction serializeCode(buffer, key, value, index, checkKeys = false, depth = 0, serializeFunctions = false, ignoreUndefined = true, path) {\n    if (value.scope && typeof value.scope === 'object') {\n        buffer[index++] = BSON_DATA_CODE_W_SCOPE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        let startIndex = index;\n        const functionString = value.code;\n        index = index + 4;\n        const codeSize = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        buffer[index] = codeSize & 0xff;\n        buffer[index + 1] = (codeSize >> 8) & 0xff;\n        buffer[index + 2] = (codeSize >> 16) & 0xff;\n        buffer[index + 3] = (codeSize >> 24) & 0xff;\n        buffer[index + 4 + codeSize - 1] = 0;\n        index = index + codeSize + 4;\n        const endIndex = serializeInto(buffer, value.scope, checkKeys, index, depth + 1, serializeFunctions, ignoreUndefined, path);\n        index = endIndex - 1;\n        const totalSize = endIndex - startIndex;\n        buffer[startIndex++] = totalSize & 0xff;\n        buffer[startIndex++] = (totalSize >> 8) & 0xff;\n        buffer[startIndex++] = (totalSize >> 16) & 0xff;\n        buffer[startIndex++] = (totalSize >> 24) & 0xff;\n        buffer[index++] = 0;\n    }\n    else {\n        buffer[index++] = BSON_DATA_CODE;\n        const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n        index = index + numberOfWrittenBytes;\n        buffer[index++] = 0;\n        const functionString = value.code.toString();\n        const size = ByteUtils.encodeUTF8Into(buffer, functionString, index + 4) + 1;\n        buffer[index] = size & 0xff;\n        buffer[index + 1] = (size >> 8) & 0xff;\n        buffer[index + 2] = (size >> 16) & 0xff;\n        buffer[index + 3] = (size >> 24) & 0xff;\n        index = index + 4 + size - 1;\n        buffer[index++] = 0;\n    }\n    return index;\n}\nfunction serializeBinary(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_BINARY;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const data = value.buffer;\n    let size = value.position;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY)\n        size = size + 4;\n    buffer[index++] = size & 0xff;\n    buffer[index++] = (size >> 8) & 0xff;\n    buffer[index++] = (size >> 16) & 0xff;\n    buffer[index++] = (size >> 24) & 0xff;\n    buffer[index++] = value.sub_type;\n    if (value.sub_type === Binary.SUBTYPE_BYTE_ARRAY) {\n        size = size - 4;\n        buffer[index++] = size & 0xff;\n        buffer[index++] = (size >> 8) & 0xff;\n        buffer[index++] = (size >> 16) & 0xff;\n        buffer[index++] = (size >> 24) & 0xff;\n    }\n    buffer.set(data, index);\n    index = index + value.position;\n    return index;\n}\nfunction serializeSymbol(buffer, key, value, index) {\n    buffer[index++] = BSON_DATA_SYMBOL;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    const size = ByteUtils.encodeUTF8Into(buffer, value.value, index + 4) + 1;\n    buffer[index] = size & 0xff;\n    buffer[index + 1] = (size >> 8) & 0xff;\n    buffer[index + 2] = (size >> 16) & 0xff;\n    buffer[index + 3] = (size >> 24) & 0xff;\n    index = index + 4 + size - 1;\n    buffer[index++] = 0x00;\n    return index;\n}\nfunction serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path) {\n    buffer[index++] = BSON_DATA_OBJECT;\n    const numberOfWrittenBytes = ByteUtils.encodeUTF8Into(buffer, key, index);\n    index = index + numberOfWrittenBytes;\n    buffer[index++] = 0;\n    let startIndex = index;\n    let output = {\n        $ref: value.collection || value.namespace,\n        $id: value.oid\n    };\n    if (value.db != null) {\n        output.$db = value.db;\n    }\n    output = Object.assign(output, value.fields);\n    const endIndex = serializeInto(buffer, output, false, index, depth + 1, serializeFunctions, true, path);\n    const size = endIndex - startIndex;\n    buffer[startIndex++] = size & 0xff;\n    buffer[startIndex++] = (size >> 8) & 0xff;\n    buffer[startIndex++] = (size >> 16) & 0xff;\n    buffer[startIndex++] = (size >> 24) & 0xff;\n    return endIndex;\n}\nfunction serializeInto(buffer, object, checkKeys, startingIndex, depth, serializeFunctions, ignoreUndefined, path) {\n    if (path == null) {\n        if (object == null) {\n            buffer[0] = 0x05;\n            buffer[1] = 0x00;\n            buffer[2] = 0x00;\n            buffer[3] = 0x00;\n            buffer[4] = 0x00;\n            return 5;\n        }\n        if (Array.isArray(object)) {\n            throw new BSONError('serialize does not support an array as the root input');\n        }\n        if (typeof object !== 'object') {\n            throw new BSONError('serialize does not support non-object as the root input');\n        }\n        else if ('_bsontype' in object && typeof object._bsontype === 'string') {\n            throw new BSONError(`BSON types cannot be serialized as a document`);\n        }\n        else if (isDate(object) ||\n            isRegExp(object) ||\n            isUint8Array(object) ||\n            isAnyArrayBuffer(object)) {\n            throw new BSONError(`date, regexp, typedarray, and arraybuffer cannot be BSON documents`);\n        }\n        path = new Set();\n    }\n    path.add(object);\n    let index = startingIndex + 4;\n    if (Array.isArray(object)) {\n        for (let i = 0; i < object.length; i++) {\n            const key = `${i}`;\n            let value = object[i];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            if (typeof value === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (typeof value === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (typeof value === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (typeof value === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (typeof value === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else if (object instanceof Map || isMap(object)) {\n        const iterator = object.entries();\n        let done = false;\n        while (!done) {\n            const entry = iterator.next();\n            done = !!entry.done;\n            if (done)\n                continue;\n            const key = entry.value[0];\n            let value = entry.value[1];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (~key.indexOf('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === null || (value === undefined && ignoreUndefined === false)) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    else {\n        if (typeof object?.toBSON === 'function') {\n            object = object.toBSON();\n            if (object != null && typeof object !== 'object') {\n                throw new BSONError('toBSON function did not return an object');\n            }\n        }\n        for (const key of Object.keys(object)) {\n            let value = object[key];\n            if (typeof value?.toBSON === 'function') {\n                value = value.toBSON();\n            }\n            const type = typeof value;\n            if (typeof key === 'string' && !ignoreKeys.has(key)) {\n                if (key.match(regexp) != null) {\n                    throw new BSONError('key ' + key + ' must not contain null bytes');\n                }\n                if (checkKeys) {\n                    if ('$' === key[0]) {\n                        throw new BSONError('key ' + key + \" must not start with '$'\");\n                    }\n                    else if (~key.indexOf('.')) {\n                        throw new BSONError('key ' + key + \" must not contain '.'\");\n                    }\n                }\n            }\n            if (type === 'string') {\n                index = serializeString(buffer, key, value, index);\n            }\n            else if (type === 'number') {\n                index = serializeNumber(buffer, key, value, index);\n            }\n            else if (type === 'bigint') {\n                index = serializeBigInt(buffer, key, value, index);\n            }\n            else if (type === 'boolean') {\n                index = serializeBoolean(buffer, key, value, index);\n            }\n            else if (value instanceof Date || isDate(value)) {\n                index = serializeDate(buffer, key, value, index);\n            }\n            else if (value === undefined) {\n                if (ignoreUndefined === false)\n                    index = serializeNull(buffer, key, value, index);\n            }\n            else if (value === null) {\n                index = serializeNull(buffer, key, value, index);\n            }\n            else if (isUint8Array(value)) {\n                index = serializeBuffer(buffer, key, value, index);\n            }\n            else if (value instanceof RegExp || isRegExp(value)) {\n                index = serializeRegExp(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype == null) {\n                index = serializeObject(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'object' &&\n                value[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n                throw new BSONVersionError();\n            }\n            else if (value._bsontype === 'ObjectId') {\n                index = serializeObjectId(buffer, key, value, index);\n            }\n            else if (type === 'object' && value._bsontype === 'Decimal128') {\n                index = serializeDecimal128(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Long' || value._bsontype === 'Timestamp') {\n                index = serializeLong(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Double') {\n                index = serializeDouble(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Code') {\n                index = serializeCode(buffer, key, value, index, checkKeys, depth, serializeFunctions, ignoreUndefined, path);\n            }\n            else if (typeof value === 'function' && serializeFunctions) {\n                index = serializeFunction(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Binary') {\n                index = serializeBinary(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'BSONSymbol') {\n                index = serializeSymbol(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'DBRef') {\n                index = serializeDBRef(buffer, key, value, index, depth, serializeFunctions, path);\n            }\n            else if (value._bsontype === 'BSONRegExp') {\n                index = serializeBSONRegExp(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'Int32') {\n                index = serializeInt32(buffer, key, value, index);\n            }\n            else if (value._bsontype === 'MinKey' || value._bsontype === 'MaxKey') {\n                index = serializeMinMax(buffer, key, value, index);\n            }\n            else if (typeof value._bsontype !== 'undefined') {\n                throw new BSONError(`Unrecognized or invalid _bsontype: ${String(value._bsontype)}`);\n            }\n        }\n    }\n    path.delete(object);\n    buffer[index++] = 0x00;\n    const size = index - startingIndex;\n    buffer[startingIndex++] = size & 0xff;\n    buffer[startingIndex++] = (size >> 8) & 0xff;\n    buffer[startingIndex++] = (size >> 16) & 0xff;\n    buffer[startingIndex++] = (size >> 24) & 0xff;\n    return index;\n}\n\nfunction isBSONType(value) {\n    return (value != null &&\n        typeof value === 'object' &&\n        '_bsontype' in value &&\n        typeof value._bsontype === 'string');\n}\nconst keysToCodecs = {\n    $oid: ObjectId,\n    $binary: Binary,\n    $uuid: Binary,\n    $symbol: BSONSymbol,\n    $numberInt: Int32,\n    $numberDecimal: Decimal128,\n    $numberDouble: Double,\n    $numberLong: Long,\n    $minKey: MinKey,\n    $maxKey: MaxKey,\n    $regex: BSONRegExp,\n    $regularExpression: BSONRegExp,\n    $timestamp: Timestamp\n};\nfunction deserializeValue(value, options = {}) {\n    if (typeof value === 'number') {\n        const in32BitRange = value <= BSON_INT32_MAX && value >= BSON_INT32_MIN;\n        const in64BitRange = value <= BSON_INT64_MAX && value >= BSON_INT64_MIN;\n        if (options.relaxed || options.legacy) {\n            return value;\n        }\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (in32BitRange) {\n                return new Int32(value);\n            }\n            if (in64BitRange) {\n                if (options.useBigInt64) {\n                    return BigInt(value);\n                }\n                return Long.fromNumber(value);\n            }\n        }\n        return new Double(value);\n    }\n    if (value == null || typeof value !== 'object')\n        return value;\n    if (value.$undefined)\n        return null;\n    const keys = Object.keys(value).filter(k => k.startsWith('$') && value[k] != null);\n    for (let i = 0; i < keys.length; i++) {\n        const c = keysToCodecs[keys[i]];\n        if (c)\n            return c.fromExtendedJSON(value, options);\n    }\n    if (value.$date != null) {\n        const d = value.$date;\n        const date = new Date();\n        if (options.legacy) {\n            if (typeof d === 'number')\n                date.setTime(d);\n            else if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        else {\n            if (typeof d === 'string')\n                date.setTime(Date.parse(d));\n            else if (Long.isLong(d))\n                date.setTime(d.toNumber());\n            else if (typeof d === 'number' && options.relaxed)\n                date.setTime(d);\n            else if (typeof d === 'bigint')\n                date.setTime(Number(d));\n            else\n                throw new BSONRuntimeError(`Unrecognized type for EJSON date: ${typeof d}`);\n        }\n        return date;\n    }\n    if (value.$code != null) {\n        const copy = Object.assign({}, value);\n        if (value.$scope) {\n            copy.$scope = deserializeValue(value.$scope);\n        }\n        return Code.fromExtendedJSON(value);\n    }\n    if (isDBRefLike(value) || value.$dbPointer) {\n        const v = value.$ref ? value : value.$dbPointer;\n        if (v instanceof DBRef)\n            return v;\n        const dollarKeys = Object.keys(v).filter(k => k.startsWith('$'));\n        let valid = true;\n        dollarKeys.forEach(k => {\n            if (['$ref', '$id', '$db'].indexOf(k) === -1)\n                valid = false;\n        });\n        if (valid)\n            return DBRef.fromExtendedJSON(v);\n    }\n    return value;\n}\nfunction serializeArray(array, options) {\n    return array.map((v, index) => {\n        options.seenObjects.push({ propertyName: `index ${index}`, obj: null });\n        try {\n            return serializeValue(v, options);\n        }\n        finally {\n            options.seenObjects.pop();\n        }\n    });\n}\nfunction getISOString(date) {\n    const isoStr = date.toISOString();\n    return date.getUTCMilliseconds() !== 0 ? isoStr : isoStr.slice(0, -5) + 'Z';\n}\nfunction serializeValue(value, options) {\n    if (value instanceof Map || isMap(value)) {\n        const obj = Object.create(null);\n        for (const [k, v] of value) {\n            if (typeof k !== 'string') {\n                throw new BSONError('Can only serialize maps with string keys');\n            }\n            obj[k] = v;\n        }\n        return serializeValue(obj, options);\n    }\n    if ((typeof value === 'object' || typeof value === 'function') && value !== null) {\n        const index = options.seenObjects.findIndex(entry => entry.obj === value);\n        if (index !== -1) {\n            const props = options.seenObjects.map(entry => entry.propertyName);\n            const leadingPart = props\n                .slice(0, index)\n                .map(prop => `${prop} -> `)\n                .join('');\n            const alreadySeen = props[index];\n            const circularPart = ' -> ' +\n                props\n                    .slice(index + 1, props.length - 1)\n                    .map(prop => `${prop} -> `)\n                    .join('');\n            const current = props[props.length - 1];\n            const leadingSpace = ' '.repeat(leadingPart.length + alreadySeen.length / 2);\n            const dashes = '-'.repeat(circularPart.length + (alreadySeen.length + current.length) / 2 - 1);\n            throw new BSONError('Converting circular structure to EJSON:\\n' +\n                `    ${leadingPart}${alreadySeen}${circularPart}${current}\\n` +\n                `    ${leadingSpace}\\\\${dashes}/`);\n        }\n        options.seenObjects[options.seenObjects.length - 1].obj = value;\n    }\n    if (Array.isArray(value))\n        return serializeArray(value, options);\n    if (value === undefined)\n        return null;\n    if (value instanceof Date || isDate(value)) {\n        const dateNum = value.getTime(), inRange = dateNum > -1 && dateNum < 253402318800000;\n        if (options.legacy) {\n            return options.relaxed && inRange\n                ? { $date: value.getTime() }\n                : { $date: getISOString(value) };\n        }\n        return options.relaxed && inRange\n            ? { $date: getISOString(value) }\n            : { $date: { $numberLong: value.getTime().toString() } };\n    }\n    if (typeof value === 'number' && (!options.relaxed || !isFinite(value))) {\n        if (Number.isInteger(value) && !Object.is(value, -0)) {\n            if (value >= BSON_INT32_MIN && value <= BSON_INT32_MAX) {\n                return { $numberInt: value.toString() };\n            }\n            if (value >= BSON_INT64_MIN && value <= BSON_INT64_MAX) {\n                return { $numberLong: value.toString() };\n            }\n        }\n        return { $numberDouble: Object.is(value, -0) ? '-0.0' : value.toString() };\n    }\n    if (typeof value === 'bigint') {\n        if (!options.relaxed) {\n            return { $numberLong: BigInt.asIntN(64, value).toString() };\n        }\n        return Number(BigInt.asIntN(64, value));\n    }\n    if (value instanceof RegExp || isRegExp(value)) {\n        let flags = value.flags;\n        if (flags === undefined) {\n            const match = value.toString().match(/[gimuy]*$/);\n            if (match) {\n                flags = match[0];\n            }\n        }\n        const rx = new BSONRegExp(value.source, flags);\n        return rx.toExtendedJSON(options);\n    }\n    if (value != null && typeof value === 'object')\n        return serializeDocument(value, options);\n    return value;\n}\nconst BSON_TYPE_MAPPINGS = {\n    Binary: (o) => new Binary(o.value(), o.sub_type),\n    Code: (o) => new Code(o.code, o.scope),\n    DBRef: (o) => new DBRef(o.collection || o.namespace, o.oid, o.db, o.fields),\n    Decimal128: (o) => new Decimal128(o.bytes),\n    Double: (o) => new Double(o.value),\n    Int32: (o) => new Int32(o.value),\n    Long: (o) => Long.fromBits(o.low != null ? o.low : o.low_, o.low != null ? o.high : o.high_, o.low != null ? o.unsigned : o.unsigned_),\n    MaxKey: () => new MaxKey(),\n    MinKey: () => new MinKey(),\n    ObjectId: (o) => new ObjectId(o),\n    BSONRegExp: (o) => new BSONRegExp(o.pattern, o.options),\n    BSONSymbol: (o) => new BSONSymbol(o.value),\n    Timestamp: (o) => Timestamp.fromBits(o.low, o.high)\n};\nfunction serializeDocument(doc, options) {\n    if (doc == null || typeof doc !== 'object')\n        throw new BSONError('not an object instance');\n    const bsontype = doc._bsontype;\n    if (typeof bsontype === 'undefined') {\n        const _doc = {};\n        for (const name of Object.keys(doc)) {\n            options.seenObjects.push({ propertyName: name, obj: null });\n            try {\n                const value = serializeValue(doc[name], options);\n                if (name === '__proto__') {\n                    Object.defineProperty(_doc, name, {\n                        value,\n                        writable: true,\n                        enumerable: true,\n                        configurable: true\n                    });\n                }\n                else {\n                    _doc[name] = value;\n                }\n            }\n            finally {\n                options.seenObjects.pop();\n            }\n        }\n        return _doc;\n    }\n    else if (doc != null &&\n        typeof doc === 'object' &&\n        typeof doc._bsontype === 'string' &&\n        doc[Symbol.for('@@mdb.bson.version')] !== BSON_MAJOR_VERSION) {\n        throw new BSONVersionError();\n    }\n    else if (isBSONType(doc)) {\n        let outDoc = doc;\n        if (typeof outDoc.toExtendedJSON !== 'function') {\n            const mapper = BSON_TYPE_MAPPINGS[doc._bsontype];\n            if (!mapper) {\n                throw new BSONError('Unrecognized or invalid _bsontype: ' + doc._bsontype);\n            }\n            outDoc = mapper(outDoc);\n        }\n        if (bsontype === 'Code' && outDoc.scope) {\n            outDoc = new Code(outDoc.code, serializeValue(outDoc.scope, options));\n        }\n        else if (bsontype === 'DBRef' && outDoc.oid) {\n            outDoc = new DBRef(serializeValue(outDoc.collection, options), serializeValue(outDoc.oid, options), serializeValue(outDoc.db, options), serializeValue(outDoc.fields, options));\n        }\n        return outDoc.toExtendedJSON(options);\n    }\n    else {\n        throw new BSONError('_bsontype must be a string, but was: ' + typeof bsontype);\n    }\n}\nfunction parse(text, options) {\n    const ejsonOptions = {\n        useBigInt64: options?.useBigInt64 ?? false,\n        relaxed: options?.relaxed ?? true,\n        legacy: options?.legacy ?? false\n    };\n    return JSON.parse(text, (key, value) => {\n        if (key.indexOf('\\x00') !== -1) {\n            throw new BSONError(`BSON Document field names cannot contain null bytes, found: ${JSON.stringify(key)}`);\n        }\n        return deserializeValue(value, ejsonOptions);\n    });\n}\nfunction stringify(value, replacer, space, options) {\n    if (space != null && typeof space === 'object') {\n        options = space;\n        space = 0;\n    }\n    if (replacer != null && typeof replacer === 'object' && !Array.isArray(replacer)) {\n        options = replacer;\n        replacer = undefined;\n        space = 0;\n    }\n    const serializeOptions = Object.assign({ relaxed: true, legacy: false }, options, {\n        seenObjects: [{ propertyName: '(root)', obj: null }]\n    });\n    const doc = serializeValue(value, serializeOptions);\n    return JSON.stringify(doc, replacer, space);\n}\nfunction EJSONserialize(value, options) {\n    options = options || {};\n    return JSON.parse(stringify(value, options));\n}\nfunction EJSONdeserialize(ejson, options) {\n    options = options || {};\n    return parse(JSON.stringify(ejson), options);\n}\nconst EJSON = Object.create(null);\nEJSON.parse = parse;\nEJSON.stringify = stringify;\nEJSON.serialize = EJSONserialize;\nEJSON.deserialize = EJSONdeserialize;\nObject.freeze(EJSON);\n\nconst MAXSIZE = 1024 * 1024 * 17;\nlet buffer = ByteUtils.allocate(MAXSIZE);\nfunction setInternalBufferSize(size) {\n    if (buffer.length < size) {\n        buffer = ByteUtils.allocate(size);\n    }\n}\nfunction serialize(object, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const minInternalBufferSize = typeof options.minInternalBufferSize === 'number' ? options.minInternalBufferSize : MAXSIZE;\n    if (buffer.length < minInternalBufferSize) {\n        buffer = ByteUtils.allocate(minInternalBufferSize);\n    }\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    const finishedBuffer = ByteUtils.allocate(serializationIndex);\n    finishedBuffer.set(buffer.subarray(0, serializationIndex), 0);\n    return finishedBuffer;\n}\nfunction serializeWithBufferAndIndex(object, finalBuffer, options = {}) {\n    const checkKeys = typeof options.checkKeys === 'boolean' ? options.checkKeys : false;\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    const startIndex = typeof options.index === 'number' ? options.index : 0;\n    const serializationIndex = serializeInto(buffer, object, checkKeys, 0, 0, serializeFunctions, ignoreUndefined, null);\n    finalBuffer.set(buffer.subarray(0, serializationIndex), startIndex);\n    return startIndex + serializationIndex - 1;\n}\nfunction deserialize(buffer, options = {}) {\n    return internalDeserialize(ByteUtils.toLocalBufferType(buffer), options);\n}\nfunction calculateObjectSize(object, options = {}) {\n    options = options || {};\n    const serializeFunctions = typeof options.serializeFunctions === 'boolean' ? options.serializeFunctions : false;\n    const ignoreUndefined = typeof options.ignoreUndefined === 'boolean' ? options.ignoreUndefined : true;\n    return internalCalculateObjectSize(object, serializeFunctions, ignoreUndefined);\n}\nfunction deserializeStream(data, startIndex, numberOfDocuments, documents, docStartIndex, options) {\n    const internalOptions = Object.assign({ allowObjectSmallerThanBufferSize: true, index: 0 }, options);\n    const bufferData = ByteUtils.toLocalBufferType(data);\n    let index = startIndex;\n    for (let i = 0; i < numberOfDocuments; i++) {\n        const size = bufferData[index] |\n            (bufferData[index + 1] << 8) |\n            (bufferData[index + 2] << 16) |\n            (bufferData[index + 3] << 24);\n        internalOptions.index = index;\n        documents[docStartIndex + i] = internalDeserialize(bufferData, internalOptions);\n        index = index + size;\n    }\n    return index;\n}\n\nvar bson = /*#__PURE__*/Object.freeze({\n    __proto__: null,\n    BSONError: BSONError,\n    BSONRegExp: BSONRegExp,\n    BSONRuntimeError: BSONRuntimeError,\n    BSONSymbol: BSONSymbol,\n    BSONType: BSONType,\n    BSONValue: BSONValue,\n    BSONVersionError: BSONVersionError,\n    Binary: Binary,\n    Code: Code,\n    DBRef: DBRef,\n    Decimal128: Decimal128,\n    Double: Double,\n    EJSON: EJSON,\n    Int32: Int32,\n    Long: Long,\n    MaxKey: MaxKey,\n    MinKey: MinKey,\n    ObjectId: ObjectId,\n    Timestamp: Timestamp,\n    UUID: UUID,\n    calculateObjectSize: calculateObjectSize,\n    deserialize: deserialize,\n    deserializeStream: deserializeStream,\n    serialize: serialize,\n    serializeWithBufferAndIndex: serializeWithBufferAndIndex,\n    setInternalBufferSize: setInternalBufferSize\n});\n\nexports.BSON = bson;\nexports.BSONError = BSONError;\nexports.BSONRegExp = BSONRegExp;\nexports.BSONRuntimeError = BSONRuntimeError;\nexports.BSONSymbol = BSONSymbol;\nexports.BSONType = BSONType;\nexports.BSONValue = BSONValue;\nexports.BSONVersionError = BSONVersionError;\nexports.Binary = Binary;\nexports.Code = Code;\nexports.DBRef = DBRef;\nexports.Decimal128 = Decimal128;\nexports.Double = Double;\nexports.EJSON = EJSON;\nexports.Int32 = Int32;\nexports.Long = Long;\nexports.MaxKey = MaxKey;\nexports.MinKey = MinKey;\nexports.ObjectId = ObjectId;\nexports.Timestamp = Timestamp;\nexports.UUID = UUID;\nexports.calculateObjectSize = calculateObjectSize;\nexports.deserialize = deserialize;\nexports.deserializeStream = deserializeStream;\nexports.serialize = serialize;\nexports.serializeWithBufferAndIndex = serializeWithBufferAndIndex;\nexports.setInternalBufferSize = setInternalBufferSize;\n//# sourceMappingURL=bson.cjs.map\n\n\n//# sourceURL=webpack://oracle2/./node_modules/bson/lib/bson.cjs?");

/***/ }),

/***/ "../../node_modules/available-typed-arrays/index.js":
/*!**********************************************************!*\
  !*** ../../node_modules/available-typed-arrays/index.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar possibleNames = [\n\t'BigInt64Array',\n\t'BigUint64Array',\n\t'Float32Array',\n\t'Float64Array',\n\t'Int16Array',\n\t'Int32Array',\n\t'Int8Array',\n\t'Uint16Array',\n\t'Uint32Array',\n\t'Uint8Array',\n\t'Uint8ClampedArray'\n];\n\nvar g = typeof globalThis === 'undefined' ? __webpack_require__.g : globalThis;\n\nmodule.exports = function availableTypedArrays() {\n\tvar out = [];\n\tfor (var i = 0; i < possibleNames.length; i++) {\n\t\tif (typeof g[possibleNames[i]] === 'function') {\n\t\t\tout[out.length] = possibleNames[i];\n\t\t}\n\t}\n\treturn out;\n};\n\n\n//# sourceURL=webpack://oracle2/../../node_modules/available-typed-arrays/index.js?");

/***/ }),

/***/ "./node_modules/dotenv/package.json":
/*!******************************************!*\
  !*** ./node_modules/dotenv/package.json ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('{\"name\":\"dotenv\",\"version\":\"16.3.1\",\"description\":\"Loads environment variables from .env file\",\"main\":\"lib/main.js\",\"types\":\"lib/main.d.ts\",\"exports\":{\".\":{\"types\":\"./lib/main.d.ts\",\"require\":\"./lib/main.js\",\"default\":\"./lib/main.js\"},\"./config\":\"./config.js\",\"./config.js\":\"./config.js\",\"./lib/env-options\":\"./lib/env-options.js\",\"./lib/env-options.js\":\"./lib/env-options.js\",\"./lib/cli-options\":\"./lib/cli-options.js\",\"./lib/cli-options.js\":\"./lib/cli-options.js\",\"./package.json\":\"./package.json\"},\"scripts\":{\"dts-check\":\"tsc --project tests/types/tsconfig.json\",\"lint\":\"standard\",\"lint-readme\":\"standard-markdown\",\"pretest\":\"npm run lint && npm run dts-check\",\"test\":\"tap tests/*.js --100 -Rspec\",\"prerelease\":\"npm test\",\"release\":\"standard-version\"},\"repository\":{\"type\":\"git\",\"url\":\"git://github.com/motdotla/dotenv.git\"},\"funding\":\"https://github.com/motdotla/dotenv?sponsor=1\",\"keywords\":[\"dotenv\",\"env\",\".env\",\"environment\",\"variables\",\"config\",\"settings\"],\"readmeFilename\":\"README.md\",\"license\":\"BSD-2-Clause\",\"devDependencies\":{\"@definitelytyped/dtslint\":\"^0.0.133\",\"@types/node\":\"^18.11.3\",\"decache\":\"^4.6.1\",\"sinon\":\"^14.0.1\",\"standard\":\"^17.0.0\",\"standard-markdown\":\"^7.1.0\",\"standard-version\":\"^9.5.0\",\"tap\":\"^16.3.0\",\"tar\":\"^6.1.11\",\"typescript\":\"^4.8.4\"},\"engines\":{\"node\":\">=12\"},\"browser\":{\"fs\":false}}');\n\n//# sourceURL=webpack://oracle2/./node_modules/dotenv/package.json?");

/***/ }),

/***/ "./node_modules/mongodb/package.json":
/*!*******************************************!*\
  !*** ./node_modules/mongodb/package.json ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('{\"name\":\"mongodb\",\"version\":\"6.3.0\",\"description\":\"The official MongoDB driver for Node.js\",\"main\":\"lib/index.js\",\"files\":[\"lib\",\"src\",\"etc/prepare.js\",\"mongodb.d.ts\",\"tsconfig.json\"],\"types\":\"mongodb.d.ts\",\"repository\":{\"type\":\"git\",\"url\":\"git@github.com:mongodb/node-mongodb-native.git\"},\"keywords\":[\"mongodb\",\"driver\",\"official\"],\"author\":{\"name\":\"The MongoDB NodeJS Team\",\"email\":\"dbx-node@mongodb.com\"},\"dependencies\":{\"@mongodb-js/saslprep\":\"^1.1.0\",\"bson\":\"^6.2.0\",\"mongodb-connection-string-url\":\"^3.0.0\"},\"peerDependencies\":{\"@aws-sdk/credential-providers\":\"^3.188.0\",\"@mongodb-js/zstd\":\"^1.1.0\",\"gcp-metadata\":\"^5.2.0\",\"kerberos\":\"^2.0.1\",\"mongodb-client-encryption\":\">=6.0.0 <7\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.7.1\"},\"peerDependenciesMeta\":{\"@aws-sdk/credential-providers\":{\"optional\":true},\"@mongodb-js/zstd\":{\"optional\":true},\"kerberos\":{\"optional\":true},\"snappy\":{\"optional\":true},\"mongodb-client-encryption\":{\"optional\":true},\"gcp-metadata\":{\"optional\":true},\"socks\":{\"optional\":true}},\"devDependencies\":{\"@iarna/toml\":\"^2.2.5\",\"@istanbuljs/nyc-config-typescript\":\"^1.0.2\",\"@microsoft/api-extractor\":\"^7.36.4\",\"@microsoft/tsdoc-config\":\"^0.16.2\",\"@mongodb-js/zstd\":\"^1.1.0\",\"@octokit/core\":\"^4.2.4\",\"@types/chai\":\"^4.3.5\",\"@types/chai-subset\":\"^1.3.3\",\"@types/express\":\"^4.17.17\",\"@types/kerberos\":\"^1.1.2\",\"@types/mocha\":\"^10.0.1\",\"@types/node\":\"^20.5.9\",\"@types/saslprep\":\"^1.0.1\",\"@types/semver\":\"^7.5.0\",\"@types/sinon\":\"^10.0.16\",\"@types/sinon-chai\":\"^3.2.9\",\"@types/whatwg-url\":\"^11.0.0\",\"@typescript-eslint/eslint-plugin\":\"^5.62.0\",\"@typescript-eslint/parser\":\"^5.62.0\",\"chai\":\"^4.3.7\",\"chai-subset\":\"^1.6.0\",\"chalk\":\"^4.1.2\",\"eslint\":\"^8.48.0\",\"eslint-config-prettier\":\"^8.10.0\",\"eslint-plugin-import\":\"^2.28.1\",\"eslint-plugin-prettier\":\"^4.2.1\",\"eslint-plugin-simple-import-sort\":\"^10.0.0\",\"eslint-plugin-tsdoc\":\"^0.2.17\",\"eslint-plugin-unused-imports\":\"^2.0.0\",\"express\":\"^4.18.2\",\"gcp-metadata\":\"^5.2.0\",\"js-yaml\":\"^4.1.0\",\"mocha\":\"^10.2.0\",\"mocha-sinon\":\"^2.1.2\",\"mongodb-client-encryption\":\"^6.0.0\",\"mongodb-legacy\":\"^6.0.0\",\"nyc\":\"^15.1.0\",\"prettier\":\"^2.8.8\",\"semver\":\"^7.5.4\",\"sinon\":\"^15.2.0\",\"sinon-chai\":\"^3.7.0\",\"snappy\":\"^7.2.2\",\"socks\":\"^2.7.1\",\"source-map-support\":\"^0.5.21\",\"ts-node\":\"^10.9.1\",\"tsd\":\"^0.28.1\",\"typescript\":\"^5.0.4\",\"typescript-cached-transpile\":\"^0.0.6\",\"v8-heapsnapshot\":\"^1.3.1\",\"yargs\":\"^17.7.2\"},\"license\":\"Apache-2.0\",\"engines\":{\"node\":\">=16.20.1\"},\"bugs\":{\"url\":\"https://jira.mongodb.org/projects/NODE/issues/\"},\"homepage\":\"https://github.com/mongodb/node-mongodb-native\",\"scripts\":{\"build:evergreen\":\"node .evergreen/generate_evergreen_tasks.js\",\"build:ts\":\"node ./node_modules/typescript/bin/tsc\",\"build:dts\":\"npm run build:ts && api-extractor run && node etc/clean_definition_files.cjs && eslint mongodb.d.ts --fix\",\"build:docs\":\"./etc/docs/build.ts\",\"build:typedoc\":\"typedoc\",\"build:nightly\":\"node ./.github/scripts/nightly.mjs\",\"check:bench\":\"node test/benchmarks/driverBench\",\"check:coverage\":\"nyc npm run test:all\",\"check:integration-coverage\":\"nyc npm run check:test\",\"check:lambda\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/handler.test.js\",\"check:lambda:aws\":\"mocha --config test/mocha_lambda.json test/integration/node-specific/examples/aws_handler.test.js\",\"check:lint\":\"npm run build:dts && npm run check:dts && npm run check:eslint && npm run check:tsd\",\"check:eslint\":\"eslint -v && eslint --max-warnings=0 --ext \\'.js,.ts\\' src test\",\"check:tsd\":\"tsd --version && tsd\",\"check:dependencies\":\"mocha test/action/dependency.test.ts\",\"check:dts\":\"node ./node_modules/typescript/bin/tsc --noEmit mongodb.d.ts && tsd\",\"check:search-indexes\":\"nyc mocha --config test/mocha_mongodb.json test/manual/search-index-management.prose.test.ts\",\"check:test\":\"mocha --config test/mocha_mongodb.json test/integration\",\"check:unit\":\"mocha test/unit\",\"check:ts\":\"node ./node_modules/typescript/bin/tsc -v && node ./node_modules/typescript/bin/tsc --noEmit\",\"check:atlas\":\"mocha --config test/manual/mocharc.json test/manual/atlas_connectivity.test.js\",\"check:drivers-atlas-testing\":\"mocha --config test/mocha_mongodb.json test/atlas/drivers_atlas_testing.test.ts\",\"check:adl\":\"mocha --config test/mocha_mongodb.json test/manual/atlas-data-lake-testing\",\"check:aws\":\"nyc mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_aws.test.ts\",\"check:oidc\":\"mocha --config test/mocha_mongodb.json test/manual/mongodb_oidc.prose.test.ts\",\"check:oidc-azure\":\"mocha --config test/mocha_mongodb.json test/integration/auth/mongodb_oidc_azure.prose.test.ts\",\"check:ocsp\":\"mocha --config test/manual/mocharc.json test/manual/ocsp_support.test.js\",\"check:kerberos\":\"nyc mocha --config test/manual/mocharc.json test/manual/kerberos.test.ts\",\"check:tls\":\"mocha --config test/manual/mocharc.json test/manual/tls_support.test.ts\",\"check:ldap\":\"nyc mocha --config test/manual/mocharc.json test/manual/ldap.test.js\",\"check:socks5\":\"mocha --config test/manual/mocharc.json test/manual/socks5.test.ts\",\"check:csfle\":\"mocha --config test/mocha_mongodb.json test/integration/client-side-encryption\",\"check:snappy\":\"mocha test/unit/assorted/snappy.test.js\",\"fix:eslint\":\"npm run check:eslint -- --fix\",\"prepare\":\"node etc/prepare.js\",\"preview:docs\":\"ts-node etc/docs/preview.ts\",\"test\":\"npm run check:lint && npm run test:all\",\"test:all\":\"npm run check:unit && npm run check:test\",\"update:docs\":\"npm run build:docs -- --yes\"},\"tsd\":{\"directory\":\"test/types\",\"compilerOptions\":{\"strict\":true,\"target\":\"esnext\",\"module\":\"commonjs\",\"moduleResolution\":\"node\"}}}');\n\n//# sourceURL=webpack://oracle2/./node_modules/mongodb/package.json?");

/***/ }),

/***/ "./node_modules/tr46/lib/mappingTable.json":
/*!*************************************************!*\
  !*** ./node_modules/tr46/lib/mappingTable.json ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = JSON.parse('[[[0,44],4],[[45,46],2],[47,4],[[48,57],2],[[58,64],4],[65,1,\"a\"],[66,1,\"b\"],[67,1,\"c\"],[68,1,\"d\"],[69,1,\"e\"],[70,1,\"f\"],[71,1,\"g\"],[72,1,\"h\"],[73,1,\"i\"],[74,1,\"j\"],[75,1,\"k\"],[76,1,\"l\"],[77,1,\"m\"],[78,1,\"n\"],[79,1,\"o\"],[80,1,\"p\"],[81,1,\"q\"],[82,1,\"r\"],[83,1,\"s\"],[84,1,\"t\"],[85,1,\"u\"],[86,1,\"v\"],[87,1,\"w\"],[88,1,\"x\"],[89,1,\"y\"],[90,1,\"z\"],[[91,96],4],[[97,122],2],[[123,127],4],[[128,159],3],[160,5,\" \"],[[161,167],2],[168,5,\" \"],[169,2],[170,1,\"a\"],[[171,172],2],[173,7],[174,2],[175,5,\" \"],[[176,177],2],[178,1,\"2\"],[179,1,\"3\"],[180,5,\" \"],[181,1,\"\"],[182,2],[183,2],[184,5,\" \"],[185,1,\"1\"],[186,1,\"o\"],[187,2],[188,1,\"14\"],[189,1,\"12\"],[190,1,\"34\"],[191,2],[192,1,\"\"],[193,1,\"\"],[194,1,\"\"],[195,1,\"\"],[196,1,\"\"],[197,1,\"\"],[198,1,\"\"],[199,1,\"\"],[200,1,\"\"],[201,1,\"\"],[202,1,\"\"],[203,1,\"\"],[204,1,\"\"],[205,1,\"\"],[206,1,\"\"],[207,1,\"\"],[208,1,\"\"],[209,1,\"\"],[210,1,\"\"],[211,1,\"\"],[212,1,\"\"],[213,1,\"\"],[214,1,\"\"],[215,2],[216,1,\"\"],[217,1,\"\"],[218,1,\"\"],[219,1,\"\"],[220,1,\"\"],[221,1,\"\"],[222,1,\"\"],[223,6,\"ss\"],[[224,246],2],[247,2],[[248,255],2],[256,1,\"\"],[257,2],[258,1,\"\"],[259,2],[260,1,\"\"],[261,2],[262,1,\"\"],[263,2],[264,1,\"\"],[265,2],[266,1,\"\"],[267,2],[268,1,\"\"],[269,2],[270,1,\"\"],[271,2],[272,1,\"\"],[273,2],[274,1,\"\"],[275,2],[276,1,\"\"],[277,2],[278,1,\"\"],[279,2],[280,1,\"\"],[281,2],[282,1,\"\"],[283,2],[284,1,\"\"],[285,2],[286,1,\"\"],[287,2],[288,1,\"\"],[289,2],[290,1,\"\"],[291,2],[292,1,\"\"],[293,2],[294,1,\"\"],[295,2],[296,1,\"\"],[297,2],[298,1,\"\"],[299,2],[300,1,\"\"],[301,2],[302,1,\"\"],[303,2],[304,1,\"i\"],[305,2],[[306,307],1,\"ij\"],[308,1,\"\"],[309,2],[310,1,\"\"],[[311,312],2],[313,1,\"\"],[314,2],[315,1,\"\"],[316,2],[317,1,\"\"],[318,2],[[319,320],1,\"l\"],[321,1,\"\"],[322,2],[323,1,\"\"],[324,2],[325,1,\"\"],[326,2],[327,1,\"\"],[328,2],[329,1,\"n\"],[330,1,\"\"],[331,2],[332,1,\"\"],[333,2],[334,1,\"\"],[335,2],[336,1,\"\"],[337,2],[338,1,\"\"],[339,2],[340,1,\"\"],[341,2],[342,1,\"\"],[343,2],[344,1,\"\"],[345,2],[346,1,\"\"],[347,2],[348,1,\"\"],[349,2],[350,1,\"\"],[351,2],[352,1,\"\"],[353,2],[354,1,\"\"],[355,2],[356,1,\"\"],[357,2],[358,1,\"\"],[359,2],[360,1,\"\"],[361,2],[362,1,\"\"],[363,2],[364,1,\"\"],[365,2],[366,1,\"\"],[367,2],[368,1,\"\"],[369,2],[370,1,\"\"],[371,2],[372,1,\"\"],[373,2],[374,1,\"\"],[375,2],[376,1,\"\"],[377,1,\"\"],[378,2],[379,1,\"\"],[380,2],[381,1,\"\"],[382,2],[383,1,\"s\"],[384,2],[385,1,\"\"],[386,1,\"\"],[387,2],[388,1,\"\"],[389,2],[390,1,\"\"],[391,1,\"\"],[392,2],[393,1,\"\"],[394,1,\"\"],[395,1,\"\"],[[396,397],2],[398,1,\"\"],[399,1,\"\"],[400,1,\"\"],[401,1,\"\"],[402,2],[403,1,\"\"],[404,1,\"\"],[405,2],[406,1,\"\"],[407,1,\"\"],[408,1,\"\"],[[409,411],2],[412,1,\"\"],[413,1,\"\"],[414,2],[415,1,\"\"],[416,1,\"\"],[417,2],[418,1,\"\"],[419,2],[420,1,\"\"],[421,2],[422,1,\"\"],[423,1,\"\"],[424,2],[425,1,\"\"],[[426,427],2],[428,1,\"\"],[429,2],[430,1,\"\"],[431,1,\"\"],[432,2],[433,1,\"\"],[434,1,\"\"],[435,1,\"\"],[436,2],[437,1,\"\"],[438,2],[439,1,\"\"],[440,1,\"\"],[[441,443],2],[444,1,\"\"],[[445,451],2],[[452,454],1,\"d\"],[[455,457],1,\"lj\"],[[458,460],1,\"nj\"],[461,1,\"\"],[462,2],[463,1,\"\"],[464,2],[465,1,\"\"],[466,2],[467,1,\"\"],[468,2],[469,1,\"\"],[470,2],[471,1,\"\"],[472,2],[473,1,\"\"],[474,2],[475,1,\"\"],[[476,477],2],[478,1,\"\"],[479,2],[480,1,\"\"],[481,2],[482,1,\"\"],[483,2],[484,1,\"\"],[485,2],[486,1,\"\"],[487,2],[488,1,\"\"],[489,2],[490,1,\"\"],[491,2],[492,1,\"\"],[493,2],[494,1,\"\"],[[495,496],2],[[497,499],1,\"dz\"],[500,1,\"\"],[501,2],[502,1,\"\"],[503,1,\"\"],[504,1,\"\"],[505,2],[506,1,\"\"],[507,2],[508,1,\"\"],[509,2],[510,1,\"\"],[511,2],[512,1,\"\"],[513,2],[514,1,\"\"],[515,2],[516,1,\"\"],[517,2],[518,1,\"\"],[519,2],[520,1,\"\"],[521,2],[522,1,\"\"],[523,2],[524,1,\"\"],[525,2],[526,1,\"\"],[527,2],[528,1,\"\"],[529,2],[530,1,\"\"],[531,2],[532,1,\"\"],[533,2],[534,1,\"\"],[535,2],[536,1,\"\"],[537,2],[538,1,\"\"],[539,2],[540,1,\"\"],[541,2],[542,1,\"\"],[543,2],[544,1,\"\"],[545,2],[546,1,\"\"],[547,2],[548,1,\"\"],[549,2],[550,1,\"\"],[551,2],[552,1,\"\"],[553,2],[554,1,\"\"],[555,2],[556,1,\"\"],[557,2],[558,1,\"\"],[559,2],[560,1,\"\"],[561,2],[562,1,\"\"],[563,2],[[564,566],2],[[567,569],2],[570,1,\"\"],[571,1,\"\"],[572,2],[573,1,\"\"],[574,1,\"\"],[[575,576],2],[577,1,\"\"],[578,2],[579,1,\"\"],[580,1,\"\"],[581,1,\"\"],[582,1,\"\"],[583,2],[584,1,\"\"],[585,2],[586,1,\"\"],[587,2],[588,1,\"\"],[589,2],[590,1,\"\"],[591,2],[[592,680],2],[[681,685],2],[[686,687],2],[688,1,\"h\"],[689,1,\"\"],[690,1,\"j\"],[691,1,\"r\"],[692,1,\"\"],[693,1,\"\"],[694,1,\"\"],[695,1,\"w\"],[696,1,\"y\"],[[697,705],2],[[706,709],2],[[710,721],2],[[722,727],2],[728,5,\" \"],[729,5,\" \"],[730,5,\" \"],[731,5,\" \"],[732,5,\" \"],[733,5,\" \"],[734,2],[735,2],[736,1,\"\"],[737,1,\"l\"],[738,1,\"s\"],[739,1,\"x\"],[740,1,\"\"],[[741,745],2],[[746,747],2],[748,2],[749,2],[750,2],[[751,767],2],[[768,831],2],[832,1,\"\"],[833,1,\"\"],[834,2],[835,1,\"\"],[836,1,\"\"],[837,1,\"\"],[[838,846],2],[847,7],[[848,855],2],[[856,860],2],[[861,863],2],[[864,865],2],[866,2],[[867,879],2],[880,1,\"\"],[881,2],[882,1,\"\"],[883,2],[884,1,\"\"],[885,2],[886,1,\"\"],[887,2],[[888,889],3],[890,5,\" \"],[[891,893],2],[894,5,\";\"],[895,1,\"\"],[[896,899],3],[900,5,\" \"],[901,5,\" \"],[902,1,\"\"],[903,1,\"\"],[904,1,\"\"],[905,1,\"\"],[906,1,\"\"],[907,3],[908,1,\"\"],[909,3],[910,1,\"\"],[911,1,\"\"],[912,2],[913,1,\"\"],[914,1,\"\"],[915,1,\"\"],[916,1,\"\"],[917,1,\"\"],[918,1,\"\"],[919,1,\"\"],[920,1,\"\"],[921,1,\"\"],[922,1,\"\"],[923,1,\"\"],[924,1,\"\"],[925,1,\"\"],[926,1,\"\"],[927,1,\"\"],[928,1,\"\"],[929,1,\"\"],[930,3],[931,1,\"\"],[932,1,\"\"],[933,1,\"\"],[934,1,\"\"],[935,1,\"\"],[936,1,\"\"],[937,1,\"\"],[938,1,\"\"],[939,1,\"\"],[[940,961],2],[962,6,\"\"],[[963,974],2],[975,1,\"\"],[976,1,\"\"],[977,1,\"\"],[978,1,\"\"],[979,1,\"\"],[980,1,\"\"],[981,1,\"\"],[982,1,\"\"],[983,2],[984,1,\"\"],[985,2],[986,1,\"\"],[987,2],[988,1,\"\"],[989,2],[990,1,\"\"],[991,2],[992,1,\"\"],[993,2],[994,1,\"\"],[995,2],[996,1,\"\"],[997,2],[998,1,\"\"],[999,2],[1000,1,\"\"],[1001,2],[1002,1,\"\"],[1003,2],[1004,1,\"\"],[1005,2],[1006,1,\"\"],[1007,2],[1008,1,\"\"],[1009,1,\"\"],[1010,1,\"\"],[1011,2],[1012,1,\"\"],[1013,1,\"\"],[1014,2],[1015,1,\"\"],[1016,2],[1017,1,\"\"],[1018,1,\"\"],[1019,2],[1020,2],[1021,1,\"\"],[1022,1,\"\"],[1023,1,\"\"],[1024,1,\"\"],[1025,1,\"\"],[1026,1,\"\"],[1027,1,\"\"],[1028,1,\"\"],[1029,1,\"\"],[1030,1,\"\"],[1031,1,\"\"],[1032,1,\"\"],[1033,1,\"\"],[1034,1,\"\"],[1035,1,\"\"],[1036,1,\"\"],[1037,1,\"\"],[1038,1,\"\"],[1039,1,\"\"],[1040,1,\"\"],[1041,1,\"\"],[1042,1,\"\"],[1043,1,\"\"],[1044,1,\"\"],[1045,1,\"\"],[1046,1,\"\"],[1047,1,\"\"],[1048,1,\"\"],[1049,1,\"\"],[1050,1,\"\"],[1051,1,\"\"],[1052,1,\"\"],[1053,1,\"\"],[1054,1,\"\"],[1055,1,\"\"],[1056,1,\"\"],[1057,1,\"\"],[1058,1,\"\"],[1059,1,\"\"],[1060,1,\"\"],[1061,1,\"\"],[1062,1,\"\"],[1063,1,\"\"],[1064,1,\"\"],[1065,1,\"\"],[1066,1,\"\"],[1067,1,\"\"],[1068,1,\"\"],[1069,1,\"\"],[1070,1,\"\"],[1071,1,\"\"],[[1072,1103],2],[1104,2],[[1105,1116],2],[1117,2],[[1118,1119],2],[1120,1,\"\"],[1121,2],[1122,1,\"\"],[1123,2],[1124,1,\"\"],[1125,2],[1126,1,\"\"],[1127,2],[1128,1,\"\"],[1129,2],[1130,1,\"\"],[1131,2],[1132,1,\"\"],[1133,2],[1134,1,\"\"],[1135,2],[1136,1,\"\"],[1137,2],[1138,1,\"\"],[1139,2],[1140,1,\"\"],[1141,2],[1142,1,\"\"],[1143,2],[1144,1,\"\"],[1145,2],[1146,1,\"\"],[1147,2],[1148,1,\"\"],[1149,2],[1150,1,\"\"],[1151,2],[1152,1,\"\"],[1153,2],[1154,2],[[1155,1158],2],[1159,2],[[1160,1161],2],[1162,1,\"\"],[1163,2],[1164,1,\"\"],[1165,2],[1166,1,\"\"],[1167,2],[1168,1,\"\"],[1169,2],[1170,1,\"\"],[1171,2],[1172,1,\"\"],[1173,2],[1174,1,\"\"],[1175,2],[1176,1,\"\"],[1177,2],[1178,1,\"\"],[1179,2],[1180,1,\"\"],[1181,2],[1182,1,\"\"],[1183,2],[1184,1,\"\"],[1185,2],[1186,1,\"\"],[1187,2],[1188,1,\"\"],[1189,2],[1190,1,\"\"],[1191,2],[1192,1,\"\"],[1193,2],[1194,1,\"\"],[1195,2],[1196,1,\"\"],[1197,2],[1198,1,\"\"],[1199,2],[1200,1,\"\"],[1201,2],[1202,1,\"\"],[1203,2],[1204,1,\"\"],[1205,2],[1206,1,\"\"],[1207,2],[1208,1,\"\"],[1209,2],[1210,1,\"\"],[1211,2],[1212,1,\"\"],[1213,2],[1214,1,\"\"],[1215,2],[1216,3],[1217,1,\"\"],[1218,2],[1219,1,\"\"],[1220,2],[1221,1,\"\"],[1222,2],[1223,1,\"\"],[1224,2],[1225,1,\"\"],[1226,2],[1227,1,\"\"],[1228,2],[1229,1,\"\"],[1230,2],[1231,2],[1232,1,\"\"],[1233,2],[1234,1,\"\"],[1235,2],[1236,1,\"\"],[1237,2],[1238,1,\"\"],[1239,2],[1240,1,\"\"],[1241,2],[1242,1,\"\"],[1243,2],[1244,1,\"\"],[1245,2],[1246,1,\"\"],[1247,2],[1248,1,\"\"],[1249,2],[1250,1,\"\"],[1251,2],[1252,1,\"\"],[1253,2],[1254,1,\"\"],[1255,2],[1256,1,\"\"],[1257,2],[1258,1,\"\"],[1259,2],[1260,1,\"\"],[1261,2],[1262,1,\"\"],[1263,2],[1264,1,\"\"],[1265,2],[1266,1,\"\"],[1267,2],[1268,1,\"\"],[1269,2],[1270,1,\"\"],[1271,2],[1272,1,\"\"],[1273,2],[1274,1,\"\"],[1275,2],[1276,1,\"\"],[1277,2],[1278,1,\"\"],[1279,2],[1280,1,\"\"],[1281,2],[1282,1,\"\"],[1283,2],[1284,1,\"\"],[1285,2],[1286,1,\"\"],[1287,2],[1288,1,\"\"],[1289,2],[1290,1,\"\"],[1291,2],[1292,1,\"\"],[1293,2],[1294,1,\"\"],[1295,2],[1296,1,\"\"],[1297,2],[1298,1,\"\"],[1299,2],[1300,1,\"\"],[1301,2],[1302,1,\"\"],[1303,2],[1304,1,\"\"],[1305,2],[1306,1,\"\"],[1307,2],[1308,1,\"\"],[1309,2],[1310,1,\"\"],[1311,2],[1312,1,\"\"],[1313,2],[1314,1,\"\"],[1315,2],[1316,1,\"\"],[1317,2],[1318,1,\"\"],[1319,2],[1320,1,\"\"],[1321,2],[1322,1,\"\"],[1323,2],[1324,1,\"\"],[1325,2],[1326,1,\"\"],[1327,2],[1328,3],[1329,1,\"\"],[1330,1,\"\"],[1331,1,\"\"],[1332,1,\"\"],[1333,1,\"\"],[1334,1,\"\"],[1335,1,\"\"],[1336,1,\"\"],[1337,1,\"\"],[1338,1,\"\"],[1339,1,\"\"],[1340,1,\"\"],[1341,1,\"\"],[1342,1,\"\"],[1343,1,\"\"],[1344,1,\"\"],[1345,1,\"\"],[1346,1,\"\"],[1347,1,\"\"],[1348,1,\"\"],[1349,1,\"\"],[1350,1,\"\"],[1351,1,\"\"],[1352,1,\"\"],[1353,1,\"\"],[1354,1,\"\"],[1355,1,\"\"],[1356,1,\"\"],[1357,1,\"\"],[1358,1,\"\"],[1359,1,\"\"],[1360,1,\"\"],[1361,1,\"\"],[1362,1,\"\"],[1363,1,\"\"],[1364,1,\"\"],[1365,1,\"\"],[1366,1,\"\"],[[1367,1368],3],[1369,2],[[1370,1375],2],[1376,2],[[1377,1414],2],[1415,1,\"\"],[1416,2],[1417,2],[1418,2],[[1419,1420],3],[[1421,1422],2],[1423,2],[1424,3],[[1425,1441],2],[1442,2],[[1443,1455],2],[[1456,1465],2],[1466,2],[[1467,1469],2],[1470,2],[1471,2],[1472,2],[[1473,1474],2],[1475,2],[1476,2],[1477,2],[1478,2],[1479,2],[[1480,1487],3],[[1488,1514],2],[[1515,1518],3],[1519,2],[[1520,1524],2],[[1525,1535],3],[[1536,1539],3],[1540,3],[1541,3],[[1542,1546],2],[1547,2],[1548,2],[[1549,1551],2],[[1552,1557],2],[[1558,1562],2],[1563,2],[1564,3],[1565,2],[1566,2],[1567,2],[1568,2],[[1569,1594],2],[[1595,1599],2],[1600,2],[[1601,1618],2],[[1619,1621],2],[[1622,1624],2],[[1625,1630],2],[1631,2],[[1632,1641],2],[[1642,1645],2],[[1646,1647],2],[[1648,1652],2],[1653,1,\"\"],[1654,1,\"\"],[1655,1,\"\"],[1656,1,\"\"],[[1657,1719],2],[[1720,1721],2],[[1722,1726],2],[1727,2],[[1728,1742],2],[1743,2],[[1744,1747],2],[1748,2],[[1749,1756],2],[1757,3],[1758,2],[[1759,1768],2],[1769,2],[[1770,1773],2],[[1774,1775],2],[[1776,1785],2],[[1786,1790],2],[1791,2],[[1792,1805],2],[1806,3],[1807,3],[[1808,1836],2],[[1837,1839],2],[[1840,1866],2],[[1867,1868],3],[[1869,1871],2],[[1872,1901],2],[[1902,1919],2],[[1920,1968],2],[1969,2],[[1970,1983],3],[[1984,2037],2],[[2038,2042],2],[[2043,2044],3],[2045,2],[[2046,2047],2],[[2048,2093],2],[[2094,2095],3],[[2096,2110],2],[2111,3],[[2112,2139],2],[[2140,2141],3],[2142,2],[2143,3],[[2144,2154],2],[[2155,2159],3],[[2160,2183],2],[2184,2],[[2185,2190],2],[2191,3],[[2192,2193],3],[[2194,2199],3],[[2200,2207],2],[2208,2],[2209,2],[[2210,2220],2],[[2221,2226],2],[[2227,2228],2],[2229,2],[[2230,2237],2],[[2238,2247],2],[[2248,2258],2],[2259,2],[[2260,2273],2],[2274,3],[2275,2],[[2276,2302],2],[2303,2],[2304,2],[[2305,2307],2],[2308,2],[[2309,2361],2],[[2362,2363],2],[[2364,2381],2],[2382,2],[2383,2],[[2384,2388],2],[2389,2],[[2390,2391],2],[2392,1,\"\"],[2393,1,\"\"],[2394,1,\"\"],[2395,1,\"\"],[2396,1,\"\"],[2397,1,\"\"],[2398,1,\"\"],[2399,1,\"\"],[[2400,2403],2],[[2404,2405],2],[[2406,2415],2],[2416,2],[[2417,2418],2],[[2419,2423],2],[2424,2],[[2425,2426],2],[[2427,2428],2],[2429,2],[[2430,2431],2],[2432,2],[[2433,2435],2],[2436,3],[[2437,2444],2],[[2445,2446],3],[[2447,2448],2],[[2449,2450],3],[[2451,2472],2],[2473,3],[[2474,2480],2],[2481,3],[2482,2],[[2483,2485],3],[[2486,2489],2],[[2490,2491],3],[2492,2],[2493,2],[[2494,2500],2],[[2501,2502],3],[[2503,2504],2],[[2505,2506],3],[[2507,2509],2],[2510,2],[[2511,2518],3],[2519,2],[[2520,2523],3],[2524,1,\"\"],[2525,1,\"\"],[2526,3],[2527,1,\"\"],[[2528,2531],2],[[2532,2533],3],[[2534,2545],2],[[2546,2554],2],[2555,2],[2556,2],[2557,2],[2558,2],[[2559,2560],3],[2561,2],[2562,2],[2563,2],[2564,3],[[2565,2570],2],[[2571,2574],3],[[2575,2576],2],[[2577,2578],3],[[2579,2600],2],[2601,3],[[2602,2608],2],[2609,3],[2610,2],[2611,1,\"\"],[2612,3],[2613,2],[2614,1,\"\"],[2615,3],[[2616,2617],2],[[2618,2619],3],[2620,2],[2621,3],[[2622,2626],2],[[2627,2630],3],[[2631,2632],2],[[2633,2634],3],[[2635,2637],2],[[2638,2640],3],[2641,2],[[2642,2648],3],[2649,1,\"\"],[2650,1,\"\"],[2651,1,\"\"],[2652,2],[2653,3],[2654,1,\"\"],[[2655,2661],3],[[2662,2676],2],[2677,2],[2678,2],[[2679,2688],3],[[2689,2691],2],[2692,3],[[2693,2699],2],[2700,2],[2701,2],[2702,3],[[2703,2705],2],[2706,3],[[2707,2728],2],[2729,3],[[2730,2736],2],[2737,3],[[2738,2739],2],[2740,3],[[2741,2745],2],[[2746,2747],3],[[2748,2757],2],[2758,3],[[2759,2761],2],[2762,3],[[2763,2765],2],[[2766,2767],3],[2768,2],[[2769,2783],3],[2784,2],[[2785,2787],2],[[2788,2789],3],[[2790,2799],2],[2800,2],[2801,2],[[2802,2808],3],[2809,2],[[2810,2815],2],[2816,3],[[2817,2819],2],[2820,3],[[2821,2828],2],[[2829,2830],3],[[2831,2832],2],[[2833,2834],3],[[2835,2856],2],[2857,3],[[2858,2864],2],[2865,3],[[2866,2867],2],[2868,3],[2869,2],[[2870,2873],2],[[2874,2875],3],[[2876,2883],2],[2884,2],[[2885,2886],3],[[2887,2888],2],[[2889,2890],3],[[2891,2893],2],[[2894,2900],3],[2901,2],[[2902,2903],2],[[2904,2907],3],[2908,1,\"\"],[2909,1,\"\"],[2910,3],[[2911,2913],2],[[2914,2915],2],[[2916,2917],3],[[2918,2927],2],[2928,2],[2929,2],[[2930,2935],2],[[2936,2945],3],[[2946,2947],2],[2948,3],[[2949,2954],2],[[2955,2957],3],[[2958,2960],2],[2961,3],[[2962,2965],2],[[2966,2968],3],[[2969,2970],2],[2971,3],[2972,2],[2973,3],[[2974,2975],2],[[2976,2978],3],[[2979,2980],2],[[2981,2983],3],[[2984,2986],2],[[2987,2989],3],[[2990,2997],2],[2998,2],[[2999,3001],2],[[3002,3005],3],[[3006,3010],2],[[3011,3013],3],[[3014,3016],2],[3017,3],[[3018,3021],2],[[3022,3023],3],[3024,2],[[3025,3030],3],[3031,2],[[3032,3045],3],[3046,2],[[3047,3055],2],[[3056,3058],2],[[3059,3066],2],[[3067,3071],3],[3072,2],[[3073,3075],2],[3076,2],[[3077,3084],2],[3085,3],[[3086,3088],2],[3089,3],[[3090,3112],2],[3113,3],[[3114,3123],2],[3124,2],[[3125,3129],2],[[3130,3131],3],[3132,2],[3133,2],[[3134,3140],2],[3141,3],[[3142,3144],2],[3145,3],[[3146,3149],2],[[3150,3156],3],[[3157,3158],2],[3159,3],[[3160,3161],2],[3162,2],[[3163,3164],3],[3165,2],[[3166,3167],3],[[3168,3169],2],[[3170,3171],2],[[3172,3173],3],[[3174,3183],2],[[3184,3190],3],[3191,2],[[3192,3199],2],[3200,2],[3201,2],[[3202,3203],2],[3204,2],[[3205,3212],2],[3213,3],[[3214,3216],2],[3217,3],[[3218,3240],2],[3241,3],[[3242,3251],2],[3252,3],[[3253,3257],2],[[3258,3259],3],[[3260,3261],2],[[3262,3268],2],[3269,3],[[3270,3272],2],[3273,3],[[3274,3277],2],[[3278,3284],3],[[3285,3286],2],[[3287,3292],3],[3293,2],[3294,2],[3295,3],[[3296,3297],2],[[3298,3299],2],[[3300,3301],3],[[3302,3311],2],[3312,3],[[3313,3314],2],[3315,2],[[3316,3327],3],[3328,2],[3329,2],[[3330,3331],2],[3332,2],[[3333,3340],2],[3341,3],[[3342,3344],2],[3345,3],[[3346,3368],2],[3369,2],[[3370,3385],2],[3386,2],[[3387,3388],2],[3389,2],[[3390,3395],2],[3396,2],[3397,3],[[3398,3400],2],[3401,3],[[3402,3405],2],[3406,2],[3407,2],[[3408,3411],3],[[3412,3414],2],[3415,2],[[3416,3422],2],[3423,2],[[3424,3425],2],[[3426,3427],2],[[3428,3429],3],[[3430,3439],2],[[3440,3445],2],[[3446,3448],2],[3449,2],[[3450,3455],2],[3456,3],[3457,2],[[3458,3459],2],[3460,3],[[3461,3478],2],[[3479,3481],3],[[3482,3505],2],[3506,3],[[3507,3515],2],[3516,3],[3517,2],[[3518,3519],3],[[3520,3526],2],[[3527,3529],3],[3530,2],[[3531,3534],3],[[3535,3540],2],[3541,3],[3542,2],[3543,3],[[3544,3551],2],[[3552,3557],3],[[3558,3567],2],[[3568,3569],3],[[3570,3571],2],[3572,2],[[3573,3584],3],[[3585,3634],2],[3635,1,\"\"],[[3636,3642],2],[[3643,3646],3],[3647,2],[[3648,3662],2],[3663,2],[[3664,3673],2],[[3674,3675],2],[[3676,3712],3],[[3713,3714],2],[3715,3],[3716,2],[3717,3],[3718,2],[[3719,3720],2],[3721,2],[3722,2],[3723,3],[3724,2],[3725,2],[[3726,3731],2],[[3732,3735],2],[3736,2],[[3737,3743],2],[3744,2],[[3745,3747],2],[3748,3],[3749,2],[3750,3],[3751,2],[[3752,3753],2],[[3754,3755],2],[3756,2],[[3757,3762],2],[3763,1,\"\"],[[3764,3769],2],[3770,2],[[3771,3773],2],[[3774,3775],3],[[3776,3780],2],[3781,3],[3782,2],[3783,3],[[3784,3789],2],[3790,2],[3791,3],[[3792,3801],2],[[3802,3803],3],[3804,1,\"\"],[3805,1,\"\"],[[3806,3807],2],[[3808,3839],3],[3840,2],[[3841,3850],2],[3851,2],[3852,1,\"\"],[[3853,3863],2],[[3864,3865],2],[[3866,3871],2],[[3872,3881],2],[[3882,3892],2],[3893,2],[3894,2],[3895,2],[3896,2],[3897,2],[[3898,3901],2],[[3902,3906],2],[3907,1,\"\"],[[3908,3911],2],[3912,3],[[3913,3916],2],[3917,1,\"\"],[[3918,3921],2],[3922,1,\"\"],[[3923,3926],2],[3927,1,\"\"],[[3928,3931],2],[3932,1,\"\"],[[3933,3944],2],[3945,1,\"\"],[3946,2],[[3947,3948],2],[[3949,3952],3],[[3953,3954],2],[3955,1,\"\"],[3956,2],[3957,1,\"\"],[3958,1,\"\"],[3959,1,\"\"],[3960,1,\"\"],[3961,1,\"\"],[[3962,3968],2],[3969,1,\"\"],[[3970,3972],2],[3973,2],[[3974,3979],2],[[3980,3983],2],[[3984,3986],2],[3987,1,\"\"],[[3988,3989],2],[3990,2],[3991,2],[3992,3],[[3993,3996],2],[3997,1,\"\"],[[3998,4001],2],[4002,1,\"\"],[[4003,4006],2],[4007,1,\"\"],[[4008,4011],2],[4012,1,\"\"],[4013,2],[[4014,4016],2],[[4017,4023],2],[4024,2],[4025,1,\"\"],[[4026,4028],2],[4029,3],[[4030,4037],2],[4038,2],[[4039,4044],2],[4045,3],[4046,2],[4047,2],[[4048,4049],2],[[4050,4052],2],[[4053,4056],2],[[4057,4058],2],[[4059,4095],3],[[4096,4129],2],[4130,2],[[4131,4135],2],[4136,2],[[4137,4138],2],[4139,2],[[4140,4146],2],[[4147,4149],2],[[4150,4153],2],[[4154,4159],2],[[4160,4169],2],[[4170,4175],2],[[4176,4185],2],[[4186,4249],2],[[4250,4253],2],[[4254,4255],2],[[4256,4293],3],[4294,3],[4295,1,\"\"],[[4296,4300],3],[4301,1,\"\"],[[4302,4303],3],[[4304,4342],2],[[4343,4344],2],[[4345,4346],2],[4347,2],[4348,1,\"\"],[[4349,4351],2],[[4352,4441],2],[[4442,4446],2],[[4447,4448],3],[[4449,4514],2],[[4515,4519],2],[[4520,4601],2],[[4602,4607],2],[[4608,4614],2],[4615,2],[[4616,4678],2],[4679,2],[4680,2],[4681,3],[[4682,4685],2],[[4686,4687],3],[[4688,4694],2],[4695,3],[4696,2],[4697,3],[[4698,4701],2],[[4702,4703],3],[[4704,4742],2],[4743,2],[4744,2],[4745,3],[[4746,4749],2],[[4750,4751],3],[[4752,4782],2],[4783,2],[4784,2],[4785,3],[[4786,4789],2],[[4790,4791],3],[[4792,4798],2],[4799,3],[4800,2],[4801,3],[[4802,4805],2],[[4806,4807],3],[[4808,4814],2],[4815,2],[[4816,4822],2],[4823,3],[[4824,4846],2],[4847,2],[[4848,4878],2],[4879,2],[4880,2],[4881,3],[[4882,4885],2],[[4886,4887],3],[[4888,4894],2],[4895,2],[[4896,4934],2],[4935,2],[[4936,4954],2],[[4955,4956],3],[[4957,4958],2],[4959,2],[4960,2],[[4961,4988],2],[[4989,4991],3],[[4992,5007],2],[[5008,5017],2],[[5018,5023],3],[[5024,5108],2],[5109,2],[[5110,5111],3],[5112,1,\"\"],[5113,1,\"\"],[5114,1,\"\"],[5115,1,\"\"],[5116,1,\"\"],[5117,1,\"\"],[[5118,5119],3],[5120,2],[[5121,5740],2],[[5741,5742],2],[[5743,5750],2],[[5751,5759],2],[5760,3],[[5761,5786],2],[[5787,5788],2],[[5789,5791],3],[[5792,5866],2],[[5867,5872],2],[[5873,5880],2],[[5881,5887],3],[[5888,5900],2],[5901,2],[[5902,5908],2],[5909,2],[[5910,5918],3],[5919,2],[[5920,5940],2],[[5941,5942],2],[[5943,5951],3],[[5952,5971],2],[[5972,5983],3],[[5984,5996],2],[5997,3],[[5998,6000],2],[6001,3],[[6002,6003],2],[[6004,6015],3],[[6016,6067],2],[[6068,6069],3],[[6070,6099],2],[[6100,6102],2],[6103,2],[[6104,6107],2],[6108,2],[6109,2],[[6110,6111],3],[[6112,6121],2],[[6122,6127],3],[[6128,6137],2],[[6138,6143],3],[[6144,6149],2],[6150,3],[[6151,6154],2],[[6155,6157],7],[6158,3],[6159,7],[[6160,6169],2],[[6170,6175],3],[[6176,6263],2],[6264,2],[[6265,6271],3],[[6272,6313],2],[6314,2],[[6315,6319],3],[[6320,6389],2],[[6390,6399],3],[[6400,6428],2],[[6429,6430],2],[6431,3],[[6432,6443],2],[[6444,6447],3],[[6448,6459],2],[[6460,6463],3],[6464,2],[[6465,6467],3],[[6468,6469],2],[[6470,6509],2],[[6510,6511],3],[[6512,6516],2],[[6517,6527],3],[[6528,6569],2],[[6570,6571],2],[[6572,6575],3],[[6576,6601],2],[[6602,6607],3],[[6608,6617],2],[6618,2],[[6619,6621],3],[[6622,6623],2],[[6624,6655],2],[[6656,6683],2],[[6684,6685],3],[[6686,6687],2],[[6688,6750],2],[6751,3],[[6752,6780],2],[[6781,6782],3],[[6783,6793],2],[[6794,6799],3],[[6800,6809],2],[[6810,6815],3],[[6816,6822],2],[6823,2],[[6824,6829],2],[[6830,6831],3],[[6832,6845],2],[6846,2],[[6847,6848],2],[[6849,6862],2],[[6863,6911],3],[[6912,6987],2],[6988,2],[[6989,6991],3],[[6992,7001],2],[[7002,7018],2],[[7019,7027],2],[[7028,7036],2],[[7037,7038],2],[7039,3],[[7040,7082],2],[[7083,7085],2],[[7086,7097],2],[[7098,7103],2],[[7104,7155],2],[[7156,7163],3],[[7164,7167],2],[[7168,7223],2],[[7224,7226],3],[[7227,7231],2],[[7232,7241],2],[[7242,7244],3],[[7245,7293],2],[[7294,7295],2],[7296,1,\"\"],[7297,1,\"\"],[7298,1,\"\"],[7299,1,\"\"],[[7300,7301],1,\"\"],[7302,1,\"\"],[7303,1,\"\"],[7304,1,\"\"],[[7305,7311],3],[7312,1,\"\"],[7313,1,\"\"],[7314,1,\"\"],[7315,1,\"\"],[7316,1,\"\"],[7317,1,\"\"],[7318,1,\"\"],[7319,1,\"\"],[7320,1,\"\"],[7321,1,\"\"],[7322,1,\"\"],[7323,1,\"\"],[7324,1,\"\"],[7325,1,\"\"],[7326,1,\"\"],[7327,1,\"\"],[7328,1,\"\"],[7329,1,\"\"],[7330,1,\"\"],[7331,1,\"\"],[7332,1,\"\"],[7333,1,\"\"],[7334,1,\"\"],[7335,1,\"\"],[7336,1,\"\"],[7337,1,\"\"],[7338,1,\"\"],[7339,1,\"\"],[7340,1,\"\"],[7341,1,\"\"],[7342,1,\"\"],[7343,1,\"\"],[7344,1,\"\"],[7345,1,\"\"],[7346,1,\"\"],[7347,1,\"\"],[7348,1,\"\"],[7349,1,\"\"],[7350,1,\"\"],[7351,1,\"\"],[7352,1,\"\"],[7353,1,\"\"],[7354,1,\"\"],[[7355,7356],3],[7357,1,\"\"],[7358,1,\"\"],[7359,1,\"\"],[[7360,7367],2],[[7368,7375],3],[[7376,7378],2],[7379,2],[[7380,7410],2],[[7411,7414],2],[7415,2],[[7416,7417],2],[7418,2],[[7419,7423],3],[[7424,7467],2],[7468,1,\"a\"],[7469,1,\"\"],[7470,1,\"b\"],[7471,2],[7472,1,\"d\"],[7473,1,\"e\"],[7474,1,\"\"],[7475,1,\"g\"],[7476,1,\"h\"],[7477,1,\"i\"],[7478,1,\"j\"],[7479,1,\"k\"],[7480,1,\"l\"],[7481,1,\"m\"],[7482,1,\"n\"],[7483,2],[7484,1,\"o\"],[7485,1,\"\"],[7486,1,\"p\"],[7487,1,\"r\"],[7488,1,\"t\"],[7489,1,\"u\"],[7490,1,\"w\"],[7491,1,\"a\"],[7492,1,\"\"],[7493,1,\"\"],[7494,1,\"\"],[7495,1,\"b\"],[7496,1,\"d\"],[7497,1,\"e\"],[7498,1,\"\"],[7499,1,\"\"],[7500,1,\"\"],[7501,1,\"g\"],[7502,2],[7503,1,\"k\"],[7504,1,\"m\"],[7505,1,\"\"],[7506,1,\"o\"],[7507,1,\"\"],[7508,1,\"\"],[7509,1,\"\"],[7510,1,\"p\"],[7511,1,\"t\"],[7512,1,\"u\"],[7513,1,\"\"],[7514,1,\"\"],[7515,1,\"v\"],[7516,1,\"\"],[7517,1,\"\"],[7518,1,\"\"],[7519,1,\"\"],[7520,1,\"\"],[7521,1,\"\"],[7522,1,\"i\"],[7523,1,\"r\"],[7524,1,\"u\"],[7525,1,\"v\"],[7526,1,\"\"],[7527,1,\"\"],[7528,1,\"\"],[7529,1,\"\"],[7530,1,\"\"],[7531,2],[[7532,7543],2],[7544,1,\"\"],[[7545,7578],2],[7579,1,\"\"],[7580,1,\"c\"],[7581,1,\"\"],[7582,1,\"\"],[7583,1,\"\"],[7584,1,\"f\"],[7585,1,\"\"],[7586,1,\"\"],[7587,1,\"\"],[7588,1,\"\"],[7589,1,\"\"],[7590,1,\"\"],[7591,1,\"\"],[7592,1,\"\"],[7593,1,\"\"],[7594,1,\"\"],[7595,1,\"\"],[7596,1,\"\"],[7597,1,\"\"],[7598,1,\"\"],[7599,1,\"\"],[7600,1,\"\"],[7601,1,\"\"],[7602,1,\"\"],[7603,1,\"\"],[7604,1,\"\"],[7605,1,\"\"],[7606,1,\"\"],[7607,1,\"\"],[7608,1,\"\"],[7609,1,\"\"],[7610,1,\"\"],[7611,1,\"z\"],[7612,1,\"\"],[7613,1,\"\"],[7614,1,\"\"],[7615,1,\"\"],[[7616,7619],2],[[7620,7626],2],[[7627,7654],2],[[7655,7669],2],[[7670,7673],2],[7674,2],[7675,2],[7676,2],[7677,2],[[7678,7679],2],[7680,1,\"\"],[7681,2],[7682,1,\"\"],[7683,2],[7684,1,\"\"],[7685,2],[7686,1,\"\"],[7687,2],[7688,1,\"\"],[7689,2],[7690,1,\"\"],[7691,2],[7692,1,\"\"],[7693,2],[7694,1,\"\"],[7695,2],[7696,1,\"\"],[7697,2],[7698,1,\"\"],[7699,2],[7700,1,\"\"],[7701,2],[7702,1,\"\"],[7703,2],[7704,1,\"\"],[7705,2],[7706,1,\"\"],[7707,2],[7708,1,\"\"],[7709,2],[7710,1,\"\"],[7711,2],[7712,1,\"\"],[7713,2],[7714,1,\"\"],[7715,2],[7716,1,\"\"],[7717,2],[7718,1,\"\"],[7719,2],[7720,1,\"\"],[7721,2],[7722,1,\"\"],[7723,2],[7724,1,\"\"],[7725,2],[7726,1,\"\"],[7727,2],[7728,1,\"\"],[7729,2],[7730,1,\"\"],[7731,2],[7732,1,\"\"],[7733,2],[7734,1,\"\"],[7735,2],[7736,1,\"\"],[7737,2],[7738,1,\"\"],[7739,2],[7740,1,\"\"],[7741,2],[7742,1,\"\"],[7743,2],[7744,1,\"\"],[7745,2],[7746,1,\"\"],[7747,2],[7748,1,\"\"],[7749,2],[7750,1,\"\"],[7751,2],[7752,1,\"\"],[7753,2],[7754,1,\"\"],[7755,2],[7756,1,\"\"],[7757,2],[7758,1,\"\"],[7759,2],[7760,1,\"\"],[7761,2],[7762,1,\"\"],[7763,2],[7764,1,\"\"],[7765,2],[7766,1,\"\"],[7767,2],[7768,1,\"\"],[7769,2],[7770,1,\"\"],[7771,2],[7772,1,\"\"],[7773,2],[7774,1,\"\"],[7775,2],[7776,1,\"\"],[7777,2],[7778,1,\"\"],[7779,2],[7780,1,\"\"],[7781,2],[7782,1,\"\"],[7783,2],[7784,1,\"\"],[7785,2],[7786,1,\"\"],[7787,2],[7788,1,\"\"],[7789,2],[7790,1,\"\"],[7791,2],[7792,1,\"\"],[7793,2],[7794,1,\"\"],[7795,2],[7796,1,\"\"],[7797,2],[7798,1,\"\"],[7799,2],[7800,1,\"\"],[7801,2],[7802,1,\"\"],[7803,2],[7804,1,\"\"],[7805,2],[7806,1,\"\"],[7807,2],[7808,1,\"\"],[7809,2],[7810,1,\"\"],[7811,2],[7812,1,\"\"],[7813,2],[7814,1,\"\"],[7815,2],[7816,1,\"\"],[7817,2],[7818,1,\"\"],[7819,2],[7820,1,\"\"],[7821,2],[7822,1,\"\"],[7823,2],[7824,1,\"\"],[7825,2],[7826,1,\"\"],[7827,2],[7828,1,\"\"],[[7829,7833],2],[7834,1,\"a\"],[7835,1,\"\"],[[7836,7837],2],[7838,1,\"ss\"],[7839,2],[7840,1,\"\"],[7841,2],[7842,1,\"\"],[7843,2],[7844,1,\"\"],[7845,2],[7846,1,\"\"],[7847,2],[7848,1,\"\"],[7849,2],[7850,1,\"\"],[7851,2],[7852,1,\"\"],[7853,2],[7854,1,\"\"],[7855,2],[7856,1,\"\"],[7857,2],[7858,1,\"\"],[7859,2],[7860,1,\"\"],[7861,2],[7862,1,\"\"],[7863,2],[7864,1,\"\"],[7865,2],[7866,1,\"\"],[7867,2],[7868,1,\"\"],[7869,2],[7870,1,\"\"],[7871,2],[7872,1,\"\"],[7873,2],[7874,1,\"\"],[7875,2],[7876,1,\"\"],[7877,2],[7878,1,\"\"],[7879,2],[7880,1,\"\"],[7881,2],[7882,1,\"\"],[7883,2],[7884,1,\"\"],[7885,2],[7886,1,\"\"],[7887,2],[7888,1,\"\"],[7889,2],[7890,1,\"\"],[7891,2],[7892,1,\"\"],[7893,2],[7894,1,\"\"],[7895,2],[7896,1,\"\"],[7897,2],[7898,1,\"\"],[7899,2],[7900,1,\"\"],[7901,2],[7902,1,\"\"],[7903,2],[7904,1,\"\"],[7905,2],[7906,1,\"\"],[7907,2],[7908,1,\"\"],[7909,2],[7910,1,\"\"],[7911,2],[7912,1,\"\"],[7913,2],[7914,1,\"\"],[7915,2],[7916,1,\"\"],[7917,2],[7918,1,\"\"],[7919,2],[7920,1,\"\"],[7921,2],[7922,1,\"\"],[7923,2],[7924,1,\"\"],[7925,2],[7926,1,\"\"],[7927,2],[7928,1,\"\"],[7929,2],[7930,1,\"\"],[7931,2],[7932,1,\"\"],[7933,2],[7934,1,\"\"],[7935,2],[[7936,7943],2],[7944,1,\"\"],[7945,1,\"\"],[7946,1,\"\"],[7947,1,\"\"],[7948,1,\"\"],[7949,1,\"\"],[7950,1,\"\"],[7951,1,\"\"],[[7952,7957],2],[[7958,7959],3],[7960,1,\"\"],[7961,1,\"\"],[7962,1,\"\"],[7963,1,\"\"],[7964,1,\"\"],[7965,1,\"\"],[[7966,7967],3],[[7968,7975],2],[7976,1,\"\"],[7977,1,\"\"],[7978,1,\"\"],[7979,1,\"\"],[7980,1,\"\"],[7981,1,\"\"],[7982,1,\"\"],[7983,1,\"\"],[[7984,7991],2],[7992,1,\"\"],[7993,1,\"\"],[7994,1,\"\"],[7995,1,\"\"],[7996,1,\"\"],[7997,1,\"\"],[7998,1,\"\"],[7999,1,\"\"],[[8000,8005],2],[[8006,8007],3],[8008,1,\"\"],[8009,1,\"\"],[8010,1,\"\"],[8011,1,\"\"],[8012,1,\"\"],[8013,1,\"\"],[[8014,8015],3],[[8016,8023],2],[8024,3],[8025,1,\"\"],[8026,3],[8027,1,\"\"],[8028,3],[8029,1,\"\"],[8030,3],[8031,1,\"\"],[[8032,8039],2],[8040,1,\"\"],[8041,1,\"\"],[8042,1,\"\"],[8043,1,\"\"],[8044,1,\"\"],[8045,1,\"\"],[8046,1,\"\"],[8047,1,\"\"],[8048,2],[8049,1,\"\"],[8050,2],[8051,1,\"\"],[8052,2],[8053,1,\"\"],[8054,2],[8055,1,\"\"],[8056,2],[8057,1,\"\"],[8058,2],[8059,1,\"\"],[8060,2],[8061,1,\"\"],[[8062,8063],3],[8064,1,\"\"],[8065,1,\"\"],[8066,1,\"\"],[8067,1,\"\"],[8068,1,\"\"],[8069,1,\"\"],[8070,1,\"\"],[8071,1,\"\"],[8072,1,\"\"],[8073,1,\"\"],[8074,1,\"\"],[8075,1,\"\"],[8076,1,\"\"],[8077,1,\"\"],[8078,1,\"\"],[8079,1,\"\"],[8080,1,\"\"],[8081,1,\"\"],[8082,1,\"\"],[8083,1,\"\"],[8084,1,\"\"],[8085,1,\"\"],[8086,1,\"\"],[8087,1,\"\"],[8088,1,\"\"],[8089,1,\"\"],[8090,1,\"\"],[8091,1,\"\"],[8092,1,\"\"],[8093,1,\"\"],[8094,1,\"\"],[8095,1,\"\"],[8096,1,\"\"],[8097,1,\"\"],[8098,1,\"\"],[8099,1,\"\"],[8100,1,\"\"],[8101,1,\"\"],[8102,1,\"\"],[8103,1,\"\"],[8104,1,\"\"],[8105,1,\"\"],[8106,1,\"\"],[8107,1,\"\"],[8108,1,\"\"],[8109,1,\"\"],[8110,1,\"\"],[8111,1,\"\"],[[8112,8113],2],[8114,1,\"\"],[8115,1,\"\"],[8116,1,\"\"],[8117,3],[8118,2],[8119,1,\"\"],[8120,1,\"\"],[8121,1,\"\"],[8122,1,\"\"],[8123,1,\"\"],[8124,1,\"\"],[8125,5,\" \"],[8126,1,\"\"],[8127,5,\" \"],[8128,5,\" \"],[8129,5,\" \"],[8130,1,\"\"],[8131,1,\"\"],[8132,1,\"\"],[8133,3],[8134,2],[8135,1,\"\"],[8136,1,\"\"],[8137,1,\"\"],[8138,1,\"\"],[8139,1,\"\"],[8140,1,\"\"],[8141,5,\" \"],[8142,5,\" \"],[8143,5,\" \"],[[8144,8146],2],[8147,1,\"\"],[[8148,8149],3],[[8150,8151],2],[8152,1,\"\"],[8153,1,\"\"],[8154,1,\"\"],[8155,1,\"\"],[8156,3],[8157,5,\" \"],[8158,5,\" \"],[8159,5,\" \"],[[8160,8162],2],[8163,1,\"\"],[[8164,8167],2],[8168,1,\"\"],[8169,1,\"\"],[8170,1,\"\"],[8171,1,\"\"],[8172,1,\"\"],[8173,5,\" \"],[8174,5,\" \"],[8175,5,\"`\"],[[8176,8177],3],[8178,1,\"\"],[8179,1,\"\"],[8180,1,\"\"],[8181,3],[8182,2],[8183,1,\"\"],[8184,1,\"\"],[8185,1,\"\"],[8186,1,\"\"],[8187,1,\"\"],[8188,1,\"\"],[8189,5,\" \"],[8190,5,\" \"],[8191,3],[[8192,8202],5,\" \"],[8203,7],[[8204,8205],6,\"\"],[[8206,8207],3],[8208,2],[8209,1,\"\"],[[8210,8214],2],[8215,5,\" \"],[[8216,8227],2],[[8228,8230],3],[8231,2],[[8232,8238],3],[8239,5,\" \"],[[8240,8242],2],[8243,1,\"\"],[8244,1,\"\"],[8245,2],[8246,1,\"\"],[8247,1,\"\"],[[8248,8251],2],[8252,5,\"!!\"],[8253,2],[8254,5,\" \"],[[8255,8262],2],[8263,5,\"??\"],[8264,5,\"?!\"],[8265,5,\"!?\"],[[8266,8269],2],[[8270,8274],2],[[8275,8276],2],[[8277,8278],2],[8279,1,\"\"],[[8280,8286],2],[8287,5,\" \"],[8288,7],[[8289,8291],3],[8292,7],[8293,3],[[8294,8297],3],[[8298,8303],3],[8304,1,\"0\"],[8305,1,\"i\"],[[8306,8307],3],[8308,1,\"4\"],[8309,1,\"5\"],[8310,1,\"6\"],[8311,1,\"7\"],[8312,1,\"8\"],[8313,1,\"9\"],[8314,5,\"+\"],[8315,1,\"\"],[8316,5,\"=\"],[8317,5,\"(\"],[8318,5,\")\"],[8319,1,\"n\"],[8320,1,\"0\"],[8321,1,\"1\"],[8322,1,\"2\"],[8323,1,\"3\"],[8324,1,\"4\"],[8325,1,\"5\"],[8326,1,\"6\"],[8327,1,\"7\"],[8328,1,\"8\"],[8329,1,\"9\"],[8330,5,\"+\"],[8331,1,\"\"],[8332,5,\"=\"],[8333,5,\"(\"],[8334,5,\")\"],[8335,3],[8336,1,\"a\"],[8337,1,\"e\"],[8338,1,\"o\"],[8339,1,\"x\"],[8340,1,\"\"],[8341,1,\"h\"],[8342,1,\"k\"],[8343,1,\"l\"],[8344,1,\"m\"],[8345,1,\"n\"],[8346,1,\"p\"],[8347,1,\"s\"],[8348,1,\"t\"],[[8349,8351],3],[[8352,8359],2],[8360,1,\"rs\"],[[8361,8362],2],[8363,2],[8364,2],[[8365,8367],2],[[8368,8369],2],[[8370,8373],2],[[8374,8376],2],[8377,2],[8378,2],[[8379,8381],2],[8382,2],[8383,2],[8384,2],[[8385,8399],3],[[8400,8417],2],[[8418,8419],2],[[8420,8426],2],[8427,2],[[8428,8431],2],[8432,2],[[8433,8447],3],[8448,5,\"a/c\"],[8449,5,\"a/s\"],[8450,1,\"c\"],[8451,1,\"c\"],[8452,2],[8453,5,\"c/o\"],[8454,5,\"c/u\"],[8455,1,\"\"],[8456,2],[8457,1,\"f\"],[8458,1,\"g\"],[[8459,8462],1,\"h\"],[8463,1,\"\"],[[8464,8465],1,\"i\"],[[8466,8467],1,\"l\"],[8468,2],[8469,1,\"n\"],[8470,1,\"no\"],[[8471,8472],2],[8473,1,\"p\"],[8474,1,\"q\"],[[8475,8477],1,\"r\"],[[8478,8479],2],[8480,1,\"sm\"],[8481,1,\"tel\"],[8482,1,\"tm\"],[8483,2],[8484,1,\"z\"],[8485,2],[8486,1,\"\"],[8487,2],[8488,1,\"z\"],[8489,2],[8490,1,\"k\"],[8491,1,\"\"],[8492,1,\"b\"],[8493,1,\"c\"],[8494,2],[[8495,8496],1,\"e\"],[8497,1,\"f\"],[8498,3],[8499,1,\"m\"],[8500,1,\"o\"],[8501,1,\"\"],[8502,1,\"\"],[8503,1,\"\"],[8504,1,\"\"],[8505,1,\"i\"],[8506,2],[8507,1,\"fax\"],[8508,1,\"\"],[[8509,8510],1,\"\"],[8511,1,\"\"],[8512,1,\"\"],[[8513,8516],2],[[8517,8518],1,\"d\"],[8519,1,\"e\"],[8520,1,\"i\"],[8521,1,\"j\"],[[8522,8523],2],[8524,2],[8525,2],[8526,2],[8527,2],[8528,1,\"17\"],[8529,1,\"19\"],[8530,1,\"110\"],[8531,1,\"13\"],[8532,1,\"23\"],[8533,1,\"15\"],[8534,1,\"25\"],[8535,1,\"35\"],[8536,1,\"45\"],[8537,1,\"16\"],[8538,1,\"56\"],[8539,1,\"18\"],[8540,1,\"38\"],[8541,1,\"58\"],[8542,1,\"78\"],[8543,1,\"1\"],[8544,1,\"i\"],[8545,1,\"ii\"],[8546,1,\"iii\"],[8547,1,\"iv\"],[8548,1,\"v\"],[8549,1,\"vi\"],[8550,1,\"vii\"],[8551,1,\"viii\"],[8552,1,\"ix\"],[8553,1,\"x\"],[8554,1,\"xi\"],[8555,1,\"xii\"],[8556,1,\"l\"],[8557,1,\"c\"],[8558,1,\"d\"],[8559,1,\"m\"],[8560,1,\"i\"],[8561,1,\"ii\"],[8562,1,\"iii\"],[8563,1,\"iv\"],[8564,1,\"v\"],[8565,1,\"vi\"],[8566,1,\"vii\"],[8567,1,\"viii\"],[8568,1,\"ix\"],[8569,1,\"x\"],[8570,1,\"xi\"],[8571,1,\"xii\"],[8572,1,\"l\"],[8573,1,\"c\"],[8574,1,\"d\"],[8575,1,\"m\"],[[8576,8578],2],[8579,3],[8580,2],[[8581,8584],2],[8585,1,\"03\"],[[8586,8587],2],[[8588,8591],3],[[8592,8682],2],[[8683,8691],2],[[8692,8703],2],[[8704,8747],2],[8748,1,\"\"],[8749,1,\"\"],[8750,2],[8751,1,\"\"],[8752,1,\"\"],[[8753,8799],2],[8800,4],[[8801,8813],2],[[8814,8815],4],[[8816,8945],2],[[8946,8959],2],[8960,2],[8961,2],[[8962,9000],2],[9001,1,\"\"],[9002,1,\"\"],[[9003,9082],2],[9083,2],[9084,2],[[9085,9114],2],[[9115,9166],2],[[9167,9168],2],[[9169,9179],2],[[9180,9191],2],[9192,2],[[9193,9203],2],[[9204,9210],2],[[9211,9214],2],[9215,2],[[9216,9252],2],[[9253,9254],2],[[9255,9279],3],[[9280,9290],2],[[9291,9311],3],[9312,1,\"1\"],[9313,1,\"2\"],[9314,1,\"3\"],[9315,1,\"4\"],[9316,1,\"5\"],[9317,1,\"6\"],[9318,1,\"7\"],[9319,1,\"8\"],[9320,1,\"9\"],[9321,1,\"10\"],[9322,1,\"11\"],[9323,1,\"12\"],[9324,1,\"13\"],[9325,1,\"14\"],[9326,1,\"15\"],[9327,1,\"16\"],[9328,1,\"17\"],[9329,1,\"18\"],[9330,1,\"19\"],[9331,1,\"20\"],[9332,5,\"(1)\"],[9333,5,\"(2)\"],[9334,5,\"(3)\"],[9335,5,\"(4)\"],[9336,5,\"(5)\"],[9337,5,\"(6)\"],[9338,5,\"(7)\"],[9339,5,\"(8)\"],[9340,5,\"(9)\"],[9341,5,\"(10)\"],[9342,5,\"(11)\"],[9343,5,\"(12)\"],[9344,5,\"(13)\"],[9345,5,\"(14)\"],[9346,5,\"(15)\"],[9347,5,\"(16)\"],[9348,5,\"(17)\"],[9349,5,\"(18)\"],[9350,5,\"(19)\"],[9351,5,\"(20)\"],[[9352,9371],3],[9372,5,\"(a)\"],[9373,5,\"(b)\"],[9374,5,\"(c)\"],[9375,5,\"(d)\"],[9376,5,\"(e)\"],[9377,5,\"(f)\"],[9378,5,\"(g)\"],[9379,5,\"(h)\"],[9380,5,\"(i)\"],[9381,5,\"(j)\"],[9382,5,\"(k)\"],[9383,5,\"(l)\"],[9384,5,\"(m)\"],[9385,5,\"(n)\"],[9386,5,\"(o)\"],[9387,5,\"(p)\"],[9388,5,\"(q)\"],[9389,5,\"(r)\"],[9390,5,\"(s)\"],[9391,5,\"(t)\"],[9392,5,\"(u)\"],[9393,5,\"(v)\"],[9394,5,\"(w)\"],[9395,5,\"(x)\"],[9396,5,\"(y)\"],[9397,5,\"(z)\"],[9398,1,\"a\"],[9399,1,\"b\"],[9400,1,\"c\"],[9401,1,\"d\"],[9402,1,\"e\"],[9403,1,\"f\"],[9404,1,\"g\"],[9405,1,\"h\"],[9406,1,\"i\"],[9407,1,\"j\"],[9408,1,\"k\"],[9409,1,\"l\"],[9410,1,\"m\"],[9411,1,\"n\"],[9412,1,\"o\"],[9413,1,\"p\"],[9414,1,\"q\"],[9415,1,\"r\"],[9416,1,\"s\"],[9417,1,\"t\"],[9418,1,\"u\"],[9419,1,\"v\"],[9420,1,\"w\"],[9421,1,\"x\"],[9422,1,\"y\"],[9423,1,\"z\"],[9424,1,\"a\"],[9425,1,\"b\"],[9426,1,\"c\"],[9427,1,\"d\"],[9428,1,\"e\"],[9429,1,\"f\"],[9430,1,\"g\"],[9431,1,\"h\"],[9432,1,\"i\"],[9433,1,\"j\"],[9434,1,\"k\"],[9435,1,\"l\"],[9436,1,\"m\"],[9437,1,\"n\"],[9438,1,\"o\"],[9439,1,\"p\"],[9440,1,\"q\"],[9441,1,\"r\"],[9442,1,\"s\"],[9443,1,\"t\"],[9444,1,\"u\"],[9445,1,\"v\"],[9446,1,\"w\"],[9447,1,\"x\"],[9448,1,\"y\"],[9449,1,\"z\"],[9450,1,\"0\"],[[9451,9470],2],[9471,2],[[9472,9621],2],[[9622,9631],2],[[9632,9711],2],[[9712,9719],2],[[9720,9727],2],[[9728,9747],2],[[9748,9749],2],[[9750,9751],2],[9752,2],[9753,2],[[9754,9839],2],[[9840,9841],2],[[9842,9853],2],[[9854,9855],2],[[9856,9865],2],[[9866,9873],2],[[9874,9884],2],[9885,2],[[9886,9887],2],[[9888,9889],2],[[9890,9905],2],[9906,2],[[9907,9916],2],[[9917,9919],2],[[9920,9923],2],[[9924,9933],2],[9934,2],[[9935,9953],2],[9954,2],[9955,2],[[9956,9959],2],[[9960,9983],2],[9984,2],[[9985,9988],2],[9989,2],[[9990,9993],2],[[9994,9995],2],[[9996,10023],2],[10024,2],[[10025,10059],2],[10060,2],[10061,2],[10062,2],[[10063,10066],2],[[10067,10069],2],[10070,2],[10071,2],[[10072,10078],2],[[10079,10080],2],[[10081,10087],2],[[10088,10101],2],[[10102,10132],2],[[10133,10135],2],[[10136,10159],2],[10160,2],[[10161,10174],2],[10175,2],[[10176,10182],2],[[10183,10186],2],[10187,2],[10188,2],[10189,2],[[10190,10191],2],[[10192,10219],2],[[10220,10223],2],[[10224,10239],2],[[10240,10495],2],[[10496,10763],2],[10764,1,\"\"],[[10765,10867],2],[10868,5,\"::=\"],[10869,5,\"==\"],[10870,5,\"===\"],[[10871,10971],2],[10972,1,\"\"],[[10973,11007],2],[[11008,11021],2],[[11022,11027],2],[[11028,11034],2],[[11035,11039],2],[[11040,11043],2],[[11044,11084],2],[[11085,11087],2],[[11088,11092],2],[[11093,11097],2],[[11098,11123],2],[[11124,11125],3],[[11126,11157],2],[11158,3],[11159,2],[[11160,11193],2],[[11194,11196],2],[[11197,11208],2],[11209,2],[[11210,11217],2],[11218,2],[[11219,11243],2],[[11244,11247],2],[[11248,11262],2],[11263,2],[11264,1,\"\"],[11265,1,\"\"],[11266,1,\"\"],[11267,1,\"\"],[11268,1,\"\"],[11269,1,\"\"],[11270,1,\"\"],[11271,1,\"\"],[11272,1,\"\"],[11273,1,\"\"],[11274,1,\"\"],[11275,1,\"\"],[11276,1,\"\"],[11277,1,\"\"],[11278,1,\"\"],[11279,1,\"\"],[11280,1,\"\"],[11281,1,\"\"],[11282,1,\"\"],[11283,1,\"\"],[11284,1,\"\"],[11285,1,\"\"],[11286,1,\"\"],[11287,1,\"\"],[11288,1,\"\"],[11289,1,\"\"],[11290,1,\"\"],[11291,1,\"\"],[11292,1,\"\"],[11293,1,\"\"],[11294,1,\"\"],[11295,1,\"\"],[11296,1,\"\"],[11297,1,\"\"],[11298,1,\"\"],[11299,1,\"\"],[11300,1,\"\"],[11301,1,\"\"],[11302,1,\"\"],[11303,1,\"\"],[11304,1,\"\"],[11305,1,\"\"],[11306,1,\"\"],[11307,1,\"\"],[11308,1,\"\"],[11309,1,\"\"],[11310,1,\"\"],[11311,1,\"\"],[[11312,11358],2],[11359,2],[11360,1,\"\"],[11361,2],[11362,1,\"\"],[11363,1,\"\"],[11364,1,\"\"],[[11365,11366],2],[11367,1,\"\"],[11368,2],[11369,1,\"\"],[11370,2],[11371,1,\"\"],[11372,2],[11373,1,\"\"],[11374,1,\"\"],[11375,1,\"\"],[11376,1,\"\"],[11377,2],[11378,1,\"\"],[11379,2],[11380,2],[11381,1,\"\"],[[11382,11383],2],[[11384,11387],2],[11388,1,\"j\"],[11389,1,\"v\"],[11390,1,\"\"],[11391,1,\"\"],[11392,1,\"\"],[11393,2],[11394,1,\"\"],[11395,2],[11396,1,\"\"],[11397,2],[11398,1,\"\"],[11399,2],[11400,1,\"\"],[11401,2],[11402,1,\"\"],[11403,2],[11404,1,\"\"],[11405,2],[11406,1,\"\"],[11407,2],[11408,1,\"\"],[11409,2],[11410,1,\"\"],[11411,2],[11412,1,\"\"],[11413,2],[11414,1,\"\"],[11415,2],[11416,1,\"\"],[11417,2],[11418,1,\"\"],[11419,2],[11420,1,\"\"],[11421,2],[11422,1,\"\"],[11423,2],[11424,1,\"\"],[11425,2],[11426,1,\"\"],[11427,2],[11428,1,\"\"],[11429,2],[11430,1,\"\"],[11431,2],[11432,1,\"\"],[11433,2],[11434,1,\"\"],[11435,2],[11436,1,\"\"],[11437,2],[11438,1,\"\"],[11439,2],[11440,1,\"\"],[11441,2],[11442,1,\"\"],[11443,2],[11444,1,\"\"],[11445,2],[11446,1,\"\"],[11447,2],[11448,1,\"\"],[11449,2],[11450,1,\"\"],[11451,2],[11452,1,\"\"],[11453,2],[11454,1,\"\"],[11455,2],[11456,1,\"\"],[11457,2],[11458,1,\"\"],[11459,2],[11460,1,\"\"],[11461,2],[11462,1,\"\"],[11463,2],[11464,1,\"\"],[11465,2],[11466,1,\"\"],[11467,2],[11468,1,\"\"],[11469,2],[11470,1,\"\"],[11471,2],[11472,1,\"\"],[11473,2],[11474,1,\"\"],[11475,2],[11476,1,\"\"],[11477,2],[11478,1,\"\"],[11479,2],[11480,1,\"\"],[11481,2],[11482,1,\"\"],[11483,2],[11484,1,\"\"],[11485,2],[11486,1,\"\"],[11487,2],[11488,1,\"\"],[11489,2],[11490,1,\"\"],[[11491,11492],2],[[11493,11498],2],[11499,1,\"\"],[11500,2],[11501,1,\"\"],[[11502,11505],2],[11506,1,\"\"],[11507,2],[[11508,11512],3],[[11513,11519],2],[[11520,11557],2],[11558,3],[11559,2],[[11560,11564],3],[11565,2],[[11566,11567],3],[[11568,11621],2],[[11622,11623],2],[[11624,11630],3],[11631,1,\"\"],[11632,2],[[11633,11646],3],[11647,2],[[11648,11670],2],[[11671,11679],3],[[11680,11686],2],[11687,3],[[11688,11694],2],[11695,3],[[11696,11702],2],[11703,3],[[11704,11710],2],[11711,3],[[11712,11718],2],[11719,3],[[11720,11726],2],[11727,3],[[11728,11734],2],[11735,3],[[11736,11742],2],[11743,3],[[11744,11775],2],[[11776,11799],2],[[11800,11803],2],[[11804,11805],2],[[11806,11822],2],[11823,2],[11824,2],[11825,2],[[11826,11835],2],[[11836,11842],2],[[11843,11844],2],[[11845,11849],2],[[11850,11854],2],[11855,2],[[11856,11858],2],[[11859,11869],2],[[11870,11903],3],[[11904,11929],2],[11930,3],[[11931,11934],2],[11935,1,\"\"],[[11936,12018],2],[12019,1,\"\"],[[12020,12031],3],[12032,1,\"\"],[12033,1,\"\"],[12034,1,\"\"],[12035,1,\"\"],[12036,1,\"\"],[12037,1,\"\"],[12038,1,\"\"],[12039,1,\"\"],[12040,1,\"\"],[12041,1,\"\"],[12042,1,\"\"],[12043,1,\"\"],[12044,1,\"\"],[12045,1,\"\"],[12046,1,\"\"],[12047,1,\"\"],[12048,1,\"\"],[12049,1,\"\"],[12050,1,\"\"],[12051,1,\"\"],[12052,1,\"\"],[12053,1,\"\"],[12054,1,\"\"],[12055,1,\"\"],[12056,1,\"\"],[12057,1,\"\"],[12058,1,\"\"],[12059,1,\"\"],[12060,1,\"\"],[12061,1,\"\"],[12062,1,\"\"],[12063,1,\"\"],[12064,1,\"\"],[12065,1,\"\"],[12066,1,\"\"],[12067,1,\"\"],[12068,1,\"\"],[12069,1,\"\"],[12070,1,\"\"],[12071,1,\"\"],[12072,1,\"\"],[12073,1,\"\"],[12074,1,\"\"],[12075,1,\"\"],[12076,1,\"\"],[12077,1,\"\"],[12078,1,\"\"],[12079,1,\"\"],[12080,1,\"\"],[12081,1,\"\"],[12082,1,\"\"],[12083,1,\"\"],[12084,1,\"\"],[12085,1,\"\"],[12086,1,\"\"],[12087,1,\"\"],[12088,1,\"\"],[12089,1,\"\"],[12090,1,\"\"],[12091,1,\"\"],[12092,1,\"\"],[12093,1,\"\"],[12094,1,\"\"],[12095,1,\"\"],[12096,1,\"\"],[12097,1,\"\"],[12098,1,\"\"],[12099,1,\"\"],[12100,1,\"\"],[12101,1,\"\"],[12102,1,\"\"],[12103,1,\"\"],[12104,1,\"\"],[12105,1,\"\"],[12106,1,\"\"],[12107,1,\"\"],[12108,1,\"\"],[12109,1,\"\"],[12110,1,\"\"],[12111,1,\"\"],[12112,1,\"\"],[12113,1,\"\"],[12114,1,\"\"],[12115,1,\"\"],[12116,1,\"\"],[12117,1,\"\"],[12118,1,\"\"],[12119,1,\"\"],[12120,1,\"\"],[12121,1,\"\"],[12122,1,\"\"],[12123,1,\"\"],[12124,1,\"\"],[12125,1,\"\"],[12126,1,\"\"],[12127,1,\"\"],[12128,1,\"\"],[12129,1,\"\"],[12130,1,\"\"],[12131,1,\"\"],[12132,1,\"\"],[12133,1,\"\"],[12134,1,\"\"],[12135,1,\"\"],[12136,1,\"\"],[12137,1,\"\"],[12138,1,\"\"],[12139,1,\"\"],[12140,1,\"\"],[12141,1,\"\"],[12142,1,\"\"],[12143,1,\"\"],[12144,1,\"\"],[12145,1,\"\"],[12146,1,\"\"],[12147,1,\"\"],[12148,1,\"\"],[12149,1,\"\"],[12150,1,\"\"],[12151,1,\"\"],[12152,1,\"\"],[12153,1,\"\"],[12154,1,\"\"],[12155,1,\"\"],[12156,1,\"\"],[12157,1,\"\"],[12158,1,\"\"],[12159,1,\"\"],[12160,1,\"\"],[12161,1,\"\"],[12162,1,\"\"],[12163,1,\"\"],[12164,1,\"\"],[12165,1,\"\"],[12166,1,\"\"],[12167,1,\"\"],[12168,1,\"\"],[12169,1,\"\"],[12170,1,\"\"],[12171,1,\"\"],[12172,1,\"\"],[12173,1,\"\"],[12174,1,\"\"],[12175,1,\"\"],[12176,1,\"\"],[12177,1,\"\"],[12178,1,\"\"],[12179,1,\"\"],[12180,1,\"\"],[12181,1,\"\"],[12182,1,\"\"],[12183,1,\"\"],[12184,1,\"\"],[12185,1,\"\"],[12186,1,\"\"],[12187,1,\"\"],[12188,1,\"\"],[12189,1,\"\"],[12190,1,\"\"],[12191,1,\"\"],[12192,1,\"\"],[12193,1,\"\"],[12194,1,\"\"],[12195,1,\"\"],[12196,1,\"\"],[12197,1,\"\"],[12198,1,\"\"],[12199,1,\"\"],[12200,1,\"\"],[12201,1,\"\"],[12202,1,\"\"],[12203,1,\"\"],[12204,1,\"\"],[12205,1,\"\"],[12206,1,\"\"],[12207,1,\"\"],[12208,1,\"\"],[12209,1,\"\"],[12210,1,\"\"],[12211,1,\"\"],[12212,1,\"\"],[12213,1,\"\"],[12214,1,\"\"],[12215,1,\"\"],[12216,1,\"\"],[12217,1,\"\"],[12218,1,\"\"],[12219,1,\"\"],[12220,1,\"\"],[12221,1,\"\"],[12222,1,\"\"],[12223,1,\"\"],[12224,1,\"\"],[12225,1,\"\"],[12226,1,\"\"],[12227,1,\"\"],[12228,1,\"\"],[12229,1,\"\"],[12230,1,\"\"],[12231,1,\"\"],[12232,1,\"\"],[12233,1,\"\"],[12234,1,\"\"],[12235,1,\"\"],[12236,1,\"\"],[12237,1,\"\"],[12238,1,\"\"],[12239,1,\"\"],[12240,1,\"\"],[12241,1,\"\"],[12242,1,\"\"],[12243,1,\"\"],[12244,1,\"\"],[12245,1,\"\"],[[12246,12271],3],[[12272,12283],3],[[12284,12287],3],[12288,5,\" \"],[12289,2],[12290,1,\".\"],[[12291,12292],2],[[12293,12295],2],[[12296,12329],2],[[12330,12333],2],[[12334,12341],2],[12342,1,\"\"],[12343,2],[12344,1,\"\"],[12345,1,\"\"],[12346,1,\"\"],[12347,2],[12348,2],[12349,2],[12350,2],[12351,2],[12352,3],[[12353,12436],2],[[12437,12438],2],[[12439,12440],3],[[12441,12442],2],[12443,5,\" \"],[12444,5,\" \"],[[12445,12446],2],[12447,1,\"\"],[12448,2],[[12449,12542],2],[12543,1,\"\"],[[12544,12548],3],[[12549,12588],2],[12589,2],[12590,2],[12591,2],[12592,3],[12593,1,\"\"],[12594,1,\"\"],[12595,1,\"\"],[12596,1,\"\"],[12597,1,\"\"],[12598,1,\"\"],[12599,1,\"\"],[12600,1,\"\"],[12601,1,\"\"],[12602,1,\"\"],[12603,1,\"\"],[12604,1,\"\"],[12605,1,\"\"],[12606,1,\"\"],[12607,1,\"\"],[12608,1,\"\"],[12609,1,\"\"],[12610,1,\"\"],[12611,1,\"\"],[12612,1,\"\"],[12613,1,\"\"],[12614,1,\"\"],[12615,1,\"\"],[12616,1,\"\"],[12617,1,\"\"],[12618,1,\"\"],[12619,1,\"\"],[12620,1,\"\"],[12621,1,\"\"],[12622,1,\"\"],[12623,1,\"\"],[12624,1,\"\"],[12625,1,\"\"],[12626,1,\"\"],[12627,1,\"\"],[12628,1,\"\"],[12629,1,\"\"],[12630,1,\"\"],[12631,1,\"\"],[12632,1,\"\"],[12633,1,\"\"],[12634,1,\"\"],[12635,1,\"\"],[12636,1,\"\"],[12637,1,\"\"],[12638,1,\"\"],[12639,1,\"\"],[12640,1,\"\"],[12641,1,\"\"],[12642,1,\"\"],[12643,1,\"\"],[12644,3],[12645,1,\"\"],[12646,1,\"\"],[12647,1,\"\"],[12648,1,\"\"],[12649,1,\"\"],[12650,1,\"\"],[12651,1,\"\"],[12652,1,\"\"],[12653,1,\"\"],[12654,1,\"\"],[12655,1,\"\"],[12656,1,\"\"],[12657,1,\"\"],[12658,1,\"\"],[12659,1,\"\"],[12660,1,\"\"],[12661,1,\"\"],[12662,1,\"\"],[12663,1,\"\"],[12664,1,\"\"],[12665,1,\"\"],[12666,1,\"\"],[12667,1,\"\"],[12668,1,\"\"],[12669,1,\"\"],[12670,1,\"\"],[12671,1,\"\"],[12672,1,\"\"],[12673,1,\"\"],[12674,1,\"\"],[12675,1,\"\"],[12676,1,\"\"],[12677,1,\"\"],[12678,1,\"\"],[12679,1,\"\"],[12680,1,\"\"],[12681,1,\"\"],[12682,1,\"\"],[12683,1,\"\"],[12684,1,\"\"],[12685,1,\"\"],[12686,1,\"\"],[12687,3],[[12688,12689],2],[12690,1,\"\"],[12691,1,\"\"],[12692,1,\"\"],[12693,1,\"\"],[12694,1,\"\"],[12695,1,\"\"],[12696,1,\"\"],[12697,1,\"\"],[12698,1,\"\"],[12699,1,\"\"],[12700,1,\"\"],[12701,1,\"\"],[12702,1,\"\"],[12703,1,\"\"],[[12704,12727],2],[[12728,12730],2],[[12731,12735],2],[[12736,12751],2],[[12752,12771],2],[[12772,12783],3],[[12784,12799],2],[12800,5,\"()\"],[12801,5,\"()\"],[12802,5,\"()\"],[12803,5,\"()\"],[12804,5,\"()\"],[12805,5,\"()\"],[12806,5,\"()\"],[12807,5,\"()\"],[12808,5,\"()\"],[12809,5,\"()\"],[12810,5,\"()\"],[12811,5,\"()\"],[12812,5,\"()\"],[12813,5,\"()\"],[12814,5,\"()\"],[12815,5,\"()\"],[12816,5,\"()\"],[12817,5,\"()\"],[12818,5,\"()\"],[12819,5,\"()\"],[12820,5,\"()\"],[12821,5,\"()\"],[12822,5,\"()\"],[12823,5,\"()\"],[12824,5,\"()\"],[12825,5,\"()\"],[12826,5,\"()\"],[12827,5,\"()\"],[12828,5,\"()\"],[12829,5,\"()\"],[12830,5,\"()\"],[12831,3],[12832,5,\"()\"],[12833,5,\"()\"],[12834,5,\"()\"],[12835,5,\"()\"],[12836,5,\"()\"],[12837,5,\"()\"],[12838,5,\"()\"],[12839,5,\"()\"],[12840,5,\"()\"],[12841,5,\"()\"],[12842,5,\"()\"],[12843,5,\"()\"],[12844,5,\"()\"],[12845,5,\"()\"],[12846,5,\"()\"],[12847,5,\"()\"],[12848,5,\"()\"],[12849,5,\"()\"],[12850,5,\"()\"],[12851,5,\"()\"],[12852,5,\"()\"],[12853,5,\"()\"],[12854,5,\"()\"],[12855,5,\"()\"],[12856,5,\"()\"],[12857,5,\"()\"],[12858,5,\"()\"],[12859,5,\"()\"],[12860,5,\"()\"],[12861,5,\"()\"],[12862,5,\"()\"],[12863,5,\"()\"],[12864,5,\"()\"],[12865,5,\"()\"],[12866,5,\"()\"],[12867,5,\"()\"],[12868,1,\"\"],[12869,1,\"\"],[12870,1,\"\"],[12871,1,\"\"],[[12872,12879],2],[12880,1,\"pte\"],[12881,1,\"21\"],[12882,1,\"22\"],[12883,1,\"23\"],[12884,1,\"24\"],[12885,1,\"25\"],[12886,1,\"26\"],[12887,1,\"27\"],[12888,1,\"28\"],[12889,1,\"29\"],[12890,1,\"30\"],[12891,1,\"31\"],[12892,1,\"32\"],[12893,1,\"33\"],[12894,1,\"34\"],[12895,1,\"35\"],[12896,1,\"\"],[12897,1,\"\"],[12898,1,\"\"],[12899,1,\"\"],[12900,1,\"\"],[12901,1,\"\"],[12902,1,\"\"],[12903,1,\"\"],[12904,1,\"\"],[12905,1,\"\"],[12906,1,\"\"],[12907,1,\"\"],[12908,1,\"\"],[12909,1,\"\"],[12910,1,\"\"],[12911,1,\"\"],[12912,1,\"\"],[12913,1,\"\"],[12914,1,\"\"],[12915,1,\"\"],[12916,1,\"\"],[12917,1,\"\"],[12918,1,\"\"],[12919,1,\"\"],[12920,1,\"\"],[12921,1,\"\"],[12922,1,\"\"],[12923,1,\"\"],[12924,1,\"\"],[12925,1,\"\"],[12926,1,\"\"],[12927,2],[12928,1,\"\"],[12929,1,\"\"],[12930,1,\"\"],[12931,1,\"\"],[12932,1,\"\"],[12933,1,\"\"],[12934,1,\"\"],[12935,1,\"\"],[12936,1,\"\"],[12937,1,\"\"],[12938,1,\"\"],[12939,1,\"\"],[12940,1,\"\"],[12941,1,\"\"],[12942,1,\"\"],[12943,1,\"\"],[12944,1,\"\"],[12945,1,\"\"],[12946,1,\"\"],[12947,1,\"\"],[12948,1,\"\"],[12949,1,\"\"],[12950,1,\"\"],[12951,1,\"\"],[12952,1,\"\"],[12953,1,\"\"],[12954,1,\"\"],[12955,1,\"\"],[12956,1,\"\"],[12957,1,\"\"],[12958,1,\"\"],[12959,1,\"\"],[12960,1,\"\"],[12961,1,\"\"],[12962,1,\"\"],[12963,1,\"\"],[12964,1,\"\"],[12965,1,\"\"],[12966,1,\"\"],[12967,1,\"\"],[12968,1,\"\"],[12969,1,\"\"],[12970,1,\"\"],[12971,1,\"\"],[12972,1,\"\"],[12973,1,\"\"],[12974,1,\"\"],[12975,1,\"\"],[12976,1,\"\"],[12977,1,\"36\"],[12978,1,\"37\"],[12979,1,\"38\"],[12980,1,\"39\"],[12981,1,\"40\"],[12982,1,\"41\"],[12983,1,\"42\"],[12984,1,\"43\"],[12985,1,\"44\"],[12986,1,\"45\"],[12987,1,\"46\"],[12988,1,\"47\"],[12989,1,\"48\"],[12990,1,\"49\"],[12991,1,\"50\"],[12992,1,\"1\"],[12993,1,\"2\"],[12994,1,\"3\"],[12995,1,\"4\"],[12996,1,\"5\"],[12997,1,\"6\"],[12998,1,\"7\"],[12999,1,\"8\"],[13000,1,\"9\"],[13001,1,\"10\"],[13002,1,\"11\"],[13003,1,\"12\"],[13004,1,\"hg\"],[13005,1,\"erg\"],[13006,1,\"ev\"],[13007,1,\"ltd\"],[13008,1,\"\"],[13009,1,\"\"],[13010,1,\"\"],[13011,1,\"\"],[13012,1,\"\"],[13013,1,\"\"],[13014,1,\"\"],[13015,1,\"\"],[13016,1,\"\"],[13017,1,\"\"],[13018,1,\"\"],[13019,1,\"\"],[13020,1,\"\"],[13021,1,\"\"],[13022,1,\"\"],[13023,1,\"\"],[13024,1,\"\"],[13025,1,\"\"],[13026,1,\"\"],[13027,1,\"\"],[13028,1,\"\"],[13029,1,\"\"],[13030,1,\"\"],[13031,1,\"\"],[13032,1,\"\"],[13033,1,\"\"],[13034,1,\"\"],[13035,1,\"\"],[13036,1,\"\"],[13037,1,\"\"],[13038,1,\"\"],[13039,1,\"\"],[13040,1,\"\"],[13041,1,\"\"],[13042,1,\"\"],[13043,1,\"\"],[13044,1,\"\"],[13045,1,\"\"],[13046,1,\"\"],[13047,1,\"\"],[13048,1,\"\"],[13049,1,\"\"],[13050,1,\"\"],[13051,1,\"\"],[13052,1,\"\"],[13053,1,\"\"],[13054,1,\"\"],[13055,1,\"\"],[13056,1,\"\"],[13057,1,\"\"],[13058,1,\"\"],[13059,1,\"\"],[13060,1,\"\"],[13061,1,\"\"],[13062,1,\"\"],[13063,1,\"\"],[13064,1,\"\"],[13065,1,\"\"],[13066,1,\"\"],[13067,1,\"\"],[13068,1,\"\"],[13069,1,\"\"],[13070,1,\"\"],[13071,1,\"\"],[13072,1,\"\"],[13073,1,\"\"],[13074,1,\"\"],[13075,1,\"\"],[13076,1,\"\"],[13077,1,\"\"],[13078,1,\"\"],[13079,1,\"\"],[13080,1,\"\"],[13081,1,\"\"],[13082,1,\"\"],[13083,1,\"\"],[13084,1,\"\"],[13085,1,\"\"],[13086,1,\"\"],[13087,1,\"\"],[13088,1,\"\"],[13089,1,\"\"],[13090,1,\"\"],[13091,1,\"\"],[13092,1,\"\"],[13093,1,\"\"],[13094,1,\"\"],[13095,1,\"\"],[13096,1,\"\"],[13097,1,\"\"],[13098,1,\"\"],[13099,1,\"\"],[13100,1,\"\"],[13101,1,\"\"],[13102,1,\"\"],[13103,1,\"\"],[13104,1,\"\"],[13105,1,\"\"],[13106,1,\"\"],[13107,1,\"\"],[13108,1,\"\"],[13109,1,\"\"],[13110,1,\"\"],[13111,1,\"\"],[13112,1,\"\"],[13113,1,\"\"],[13114,1,\"\"],[13115,1,\"\"],[13116,1,\"\"],[13117,1,\"\"],[13118,1,\"\"],[13119,1,\"\"],[13120,1,\"\"],[13121,1,\"\"],[13122,1,\"\"],[13123,1,\"\"],[13124,1,\"\"],[13125,1,\"\"],[13126,1,\"\"],[13127,1,\"\"],[13128,1,\"\"],[13129,1,\"\"],[13130,1,\"\"],[13131,1,\"\"],[13132,1,\"\"],[13133,1,\"\"],[13134,1,\"\"],[13135,1,\"\"],[13136,1,\"\"],[13137,1,\"\"],[13138,1,\"\"],[13139,1,\"\"],[13140,1,\"\"],[13141,1,\"\"],[13142,1,\"\"],[13143,1,\"\"],[13144,1,\"0\"],[13145,1,\"1\"],[13146,1,\"2\"],[13147,1,\"3\"],[13148,1,\"4\"],[13149,1,\"5\"],[13150,1,\"6\"],[13151,1,\"7\"],[13152,1,\"8\"],[13153,1,\"9\"],[13154,1,\"10\"],[13155,1,\"11\"],[13156,1,\"12\"],[13157,1,\"13\"],[13158,1,\"14\"],[13159,1,\"15\"],[13160,1,\"16\"],[13161,1,\"17\"],[13162,1,\"18\"],[13163,1,\"19\"],[13164,1,\"20\"],[13165,1,\"21\"],[13166,1,\"22\"],[13167,1,\"23\"],[13168,1,\"24\"],[13169,1,\"hpa\"],[13170,1,\"da\"],[13171,1,\"au\"],[13172,1,\"bar\"],[13173,1,\"ov\"],[13174,1,\"pc\"],[13175,1,\"dm\"],[13176,1,\"dm2\"],[13177,1,\"dm3\"],[13178,1,\"iu\"],[13179,1,\"\"],[13180,1,\"\"],[13181,1,\"\"],[13182,1,\"\"],[13183,1,\"\"],[13184,1,\"pa\"],[13185,1,\"na\"],[13186,1,\"a\"],[13187,1,\"ma\"],[13188,1,\"ka\"],[13189,1,\"kb\"],[13190,1,\"mb\"],[13191,1,\"gb\"],[13192,1,\"cal\"],[13193,1,\"kcal\"],[13194,1,\"pf\"],[13195,1,\"nf\"],[13196,1,\"f\"],[13197,1,\"g\"],[13198,1,\"mg\"],[13199,1,\"kg\"],[13200,1,\"hz\"],[13201,1,\"khz\"],[13202,1,\"mhz\"],[13203,1,\"ghz\"],[13204,1,\"thz\"],[13205,1,\"l\"],[13206,1,\"ml\"],[13207,1,\"dl\"],[13208,1,\"kl\"],[13209,1,\"fm\"],[13210,1,\"nm\"],[13211,1,\"m\"],[13212,1,\"mm\"],[13213,1,\"cm\"],[13214,1,\"km\"],[13215,1,\"mm2\"],[13216,1,\"cm2\"],[13217,1,\"m2\"],[13218,1,\"km2\"],[13219,1,\"mm3\"],[13220,1,\"cm3\"],[13221,1,\"m3\"],[13222,1,\"km3\"],[13223,1,\"ms\"],[13224,1,\"ms2\"],[13225,1,\"pa\"],[13226,1,\"kpa\"],[13227,1,\"mpa\"],[13228,1,\"gpa\"],[13229,1,\"rad\"],[13230,1,\"rads\"],[13231,1,\"rads2\"],[13232,1,\"ps\"],[13233,1,\"ns\"],[13234,1,\"s\"],[13235,1,\"ms\"],[13236,1,\"pv\"],[13237,1,\"nv\"],[13238,1,\"v\"],[13239,1,\"mv\"],[13240,1,\"kv\"],[13241,1,\"mv\"],[13242,1,\"pw\"],[13243,1,\"nw\"],[13244,1,\"w\"],[13245,1,\"mw\"],[13246,1,\"kw\"],[13247,1,\"mw\"],[13248,1,\"k\"],[13249,1,\"m\"],[13250,3],[13251,1,\"bq\"],[13252,1,\"cc\"],[13253,1,\"cd\"],[13254,1,\"ckg\"],[13255,3],[13256,1,\"db\"],[13257,1,\"gy\"],[13258,1,\"ha\"],[13259,1,\"hp\"],[13260,1,\"in\"],[13261,1,\"kk\"],[13262,1,\"km\"],[13263,1,\"kt\"],[13264,1,\"lm\"],[13265,1,\"ln\"],[13266,1,\"log\"],[13267,1,\"lx\"],[13268,1,\"mb\"],[13269,1,\"mil\"],[13270,1,\"mol\"],[13271,1,\"ph\"],[13272,3],[13273,1,\"ppm\"],[13274,1,\"pr\"],[13275,1,\"sr\"],[13276,1,\"sv\"],[13277,1,\"wb\"],[13278,1,\"vm\"],[13279,1,\"am\"],[13280,1,\"1\"],[13281,1,\"2\"],[13282,1,\"3\"],[13283,1,\"4\"],[13284,1,\"5\"],[13285,1,\"6\"],[13286,1,\"7\"],[13287,1,\"8\"],[13288,1,\"9\"],[13289,1,\"10\"],[13290,1,\"11\"],[13291,1,\"12\"],[13292,1,\"13\"],[13293,1,\"14\"],[13294,1,\"15\"],[13295,1,\"16\"],[13296,1,\"17\"],[13297,1,\"18\"],[13298,1,\"19\"],[13299,1,\"20\"],[13300,1,\"21\"],[13301,1,\"22\"],[13302,1,\"23\"],[13303,1,\"24\"],[13304,1,\"25\"],[13305,1,\"26\"],[13306,1,\"27\"],[13307,1,\"28\"],[13308,1,\"29\"],[13309,1,\"30\"],[13310,1,\"31\"],[13311,1,\"gal\"],[[13312,19893],2],[[19894,19903],2],[[19904,19967],2],[[19968,40869],2],[[40870,40891],2],[[40892,40899],2],[[40900,40907],2],[40908,2],[[40909,40917],2],[[40918,40938],2],[[40939,40943],2],[[40944,40956],2],[[40957,40959],2],[[40960,42124],2],[[42125,42127],3],[[42128,42145],2],[[42146,42147],2],[[42148,42163],2],[42164,2],[[42165,42176],2],[42177,2],[[42178,42180],2],[42181,2],[42182,2],[[42183,42191],3],[[42192,42237],2],[[42238,42239],2],[[42240,42508],2],[[42509,42511],2],[[42512,42539],2],[[42540,42559],3],[42560,1,\"\"],[42561,2],[42562,1,\"\"],[42563,2],[42564,1,\"\"],[42565,2],[42566,1,\"\"],[42567,2],[42568,1,\"\"],[42569,2],[42570,1,\"\"],[42571,2],[42572,1,\"\"],[42573,2],[42574,1,\"\"],[42575,2],[42576,1,\"\"],[42577,2],[42578,1,\"\"],[42579,2],[42580,1,\"\"],[42581,2],[42582,1,\"\"],[42583,2],[42584,1,\"\"],[42585,2],[42586,1,\"\"],[42587,2],[42588,1,\"\"],[42589,2],[42590,1,\"\"],[42591,2],[42592,1,\"\"],[42593,2],[42594,1,\"\"],[42595,2],[42596,1,\"\"],[42597,2],[42598,1,\"\"],[42599,2],[42600,1,\"\"],[42601,2],[42602,1,\"\"],[42603,2],[42604,1,\"\"],[[42605,42607],2],[[42608,42611],2],[[42612,42619],2],[[42620,42621],2],[42622,2],[42623,2],[42624,1,\"\"],[42625,2],[42626,1,\"\"],[42627,2],[42628,1,\"\"],[42629,2],[42630,1,\"\"],[42631,2],[42632,1,\"\"],[42633,2],[42634,1,\"\"],[42635,2],[42636,1,\"\"],[42637,2],[42638,1,\"\"],[42639,2],[42640,1,\"\"],[42641,2],[42642,1,\"\"],[42643,2],[42644,1,\"\"],[42645,2],[42646,1,\"\"],[42647,2],[42648,1,\"\"],[42649,2],[42650,1,\"\"],[42651,2],[42652,1,\"\"],[42653,1,\"\"],[42654,2],[42655,2],[[42656,42725],2],[[42726,42735],2],[[42736,42737],2],[[42738,42743],2],[[42744,42751],3],[[42752,42774],2],[[42775,42778],2],[[42779,42783],2],[[42784,42785],2],[42786,1,\"\"],[42787,2],[42788,1,\"\"],[42789,2],[42790,1,\"\"],[42791,2],[42792,1,\"\"],[42793,2],[42794,1,\"\"],[42795,2],[42796,1,\"\"],[42797,2],[42798,1,\"\"],[[42799,42801],2],[42802,1,\"\"],[42803,2],[42804,1,\"\"],[42805,2],[42806,1,\"\"],[42807,2],[42808,1,\"\"],[42809,2],[42810,1,\"\"],[42811,2],[42812,1,\"\"],[42813,2],[42814,1,\"\"],[42815,2],[42816,1,\"\"],[42817,2],[42818,1,\"\"],[42819,2],[42820,1,\"\"],[42821,2],[42822,1,\"\"],[42823,2],[42824,1,\"\"],[42825,2],[42826,1,\"\"],[42827,2],[42828,1,\"\"],[42829,2],[42830,1,\"\"],[42831,2],[42832,1,\"\"],[42833,2],[42834,1,\"\"],[42835,2],[42836,1,\"\"],[42837,2],[42838,1,\"\"],[42839,2],[42840,1,\"\"],[42841,2],[42842,1,\"\"],[42843,2],[42844,1,\"\"],[42845,2],[42846,1,\"\"],[42847,2],[42848,1,\"\"],[42849,2],[42850,1,\"\"],[42851,2],[42852,1,\"\"],[42853,2],[42854,1,\"\"],[42855,2],[42856,1,\"\"],[42857,2],[42858,1,\"\"],[42859,2],[42860,1,\"\"],[42861,2],[42862,1,\"\"],[42863,2],[42864,1,\"\"],[[42865,42872],2],[42873,1,\"\"],[42874,2],[42875,1,\"\"],[42876,2],[42877,1,\"\"],[42878,1,\"\"],[42879,2],[42880,1,\"\"],[42881,2],[42882,1,\"\"],[42883,2],[42884,1,\"\"],[42885,2],[42886,1,\"\"],[[42887,42888],2],[[42889,42890],2],[42891,1,\"\"],[42892,2],[42893,1,\"\"],[42894,2],[42895,2],[42896,1,\"\"],[42897,2],[42898,1,\"\"],[42899,2],[[42900,42901],2],[42902,1,\"\"],[42903,2],[42904,1,\"\"],[42905,2],[42906,1,\"\"],[42907,2],[42908,1,\"\"],[42909,2],[42910,1,\"\"],[42911,2],[42912,1,\"\"],[42913,2],[42914,1,\"\"],[42915,2],[42916,1,\"\"],[42917,2],[42918,1,\"\"],[42919,2],[42920,1,\"\"],[42921,2],[42922,1,\"\"],[42923,1,\"\"],[42924,1,\"\"],[42925,1,\"\"],[42926,1,\"\"],[42927,2],[42928,1,\"\"],[42929,1,\"\"],[42930,1,\"\"],[42931,1,\"\"],[42932,1,\"\"],[42933,2],[42934,1,\"\"],[42935,2],[42936,1,\"\"],[42937,2],[42938,1,\"\"],[42939,2],[42940,1,\"\"],[42941,2],[42942,1,\"\"],[42943,2],[42944,1,\"\"],[42945,2],[42946,1,\"\"],[42947,2],[42948,1,\"\"],[42949,1,\"\"],[42950,1,\"\"],[42951,1,\"\"],[42952,2],[42953,1,\"\"],[42954,2],[[42955,42959],3],[42960,1,\"\"],[42961,2],[42962,3],[42963,2],[42964,3],[42965,2],[42966,1,\"\"],[42967,2],[42968,1,\"\"],[42969,2],[[42970,42993],3],[42994,1,\"c\"],[42995,1,\"f\"],[42996,1,\"q\"],[42997,1,\"\"],[42998,2],[42999,2],[43000,1,\"\"],[43001,1,\"\"],[43002,2],[[43003,43007],2],[[43008,43047],2],[[43048,43051],2],[43052,2],[[43053,43055],3],[[43056,43065],2],[[43066,43071],3],[[43072,43123],2],[[43124,43127],2],[[43128,43135],3],[[43136,43204],2],[43205,2],[[43206,43213],3],[[43214,43215],2],[[43216,43225],2],[[43226,43231],3],[[43232,43255],2],[[43256,43258],2],[43259,2],[43260,2],[43261,2],[[43262,43263],2],[[43264,43309],2],[[43310,43311],2],[[43312,43347],2],[[43348,43358],3],[43359,2],[[43360,43388],2],[[43389,43391],3],[[43392,43456],2],[[43457,43469],2],[43470,3],[[43471,43481],2],[[43482,43485],3],[[43486,43487],2],[[43488,43518],2],[43519,3],[[43520,43574],2],[[43575,43583],3],[[43584,43597],2],[[43598,43599],3],[[43600,43609],2],[[43610,43611],3],[[43612,43615],2],[[43616,43638],2],[[43639,43641],2],[[43642,43643],2],[[43644,43647],2],[[43648,43714],2],[[43715,43738],3],[[43739,43741],2],[[43742,43743],2],[[43744,43759],2],[[43760,43761],2],[[43762,43766],2],[[43767,43776],3],[[43777,43782],2],[[43783,43784],3],[[43785,43790],2],[[43791,43792],3],[[43793,43798],2],[[43799,43807],3],[[43808,43814],2],[43815,3],[[43816,43822],2],[43823,3],[[43824,43866],2],[43867,2],[43868,1,\"\"],[43869,1,\"\"],[43870,1,\"\"],[43871,1,\"\"],[[43872,43875],2],[[43876,43877],2],[[43878,43879],2],[43880,2],[43881,1,\"\"],[[43882,43883],2],[[43884,43887],3],[43888,1,\"\"],[43889,1,\"\"],[43890,1,\"\"],[43891,1,\"\"],[43892,1,\"\"],[43893,1,\"\"],[43894,1,\"\"],[43895,1,\"\"],[43896,1,\"\"],[43897,1,\"\"],[43898,1,\"\"],[43899,1,\"\"],[43900,1,\"\"],[43901,1,\"\"],[43902,1,\"\"],[43903,1,\"\"],[43904,1,\"\"],[43905,1,\"\"],[43906,1,\"\"],[43907,1,\"\"],[43908,1,\"\"],[43909,1,\"\"],[43910,1,\"\"],[43911,1,\"\"],[43912,1,\"\"],[43913,1,\"\"],[43914,1,\"\"],[43915,1,\"\"],[43916,1,\"\"],[43917,1,\"\"],[43918,1,\"\"],[43919,1,\"\"],[43920,1,\"\"],[43921,1,\"\"],[43922,1,\"\"],[43923,1,\"\"],[43924,1,\"\"],[43925,1,\"\"],[43926,1,\"\"],[43927,1,\"\"],[43928,1,\"\"],[43929,1,\"\"],[43930,1,\"\"],[43931,1,\"\"],[43932,1,\"\"],[43933,1,\"\"],[43934,1,\"\"],[43935,1,\"\"],[43936,1,\"\"],[43937,1,\"\"],[43938,1,\"\"],[43939,1,\"\"],[43940,1,\"\"],[43941,1,\"\"],[43942,1,\"\"],[43943,1,\"\"],[43944,1,\"\"],[43945,1,\"\"],[43946,1,\"\"],[43947,1,\"\"],[43948,1,\"\"],[43949,1,\"\"],[43950,1,\"\"],[43951,1,\"\"],[43952,1,\"\"],[43953,1,\"\"],[43954,1,\"\"],[43955,1,\"\"],[43956,1,\"\"],[43957,1,\"\"],[43958,1,\"\"],[43959,1,\"\"],[43960,1,\"\"],[43961,1,\"\"],[43962,1,\"\"],[43963,1,\"\"],[43964,1,\"\"],[43965,1,\"\"],[43966,1,\"\"],[43967,1,\"\"],[[43968,44010],2],[44011,2],[[44012,44013],2],[[44014,44015],3],[[44016,44025],2],[[44026,44031],3],[[44032,55203],2],[[55204,55215],3],[[55216,55238],2],[[55239,55242],3],[[55243,55291],2],[[55292,55295],3],[[55296,57343],3],[[57344,63743],3],[63744,1,\"\"],[63745,1,\"\"],[63746,1,\"\"],[63747,1,\"\"],[63748,1,\"\"],[63749,1,\"\"],[63750,1,\"\"],[[63751,63752],1,\"\"],[63753,1,\"\"],[63754,1,\"\"],[63755,1,\"\"],[63756,1,\"\"],[63757,1,\"\"],[63758,1,\"\"],[63759,1,\"\"],[63760,1,\"\"],[63761,1,\"\"],[63762,1,\"\"],[63763,1,\"\"],[63764,1,\"\"],[63765,1,\"\"],[63766,1,\"\"],[63767,1,\"\"],[63768,1,\"\"],[63769,1,\"\"],[63770,1,\"\"],[63771,1,\"\"],[63772,1,\"\"],[63773,1,\"\"],[63774,1,\"\"],[63775,1,\"\"],[63776,1,\"\"],[63777,1,\"\"],[63778,1,\"\"],[63779,1,\"\"],[63780,1,\"\"],[63781,1,\"\"],[63782,1,\"\"],[63783,1,\"\"],[63784,1,\"\"],[63785,1,\"\"],[63786,1,\"\"],[63787,1,\"\"],[63788,1,\"\"],[63789,1,\"\"],[63790,1,\"\"],[63791,1,\"\"],[63792,1,\"\"],[63793,1,\"\"],[63794,1,\"\"],[63795,1,\"\"],[63796,1,\"\"],[63797,1,\"\"],[63798,1,\"\"],[63799,1,\"\"],[63800,1,\"\"],[63801,1,\"\"],[63802,1,\"\"],[63803,1,\"\"],[63804,1,\"\"],[63805,1,\"\"],[63806,1,\"\"],[63807,1,\"\"],[63808,1,\"\"],[63809,1,\"\"],[63810,1,\"\"],[63811,1,\"\"],[63812,1,\"\"],[63813,1,\"\"],[63814,1,\"\"],[63815,1,\"\"],[63816,1,\"\"],[63817,1,\"\"],[63818,1,\"\"],[63819,1,\"\"],[63820,1,\"\"],[63821,1,\"\"],[63822,1,\"\"],[63823,1,\"\"],[63824,1,\"\"],[63825,1,\"\"],[63826,1,\"\"],[63827,1,\"\"],[63828,1,\"\"],[63829,1,\"\"],[63830,1,\"\"],[63831,1,\"\"],[63832,1,\"\"],[63833,1,\"\"],[63834,1,\"\"],[63835,1,\"\"],[63836,1,\"\"],[63837,1,\"\"],[63838,1,\"\"],[63839,1,\"\"],[63840,1,\"\"],[63841,1,\"\"],[63842,1,\"\"],[63843,1,\"\"],[63844,1,\"\"],[63845,1,\"\"],[63846,1,\"\"],[63847,1,\"\"],[63848,1,\"\"],[63849,1,\"\"],[63850,1,\"\"],[63851,1,\"\"],[63852,1,\"\"],[63853,1,\"\"],[63854,1,\"\"],[63855,1,\"\"],[63856,1,\"\"],[63857,1,\"\"],[63858,1,\"\"],[63859,1,\"\"],[63860,1,\"\"],[63861,1,\"\"],[63862,1,\"\"],[63863,1,\"\"],[63864,1,\"\"],[63865,1,\"\"],[63866,1,\"\"],[63867,1,\"\"],[63868,1,\"\"],[63869,1,\"\"],[63870,1,\"\"],[63871,1,\"\"],[63872,1,\"\"],[63873,1,\"\"],[63874,1,\"\"],[63875,1,\"\"],[63876,1,\"\"],[63877,1,\"\"],[63878,1,\"\"],[63879,1,\"\"],[63880,1,\"\"],[63881,1,\"\"],[63882,1,\"\"],[63883,1,\"\"],[63884,1,\"\"],[63885,1,\"\"],[63886,1,\"\"],[63887,1,\"\"],[63888,1,\"\"],[63889,1,\"\"],[63890,1,\"\"],[63891,1,\"\"],[63892,1,\"\"],[63893,1,\"\"],[63894,1,\"\"],[63895,1,\"\"],[63896,1,\"\"],[63897,1,\"\"],[63898,1,\"\"],[63899,1,\"\"],[63900,1,\"\"],[63901,1,\"\"],[63902,1,\"\"],[63903,1,\"\"],[63904,1,\"\"],[63905,1,\"\"],[63906,1,\"\"],[63907,1,\"\"],[63908,1,\"\"],[63909,1,\"\"],[63910,1,\"\"],[63911,1,\"\"],[63912,1,\"\"],[63913,1,\"\"],[63914,1,\"\"],[63915,1,\"\"],[63916,1,\"\"],[63917,1,\"\"],[63918,1,\"\"],[63919,1,\"\"],[63920,1,\"\"],[63921,1,\"\"],[63922,1,\"\"],[63923,1,\"\"],[63924,1,\"\"],[63925,1,\"\"],[63926,1,\"\"],[63927,1,\"\"],[63928,1,\"\"],[63929,1,\"\"],[63930,1,\"\"],[63931,1,\"\"],[63932,1,\"\"],[63933,1,\"\"],[63934,1,\"\"],[63935,1,\"\"],[63936,1,\"\"],[63937,1,\"\"],[63938,1,\"\"],[63939,1,\"\"],[63940,1,\"\"],[63941,1,\"\"],[63942,1,\"\"],[63943,1,\"\"],[63944,1,\"\"],[63945,1,\"\"],[63946,1,\"\"],[63947,1,\"\"],[63948,1,\"\"],[63949,1,\"\"],[63950,1,\"\"],[63951,1,\"\"],[63952,1,\"\"],[63953,1,\"\"],[63954,1,\"\"],[63955,1,\"\"],[63956,1,\"\"],[63957,1,\"\"],[63958,1,\"\"],[63959,1,\"\"],[63960,1,\"\"],[63961,1,\"\"],[63962,1,\"\"],[63963,1,\"\"],[63964,1,\"\"],[63965,1,\"\"],[63966,1,\"\"],[63967,1,\"\"],[63968,1,\"\"],[63969,1,\"\"],[63970,1,\"\"],[63971,1,\"\"],[63972,1,\"\"],[63973,1,\"\"],[63974,1,\"\"],[63975,1,\"\"],[63976,1,\"\"],[63977,1,\"\"],[63978,1,\"\"],[63979,1,\"\"],[63980,1,\"\"],[63981,1,\"\"],[63982,1,\"\"],[63983,1,\"\"],[63984,1,\"\"],[63985,1,\"\"],[63986,1,\"\"],[63987,1,\"\"],[63988,1,\"\"],[63989,1,\"\"],[63990,1,\"\"],[63991,1,\"\"],[63992,1,\"\"],[63993,1,\"\"],[63994,1,\"\"],[63995,1,\"\"],[63996,1,\"\"],[63997,1,\"\"],[63998,1,\"\"],[63999,1,\"\"],[64000,1,\"\"],[64001,1,\"\"],[64002,1,\"\"],[64003,1,\"\"],[64004,1,\"\"],[64005,1,\"\"],[64006,1,\"\"],[64007,1,\"\"],[64008,1,\"\"],[64009,1,\"\"],[64010,1,\"\"],[64011,1,\"\"],[64012,1,\"\"],[64013,1,\"\"],[[64014,64015],2],[64016,1,\"\"],[64017,2],[64018,1,\"\"],[[64019,64020],2],[64021,1,\"\"],[64022,1,\"\"],[64023,1,\"\"],[64024,1,\"\"],[64025,1,\"\"],[64026,1,\"\"],[64027,1,\"\"],[64028,1,\"\"],[64029,1,\"\"],[64030,1,\"\"],[64031,2],[64032,1,\"\"],[64033,2],[64034,1,\"\"],[[64035,64036],2],[64037,1,\"\"],[64038,1,\"\"],[[64039,64041],2],[64042,1,\"\"],[64043,1,\"\"],[64044,1,\"\"],[64045,1,\"\"],[64046,1,\"\"],[64047,1,\"\"],[64048,1,\"\"],[64049,1,\"\"],[64050,1,\"\"],[64051,1,\"\"],[64052,1,\"\"],[64053,1,\"\"],[64054,1,\"\"],[64055,1,\"\"],[64056,1,\"\"],[64057,1,\"\"],[64058,1,\"\"],[64059,1,\"\"],[64060,1,\"\"],[64061,1,\"\"],[64062,1,\"\"],[64063,1,\"\"],[64064,1,\"\"],[64065,1,\"\"],[64066,1,\"\"],[64067,1,\"\"],[64068,1,\"\"],[64069,1,\"\"],[64070,1,\"\"],[64071,1,\"\"],[64072,1,\"\"],[64073,1,\"\"],[64074,1,\"\"],[64075,1,\"\"],[64076,1,\"\"],[64077,1,\"\"],[64078,1,\"\"],[64079,1,\"\"],[64080,1,\"\"],[64081,1,\"\"],[64082,1,\"\"],[64083,1,\"\"],[64084,1,\"\"],[64085,1,\"\"],[64086,1,\"\"],[64087,1,\"\"],[64088,1,\"\"],[64089,1,\"\"],[64090,1,\"\"],[64091,1,\"\"],[64092,1,\"\"],[[64093,64094],1,\"\"],[64095,1,\"\"],[64096,1,\"\"],[64097,1,\"\"],[64098,1,\"\"],[64099,1,\"\"],[64100,1,\"\"],[64101,1,\"\"],[64102,1,\"\"],[64103,1,\"\"],[64104,1,\"\"],[64105,1,\"\"],[64106,1,\"\"],[64107,1,\"\"],[64108,1,\"\"],[64109,1,\"\"],[[64110,64111],3],[64112,1,\"\"],[64113,1,\"\"],[64114,1,\"\"],[64115,1,\"\"],[64116,1,\"\"],[64117,1,\"\"],[64118,1,\"\"],[64119,1,\"\"],[64120,1,\"\"],[64121,1,\"\"],[64122,1,\"\"],[64123,1,\"\"],[64124,1,\"\"],[64125,1,\"\"],[64126,1,\"\"],[64127,1,\"\"],[64128,1,\"\"],[64129,1,\"\"],[64130,1,\"\"],[64131,1,\"\"],[64132,1,\"\"],[64133,1,\"\"],[64134,1,\"\"],[64135,1,\"\"],[64136,1,\"\"],[64137,1,\"\"],[64138,1,\"\"],[64139,1,\"\"],[64140,1,\"\"],[64141,1,\"\"],[64142,1,\"\"],[64143,1,\"\"],[64144,1,\"\"],[64145,1,\"\"],[64146,1,\"\"],[64147,1,\"\"],[64148,1,\"\"],[64149,1,\"\"],[64150,1,\"\"],[64151,1,\"\"],[64152,1,\"\"],[64153,1,\"\"],[64154,1,\"\"],[64155,1,\"\"],[64156,1,\"\"],[64157,1,\"\"],[64158,1,\"\"],[64159,1,\"\"],[64160,1,\"\"],[64161,1,\"\"],[64162,1,\"\"],[64163,1,\"\"],[64164,1,\"\"],[64165,1,\"\"],[64166,1,\"\"],[64167,1,\"\"],[64168,1,\"\"],[64169,1,\"\"],[64170,1,\"\"],[64171,1,\"\"],[64172,1,\"\"],[64173,1,\"\"],[64174,1,\"\"],[64175,1,\"\"],[64176,1,\"\"],[64177,1,\"\"],[64178,1,\"\"],[64179,1,\"\"],[64180,1,\"\"],[64181,1,\"\"],[64182,1,\"\"],[64183,1,\"\"],[64184,1,\"\"],[64185,1,\"\"],[64186,1,\"\"],[64187,1,\"\"],[64188,1,\"\"],[64189,1,\"\"],[64190,1,\"\"],[64191,1,\"\"],[64192,1,\"\"],[64193,1,\"\"],[64194,1,\"\"],[64195,1,\"\"],[64196,1,\"\"],[64197,1,\"\"],[64198,1,\"\"],[64199,1,\"\"],[64200,1,\"\"],[64201,1,\"\"],[64202,1,\"\"],[64203,1,\"\"],[64204,1,\"\"],[64205,1,\"\"],[64206,1,\"\"],[64207,1,\"\"],[64208,1,\"\"],[64209,1,\"\"],[64210,1,\"\"],[64211,1,\"\"],[64212,1,\"\"],[64213,1,\"\"],[64214,1,\"\"],[64215,1,\"\"],[64216,1,\"\"],[64217,1,\"\"],[[64218,64255],3],[64256,1,\"ff\"],[64257,1,\"fi\"],[64258,1,\"fl\"],[64259,1,\"ffi\"],[64260,1,\"ffl\"],[[64261,64262],1,\"st\"],[[64263,64274],3],[64275,1,\"\"],[64276,1,\"\"],[64277,1,\"\"],[64278,1,\"\"],[64279,1,\"\"],[[64280,64284],3],[64285,1,\"\"],[64286,2],[64287,1,\"\"],[64288,1,\"\"],[64289,1,\"\"],[64290,1,\"\"],[64291,1,\"\"],[64292,1,\"\"],[64293,1,\"\"],[64294,1,\"\"],[64295,1,\"\"],[64296,1,\"\"],[64297,5,\"+\"],[64298,1,\"\"],[64299,1,\"\"],[64300,1,\"\"],[64301,1,\"\"],[64302,1,\"\"],[64303,1,\"\"],[64304,1,\"\"],[64305,1,\"\"],[64306,1,\"\"],[64307,1,\"\"],[64308,1,\"\"],[64309,1,\"\"],[64310,1,\"\"],[64311,3],[64312,1,\"\"],[64313,1,\"\"],[64314,1,\"\"],[64315,1,\"\"],[64316,1,\"\"],[64317,3],[64318,1,\"\"],[64319,3],[64320,1,\"\"],[64321,1,\"\"],[64322,3],[64323,1,\"\"],[64324,1,\"\"],[64325,3],[64326,1,\"\"],[64327,1,\"\"],[64328,1,\"\"],[64329,1,\"\"],[64330,1,\"\"],[64331,1,\"\"],[64332,1,\"\"],[64333,1,\"\"],[64334,1,\"\"],[64335,1,\"\"],[[64336,64337],1,\"\"],[[64338,64341],1,\"\"],[[64342,64345],1,\"\"],[[64346,64349],1,\"\"],[[64350,64353],1,\"\"],[[64354,64357],1,\"\"],[[64358,64361],1,\"\"],[[64362,64365],1,\"\"],[[64366,64369],1,\"\"],[[64370,64373],1,\"\"],[[64374,64377],1,\"\"],[[64378,64381],1,\"\"],[[64382,64385],1,\"\"],[[64386,64387],1,\"\"],[[64388,64389],1,\"\"],[[64390,64391],1,\"\"],[[64392,64393],1,\"\"],[[64394,64395],1,\"\"],[[64396,64397],1,\"\"],[[64398,64401],1,\"\"],[[64402,64405],1,\"\"],[[64406,64409],1,\"\"],[[64410,64413],1,\"\"],[[64414,64415],1,\"\"],[[64416,64419],1,\"\"],[[64420,64421],1,\"\"],[[64422,64425],1,\"\"],[[64426,64429],1,\"\"],[[64430,64431],1,\"\"],[[64432,64433],1,\"\"],[[64434,64449],2],[64450,2],[[64451,64466],3],[[64467,64470],1,\"\"],[[64471,64472],1,\"\"],[[64473,64474],1,\"\"],[[64475,64476],1,\"\"],[64477,1,\"\"],[[64478,64479],1,\"\"],[[64480,64481],1,\"\"],[[64482,64483],1,\"\"],[[64484,64487],1,\"\"],[[64488,64489],1,\"\"],[[64490,64491],1,\"\"],[[64492,64493],1,\"\"],[[64494,64495],1,\"\"],[[64496,64497],1,\"\"],[[64498,64499],1,\"\"],[[64500,64501],1,\"\"],[[64502,64504],1,\"\"],[[64505,64507],1,\"\"],[[64508,64511],1,\"\"],[64512,1,\"\"],[64513,1,\"\"],[64514,1,\"\"],[64515,1,\"\"],[64516,1,\"\"],[64517,1,\"\"],[64518,1,\"\"],[64519,1,\"\"],[64520,1,\"\"],[64521,1,\"\"],[64522,1,\"\"],[64523,1,\"\"],[64524,1,\"\"],[64525,1,\"\"],[64526,1,\"\"],[64527,1,\"\"],[64528,1,\"\"],[64529,1,\"\"],[64530,1,\"\"],[64531,1,\"\"],[64532,1,\"\"],[64533,1,\"\"],[64534,1,\"\"],[64535,1,\"\"],[64536,1,\"\"],[64537,1,\"\"],[64538,1,\"\"],[64539,1,\"\"],[64540,1,\"\"],[64541,1,\"\"],[64542,1,\"\"],[64543,1,\"\"],[64544,1,\"\"],[64545,1,\"\"],[64546,1,\"\"],[64547,1,\"\"],[64548,1,\"\"],[64549,1,\"\"],[64550,1,\"\"],[64551,1,\"\"],[64552,1,\"\"],[64553,1,\"\"],[64554,1,\"\"],[64555,1,\"\"],[64556,1,\"\"],[64557,1,\"\"],[64558,1,\"\"],[64559,1,\"\"],[64560,1,\"\"],[64561,1,\"\"],[64562,1,\"\"],[64563,1,\"\"],[64564,1,\"\"],[64565,1,\"\"],[64566,1,\"\"],[64567,1,\"\"],[64568,1,\"\"],[64569,1,\"\"],[64570,1,\"\"],[64571,1,\"\"],[64572,1,\"\"],[64573,1,\"\"],[64574,1,\"\"],[64575,1,\"\"],[64576,1,\"\"],[64577,1,\"\"],[64578,1,\"\"],[64579,1,\"\"],[64580,1,\"\"],[64581,1,\"\"],[64582,1,\"\"],[64583,1,\"\"],[64584,1,\"\"],[64585,1,\"\"],[64586,1,\"\"],[64587,1,\"\"],[64588,1,\"\"],[64589,1,\"\"],[64590,1,\"\"],[64591,1,\"\"],[64592,1,\"\"],[64593,1,\"\"],[64594,1,\"\"],[64595,1,\"\"],[64596,1,\"\"],[64597,1,\"\"],[64598,1,\"\"],[64599,1,\"\"],[64600,1,\"\"],[64601,1,\"\"],[64602,1,\"\"],[64603,1,\"\"],[64604,1,\"\"],[64605,1,\"\"],[64606,5,\" \"],[64607,5,\" \"],[64608,5,\" \"],[64609,5,\" \"],[64610,5,\" \"],[64611,5,\" \"],[64612,1,\"\"],[64613,1,\"\"],[64614,1,\"\"],[64615,1,\"\"],[64616,1,\"\"],[64617,1,\"\"],[64618,1,\"\"],[64619,1,\"\"],[64620,1,\"\"],[64621,1,\"\"],[64622,1,\"\"],[64623,1,\"\"],[64624,1,\"\"],[64625,1,\"\"],[64626,1,\"\"],[64627,1,\"\"],[64628,1,\"\"],[64629,1,\"\"],[64630,1,\"\"],[64631,1,\"\"],[64632,1,\"\"],[64633,1,\"\"],[64634,1,\"\"],[64635,1,\"\"],[64636,1,\"\"],[64637,1,\"\"],[64638,1,\"\"],[64639,1,\"\"],[64640,1,\"\"],[64641,1,\"\"],[64642,1,\"\"],[64643,1,\"\"],[64644,1,\"\"],[64645,1,\"\"],[64646,1,\"\"],[64647,1,\"\"],[64648,1,\"\"],[64649,1,\"\"],[64650,1,\"\"],[64651,1,\"\"],[64652,1,\"\"],[64653,1,\"\"],[64654,1,\"\"],[64655,1,\"\"],[64656,1,\"\"],[64657,1,\"\"],[64658,1,\"\"],[64659,1,\"\"],[64660,1,\"\"],[64661,1,\"\"],[64662,1,\"\"],[64663,1,\"\"],[64664,1,\"\"],[64665,1,\"\"],[64666,1,\"\"],[64667,1,\"\"],[64668,1,\"\"],[64669,1,\"\"],[64670,1,\"\"],[64671,1,\"\"],[64672,1,\"\"],[64673,1,\"\"],[64674,1,\"\"],[64675,1,\"\"],[64676,1,\"\"],[64677,1,\"\"],[64678,1,\"\"],[64679,1,\"\"],[64680,1,\"\"],[64681,1,\"\"],[64682,1,\"\"],[64683,1,\"\"],[64684,1,\"\"],[64685,1,\"\"],[64686,1,\"\"],[64687,1,\"\"],[64688,1,\"\"],[64689,1,\"\"],[64690,1,\"\"],[64691,1,\"\"],[64692,1,\"\"],[64693,1,\"\"],[64694,1,\"\"],[64695,1,\"\"],[64696,1,\"\"],[64697,1,\"\"],[64698,1,\"\"],[64699,1,\"\"],[64700,1,\"\"],[64701,1,\"\"],[64702,1,\"\"],[64703,1,\"\"],[64704,1,\"\"],[64705,1,\"\"],[64706,1,\"\"],[64707,1,\"\"],[64708,1,\"\"],[64709,1,\"\"],[64710,1,\"\"],[64711,1,\"\"],[64712,1,\"\"],[64713,1,\"\"],[64714,1,\"\"],[64715,1,\"\"],[64716,1,\"\"],[64717,1,\"\"],[64718,1,\"\"],[64719,1,\"\"],[64720,1,\"\"],[64721,1,\"\"],[64722,1,\"\"],[64723,1,\"\"],[64724,1,\"\"],[64725,1,\"\"],[64726,1,\"\"],[64727,1,\"\"],[64728,1,\"\"],[64729,1,\"\"],[64730,1,\"\"],[64731,1,\"\"],[64732,1,\"\"],[64733,1,\"\"],[64734,1,\"\"],[64735,1,\"\"],[64736,1,\"\"],[64737,1,\"\"],[64738,1,\"\"],[64739,1,\"\"],[64740,1,\"\"],[64741,1,\"\"],[64742,1,\"\"],[64743,1,\"\"],[64744,1,\"\"],[64745,1,\"\"],[64746,1,\"\"],[64747,1,\"\"],[64748,1,\"\"],[64749,1,\"\"],[64750,1,\"\"],[64751,1,\"\"],[64752,1,\"\"],[64753,1,\"\"],[64754,1,\"\"],[64755,1,\"\"],[64756,1,\"\"],[64757,1,\"\"],[64758,1,\"\"],[64759,1,\"\"],[64760,1,\"\"],[64761,1,\"\"],[64762,1,\"\"],[64763,1,\"\"],[64764,1,\"\"],[64765,1,\"\"],[64766,1,\"\"],[64767,1,\"\"],[64768,1,\"\"],[64769,1,\"\"],[64770,1,\"\"],[64771,1,\"\"],[64772,1,\"\"],[64773,1,\"\"],[64774,1,\"\"],[64775,1,\"\"],[64776,1,\"\"],[64777,1,\"\"],[64778,1,\"\"],[64779,1,\"\"],[64780,1,\"\"],[64781,1,\"\"],[64782,1,\"\"],[64783,1,\"\"],[64784,1,\"\"],[64785,1,\"\"],[64786,1,\"\"],[64787,1,\"\"],[64788,1,\"\"],[64789,1,\"\"],[64790,1,\"\"],[64791,1,\"\"],[64792,1,\"\"],[64793,1,\"\"],[64794,1,\"\"],[64795,1,\"\"],[64796,1,\"\"],[64797,1,\"\"],[64798,1,\"\"],[64799,1,\"\"],[64800,1,\"\"],[64801,1,\"\"],[64802,1,\"\"],[64803,1,\"\"],[64804,1,\"\"],[64805,1,\"\"],[64806,1,\"\"],[64807,1,\"\"],[64808,1,\"\"],[64809,1,\"\"],[64810,1,\"\"],[64811,1,\"\"],[64812,1,\"\"],[64813,1,\"\"],[64814,1,\"\"],[64815,1,\"\"],[64816,1,\"\"],[64817,1,\"\"],[64818,1,\"\"],[64819,1,\"\"],[64820,1,\"\"],[64821,1,\"\"],[64822,1,\"\"],[64823,1,\"\"],[64824,1,\"\"],[64825,1,\"\"],[64826,1,\"\"],[64827,1,\"\"],[[64828,64829],1,\"\"],[[64830,64831],2],[[64832,64847],2],[64848,1,\"\"],[[64849,64850],1,\"\"],[64851,1,\"\"],[64852,1,\"\"],[64853,1,\"\"],[64854,1,\"\"],[64855,1,\"\"],[[64856,64857],1,\"\"],[64858,1,\"\"],[64859,1,\"\"],[64860,1,\"\"],[64861,1,\"\"],[64862,1,\"\"],[[64863,64864],1,\"\"],[64865,1,\"\"],[[64866,64867],1,\"\"],[[64868,64869],1,\"\"],[64870,1,\"\"],[[64871,64872],1,\"\"],[64873,1,\"\"],[[64874,64875],1,\"\"],[[64876,64877],1,\"\"],[64878,1,\"\"],[[64879,64880],1,\"\"],[[64881,64882],1,\"\"],[64883,1,\"\"],[64884,1,\"\"],[64885,1,\"\"],[[64886,64887],1,\"\"],[64888,1,\"\"],[64889,1,\"\"],[64890,1,\"\"],[64891,1,\"\"],[[64892,64893],1,\"\"],[64894,1,\"\"],[64895,1,\"\"],[64896,1,\"\"],[64897,1,\"\"],[64898,1,\"\"],[[64899,64900],1,\"\"],[[64901,64902],1,\"\"],[[64903,64904],1,\"\"],[64905,1,\"\"],[64906,1,\"\"],[64907,1,\"\"],[64908,1,\"\"],[64909,1,\"\"],[64910,1,\"\"],[64911,1,\"\"],[[64912,64913],3],[64914,1,\"\"],[64915,1,\"\"],[64916,1,\"\"],[64917,1,\"\"],[64918,1,\"\"],[[64919,64920],1,\"\"],[64921,1,\"\"],[64922,1,\"\"],[64923,1,\"\"],[[64924,64925],1,\"\"],[64926,1,\"\"],[64927,1,\"\"],[64928,1,\"\"],[64929,1,\"\"],[64930,1,\"\"],[64931,1,\"\"],[64932,1,\"\"],[64933,1,\"\"],[64934,1,\"\"],[64935,1,\"\"],[64936,1,\"\"],[64937,1,\"\"],[64938,1,\"\"],[64939,1,\"\"],[64940,1,\"\"],[64941,1,\"\"],[64942,1,\"\"],[64943,1,\"\"],[64944,1,\"\"],[64945,1,\"\"],[64946,1,\"\"],[64947,1,\"\"],[64948,1,\"\"],[64949,1,\"\"],[64950,1,\"\"],[64951,1,\"\"],[64952,1,\"\"],[64953,1,\"\"],[64954,1,\"\"],[64955,1,\"\"],[64956,1,\"\"],[64957,1,\"\"],[64958,1,\"\"],[64959,1,\"\"],[64960,1,\"\"],[64961,1,\"\"],[64962,1,\"\"],[64963,1,\"\"],[64964,1,\"\"],[64965,1,\"\"],[64966,1,\"\"],[64967,1,\"\"],[[64968,64974],3],[64975,2],[[64976,65007],3],[65008,1,\"\"],[65009,1,\"\"],[65010,1,\"\"],[65011,1,\"\"],[65012,1,\"\"],[65013,1,\"\"],[65014,1,\"\"],[65015,1,\"\"],[65016,1,\"\"],[65017,1,\"\"],[65018,5,\"   \"],[65019,5,\" \"],[65020,1,\"\"],[65021,2],[[65022,65023],2],[[65024,65039],7],[65040,5,\",\"],[65041,1,\"\"],[65042,3],[65043,5,\":\"],[65044,5,\";\"],[65045,5,\"!\"],[65046,5,\"?\"],[65047,1,\"\"],[65048,1,\"\"],[65049,3],[[65050,65055],3],[[65056,65059],2],[[65060,65062],2],[[65063,65069],2],[[65070,65071],2],[65072,3],[65073,1,\"\"],[65074,1,\"\"],[[65075,65076],5,\"_\"],[65077,5,\"(\"],[65078,5,\")\"],[65079,5,\"{\"],[65080,5,\"}\"],[65081,1,\"\"],[65082,1,\"\"],[65083,1,\"\"],[65084,1,\"\"],[65085,1,\"\"],[65086,1,\"\"],[65087,1,\"\"],[65088,1,\"\"],[65089,1,\"\"],[65090,1,\"\"],[65091,1,\"\"],[65092,1,\"\"],[[65093,65094],2],[65095,5,\"[\"],[65096,5,\"]\"],[[65097,65100],5,\" \"],[[65101,65103],5,\"_\"],[65104,5,\",\"],[65105,1,\"\"],[65106,3],[65107,3],[65108,5,\";\"],[65109,5,\":\"],[65110,5,\"?\"],[65111,5,\"!\"],[65112,1,\"\"],[65113,5,\"(\"],[65114,5,\")\"],[65115,5,\"{\"],[65116,5,\"}\"],[65117,1,\"\"],[65118,1,\"\"],[65119,5,\"#\"],[65120,5,\"&\"],[65121,5,\"*\"],[65122,5,\"+\"],[65123,1,\"-\"],[65124,5,\"<\"],[65125,5,\">\"],[65126,5,\"=\"],[65127,3],[65128,5,\"\\\\\\\\\"],[65129,5,\"$\"],[65130,5,\"%\"],[65131,5,\"@\"],[[65132,65135],3],[65136,5,\" \"],[65137,1,\"\"],[65138,5,\" \"],[65139,2],[65140,5,\" \"],[65141,3],[65142,5,\" \"],[65143,1,\"\"],[65144,5,\" \"],[65145,1,\"\"],[65146,5,\" \"],[65147,1,\"\"],[65148,5,\" \"],[65149,1,\"\"],[65150,5,\" \"],[65151,1,\"\"],[65152,1,\"\"],[[65153,65154],1,\"\"],[[65155,65156],1,\"\"],[[65157,65158],1,\"\"],[[65159,65160],1,\"\"],[[65161,65164],1,\"\"],[[65165,65166],1,\"\"],[[65167,65170],1,\"\"],[[65171,65172],1,\"\"],[[65173,65176],1,\"\"],[[65177,65180],1,\"\"],[[65181,65184],1,\"\"],[[65185,65188],1,\"\"],[[65189,65192],1,\"\"],[[65193,65194],1,\"\"],[[65195,65196],1,\"\"],[[65197,65198],1,\"\"],[[65199,65200],1,\"\"],[[65201,65204],1,\"\"],[[65205,65208],1,\"\"],[[65209,65212],1,\"\"],[[65213,65216],1,\"\"],[[65217,65220],1,\"\"],[[65221,65224],1,\"\"],[[65225,65228],1,\"\"],[[65229,65232],1,\"\"],[[65233,65236],1,\"\"],[[65237,65240],1,\"\"],[[65241,65244],1,\"\"],[[65245,65248],1,\"\"],[[65249,65252],1,\"\"],[[65253,65256],1,\"\"],[[65257,65260],1,\"\"],[[65261,65262],1,\"\"],[[65263,65264],1,\"\"],[[65265,65268],1,\"\"],[[65269,65270],1,\"\"],[[65271,65272],1,\"\"],[[65273,65274],1,\"\"],[[65275,65276],1,\"\"],[[65277,65278],3],[65279,7],[65280,3],[65281,5,\"!\"],[65282,5,\"\\\\\"\"],[65283,5,\"#\"],[65284,5,\"$\"],[65285,5,\"%\"],[65286,5,\"&\"],[65287,5,\"\\'\"],[65288,5,\"(\"],[65289,5,\")\"],[65290,5,\"*\"],[65291,5,\"+\"],[65292,5,\",\"],[65293,1,\"-\"],[65294,1,\".\"],[65295,5,\"/\"],[65296,1,\"0\"],[65297,1,\"1\"],[65298,1,\"2\"],[65299,1,\"3\"],[65300,1,\"4\"],[65301,1,\"5\"],[65302,1,\"6\"],[65303,1,\"7\"],[65304,1,\"8\"],[65305,1,\"9\"],[65306,5,\":\"],[65307,5,\";\"],[65308,5,\"<\"],[65309,5,\"=\"],[65310,5,\">\"],[65311,5,\"?\"],[65312,5,\"@\"],[65313,1,\"a\"],[65314,1,\"b\"],[65315,1,\"c\"],[65316,1,\"d\"],[65317,1,\"e\"],[65318,1,\"f\"],[65319,1,\"g\"],[65320,1,\"h\"],[65321,1,\"i\"],[65322,1,\"j\"],[65323,1,\"k\"],[65324,1,\"l\"],[65325,1,\"m\"],[65326,1,\"n\"],[65327,1,\"o\"],[65328,1,\"p\"],[65329,1,\"q\"],[65330,1,\"r\"],[65331,1,\"s\"],[65332,1,\"t\"],[65333,1,\"u\"],[65334,1,\"v\"],[65335,1,\"w\"],[65336,1,\"x\"],[65337,1,\"y\"],[65338,1,\"z\"],[65339,5,\"[\"],[65340,5,\"\\\\\\\\\"],[65341,5,\"]\"],[65342,5,\"^\"],[65343,5,\"_\"],[65344,5,\"`\"],[65345,1,\"a\"],[65346,1,\"b\"],[65347,1,\"c\"],[65348,1,\"d\"],[65349,1,\"e\"],[65350,1,\"f\"],[65351,1,\"g\"],[65352,1,\"h\"],[65353,1,\"i\"],[65354,1,\"j\"],[65355,1,\"k\"],[65356,1,\"l\"],[65357,1,\"m\"],[65358,1,\"n\"],[65359,1,\"o\"],[65360,1,\"p\"],[65361,1,\"q\"],[65362,1,\"r\"],[65363,1,\"s\"],[65364,1,\"t\"],[65365,1,\"u\"],[65366,1,\"v\"],[65367,1,\"w\"],[65368,1,\"x\"],[65369,1,\"y\"],[65370,1,\"z\"],[65371,5,\"{\"],[65372,5,\"|\"],[65373,5,\"}\"],[65374,5,\"~\"],[65375,1,\"\"],[65376,1,\"\"],[65377,1,\".\"],[65378,1,\"\"],[65379,1,\"\"],[65380,1,\"\"],[65381,1,\"\"],[65382,1,\"\"],[65383,1,\"\"],[65384,1,\"\"],[65385,1,\"\"],[65386,1,\"\"],[65387,1,\"\"],[65388,1,\"\"],[65389,1,\"\"],[65390,1,\"\"],[65391,1,\"\"],[65392,1,\"\"],[65393,1,\"\"],[65394,1,\"\"],[65395,1,\"\"],[65396,1,\"\"],[65397,1,\"\"],[65398,1,\"\"],[65399,1,\"\"],[65400,1,\"\"],[65401,1,\"\"],[65402,1,\"\"],[65403,1,\"\"],[65404,1,\"\"],[65405,1,\"\"],[65406,1,\"\"],[65407,1,\"\"],[65408,1,\"\"],[65409,1,\"\"],[65410,1,\"\"],[65411,1,\"\"],[65412,1,\"\"],[65413,1,\"\"],[65414,1,\"\"],[65415,1,\"\"],[65416,1,\"\"],[65417,1,\"\"],[65418,1,\"\"],[65419,1,\"\"],[65420,1,\"\"],[65421,1,\"\"],[65422,1,\"\"],[65423,1,\"\"],[65424,1,\"\"],[65425,1,\"\"],[65426,1,\"\"],[65427,1,\"\"],[65428,1,\"\"],[65429,1,\"\"],[65430,1,\"\"],[65431,1,\"\"],[65432,1,\"\"],[65433,1,\"\"],[65434,1,\"\"],[65435,1,\"\"],[65436,1,\"\"],[65437,1,\"\"],[65438,1,\"\"],[65439,1,\"\"],[65440,3],[65441,1,\"\"],[65442,1,\"\"],[65443,1,\"\"],[65444,1,\"\"],[65445,1,\"\"],[65446,1,\"\"],[65447,1,\"\"],[65448,1,\"\"],[65449,1,\"\"],[65450,1,\"\"],[65451,1,\"\"],[65452,1,\"\"],[65453,1,\"\"],[65454,1,\"\"],[65455,1,\"\"],[65456,1,\"\"],[65457,1,\"\"],[65458,1,\"\"],[65459,1,\"\"],[65460,1,\"\"],[65461,1,\"\"],[65462,1,\"\"],[65463,1,\"\"],[65464,1,\"\"],[65465,1,\"\"],[65466,1,\"\"],[65467,1,\"\"],[65468,1,\"\"],[65469,1,\"\"],[65470,1,\"\"],[[65471,65473],3],[65474,1,\"\"],[65475,1,\"\"],[65476,1,\"\"],[65477,1,\"\"],[65478,1,\"\"],[65479,1,\"\"],[[65480,65481],3],[65482,1,\"\"],[65483,1,\"\"],[65484,1,\"\"],[65485,1,\"\"],[65486,1,\"\"],[65487,1,\"\"],[[65488,65489],3],[65490,1,\"\"],[65491,1,\"\"],[65492,1,\"\"],[65493,1,\"\"],[65494,1,\"\"],[65495,1,\"\"],[[65496,65497],3],[65498,1,\"\"],[65499,1,\"\"],[65500,1,\"\"],[[65501,65503],3],[65504,1,\"\"],[65505,1,\"\"],[65506,1,\"\"],[65507,5,\" \"],[65508,1,\"\"],[65509,1,\"\"],[65510,1,\"\"],[65511,3],[65512,1,\"\"],[65513,1,\"\"],[65514,1,\"\"],[65515,1,\"\"],[65516,1,\"\"],[65517,1,\"\"],[65518,1,\"\"],[[65519,65528],3],[[65529,65531],3],[65532,3],[65533,3],[[65534,65535],3],[[65536,65547],2],[65548,3],[[65549,65574],2],[65575,3],[[65576,65594],2],[65595,3],[[65596,65597],2],[65598,3],[[65599,65613],2],[[65614,65615],3],[[65616,65629],2],[[65630,65663],3],[[65664,65786],2],[[65787,65791],3],[[65792,65794],2],[[65795,65798],3],[[65799,65843],2],[[65844,65846],3],[[65847,65855],2],[[65856,65930],2],[[65931,65932],2],[[65933,65934],2],[65935,3],[[65936,65947],2],[65948,2],[[65949,65951],3],[65952,2],[[65953,65999],3],[[66000,66044],2],[66045,2],[[66046,66175],3],[[66176,66204],2],[[66205,66207],3],[[66208,66256],2],[[66257,66271],3],[66272,2],[[66273,66299],2],[[66300,66303],3],[[66304,66334],2],[66335,2],[[66336,66339],2],[[66340,66348],3],[[66349,66351],2],[[66352,66368],2],[66369,2],[[66370,66377],2],[66378,2],[[66379,66383],3],[[66384,66426],2],[[66427,66431],3],[[66432,66461],2],[66462,3],[66463,2],[[66464,66499],2],[[66500,66503],3],[[66504,66511],2],[[66512,66517],2],[[66518,66559],3],[66560,1,\"\"],[66561,1,\"\"],[66562,1,\"\"],[66563,1,\"\"],[66564,1,\"\"],[66565,1,\"\"],[66566,1,\"\"],[66567,1,\"\"],[66568,1,\"\"],[66569,1,\"\"],[66570,1,\"\"],[66571,1,\"\"],[66572,1,\"\"],[66573,1,\"\"],[66574,1,\"\"],[66575,1,\"\"],[66576,1,\"\"],[66577,1,\"\"],[66578,1,\"\"],[66579,1,\"\"],[66580,1,\"\"],[66581,1,\"\"],[66582,1,\"\"],[66583,1,\"\"],[66584,1,\"\"],[66585,1,\"\"],[66586,1,\"\"],[66587,1,\"\"],[66588,1,\"\"],[66589,1,\"\"],[66590,1,\"\"],[66591,1,\"\"],[66592,1,\"\"],[66593,1,\"\"],[66594,1,\"\"],[66595,1,\"\"],[66596,1,\"\"],[66597,1,\"\"],[66598,1,\"\"],[66599,1,\"\"],[[66600,66637],2],[[66638,66717],2],[[66718,66719],3],[[66720,66729],2],[[66730,66735],3],[66736,1,\"\"],[66737,1,\"\"],[66738,1,\"\"],[66739,1,\"\"],[66740,1,\"\"],[66741,1,\"\"],[66742,1,\"\"],[66743,1,\"\"],[66744,1,\"\"],[66745,1,\"\"],[66746,1,\"\"],[66747,1,\"\"],[66748,1,\"\"],[66749,1,\"\"],[66750,1,\"\"],[66751,1,\"\"],[66752,1,\"\"],[66753,1,\"\"],[66754,1,\"\"],[66755,1,\"\"],[66756,1,\"\"],[66757,1,\"\"],[66758,1,\"\"],[66759,1,\"\"],[66760,1,\"\"],[66761,1,\"\"],[66762,1,\"\"],[66763,1,\"\"],[66764,1,\"\"],[66765,1,\"\"],[66766,1,\"\"],[66767,1,\"\"],[66768,1,\"\"],[66769,1,\"\"],[66770,1,\"\"],[66771,1,\"\"],[[66772,66775],3],[[66776,66811],2],[[66812,66815],3],[[66816,66855],2],[[66856,66863],3],[[66864,66915],2],[[66916,66926],3],[66927,2],[66928,1,\"\"],[66929,1,\"\"],[66930,1,\"\"],[66931,1,\"\"],[66932,1,\"\"],[66933,1,\"\"],[66934,1,\"\"],[66935,1,\"\"],[66936,1,\"\"],[66937,1,\"\"],[66938,1,\"\"],[66939,3],[66940,1,\"\"],[66941,1,\"\"],[66942,1,\"\"],[66943,1,\"\"],[66944,1,\"\"],[66945,1,\"\"],[66946,1,\"\"],[66947,1,\"\"],[66948,1,\"\"],[66949,1,\"\"],[66950,1,\"\"],[66951,1,\"\"],[66952,1,\"\"],[66953,1,\"\"],[66954,1,\"\"],[66955,3],[66956,1,\"\"],[66957,1,\"\"],[66958,1,\"\"],[66959,1,\"\"],[66960,1,\"\"],[66961,1,\"\"],[66962,1,\"\"],[66963,3],[66964,1,\"\"],[66965,1,\"\"],[66966,3],[[66967,66977],2],[66978,3],[[66979,66993],2],[66994,3],[[66995,67001],2],[67002,3],[[67003,67004],2],[[67005,67071],3],[[67072,67382],2],[[67383,67391],3],[[67392,67413],2],[[67414,67423],3],[[67424,67431],2],[[67432,67455],3],[67456,2],[67457,1,\"\"],[67458,1,\"\"],[67459,1,\"\"],[67460,1,\"\"],[67461,1,\"\"],[67462,3],[67463,1,\"\"],[67464,1,\"\"],[67465,1,\"\"],[67466,1,\"\"],[67467,1,\"\"],[67468,1,\"\"],[67469,1,\"\"],[67470,1,\"\"],[67471,1,\"\"],[67472,1,\"\"],[67473,1,\"\"],[67474,1,\"\"],[67475,1,\"\"],[67476,1,\"\"],[67477,1,\"\"],[67478,1,\"\"],[67479,1,\"\"],[67480,1,\"\"],[67481,1,\"\"],[67482,1,\"\"],[67483,1,\"\"],[67484,1,\"\"],[67485,1,\"\"],[67486,1,\"\"],[67487,1,\"\"],[67488,1,\"\"],[67489,1,\"\"],[67490,1,\"\"],[67491,1,\"\"],[67492,1,\"\"],[67493,1,\"q\"],[67494,1,\"\"],[67495,1,\"\"],[67496,1,\"\"],[67497,1,\"\"],[67498,1,\"\"],[67499,1,\"\"],[67500,1,\"\"],[67501,1,\"\"],[67502,1,\"\"],[67503,1,\"\"],[67504,1,\"\"],[67505,3],[67506,1,\"\"],[67507,1,\"\"],[67508,1,\"\"],[67509,1,\"\"],[67510,1,\"\"],[67511,1,\"\"],[67512,1,\"\"],[67513,1,\"\"],[67514,1,\"\"],[[67515,67583],3],[[67584,67589],2],[[67590,67591],3],[67592,2],[67593,3],[[67594,67637],2],[67638,3],[[67639,67640],2],[[67641,67643],3],[67644,2],[[67645,67646],3],[67647,2],[[67648,67669],2],[67670,3],[[67671,67679],2],[[67680,67702],2],[[67703,67711],2],[[67712,67742],2],[[67743,67750],3],[[67751,67759],2],[[67760,67807],3],[[67808,67826],2],[67827,3],[[67828,67829],2],[[67830,67834],3],[[67835,67839],2],[[67840,67861],2],[[67862,67865],2],[[67866,67867],2],[[67868,67870],3],[67871,2],[[67872,67897],2],[[67898,67902],3],[67903,2],[[67904,67967],3],[[67968,68023],2],[[68024,68027],3],[[68028,68029],2],[[68030,68031],2],[[68032,68047],2],[[68048,68049],3],[[68050,68095],2],[[68096,68099],2],[68100,3],[[68101,68102],2],[[68103,68107],3],[[68108,68115],2],[68116,3],[[68117,68119],2],[68120,3],[[68121,68147],2],[[68148,68149],2],[[68150,68151],3],[[68152,68154],2],[[68155,68158],3],[68159,2],[[68160,68167],2],[68168,2],[[68169,68175],3],[[68176,68184],2],[[68185,68191],3],[[68192,68220],2],[[68221,68223],2],[[68224,68252],2],[[68253,68255],2],[[68256,68287],3],[[68288,68295],2],[68296,2],[[68297,68326],2],[[68327,68330],3],[[68331,68342],2],[[68343,68351],3],[[68352,68405],2],[[68406,68408],3],[[68409,68415],2],[[68416,68437],2],[[68438,68439],3],[[68440,68447],2],[[68448,68466],2],[[68467,68471],3],[[68472,68479],2],[[68480,68497],2],[[68498,68504],3],[[68505,68508],2],[[68509,68520],3],[[68521,68527],2],[[68528,68607],3],[[68608,68680],2],[[68681,68735],3],[68736,1,\"\"],[68737,1,\"\"],[68738,1,\"\"],[68739,1,\"\"],[68740,1,\"\"],[68741,1,\"\"],[68742,1,\"\"],[68743,1,\"\"],[68744,1,\"\"],[68745,1,\"\"],[68746,1,\"\"],[68747,1,\"\"],[68748,1,\"\"],[68749,1,\"\"],[68750,1,\"\"],[68751,1,\"\"],[68752,1,\"\"],[68753,1,\"\"],[68754,1,\"\"],[68755,1,\"\"],[68756,1,\"\"],[68757,1,\"\"],[68758,1,\"\"],[68759,1,\"\"],[68760,1,\"\"],[68761,1,\"\"],[68762,1,\"\"],[68763,1,\"\"],[68764,1,\"\"],[68765,1,\"\"],[68766,1,\"\"],[68767,1,\"\"],[68768,1,\"\"],[68769,1,\"\"],[68770,1,\"\"],[68771,1,\"\"],[68772,1,\"\"],[68773,1,\"\"],[68774,1,\"\"],[68775,1,\"\"],[68776,1,\"\"],[68777,1,\"\"],[68778,1,\"\"],[68779,1,\"\"],[68780,1,\"\"],[68781,1,\"\"],[68782,1,\"\"],[68783,1,\"\"],[68784,1,\"\"],[68785,1,\"\"],[68786,1,\"\"],[[68787,68799],3],[[68800,68850],2],[[68851,68857],3],[[68858,68863],2],[[68864,68903],2],[[68904,68911],3],[[68912,68921],2],[[68922,69215],3],[[69216,69246],2],[69247,3],[[69248,69289],2],[69290,3],[[69291,69292],2],[69293,2],[[69294,69295],3],[[69296,69297],2],[[69298,69372],3],[[69373,69375],2],[[69376,69404],2],[[69405,69414],2],[69415,2],[[69416,69423],3],[[69424,69456],2],[[69457,69465],2],[[69466,69487],3],[[69488,69509],2],[[69510,69513],2],[[69514,69551],3],[[69552,69572],2],[[69573,69579],2],[[69580,69599],3],[[69600,69622],2],[[69623,69631],3],[[69632,69702],2],[[69703,69709],2],[[69710,69713],3],[[69714,69733],2],[[69734,69743],2],[[69744,69749],2],[[69750,69758],3],[69759,2],[[69760,69818],2],[[69819,69820],2],[69821,3],[[69822,69825],2],[69826,2],[[69827,69836],3],[69837,3],[[69838,69839],3],[[69840,69864],2],[[69865,69871],3],[[69872,69881],2],[[69882,69887],3],[[69888,69940],2],[69941,3],[[69942,69951],2],[[69952,69955],2],[[69956,69958],2],[69959,2],[[69960,69967],3],[[69968,70003],2],[[70004,70005],2],[70006,2],[[70007,70015],3],[[70016,70084],2],[[70085,70088],2],[[70089,70092],2],[70093,2],[[70094,70095],2],[[70096,70105],2],[70106,2],[70107,2],[70108,2],[[70109,70111],2],[70112,3],[[70113,70132],2],[[70133,70143],3],[[70144,70161],2],[70162,3],[[70163,70199],2],[[70200,70205],2],[70206,2],[[70207,70209],2],[[70210,70271],3],[[70272,70278],2],[70279,3],[70280,2],[70281,3],[[70282,70285],2],[70286,3],[[70287,70301],2],[70302,3],[[70303,70312],2],[70313,2],[[70314,70319],3],[[70320,70378],2],[[70379,70383],3],[[70384,70393],2],[[70394,70399],3],[70400,2],[[70401,70403],2],[70404,3],[[70405,70412],2],[[70413,70414],3],[[70415,70416],2],[[70417,70418],3],[[70419,70440],2],[70441,3],[[70442,70448],2],[70449,3],[[70450,70451],2],[70452,3],[[70453,70457],2],[70458,3],[70459,2],[[70460,70468],2],[[70469,70470],3],[[70471,70472],2],[[70473,70474],3],[[70475,70477],2],[[70478,70479],3],[70480,2],[[70481,70486],3],[70487,2],[[70488,70492],3],[[70493,70499],2],[[70500,70501],3],[[70502,70508],2],[[70509,70511],3],[[70512,70516],2],[[70517,70655],3],[[70656,70730],2],[[70731,70735],2],[[70736,70745],2],[70746,2],[70747,2],[70748,3],[70749,2],[70750,2],[70751,2],[[70752,70753],2],[[70754,70783],3],[[70784,70853],2],[70854,2],[70855,2],[[70856,70863],3],[[70864,70873],2],[[70874,71039],3],[[71040,71093],2],[[71094,71095],3],[[71096,71104],2],[[71105,71113],2],[[71114,71127],2],[[71128,71133],2],[[71134,71167],3],[[71168,71232],2],[[71233,71235],2],[71236,2],[[71237,71247],3],[[71248,71257],2],[[71258,71263],3],[[71264,71276],2],[[71277,71295],3],[[71296,71351],2],[71352,2],[71353,2],[[71354,71359],3],[[71360,71369],2],[[71370,71423],3],[[71424,71449],2],[71450,2],[[71451,71452],3],[[71453,71467],2],[[71468,71471],3],[[71472,71481],2],[[71482,71487],2],[[71488,71494],2],[[71495,71679],3],[[71680,71738],2],[71739,2],[[71740,71839],3],[71840,1,\"\"],[71841,1,\"\"],[71842,1,\"\"],[71843,1,\"\"],[71844,1,\"\"],[71845,1,\"\"],[71846,1,\"\"],[71847,1,\"\"],[71848,1,\"\"],[71849,1,\"\"],[71850,1,\"\"],[71851,1,\"\"],[71852,1,\"\"],[71853,1,\"\"],[71854,1,\"\"],[71855,1,\"\"],[71856,1,\"\"],[71857,1,\"\"],[71858,1,\"\"],[71859,1,\"\"],[71860,1,\"\"],[71861,1,\"\"],[71862,1,\"\"],[71863,1,\"\"],[71864,1,\"\"],[71865,1,\"\"],[71866,1,\"\"],[71867,1,\"\"],[71868,1,\"\"],[71869,1,\"\"],[71870,1,\"\"],[71871,1,\"\"],[[71872,71913],2],[[71914,71922],2],[[71923,71934],3],[71935,2],[[71936,71942],2],[[71943,71944],3],[71945,2],[[71946,71947],3],[[71948,71955],2],[71956,3],[[71957,71958],2],[71959,3],[[71960,71989],2],[71990,3],[[71991,71992],2],[[71993,71994],3],[[71995,72003],2],[[72004,72006],2],[[72007,72015],3],[[72016,72025],2],[[72026,72095],3],[[72096,72103],2],[[72104,72105],3],[[72106,72151],2],[[72152,72153],3],[[72154,72161],2],[72162,2],[[72163,72164],2],[[72165,72191],3],[[72192,72254],2],[[72255,72262],2],[72263,2],[[72264,72271],3],[[72272,72323],2],[[72324,72325],2],[[72326,72345],2],[[72346,72348],2],[72349,2],[[72350,72354],2],[[72355,72367],3],[[72368,72383],2],[[72384,72440],2],[[72441,72447],3],[[72448,72457],2],[[72458,72703],3],[[72704,72712],2],[72713,3],[[72714,72758],2],[72759,3],[[72760,72768],2],[[72769,72773],2],[[72774,72783],3],[[72784,72793],2],[[72794,72812],2],[[72813,72815],3],[[72816,72817],2],[[72818,72847],2],[[72848,72849],3],[[72850,72871],2],[72872,3],[[72873,72886],2],[[72887,72959],3],[[72960,72966],2],[72967,3],[[72968,72969],2],[72970,3],[[72971,73014],2],[[73015,73017],3],[73018,2],[73019,3],[[73020,73021],2],[73022,3],[[73023,73031],2],[[73032,73039],3],[[73040,73049],2],[[73050,73055],3],[[73056,73061],2],[73062,3],[[73063,73064],2],[73065,3],[[73066,73102],2],[73103,3],[[73104,73105],2],[73106,3],[[73107,73112],2],[[73113,73119],3],[[73120,73129],2],[[73130,73439],3],[[73440,73462],2],[[73463,73464],2],[[73465,73471],3],[[73472,73488],2],[73489,3],[[73490,73530],2],[[73531,73533],3],[[73534,73538],2],[[73539,73551],2],[[73552,73561],2],[[73562,73647],3],[73648,2],[[73649,73663],3],[[73664,73713],2],[[73714,73726],3],[73727,2],[[73728,74606],2],[[74607,74648],2],[74649,2],[[74650,74751],3],[[74752,74850],2],[[74851,74862],2],[74863,3],[[74864,74867],2],[74868,2],[[74869,74879],3],[[74880,75075],2],[[75076,77711],3],[[77712,77808],2],[[77809,77810],2],[[77811,77823],3],[[77824,78894],2],[78895,2],[[78896,78904],3],[[78905,78911],3],[[78912,78933],2],[[78934,82943],3],[[82944,83526],2],[[83527,92159],3],[[92160,92728],2],[[92729,92735],3],[[92736,92766],2],[92767,3],[[92768,92777],2],[[92778,92781],3],[[92782,92783],2],[[92784,92862],2],[92863,3],[[92864,92873],2],[[92874,92879],3],[[92880,92909],2],[[92910,92911],3],[[92912,92916],2],[92917,2],[[92918,92927],3],[[92928,92982],2],[[92983,92991],2],[[92992,92995],2],[[92996,92997],2],[[92998,93007],3],[[93008,93017],2],[93018,3],[[93019,93025],2],[93026,3],[[93027,93047],2],[[93048,93052],3],[[93053,93071],2],[[93072,93759],3],[93760,1,\"\"],[93761,1,\"\"],[93762,1,\"\"],[93763,1,\"\"],[93764,1,\"\"],[93765,1,\"\"],[93766,1,\"\"],[93767,1,\"\"],[93768,1,\"\"],[93769,1,\"\"],[93770,1,\"\"],[93771,1,\"\"],[93772,1,\"\"],[93773,1,\"\"],[93774,1,\"\"],[93775,1,\"\"],[93776,1,\"\"],[93777,1,\"\"],[93778,1,\"\"],[93779,1,\"\"],[93780,1,\"\"],[93781,1,\"\"],[93782,1,\"\"],[93783,1,\"\"],[93784,1,\"\"],[93785,1,\"\"],[93786,1,\"\"],[93787,1,\"\"],[93788,1,\"\"],[93789,1,\"\"],[93790,1,\"\"],[93791,1,\"\"],[[93792,93823],2],[[93824,93850],2],[[93851,93951],3],[[93952,94020],2],[[94021,94026],2],[[94027,94030],3],[94031,2],[[94032,94078],2],[[94079,94087],2],[[94088,94094],3],[[94095,94111],2],[[94112,94175],3],[94176,2],[94177,2],[94178,2],[94179,2],[94180,2],[[94181,94191],3],[[94192,94193],2],[[94194,94207],3],[[94208,100332],2],[[100333,100337],2],[[100338,100343],2],[[100344,100351],3],[[100352,101106],2],[[101107,101589],2],[[101590,101631],3],[[101632,101640],2],[[101641,110575],3],[[110576,110579],2],[110580,3],[[110581,110587],2],[110588,3],[[110589,110590],2],[110591,3],[[110592,110593],2],[[110594,110878],2],[[110879,110882],2],[[110883,110897],3],[110898,2],[[110899,110927],3],[[110928,110930],2],[[110931,110932],3],[110933,2],[[110934,110947],3],[[110948,110951],2],[[110952,110959],3],[[110960,111355],2],[[111356,113663],3],[[113664,113770],2],[[113771,113775],3],[[113776,113788],2],[[113789,113791],3],[[113792,113800],2],[[113801,113807],3],[[113808,113817],2],[[113818,113819],3],[113820,2],[[113821,113822],2],[113823,2],[[113824,113827],7],[[113828,118527],3],[[118528,118573],2],[[118574,118575],3],[[118576,118598],2],[[118599,118607],3],[[118608,118723],2],[[118724,118783],3],[[118784,119029],2],[[119030,119039],3],[[119040,119078],2],[[119079,119080],3],[119081,2],[[119082,119133],2],[119134,1,\"\"],[119135,1,\"\"],[119136,1,\"\"],[119137,1,\"\"],[119138,1,\"\"],[119139,1,\"\"],[119140,1,\"\"],[[119141,119154],2],[[119155,119162],3],[[119163,119226],2],[119227,1,\"\"],[119228,1,\"\"],[119229,1,\"\"],[119230,1,\"\"],[119231,1,\"\"],[119232,1,\"\"],[[119233,119261],2],[[119262,119272],2],[[119273,119274],2],[[119275,119295],3],[[119296,119365],2],[[119366,119487],3],[[119488,119507],2],[[119508,119519],3],[[119520,119539],2],[[119540,119551],3],[[119552,119638],2],[[119639,119647],3],[[119648,119665],2],[[119666,119672],2],[[119673,119807],3],[119808,1,\"a\"],[119809,1,\"b\"],[119810,1,\"c\"],[119811,1,\"d\"],[119812,1,\"e\"],[119813,1,\"f\"],[119814,1,\"g\"],[119815,1,\"h\"],[119816,1,\"i\"],[119817,1,\"j\"],[119818,1,\"k\"],[119819,1,\"l\"],[119820,1,\"m\"],[119821,1,\"n\"],[119822,1,\"o\"],[119823,1,\"p\"],[119824,1,\"q\"],[119825,1,\"r\"],[119826,1,\"s\"],[119827,1,\"t\"],[119828,1,\"u\"],[119829,1,\"v\"],[119830,1,\"w\"],[119831,1,\"x\"],[119832,1,\"y\"],[119833,1,\"z\"],[119834,1,\"a\"],[119835,1,\"b\"],[119836,1,\"c\"],[119837,1,\"d\"],[119838,1,\"e\"],[119839,1,\"f\"],[119840,1,\"g\"],[119841,1,\"h\"],[119842,1,\"i\"],[119843,1,\"j\"],[119844,1,\"k\"],[119845,1,\"l\"],[119846,1,\"m\"],[119847,1,\"n\"],[119848,1,\"o\"],[119849,1,\"p\"],[119850,1,\"q\"],[119851,1,\"r\"],[119852,1,\"s\"],[119853,1,\"t\"],[119854,1,\"u\"],[119855,1,\"v\"],[119856,1,\"w\"],[119857,1,\"x\"],[119858,1,\"y\"],[119859,1,\"z\"],[119860,1,\"a\"],[119861,1,\"b\"],[119862,1,\"c\"],[119863,1,\"d\"],[119864,1,\"e\"],[119865,1,\"f\"],[119866,1,\"g\"],[119867,1,\"h\"],[119868,1,\"i\"],[119869,1,\"j\"],[119870,1,\"k\"],[119871,1,\"l\"],[119872,1,\"m\"],[119873,1,\"n\"],[119874,1,\"o\"],[119875,1,\"p\"],[119876,1,\"q\"],[119877,1,\"r\"],[119878,1,\"s\"],[119879,1,\"t\"],[119880,1,\"u\"],[119881,1,\"v\"],[119882,1,\"w\"],[119883,1,\"x\"],[119884,1,\"y\"],[119885,1,\"z\"],[119886,1,\"a\"],[119887,1,\"b\"],[119888,1,\"c\"],[119889,1,\"d\"],[119890,1,\"e\"],[119891,1,\"f\"],[119892,1,\"g\"],[119893,3],[119894,1,\"i\"],[119895,1,\"j\"],[119896,1,\"k\"],[119897,1,\"l\"],[119898,1,\"m\"],[119899,1,\"n\"],[119900,1,\"o\"],[119901,1,\"p\"],[119902,1,\"q\"],[119903,1,\"r\"],[119904,1,\"s\"],[119905,1,\"t\"],[119906,1,\"u\"],[119907,1,\"v\"],[119908,1,\"w\"],[119909,1,\"x\"],[119910,1,\"y\"],[119911,1,\"z\"],[119912,1,\"a\"],[119913,1,\"b\"],[119914,1,\"c\"],[119915,1,\"d\"],[119916,1,\"e\"],[119917,1,\"f\"],[119918,1,\"g\"],[119919,1,\"h\"],[119920,1,\"i\"],[119921,1,\"j\"],[119922,1,\"k\"],[119923,1,\"l\"],[119924,1,\"m\"],[119925,1,\"n\"],[119926,1,\"o\"],[119927,1,\"p\"],[119928,1,\"q\"],[119929,1,\"r\"],[119930,1,\"s\"],[119931,1,\"t\"],[119932,1,\"u\"],[119933,1,\"v\"],[119934,1,\"w\"],[119935,1,\"x\"],[119936,1,\"y\"],[119937,1,\"z\"],[119938,1,\"a\"],[119939,1,\"b\"],[119940,1,\"c\"],[119941,1,\"d\"],[119942,1,\"e\"],[119943,1,\"f\"],[119944,1,\"g\"],[119945,1,\"h\"],[119946,1,\"i\"],[119947,1,\"j\"],[119948,1,\"k\"],[119949,1,\"l\"],[119950,1,\"m\"],[119951,1,\"n\"],[119952,1,\"o\"],[119953,1,\"p\"],[119954,1,\"q\"],[119955,1,\"r\"],[119956,1,\"s\"],[119957,1,\"t\"],[119958,1,\"u\"],[119959,1,\"v\"],[119960,1,\"w\"],[119961,1,\"x\"],[119962,1,\"y\"],[119963,1,\"z\"],[119964,1,\"a\"],[119965,3],[119966,1,\"c\"],[119967,1,\"d\"],[[119968,119969],3],[119970,1,\"g\"],[[119971,119972],3],[119973,1,\"j\"],[119974,1,\"k\"],[[119975,119976],3],[119977,1,\"n\"],[119978,1,\"o\"],[119979,1,\"p\"],[119980,1,\"q\"],[119981,3],[119982,1,\"s\"],[119983,1,\"t\"],[119984,1,\"u\"],[119985,1,\"v\"],[119986,1,\"w\"],[119987,1,\"x\"],[119988,1,\"y\"],[119989,1,\"z\"],[119990,1,\"a\"],[119991,1,\"b\"],[119992,1,\"c\"],[119993,1,\"d\"],[119994,3],[119995,1,\"f\"],[119996,3],[119997,1,\"h\"],[119998,1,\"i\"],[119999,1,\"j\"],[120000,1,\"k\"],[120001,1,\"l\"],[120002,1,\"m\"],[120003,1,\"n\"],[120004,3],[120005,1,\"p\"],[120006,1,\"q\"],[120007,1,\"r\"],[120008,1,\"s\"],[120009,1,\"t\"],[120010,1,\"u\"],[120011,1,\"v\"],[120012,1,\"w\"],[120013,1,\"x\"],[120014,1,\"y\"],[120015,1,\"z\"],[120016,1,\"a\"],[120017,1,\"b\"],[120018,1,\"c\"],[120019,1,\"d\"],[120020,1,\"e\"],[120021,1,\"f\"],[120022,1,\"g\"],[120023,1,\"h\"],[120024,1,\"i\"],[120025,1,\"j\"],[120026,1,\"k\"],[120027,1,\"l\"],[120028,1,\"m\"],[120029,1,\"n\"],[120030,1,\"o\"],[120031,1,\"p\"],[120032,1,\"q\"],[120033,1,\"r\"],[120034,1,\"s\"],[120035,1,\"t\"],[120036,1,\"u\"],[120037,1,\"v\"],[120038,1,\"w\"],[120039,1,\"x\"],[120040,1,\"y\"],[120041,1,\"z\"],[120042,1,\"a\"],[120043,1,\"b\"],[120044,1,\"c\"],[120045,1,\"d\"],[120046,1,\"e\"],[120047,1,\"f\"],[120048,1,\"g\"],[120049,1,\"h\"],[120050,1,\"i\"],[120051,1,\"j\"],[120052,1,\"k\"],[120053,1,\"l\"],[120054,1,\"m\"],[120055,1,\"n\"],[120056,1,\"o\"],[120057,1,\"p\"],[120058,1,\"q\"],[120059,1,\"r\"],[120060,1,\"s\"],[120061,1,\"t\"],[120062,1,\"u\"],[120063,1,\"v\"],[120064,1,\"w\"],[120065,1,\"x\"],[120066,1,\"y\"],[120067,1,\"z\"],[120068,1,\"a\"],[120069,1,\"b\"],[120070,3],[120071,1,\"d\"],[120072,1,\"e\"],[120073,1,\"f\"],[120074,1,\"g\"],[[120075,120076],3],[120077,1,\"j\"],[120078,1,\"k\"],[120079,1,\"l\"],[120080,1,\"m\"],[120081,1,\"n\"],[120082,1,\"o\"],[120083,1,\"p\"],[120084,1,\"q\"],[120085,3],[120086,1,\"s\"],[120087,1,\"t\"],[120088,1,\"u\"],[120089,1,\"v\"],[120090,1,\"w\"],[120091,1,\"x\"],[120092,1,\"y\"],[120093,3],[120094,1,\"a\"],[120095,1,\"b\"],[120096,1,\"c\"],[120097,1,\"d\"],[120098,1,\"e\"],[120099,1,\"f\"],[120100,1,\"g\"],[120101,1,\"h\"],[120102,1,\"i\"],[120103,1,\"j\"],[120104,1,\"k\"],[120105,1,\"l\"],[120106,1,\"m\"],[120107,1,\"n\"],[120108,1,\"o\"],[120109,1,\"p\"],[120110,1,\"q\"],[120111,1,\"r\"],[120112,1,\"s\"],[120113,1,\"t\"],[120114,1,\"u\"],[120115,1,\"v\"],[120116,1,\"w\"],[120117,1,\"x\"],[120118,1,\"y\"],[120119,1,\"z\"],[120120,1,\"a\"],[120121,1,\"b\"],[120122,3],[120123,1,\"d\"],[120124,1,\"e\"],[120125,1,\"f\"],[120126,1,\"g\"],[120127,3],[120128,1,\"i\"],[120129,1,\"j\"],[120130,1,\"k\"],[120131,1,\"l\"],[120132,1,\"m\"],[120133,3],[120134,1,\"o\"],[[120135,120137],3],[120138,1,\"s\"],[120139,1,\"t\"],[120140,1,\"u\"],[120141,1,\"v\"],[120142,1,\"w\"],[120143,1,\"x\"],[120144,1,\"y\"],[120145,3],[120146,1,\"a\"],[120147,1,\"b\"],[120148,1,\"c\"],[120149,1,\"d\"],[120150,1,\"e\"],[120151,1,\"f\"],[120152,1,\"g\"],[120153,1,\"h\"],[120154,1,\"i\"],[120155,1,\"j\"],[120156,1,\"k\"],[120157,1,\"l\"],[120158,1,\"m\"],[120159,1,\"n\"],[120160,1,\"o\"],[120161,1,\"p\"],[120162,1,\"q\"],[120163,1,\"r\"],[120164,1,\"s\"],[120165,1,\"t\"],[120166,1,\"u\"],[120167,1,\"v\"],[120168,1,\"w\"],[120169,1,\"x\"],[120170,1,\"y\"],[120171,1,\"z\"],[120172,1,\"a\"],[120173,1,\"b\"],[120174,1,\"c\"],[120175,1,\"d\"],[120176,1,\"e\"],[120177,1,\"f\"],[120178,1,\"g\"],[120179,1,\"h\"],[120180,1,\"i\"],[120181,1,\"j\"],[120182,1,\"k\"],[120183,1,\"l\"],[120184,1,\"m\"],[120185,1,\"n\"],[120186,1,\"o\"],[120187,1,\"p\"],[120188,1,\"q\"],[120189,1,\"r\"],[120190,1,\"s\"],[120191,1,\"t\"],[120192,1,\"u\"],[120193,1,\"v\"],[120194,1,\"w\"],[120195,1,\"x\"],[120196,1,\"y\"],[120197,1,\"z\"],[120198,1,\"a\"],[120199,1,\"b\"],[120200,1,\"c\"],[120201,1,\"d\"],[120202,1,\"e\"],[120203,1,\"f\"],[120204,1,\"g\"],[120205,1,\"h\"],[120206,1,\"i\"],[120207,1,\"j\"],[120208,1,\"k\"],[120209,1,\"l\"],[120210,1,\"m\"],[120211,1,\"n\"],[120212,1,\"o\"],[120213,1,\"p\"],[120214,1,\"q\"],[120215,1,\"r\"],[120216,1,\"s\"],[120217,1,\"t\"],[120218,1,\"u\"],[120219,1,\"v\"],[120220,1,\"w\"],[120221,1,\"x\"],[120222,1,\"y\"],[120223,1,\"z\"],[120224,1,\"a\"],[120225,1,\"b\"],[120226,1,\"c\"],[120227,1,\"d\"],[120228,1,\"e\"],[120229,1,\"f\"],[120230,1,\"g\"],[120231,1,\"h\"],[120232,1,\"i\"],[120233,1,\"j\"],[120234,1,\"k\"],[120235,1,\"l\"],[120236,1,\"m\"],[120237,1,\"n\"],[120238,1,\"o\"],[120239,1,\"p\"],[120240,1,\"q\"],[120241,1,\"r\"],[120242,1,\"s\"],[120243,1,\"t\"],[120244,1,\"u\"],[120245,1,\"v\"],[120246,1,\"w\"],[120247,1,\"x\"],[120248,1,\"y\"],[120249,1,\"z\"],[120250,1,\"a\"],[120251,1,\"b\"],[120252,1,\"c\"],[120253,1,\"d\"],[120254,1,\"e\"],[120255,1,\"f\"],[120256,1,\"g\"],[120257,1,\"h\"],[120258,1,\"i\"],[120259,1,\"j\"],[120260,1,\"k\"],[120261,1,\"l\"],[120262,1,\"m\"],[120263,1,\"n\"],[120264,1,\"o\"],[120265,1,\"p\"],[120266,1,\"q\"],[120267,1,\"r\"],[120268,1,\"s\"],[120269,1,\"t\"],[120270,1,\"u\"],[120271,1,\"v\"],[120272,1,\"w\"],[120273,1,\"x\"],[120274,1,\"y\"],[120275,1,\"z\"],[120276,1,\"a\"],[120277,1,\"b\"],[120278,1,\"c\"],[120279,1,\"d\"],[120280,1,\"e\"],[120281,1,\"f\"],[120282,1,\"g\"],[120283,1,\"h\"],[120284,1,\"i\"],[120285,1,\"j\"],[120286,1,\"k\"],[120287,1,\"l\"],[120288,1,\"m\"],[120289,1,\"n\"],[120290,1,\"o\"],[120291,1,\"p\"],[120292,1,\"q\"],[120293,1,\"r\"],[120294,1,\"s\"],[120295,1,\"t\"],[120296,1,\"u\"],[120297,1,\"v\"],[120298,1,\"w\"],[120299,1,\"x\"],[120300,1,\"y\"],[120301,1,\"z\"],[120302,1,\"a\"],[120303,1,\"b\"],[120304,1,\"c\"],[120305,1,\"d\"],[120306,1,\"e\"],[120307,1,\"f\"],[120308,1,\"g\"],[120309,1,\"h\"],[120310,1,\"i\"],[120311,1,\"j\"],[120312,1,\"k\"],[120313,1,\"l\"],[120314,1,\"m\"],[120315,1,\"n\"],[120316,1,\"o\"],[120317,1,\"p\"],[120318,1,\"q\"],[120319,1,\"r\"],[120320,1,\"s\"],[120321,1,\"t\"],[120322,1,\"u\"],[120323,1,\"v\"],[120324,1,\"w\"],[120325,1,\"x\"],[120326,1,\"y\"],[120327,1,\"z\"],[120328,1,\"a\"],[120329,1,\"b\"],[120330,1,\"c\"],[120331,1,\"d\"],[120332,1,\"e\"],[120333,1,\"f\"],[120334,1,\"g\"],[120335,1,\"h\"],[120336,1,\"i\"],[120337,1,\"j\"],[120338,1,\"k\"],[120339,1,\"l\"],[120340,1,\"m\"],[120341,1,\"n\"],[120342,1,\"o\"],[120343,1,\"p\"],[120344,1,\"q\"],[120345,1,\"r\"],[120346,1,\"s\"],[120347,1,\"t\"],[120348,1,\"u\"],[120349,1,\"v\"],[120350,1,\"w\"],[120351,1,\"x\"],[120352,1,\"y\"],[120353,1,\"z\"],[120354,1,\"a\"],[120355,1,\"b\"],[120356,1,\"c\"],[120357,1,\"d\"],[120358,1,\"e\"],[120359,1,\"f\"],[120360,1,\"g\"],[120361,1,\"h\"],[120362,1,\"i\"],[120363,1,\"j\"],[120364,1,\"k\"],[120365,1,\"l\"],[120366,1,\"m\"],[120367,1,\"n\"],[120368,1,\"o\"],[120369,1,\"p\"],[120370,1,\"q\"],[120371,1,\"r\"],[120372,1,\"s\"],[120373,1,\"t\"],[120374,1,\"u\"],[120375,1,\"v\"],[120376,1,\"w\"],[120377,1,\"x\"],[120378,1,\"y\"],[120379,1,\"z\"],[120380,1,\"a\"],[120381,1,\"b\"],[120382,1,\"c\"],[120383,1,\"d\"],[120384,1,\"e\"],[120385,1,\"f\"],[120386,1,\"g\"],[120387,1,\"h\"],[120388,1,\"i\"],[120389,1,\"j\"],[120390,1,\"k\"],[120391,1,\"l\"],[120392,1,\"m\"],[120393,1,\"n\"],[120394,1,\"o\"],[120395,1,\"p\"],[120396,1,\"q\"],[120397,1,\"r\"],[120398,1,\"s\"],[120399,1,\"t\"],[120400,1,\"u\"],[120401,1,\"v\"],[120402,1,\"w\"],[120403,1,\"x\"],[120404,1,\"y\"],[120405,1,\"z\"],[120406,1,\"a\"],[120407,1,\"b\"],[120408,1,\"c\"],[120409,1,\"d\"],[120410,1,\"e\"],[120411,1,\"f\"],[120412,1,\"g\"],[120413,1,\"h\"],[120414,1,\"i\"],[120415,1,\"j\"],[120416,1,\"k\"],[120417,1,\"l\"],[120418,1,\"m\"],[120419,1,\"n\"],[120420,1,\"o\"],[120421,1,\"p\"],[120422,1,\"q\"],[120423,1,\"r\"],[120424,1,\"s\"],[120425,1,\"t\"],[120426,1,\"u\"],[120427,1,\"v\"],[120428,1,\"w\"],[120429,1,\"x\"],[120430,1,\"y\"],[120431,1,\"z\"],[120432,1,\"a\"],[120433,1,\"b\"],[120434,1,\"c\"],[120435,1,\"d\"],[120436,1,\"e\"],[120437,1,\"f\"],[120438,1,\"g\"],[120439,1,\"h\"],[120440,1,\"i\"],[120441,1,\"j\"],[120442,1,\"k\"],[120443,1,\"l\"],[120444,1,\"m\"],[120445,1,\"n\"],[120446,1,\"o\"],[120447,1,\"p\"],[120448,1,\"q\"],[120449,1,\"r\"],[120450,1,\"s\"],[120451,1,\"t\"],[120452,1,\"u\"],[120453,1,\"v\"],[120454,1,\"w\"],[120455,1,\"x\"],[120456,1,\"y\"],[120457,1,\"z\"],[120458,1,\"a\"],[120459,1,\"b\"],[120460,1,\"c\"],[120461,1,\"d\"],[120462,1,\"e\"],[120463,1,\"f\"],[120464,1,\"g\"],[120465,1,\"h\"],[120466,1,\"i\"],[120467,1,\"j\"],[120468,1,\"k\"],[120469,1,\"l\"],[120470,1,\"m\"],[120471,1,\"n\"],[120472,1,\"o\"],[120473,1,\"p\"],[120474,1,\"q\"],[120475,1,\"r\"],[120476,1,\"s\"],[120477,1,\"t\"],[120478,1,\"u\"],[120479,1,\"v\"],[120480,1,\"w\"],[120481,1,\"x\"],[120482,1,\"y\"],[120483,1,\"z\"],[120484,1,\"\"],[120485,1,\"\"],[[120486,120487],3],[120488,1,\"\"],[120489,1,\"\"],[120490,1,\"\"],[120491,1,\"\"],[120492,1,\"\"],[120493,1,\"\"],[120494,1,\"\"],[120495,1,\"\"],[120496,1,\"\"],[120497,1,\"\"],[120498,1,\"\"],[120499,1,\"\"],[120500,1,\"\"],[120501,1,\"\"],[120502,1,\"\"],[120503,1,\"\"],[120504,1,\"\"],[120505,1,\"\"],[120506,1,\"\"],[120507,1,\"\"],[120508,1,\"\"],[120509,1,\"\"],[120510,1,\"\"],[120511,1,\"\"],[120512,1,\"\"],[120513,1,\"\"],[120514,1,\"\"],[120515,1,\"\"],[120516,1,\"\"],[120517,1,\"\"],[120518,1,\"\"],[120519,1,\"\"],[120520,1,\"\"],[120521,1,\"\"],[120522,1,\"\"],[120523,1,\"\"],[120524,1,\"\"],[120525,1,\"\"],[120526,1,\"\"],[120527,1,\"\"],[120528,1,\"\"],[120529,1,\"\"],[120530,1,\"\"],[[120531,120532],1,\"\"],[120533,1,\"\"],[120534,1,\"\"],[120535,1,\"\"],[120536,1,\"\"],[120537,1,\"\"],[120538,1,\"\"],[120539,1,\"\"],[120540,1,\"\"],[120541,1,\"\"],[120542,1,\"\"],[120543,1,\"\"],[120544,1,\"\"],[120545,1,\"\"],[120546,1,\"\"],[120547,1,\"\"],[120548,1,\"\"],[120549,1,\"\"],[120550,1,\"\"],[120551,1,\"\"],[120552,1,\"\"],[120553,1,\"\"],[120554,1,\"\"],[120555,1,\"\"],[120556,1,\"\"],[120557,1,\"\"],[120558,1,\"\"],[120559,1,\"\"],[120560,1,\"\"],[120561,1,\"\"],[120562,1,\"\"],[120563,1,\"\"],[120564,1,\"\"],[120565,1,\"\"],[120566,1,\"\"],[120567,1,\"\"],[120568,1,\"\"],[120569,1,\"\"],[120570,1,\"\"],[120571,1,\"\"],[120572,1,\"\"],[120573,1,\"\"],[120574,1,\"\"],[120575,1,\"\"],[120576,1,\"\"],[120577,1,\"\"],[120578,1,\"\"],[120579,1,\"\"],[120580,1,\"\"],[120581,1,\"\"],[120582,1,\"\"],[120583,1,\"\"],[120584,1,\"\"],[120585,1,\"\"],[120586,1,\"\"],[120587,1,\"\"],[120588,1,\"\"],[[120589,120590],1,\"\"],[120591,1,\"\"],[120592,1,\"\"],[120593,1,\"\"],[120594,1,\"\"],[120595,1,\"\"],[120596,1,\"\"],[120597,1,\"\"],[120598,1,\"\"],[120599,1,\"\"],[120600,1,\"\"],[120601,1,\"\"],[120602,1,\"\"],[120603,1,\"\"],[120604,1,\"\"],[120605,1,\"\"],[120606,1,\"\"],[120607,1,\"\"],[120608,1,\"\"],[120609,1,\"\"],[120610,1,\"\"],[120611,1,\"\"],[120612,1,\"\"],[120613,1,\"\"],[120614,1,\"\"],[120615,1,\"\"],[120616,1,\"\"],[120617,1,\"\"],[120618,1,\"\"],[120619,1,\"\"],[120620,1,\"\"],[120621,1,\"\"],[120622,1,\"\"],[120623,1,\"\"],[120624,1,\"\"],[120625,1,\"\"],[120626,1,\"\"],[120627,1,\"\"],[120628,1,\"\"],[120629,1,\"\"],[120630,1,\"\"],[120631,1,\"\"],[120632,1,\"\"],[120633,1,\"\"],[120634,1,\"\"],[120635,1,\"\"],[120636,1,\"\"],[120637,1,\"\"],[120638,1,\"\"],[120639,1,\"\"],[120640,1,\"\"],[120641,1,\"\"],[120642,1,\"\"],[120643,1,\"\"],[120644,1,\"\"],[120645,1,\"\"],[120646,1,\"\"],[[120647,120648],1,\"\"],[120649,1,\"\"],[120650,1,\"\"],[120651,1,\"\"],[120652,1,\"\"],[120653,1,\"\"],[120654,1,\"\"],[120655,1,\"\"],[120656,1,\"\"],[120657,1,\"\"],[120658,1,\"\"],[120659,1,\"\"],[120660,1,\"\"],[120661,1,\"\"],[120662,1,\"\"],[120663,1,\"\"],[120664,1,\"\"],[120665,1,\"\"],[120666,1,\"\"],[120667,1,\"\"],[120668,1,\"\"],[120669,1,\"\"],[120670,1,\"\"],[120671,1,\"\"],[120672,1,\"\"],[120673,1,\"\"],[120674,1,\"\"],[120675,1,\"\"],[120676,1,\"\"],[120677,1,\"\"],[120678,1,\"\"],[120679,1,\"\"],[120680,1,\"\"],[120681,1,\"\"],[120682,1,\"\"],[120683,1,\"\"],[120684,1,\"\"],[120685,1,\"\"],[120686,1,\"\"],[120687,1,\"\"],[120688,1,\"\"],[120689,1,\"\"],[120690,1,\"\"],[120691,1,\"\"],[120692,1,\"\"],[120693,1,\"\"],[120694,1,\"\"],[120695,1,\"\"],[120696,1,\"\"],[120697,1,\"\"],[120698,1,\"\"],[120699,1,\"\"],[120700,1,\"\"],[120701,1,\"\"],[120702,1,\"\"],[120703,1,\"\"],[120704,1,\"\"],[[120705,120706],1,\"\"],[120707,1,\"\"],[120708,1,\"\"],[120709,1,\"\"],[120710,1,\"\"],[120711,1,\"\"],[120712,1,\"\"],[120713,1,\"\"],[120714,1,\"\"],[120715,1,\"\"],[120716,1,\"\"],[120717,1,\"\"],[120718,1,\"\"],[120719,1,\"\"],[120720,1,\"\"],[120721,1,\"\"],[120722,1,\"\"],[120723,1,\"\"],[120724,1,\"\"],[120725,1,\"\"],[120726,1,\"\"],[120727,1,\"\"],[120728,1,\"\"],[120729,1,\"\"],[120730,1,\"\"],[120731,1,\"\"],[120732,1,\"\"],[120733,1,\"\"],[120734,1,\"\"],[120735,1,\"\"],[120736,1,\"\"],[120737,1,\"\"],[120738,1,\"\"],[120739,1,\"\"],[120740,1,\"\"],[120741,1,\"\"],[120742,1,\"\"],[120743,1,\"\"],[120744,1,\"\"],[120745,1,\"\"],[120746,1,\"\"],[120747,1,\"\"],[120748,1,\"\"],[120749,1,\"\"],[120750,1,\"\"],[120751,1,\"\"],[120752,1,\"\"],[120753,1,\"\"],[120754,1,\"\"],[120755,1,\"\"],[120756,1,\"\"],[120757,1,\"\"],[120758,1,\"\"],[120759,1,\"\"],[120760,1,\"\"],[120761,1,\"\"],[120762,1,\"\"],[[120763,120764],1,\"\"],[120765,1,\"\"],[120766,1,\"\"],[120767,1,\"\"],[120768,1,\"\"],[120769,1,\"\"],[120770,1,\"\"],[120771,1,\"\"],[120772,1,\"\"],[120773,1,\"\"],[120774,1,\"\"],[120775,1,\"\"],[120776,1,\"\"],[120777,1,\"\"],[[120778,120779],1,\"\"],[[120780,120781],3],[120782,1,\"0\"],[120783,1,\"1\"],[120784,1,\"2\"],[120785,1,\"3\"],[120786,1,\"4\"],[120787,1,\"5\"],[120788,1,\"6\"],[120789,1,\"7\"],[120790,1,\"8\"],[120791,1,\"9\"],[120792,1,\"0\"],[120793,1,\"1\"],[120794,1,\"2\"],[120795,1,\"3\"],[120796,1,\"4\"],[120797,1,\"5\"],[120798,1,\"6\"],[120799,1,\"7\"],[120800,1,\"8\"],[120801,1,\"9\"],[120802,1,\"0\"],[120803,1,\"1\"],[120804,1,\"2\"],[120805,1,\"3\"],[120806,1,\"4\"],[120807,1,\"5\"],[120808,1,\"6\"],[120809,1,\"7\"],[120810,1,\"8\"],[120811,1,\"9\"],[120812,1,\"0\"],[120813,1,\"1\"],[120814,1,\"2\"],[120815,1,\"3\"],[120816,1,\"4\"],[120817,1,\"5\"],[120818,1,\"6\"],[120819,1,\"7\"],[120820,1,\"8\"],[120821,1,\"9\"],[120822,1,\"0\"],[120823,1,\"1\"],[120824,1,\"2\"],[120825,1,\"3\"],[120826,1,\"4\"],[120827,1,\"5\"],[120828,1,\"6\"],[120829,1,\"7\"],[120830,1,\"8\"],[120831,1,\"9\"],[[120832,121343],2],[[121344,121398],2],[[121399,121402],2],[[121403,121452],2],[[121453,121460],2],[121461,2],[[121462,121475],2],[121476,2],[[121477,121483],2],[[121484,121498],3],[[121499,121503],2],[121504,3],[[121505,121519],2],[[121520,122623],3],[[122624,122654],2],[[122655,122660],3],[[122661,122666],2],[[122667,122879],3],[[122880,122886],2],[122887,3],[[122888,122904],2],[[122905,122906],3],[[122907,122913],2],[122914,3],[[122915,122916],2],[122917,3],[[122918,122922],2],[[122923,122927],3],[122928,1,\"\"],[122929,1,\"\"],[122930,1,\"\"],[122931,1,\"\"],[122932,1,\"\"],[122933,1,\"\"],[122934,1,\"\"],[122935,1,\"\"],[122936,1,\"\"],[122937,1,\"\"],[122938,1,\"\"],[122939,1,\"\"],[122940,1,\"\"],[122941,1,\"\"],[122942,1,\"\"],[122943,1,\"\"],[122944,1,\"\"],[122945,1,\"\"],[122946,1,\"\"],[122947,1,\"\"],[122948,1,\"\"],[122949,1,\"\"],[122950,1,\"\"],[122951,1,\"\"],[122952,1,\"\"],[122953,1,\"\"],[122954,1,\"\"],[122955,1,\"\"],[122956,1,\"\"],[122957,1,\"\"],[122958,1,\"\"],[122959,1,\"\"],[122960,1,\"\"],[122961,1,\"\"],[122962,1,\"\"],[122963,1,\"\"],[122964,1,\"\"],[122965,1,\"\"],[122966,1,\"\"],[122967,1,\"\"],[122968,1,\"\"],[122969,1,\"\"],[122970,1,\"\"],[122971,1,\"\"],[122972,1,\"\"],[122973,1,\"\"],[122974,1,\"\"],[122975,1,\"\"],[122976,1,\"\"],[122977,1,\"\"],[122978,1,\"\"],[122979,1,\"\"],[122980,1,\"\"],[122981,1,\"\"],[122982,1,\"\"],[122983,1,\"\"],[122984,1,\"\"],[122985,1,\"\"],[122986,1,\"\"],[122987,1,\"\"],[122988,1,\"\"],[122989,1,\"\"],[[122990,123022],3],[123023,2],[[123024,123135],3],[[123136,123180],2],[[123181,123183],3],[[123184,123197],2],[[123198,123199],3],[[123200,123209],2],[[123210,123213],3],[123214,2],[123215,2],[[123216,123535],3],[[123536,123566],2],[[123567,123583],3],[[123584,123641],2],[[123642,123646],3],[123647,2],[[123648,124111],3],[[124112,124153],2],[[124154,124895],3],[[124896,124902],2],[124903,3],[[124904,124907],2],[124908,3],[[124909,124910],2],[124911,3],[[124912,124926],2],[124927,3],[[124928,125124],2],[[125125,125126],3],[[125127,125135],2],[[125136,125142],2],[[125143,125183],3],[125184,1,\"\"],[125185,1,\"\"],[125186,1,\"\"],[125187,1,\"\"],[125188,1,\"\"],[125189,1,\"\"],[125190,1,\"\"],[125191,1,\"\"],[125192,1,\"\"],[125193,1,\"\"],[125194,1,\"\"],[125195,1,\"\"],[125196,1,\"\"],[125197,1,\"\"],[125198,1,\"\"],[125199,1,\"\"],[125200,1,\"\"],[125201,1,\"\"],[125202,1,\"\"],[125203,1,\"\"],[125204,1,\"\"],[125205,1,\"\"],[125206,1,\"\"],[125207,1,\"\"],[125208,1,\"\"],[125209,1,\"\"],[125210,1,\"\"],[125211,1,\"\"],[125212,1,\"\"],[125213,1,\"\"],[125214,1,\"\"],[125215,1,\"\"],[125216,1,\"\"],[125217,1,\"\"],[[125218,125258],2],[125259,2],[[125260,125263],3],[[125264,125273],2],[[125274,125277],3],[[125278,125279],2],[[125280,126064],3],[[126065,126132],2],[[126133,126208],3],[[126209,126269],2],[[126270,126463],3],[126464,1,\"\"],[126465,1,\"\"],[126466,1,\"\"],[126467,1,\"\"],[126468,3],[126469,1,\"\"],[126470,1,\"\"],[126471,1,\"\"],[126472,1,\"\"],[126473,1,\"\"],[126474,1,\"\"],[126475,1,\"\"],[126476,1,\"\"],[126477,1,\"\"],[126478,1,\"\"],[126479,1,\"\"],[126480,1,\"\"],[126481,1,\"\"],[126482,1,\"\"],[126483,1,\"\"],[126484,1,\"\"],[126485,1,\"\"],[126486,1,\"\"],[126487,1,\"\"],[126488,1,\"\"],[126489,1,\"\"],[126490,1,\"\"],[126491,1,\"\"],[126492,1,\"\"],[126493,1,\"\"],[126494,1,\"\"],[126495,1,\"\"],[126496,3],[126497,1,\"\"],[126498,1,\"\"],[126499,3],[126500,1,\"\"],[[126501,126502],3],[126503,1,\"\"],[126504,3],[126505,1,\"\"],[126506,1,\"\"],[126507,1,\"\"],[126508,1,\"\"],[126509,1,\"\"],[126510,1,\"\"],[126511,1,\"\"],[126512,1,\"\"],[126513,1,\"\"],[126514,1,\"\"],[126515,3],[126516,1,\"\"],[126517,1,\"\"],[126518,1,\"\"],[126519,1,\"\"],[126520,3],[126521,1,\"\"],[126522,3],[126523,1,\"\"],[[126524,126529],3],[126530,1,\"\"],[[126531,126534],3],[126535,1,\"\"],[126536,3],[126537,1,\"\"],[126538,3],[126539,1,\"\"],[126540,3],[126541,1,\"\"],[126542,1,\"\"],[126543,1,\"\"],[126544,3],[126545,1,\"\"],[126546,1,\"\"],[126547,3],[126548,1,\"\"],[[126549,126550],3],[126551,1,\"\"],[126552,3],[126553,1,\"\"],[126554,3],[126555,1,\"\"],[126556,3],[126557,1,\"\"],[126558,3],[126559,1,\"\"],[126560,3],[126561,1,\"\"],[126562,1,\"\"],[126563,3],[126564,1,\"\"],[[126565,126566],3],[126567,1,\"\"],[126568,1,\"\"],[126569,1,\"\"],[126570,1,\"\"],[126571,3],[126572,1,\"\"],[126573,1,\"\"],[126574,1,\"\"],[126575,1,\"\"],[126576,1,\"\"],[126577,1,\"\"],[126578,1,\"\"],[126579,3],[126580,1,\"\"],[126581,1,\"\"],[126582,1,\"\"],[126583,1,\"\"],[126584,3],[126585,1,\"\"],[126586,1,\"\"],[126587,1,\"\"],[126588,1,\"\"],[126589,3],[126590,1,\"\"],[126591,3],[126592,1,\"\"],[126593,1,\"\"],[126594,1,\"\"],[126595,1,\"\"],[126596,1,\"\"],[126597,1,\"\"],[126598,1,\"\"],[126599,1,\"\"],[126600,1,\"\"],[126601,1,\"\"],[126602,3],[126603,1,\"\"],[126604,1,\"\"],[126605,1,\"\"],[126606,1,\"\"],[126607,1,\"\"],[126608,1,\"\"],[126609,1,\"\"],[126610,1,\"\"],[126611,1,\"\"],[126612,1,\"\"],[126613,1,\"\"],[126614,1,\"\"],[126615,1,\"\"],[126616,1,\"\"],[126617,1,\"\"],[126618,1,\"\"],[126619,1,\"\"],[[126620,126624],3],[126625,1,\"\"],[126626,1,\"\"],[126627,1,\"\"],[126628,3],[126629,1,\"\"],[126630,1,\"\"],[126631,1,\"\"],[126632,1,\"\"],[126633,1,\"\"],[126634,3],[126635,1,\"\"],[126636,1,\"\"],[126637,1,\"\"],[126638,1,\"\"],[126639,1,\"\"],[126640,1,\"\"],[126641,1,\"\"],[126642,1,\"\"],[126643,1,\"\"],[126644,1,\"\"],[126645,1,\"\"],[126646,1,\"\"],[126647,1,\"\"],[126648,1,\"\"],[126649,1,\"\"],[126650,1,\"\"],[126651,1,\"\"],[[126652,126703],3],[[126704,126705],2],[[126706,126975],3],[[126976,127019],2],[[127020,127023],3],[[127024,127123],2],[[127124,127135],3],[[127136,127150],2],[[127151,127152],3],[[127153,127166],2],[127167,2],[127168,3],[[127169,127183],2],[127184,3],[[127185,127199],2],[[127200,127221],2],[[127222,127231],3],[127232,3],[127233,5,\"0,\"],[127234,5,\"1,\"],[127235,5,\"2,\"],[127236,5,\"3,\"],[127237,5,\"4,\"],[127238,5,\"5,\"],[127239,5,\"6,\"],[127240,5,\"7,\"],[127241,5,\"8,\"],[127242,5,\"9,\"],[[127243,127244],2],[[127245,127247],2],[127248,5,\"(a)\"],[127249,5,\"(b)\"],[127250,5,\"(c)\"],[127251,5,\"(d)\"],[127252,5,\"(e)\"],[127253,5,\"(f)\"],[127254,5,\"(g)\"],[127255,5,\"(h)\"],[127256,5,\"(i)\"],[127257,5,\"(j)\"],[127258,5,\"(k)\"],[127259,5,\"(l)\"],[127260,5,\"(m)\"],[127261,5,\"(n)\"],[127262,5,\"(o)\"],[127263,5,\"(p)\"],[127264,5,\"(q)\"],[127265,5,\"(r)\"],[127266,5,\"(s)\"],[127267,5,\"(t)\"],[127268,5,\"(u)\"],[127269,5,\"(v)\"],[127270,5,\"(w)\"],[127271,5,\"(x)\"],[127272,5,\"(y)\"],[127273,5,\"(z)\"],[127274,1,\"s\"],[127275,1,\"c\"],[127276,1,\"r\"],[127277,1,\"cd\"],[127278,1,\"wz\"],[127279,2],[127280,1,\"a\"],[127281,1,\"b\"],[127282,1,\"c\"],[127283,1,\"d\"],[127284,1,\"e\"],[127285,1,\"f\"],[127286,1,\"g\"],[127287,1,\"h\"],[127288,1,\"i\"],[127289,1,\"j\"],[127290,1,\"k\"],[127291,1,\"l\"],[127292,1,\"m\"],[127293,1,\"n\"],[127294,1,\"o\"],[127295,1,\"p\"],[127296,1,\"q\"],[127297,1,\"r\"],[127298,1,\"s\"],[127299,1,\"t\"],[127300,1,\"u\"],[127301,1,\"v\"],[127302,1,\"w\"],[127303,1,\"x\"],[127304,1,\"y\"],[127305,1,\"z\"],[127306,1,\"hv\"],[127307,1,\"mv\"],[127308,1,\"sd\"],[127309,1,\"ss\"],[127310,1,\"ppv\"],[127311,1,\"wc\"],[[127312,127318],2],[127319,2],[[127320,127326],2],[127327,2],[[127328,127337],2],[127338,1,\"mc\"],[127339,1,\"md\"],[127340,1,\"mr\"],[[127341,127343],2],[[127344,127352],2],[127353,2],[127354,2],[[127355,127356],2],[[127357,127358],2],[127359,2],[[127360,127369],2],[[127370,127373],2],[[127374,127375],2],[127376,1,\"dj\"],[[127377,127386],2],[[127387,127404],2],[127405,2],[[127406,127461],3],[[127462,127487],2],[127488,1,\"\"],[127489,1,\"\"],[127490,1,\"\"],[[127491,127503],3],[127504,1,\"\"],[127505,1,\"\"],[127506,1,\"\"],[127507,1,\"\"],[127508,1,\"\"],[127509,1,\"\"],[127510,1,\"\"],[127511,1,\"\"],[127512,1,\"\"],[127513,1,\"\"],[127514,1,\"\"],[127515,1,\"\"],[127516,1,\"\"],[127517,1,\"\"],[127518,1,\"\"],[127519,1,\"\"],[127520,1,\"\"],[127521,1,\"\"],[127522,1,\"\"],[127523,1,\"\"],[127524,1,\"\"],[127525,1,\"\"],[127526,1,\"\"],[127527,1,\"\"],[127528,1,\"\"],[127529,1,\"\"],[127530,1,\"\"],[127531,1,\"\"],[127532,1,\"\"],[127533,1,\"\"],[127534,1,\"\"],[127535,1,\"\"],[127536,1,\"\"],[127537,1,\"\"],[127538,1,\"\"],[127539,1,\"\"],[127540,1,\"\"],[127541,1,\"\"],[127542,1,\"\"],[127543,1,\"\"],[127544,1,\"\"],[127545,1,\"\"],[127546,1,\"\"],[127547,1,\"\"],[[127548,127551],3],[127552,1,\"\"],[127553,1,\"\"],[127554,1,\"\"],[127555,1,\"\"],[127556,1,\"\"],[127557,1,\"\"],[127558,1,\"\"],[127559,1,\"\"],[127560,1,\"\"],[[127561,127567],3],[127568,1,\"\"],[127569,1,\"\"],[[127570,127583],3],[[127584,127589],2],[[127590,127743],3],[[127744,127776],2],[[127777,127788],2],[[127789,127791],2],[[127792,127797],2],[127798,2],[[127799,127868],2],[127869,2],[[127870,127871],2],[[127872,127891],2],[[127892,127903],2],[[127904,127940],2],[127941,2],[[127942,127946],2],[[127947,127950],2],[[127951,127955],2],[[127956,127967],2],[[127968,127984],2],[[127985,127991],2],[[127992,127999],2],[[128000,128062],2],[128063,2],[128064,2],[128065,2],[[128066,128247],2],[128248,2],[[128249,128252],2],[[128253,128254],2],[128255,2],[[128256,128317],2],[[128318,128319],2],[[128320,128323],2],[[128324,128330],2],[[128331,128335],2],[[128336,128359],2],[[128360,128377],2],[128378,2],[[128379,128419],2],[128420,2],[[128421,128506],2],[[128507,128511],2],[128512,2],[[128513,128528],2],[128529,2],[[128530,128532],2],[128533,2],[128534,2],[128535,2],[128536,2],[128537,2],[128538,2],[128539,2],[[128540,128542],2],[128543,2],[[128544,128549],2],[[128550,128551],2],[[128552,128555],2],[128556,2],[128557,2],[[128558,128559],2],[[128560,128563],2],[128564,2],[[128565,128576],2],[[128577,128578],2],[[128579,128580],2],[[128581,128591],2],[[128592,128639],2],[[128640,128709],2],[[128710,128719],2],[128720,2],[[128721,128722],2],[[128723,128724],2],[128725,2],[[128726,128727],2],[[128728,128731],3],[128732,2],[[128733,128735],2],[[128736,128748],2],[[128749,128751],3],[[128752,128755],2],[[128756,128758],2],[[128759,128760],2],[128761,2],[128762,2],[[128763,128764],2],[[128765,128767],3],[[128768,128883],2],[[128884,128886],2],[[128887,128890],3],[[128891,128895],2],[[128896,128980],2],[[128981,128984],2],[128985,2],[[128986,128991],3],[[128992,129003],2],[[129004,129007],3],[129008,2],[[129009,129023],3],[[129024,129035],2],[[129036,129039],3],[[129040,129095],2],[[129096,129103],3],[[129104,129113],2],[[129114,129119],3],[[129120,129159],2],[[129160,129167],3],[[129168,129197],2],[[129198,129199],3],[[129200,129201],2],[[129202,129279],3],[[129280,129291],2],[129292,2],[[129293,129295],2],[[129296,129304],2],[[129305,129310],2],[129311,2],[[129312,129319],2],[[129320,129327],2],[129328,2],[[129329,129330],2],[[129331,129342],2],[129343,2],[[129344,129355],2],[129356,2],[[129357,129359],2],[[129360,129374],2],[[129375,129387],2],[[129388,129392],2],[129393,2],[129394,2],[[129395,129398],2],[[129399,129400],2],[129401,2],[129402,2],[129403,2],[[129404,129407],2],[[129408,129412],2],[[129413,129425],2],[[129426,129431],2],[[129432,129442],2],[[129443,129444],2],[[129445,129450],2],[[129451,129453],2],[[129454,129455],2],[[129456,129465],2],[[129466,129471],2],[129472,2],[[129473,129474],2],[[129475,129482],2],[129483,2],[129484,2],[[129485,129487],2],[[129488,129510],2],[[129511,129535],2],[[129536,129619],2],[[129620,129631],3],[[129632,129645],2],[[129646,129647],3],[[129648,129651],2],[129652,2],[[129653,129655],2],[[129656,129658],2],[[129659,129660],2],[[129661,129663],3],[[129664,129666],2],[[129667,129670],2],[[129671,129672],2],[[129673,129679],3],[[129680,129685],2],[[129686,129704],2],[[129705,129708],2],[[129709,129711],2],[[129712,129718],2],[[129719,129722],2],[[129723,129725],2],[129726,3],[129727,2],[[129728,129730],2],[[129731,129733],2],[[129734,129741],3],[[129742,129743],2],[[129744,129750],2],[[129751,129753],2],[[129754,129755],2],[[129756,129759],3],[[129760,129767],2],[129768,2],[[129769,129775],3],[[129776,129782],2],[[129783,129784],2],[[129785,129791],3],[[129792,129938],2],[129939,3],[[129940,129994],2],[[129995,130031],3],[130032,1,\"0\"],[130033,1,\"1\"],[130034,1,\"2\"],[130035,1,\"3\"],[130036,1,\"4\"],[130037,1,\"5\"],[130038,1,\"6\"],[130039,1,\"7\"],[130040,1,\"8\"],[130041,1,\"9\"],[[130042,131069],3],[[131070,131071],3],[[131072,173782],2],[[173783,173789],2],[[173790,173791],2],[[173792,173823],3],[[173824,177972],2],[[177973,177976],2],[177977,2],[[177978,177983],3],[[177984,178205],2],[[178206,178207],3],[[178208,183969],2],[[183970,183983],3],[[183984,191456],2],[[191457,194559],3],[194560,1,\"\"],[194561,1,\"\"],[194562,1,\"\"],[194563,1,\"\"],[194564,1,\"\"],[194565,1,\"\"],[194566,1,\"\"],[194567,1,\"\"],[194568,1,\"\"],[194569,1,\"\"],[194570,1,\"\"],[194571,1,\"\"],[194572,1,\"\"],[194573,1,\"\"],[194574,1,\"\"],[194575,1,\"\"],[194576,1,\"\"],[194577,1,\"\"],[194578,1,\"\"],[194579,1,\"\"],[194580,1,\"\"],[194581,1,\"\"],[194582,1,\"\"],[194583,1,\"\"],[194584,1,\"\"],[194585,1,\"\"],[194586,1,\"\"],[194587,1,\"\"],[194588,1,\"\"],[194589,1,\"\"],[194590,1,\"\"],[194591,1,\"\"],[194592,1,\"\"],[194593,1,\"\"],[194594,1,\"\"],[194595,1,\"\"],[194596,1,\"\"],[194597,1,\"\"],[194598,1,\"\"],[194599,1,\"\"],[194600,1,\"\"],[194601,1,\"\"],[194602,1,\"\"],[194603,1,\"\"],[194604,1,\"\"],[194605,1,\"\"],[194606,1,\"\"],[194607,1,\"\"],[194608,1,\"\"],[[194609,194611],1,\"\"],[194612,1,\"\"],[194613,1,\"\"],[194614,1,\"\"],[194615,1,\"\"],[194616,1,\"\"],[194617,1,\"\"],[194618,1,\"\"],[194619,1,\"\"],[194620,1,\"\"],[194621,1,\"\"],[194622,1,\"\"],[194623,1,\"\"],[194624,1,\"\"],[194625,1,\"\"],[194626,1,\"\"],[194627,1,\"\"],[194628,1,\"\"],[[194629,194630],1,\"\"],[194631,1,\"\"],[194632,1,\"\"],[194633,1,\"\"],[194634,1,\"\"],[194635,1,\"\"],[194636,1,\"\"],[194637,1,\"\"],[194638,1,\"\"],[194639,1,\"\"],[194640,1,\"\"],[194641,1,\"\"],[194642,1,\"\"],[194643,1,\"\"],[194644,1,\"\"],[194645,1,\"\"],[194646,1,\"\"],[194647,1,\"\"],[194648,1,\"\"],[194649,1,\"\"],[194650,1,\"\"],[194651,1,\"\"],[194652,1,\"\"],[194653,1,\"\"],[194654,1,\"\"],[194655,1,\"\"],[194656,1,\"\"],[194657,1,\"\"],[194658,1,\"\"],[194659,1,\"\"],[194660,1,\"\"],[194661,1,\"\"],[194662,1,\"\"],[194663,1,\"\"],[194664,3],[194665,1,\"\"],[[194666,194667],1,\"\"],[194668,1,\"\"],[194669,1,\"\"],[194670,1,\"\"],[194671,1,\"\"],[194672,1,\"\"],[194673,1,\"\"],[194674,1,\"\"],[194675,1,\"\"],[194676,3],[194677,1,\"\"],[194678,1,\"\"],[194679,1,\"\"],[194680,1,\"\"],[194681,1,\"\"],[194682,1,\"\"],[194683,1,\"\"],[194684,1,\"\"],[194685,1,\"\"],[194686,1,\"\"],[194687,1,\"\"],[194688,1,\"\"],[194689,1,\"\"],[194690,1,\"\"],[194691,1,\"\"],[194692,1,\"\"],[194693,1,\"\"],[194694,1,\"\"],[194695,1,\"\"],[194696,1,\"\"],[194697,1,\"\"],[194698,1,\"\"],[194699,1,\"\"],[194700,1,\"\"],[194701,1,\"\"],[194702,1,\"\"],[194703,1,\"\"],[194704,1,\"\"],[[194705,194706],1,\"\"],[194707,1,\"\"],[[194708,194709],1,\"\"],[194710,1,\"\"],[194711,1,\"\"],[194712,1,\"\"],[194713,1,\"\"],[194714,1,\"\"],[194715,1,\"\"],[194716,1,\"\"],[194717,1,\"\"],[194718,1,\"\"],[194719,1,\"\"],[194720,1,\"\"],[194721,1,\"\"],[194722,1,\"\"],[194723,1,\"\"],[194724,1,\"\"],[194725,1,\"\"],[194726,1,\"\"],[194727,1,\"\"],[194728,1,\"\"],[194729,1,\"\"],[194730,1,\"\"],[194731,1,\"\"],[194732,1,\"\"],[194733,1,\"\"],[194734,1,\"\"],[194735,1,\"\"],[194736,1,\"\"],[194737,1,\"\"],[194738,1,\"\"],[194739,1,\"\"],[194740,1,\"\"],[194741,1,\"\"],[194742,1,\"\"],[194743,1,\"\"],[194744,1,\"\"],[194745,1,\"\"],[194746,1,\"\"],[194747,1,\"\"],[194748,1,\"\"],[194749,1,\"\"],[194750,1,\"\"],[194751,1,\"\"],[194752,1,\"\"],[194753,1,\"\"],[194754,1,\"\"],[194755,1,\"\"],[194756,1,\"\"],[194757,1,\"\"],[194758,1,\"\"],[194759,1,\"\"],[194760,1,\"\"],[194761,1,\"\"],[194762,1,\"\"],[194763,1,\"\"],[194764,1,\"\"],[194765,1,\"\"],[194766,1,\"\"],[194767,1,\"\"],[194768,1,\"\"],[194769,1,\"\"],[194770,1,\"\"],[194771,1,\"\"],[194772,1,\"\"],[194773,1,\"\"],[194774,1,\"\"],[194775,1,\"\"],[194776,1,\"\"],[194777,1,\"\"],[194778,1,\"\"],[194779,1,\"\"],[194780,1,\"\"],[194781,1,\"\"],[194782,1,\"\"],[194783,1,\"\"],[194784,1,\"\"],[194785,1,\"\"],[194786,1,\"\"],[194787,1,\"\"],[194788,1,\"\"],[194789,1,\"\"],[194790,1,\"\"],[194791,1,\"\"],[194792,1,\"\"],[194793,1,\"\"],[194794,1,\"\"],[194795,1,\"\"],[194796,1,\"\"],[194797,1,\"\"],[194798,1,\"\"],[194799,1,\"\"],[194800,1,\"\"],[194801,1,\"\"],[194802,1,\"\"],[194803,1,\"\"],[194804,1,\"\"],[194805,1,\"\"],[194806,1,\"\"],[194807,1,\"\"],[194808,1,\"\"],[194809,1,\"\"],[194810,1,\"\"],[194811,1,\"\"],[194812,1,\"\"],[194813,1,\"\"],[194814,1,\"\"],[194815,1,\"\"],[194816,1,\"\"],[194817,1,\"\"],[194818,1,\"\"],[194819,1,\"\"],[194820,1,\"\"],[194821,1,\"\"],[194822,1,\"\"],[194823,1,\"\"],[194824,1,\"\"],[194825,1,\"\"],[194826,1,\"\"],[194827,1,\"\"],[194828,1,\"\"],[194829,1,\"\"],[194830,1,\"\"],[194831,1,\"\"],[194832,1,\"\"],[194833,1,\"\"],[194834,1,\"\"],[194835,1,\"\"],[194836,1,\"\"],[194837,1,\"\"],[194838,1,\"\"],[194839,1,\"\"],[194840,1,\"\"],[194841,1,\"\"],[194842,1,\"\"],[194843,1,\"\"],[194844,1,\"\"],[194845,1,\"\"],[194846,1,\"\"],[194847,3],[194848,1,\"\"],[194849,1,\"\"],[194850,1,\"\"],[194851,1,\"\"],[194852,1,\"\"],[194853,1,\"\"],[194854,1,\"\"],[194855,1,\"\"],[194856,1,\"\"],[194857,1,\"\"],[194858,1,\"\"],[194859,1,\"\"],[[194860,194861],1,\"\"],[194862,1,\"\"],[194863,1,\"\"],[194864,1,\"\"],[194865,1,\"\"],[194866,1,\"\"],[194867,1,\"\"],[194868,1,\"\"],[194869,1,\"\"],[194870,1,\"\"],[194871,1,\"\"],[194872,1,\"\"],[194873,1,\"\"],[194874,1,\"\"],[194875,1,\"\"],[194876,1,\"\"],[194877,1,\"\"],[194878,1,\"\"],[194879,1,\"\"],[194880,1,\"\"],[194881,1,\"\"],[194882,1,\"\"],[194883,1,\"\"],[194884,1,\"\"],[194885,1,\"\"],[[194886,194887],1,\"\"],[194888,1,\"\"],[194889,1,\"\"],[194890,1,\"\"],[194891,1,\"\"],[194892,1,\"\"],[194893,1,\"\"],[194894,1,\"\"],[194895,1,\"\"],[194896,1,\"\"],[194897,1,\"\"],[194898,1,\"\"],[194899,1,\"\"],[194900,1,\"\"],[194901,1,\"\"],[194902,1,\"\"],[194903,1,\"\"],[194904,1,\"\"],[194905,1,\"\"],[194906,1,\"\"],[194907,1,\"\"],[194908,1,\"\"],[[194909,194910],1,\"\"],[194911,3],[194912,1,\"\"],[194913,1,\"\"],[194914,1,\"\"],[194915,1,\"\"],[194916,1,\"\"],[194917,1,\"\"],[194918,1,\"\"],[194919,1,\"\"],[194920,1,\"\"],[194921,1,\"\"],[194922,1,\"\"],[194923,1,\"\"],[194924,1,\"\"],[194925,1,\"\"],[194926,1,\"\"],[194927,1,\"\"],[194928,1,\"\"],[194929,1,\"\"],[194930,1,\"\"],[194931,1,\"\"],[194932,1,\"\"],[194933,1,\"\"],[194934,1,\"\"],[194935,1,\"\"],[194936,1,\"\"],[194937,1,\"\"],[194938,1,\"\"],[194939,1,\"\"],[194940,1,\"\"],[194941,1,\"\"],[194942,1,\"\"],[194943,1,\"\"],[194944,1,\"\"],[194945,1,\"\"],[194946,1,\"\"],[194947,1,\"\"],[194948,1,\"\"],[194949,1,\"\"],[194950,1,\"\"],[194951,1,\"\"],[194952,1,\"\"],[194953,1,\"\"],[194954,1,\"\"],[194955,1,\"\"],[194956,1,\"\"],[194957,1,\"\"],[194958,1,\"\"],[194959,1,\"\"],[194960,1,\"\"],[194961,1,\"\"],[194962,1,\"\"],[194963,1,\"\"],[194964,1,\"\"],[194965,1,\"\"],[194966,1,\"\"],[194967,1,\"\"],[194968,1,\"\"],[194969,1,\"\"],[194970,1,\"\"],[194971,1,\"\"],[194972,1,\"\"],[194973,1,\"\"],[194974,1,\"\"],[194975,1,\"\"],[194976,1,\"\"],[194977,1,\"\"],[194978,1,\"\"],[194979,1,\"\"],[194980,1,\"\"],[194981,1,\"\"],[194982,1,\"\"],[194983,1,\"\"],[194984,1,\"\"],[194985,1,\"\"],[194986,1,\"\"],[194987,1,\"\"],[194988,1,\"\"],[194989,1,\"\"],[194990,1,\"\"],[194991,1,\"\"],[194992,1,\"\"],[194993,1,\"\"],[194994,1,\"\"],[194995,1,\"\"],[194996,1,\"\"],[194997,1,\"\"],[194998,1,\"\"],[194999,1,\"\"],[195000,1,\"\"],[195001,1,\"\"],[195002,1,\"\"],[195003,1,\"\"],[195004,1,\"\"],[195005,1,\"\"],[195006,1,\"\"],[195007,3],[195008,1,\"\"],[195009,1,\"\"],[195010,1,\"\"],[195011,1,\"\"],[195012,1,\"\"],[195013,1,\"\"],[195014,1,\"\"],[195015,1,\"\"],[195016,1,\"\"],[195017,1,\"\"],[195018,1,\"\"],[195019,1,\"\"],[195020,1,\"\"],[195021,1,\"\"],[195022,1,\"\"],[195023,1,\"\"],[195024,1,\"\"],[195025,1,\"\"],[195026,1,\"\"],[195027,1,\"\"],[195028,1,\"\"],[195029,1,\"\"],[195030,1,\"\"],[195031,1,\"\"],[195032,1,\"\"],[195033,1,\"\"],[195034,1,\"\"],[195035,1,\"\"],[195036,1,\"\"],[195037,1,\"\"],[195038,1,\"\"],[195039,1,\"\"],[195040,1,\"\"],[195041,1,\"\"],[195042,1,\"\"],[195043,1,\"\"],[195044,1,\"\"],[195045,1,\"\"],[195046,1,\"\"],[195047,1,\"\"],[195048,1,\"\"],[195049,1,\"\"],[195050,1,\"\"],[195051,1,\"\"],[195052,1,\"\"],[195053,1,\"\"],[195054,1,\"\"],[195055,1,\"\"],[195056,1,\"\"],[195057,1,\"\"],[195058,1,\"\"],[195059,1,\"\"],[195060,1,\"\"],[195061,1,\"\"],[195062,1,\"\"],[195063,1,\"\"],[195064,1,\"\"],[195065,1,\"\"],[195066,1,\"\"],[195067,1,\"\"],[195068,1,\"\"],[195069,1,\"\"],[[195070,195071],1,\"\"],[195072,1,\"\"],[195073,1,\"\"],[195074,1,\"\"],[195075,1,\"\"],[195076,1,\"\"],[195077,1,\"\"],[195078,1,\"\"],[195079,1,\"\"],[195080,1,\"\"],[195081,1,\"\"],[195082,1,\"\"],[195083,1,\"\"],[195084,1,\"\"],[195085,1,\"\"],[195086,1,\"\"],[195087,1,\"\"],[195088,1,\"\"],[195089,1,\"\"],[195090,1,\"\"],[195091,1,\"\"],[195092,1,\"\"],[195093,1,\"\"],[195094,1,\"\"],[195095,1,\"\"],[195096,1,\"\"],[195097,1,\"\"],[195098,1,\"\"],[195099,1,\"\"],[195100,1,\"\"],[195101,1,\"\"],[[195102,196605],3],[[196606,196607],3],[[196608,201546],2],[[201547,201551],3],[[201552,205743],2],[[205744,262141],3],[[262142,262143],3],[[262144,327677],3],[[327678,327679],3],[[327680,393213],3],[[393214,393215],3],[[393216,458749],3],[[458750,458751],3],[[458752,524285],3],[[524286,524287],3],[[524288,589821],3],[[589822,589823],3],[[589824,655357],3],[[655358,655359],3],[[655360,720893],3],[[720894,720895],3],[[720896,786429],3],[[786430,786431],3],[[786432,851965],3],[[851966,851967],3],[[851968,917501],3],[[917502,917503],3],[917504,3],[917505,3],[[917506,917535],3],[[917536,917631],3],[[917632,917759],3],[[917760,917999],7],[[918000,983037],3],[[983038,983039],3],[[983040,1048573],3],[[1048574,1048575],3],[[1048576,1114109],3],[[1114110,1114111],3]]');\n\n//# sourceURL=webpack://oracle2/./node_modules/tr46/lib/mappingTable.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;